{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of NN Energy Predictor.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yovelop/NN/blob/master/NN_Energy_Predictor_0.2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zO1azhvf_t9_",
        "colab_type": "code",
        "outputId": "c0b85e32-8fbe-45c4-db19-e26da0fefb3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "DIR = '/content/drive/My Drive/Colab Notebooks/ENSaver/'\n",
        "#drive.flush_and_unmount()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRgT9oDx_vpi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Импорты\n",
        "  import numpy as np # linear algebra\n",
        "  import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "  import gc\n",
        "\n",
        "  import matplotlib.pyplot as plt\n",
        "  import matplotlib.style\n",
        "  matplotlib.style.use('ggplot')\n",
        "\n",
        "  from sys import getsizeof\n",
        "\n",
        "  import os\n",
        "  for dirname, _, filenames in os.walk(DIR):\n",
        "      for filename in filenames:\n",
        "          print(os.path.join(dirname, filename))\n",
        "\n",
        "  pd.options.mode.chained_assignment = None  # default='warn'\n",
        "  import warnings\n",
        "  pd.set_option('display.max_rows', 500)\n",
        "  pd.set_option('display.max_columns', 500)\n",
        "  pd.set_option('display.width', 100)\n",
        "  warnings.filterwarnings('ignore')\n",
        "  np.set_printoptions (precision = 4, suppress  = True)\n",
        "\n",
        "  def reduce_mem_usage(df):\n",
        "      start_mem_usg = df.memory_usage().sum() / 1024**2 \n",
        "      print(\"Memory usage of properties dataframe is :\",start_mem_usg,\" MB\")\n",
        "      NAlist = [] # Keeps track of columns that have missing values filled in. \n",
        "      for col in df.columns:\n",
        "          if (df[col].dtype != object) &  (df[col].dtype != 'datetime64[ns]'):  # Exclude strings            \n",
        "              # Print current column type\n",
        "              print(\"******************************\")\n",
        "              print(\"Column: \",col)\n",
        "              print(\"dtype before: \",df[col].dtype)            \n",
        "              # make variables for Int, max and min\n",
        "              IsInt = False\n",
        "              mx = df[col].max()\n",
        "              mn = df[col].min()\n",
        "              print(\"min for this col: \",mn)\n",
        "              print(\"max for this col: \",mx)\n",
        "              # Integer does not support NA, therefore, NA needs to be filled\n",
        "              if not np.isfinite(df[col]).all(): \n",
        "                  NAlist.append(col)\n",
        "                  df[col].fillna(mn-1,inplace=True)  \n",
        "                    \n",
        "              # test if column can be converted to an integer\n",
        "              asint = df[col].fillna(0).astype(np.int64)\n",
        "              result = (df[col] - asint)\n",
        "              result = result.sum()\n",
        "              if result > -0.01 and result < 0.01:\n",
        "                  IsInt = True            \n",
        "              # Make Integer/unsigned Integer datatypes\n",
        "              if IsInt:\n",
        "                  if mn >= 0:\n",
        "                      if mx < 255:\n",
        "                          df[col] = df[col].astype(np.uint8)\n",
        "                      elif mx < 65535:\n",
        "                          df[col] = df[col].astype(np.uint16)\n",
        "                      elif mx < 4294967295:\n",
        "                          df[col] = df[col].astype(np.uint32)\n",
        "                      else:\n",
        "                          df[col] = df[col].astype(np.uint64)\n",
        "                  else:\n",
        "                      if mn > np.iinfo(np.int8).min and mx < np.iinfo(np.int8).max:\n",
        "                          df[col] = df[col].astype(np.int8)\n",
        "                      elif mn > np.iinfo(np.int16).min and mx < np.iinfo(np.int16).max:\n",
        "                          df[col] = df[col].astype(np.int16)\n",
        "                      elif mn > np.iinfo(np.int32).min and mx < np.iinfo(np.int32).max:\n",
        "                          df[col] = df[col].astype(np.int32)\n",
        "                      elif mn > np.iinfo(np.int64).min and mx < np.iinfo(np.int64).max:\n",
        "                          df[col] = df[col].astype(np.int64)    \n",
        "              # Make float datatypes 32 bit\n",
        "              else:\n",
        "                  df[col] = df[col].astype(np.float32)\n",
        "              \n",
        "              # Print new column type\n",
        "              print(\"dtype after: \",df[col].dtype)\n",
        "              print(\"******************************\")\n",
        "      # Print final result\n",
        "      print(\"___MEMORY USAGE AFTER COMPLETION:___\")\n",
        "      mem_usg = df.memory_usage().sum() / 1024**2 \n",
        "      print(\"Memory usage is: \",mem_usg,\" MB\")\n",
        "      print(\"This is \",100*mem_usg/start_mem_usg,\"% of the initial size\")\n",
        "      return df, NAlist\n",
        "\n",
        "  def show_plot(hist):\n",
        "    plt.plot(hist.history['loss'])\n",
        "    plt.plot(hist.history['val_loss'])\n",
        "    plt.title('Model NN')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend(['Train','Val'])\n",
        "    plt.show()\n",
        "    \n",
        "    plt.plot(hist.history['loss'])\n",
        "    plt.plot(hist.history['val_loss'])\n",
        "    plt.title('Model NN')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.ylim([1,2])\n",
        "    plt.legend(['Train','Val'])\n",
        "    plt.show()\n",
        "\n",
        "    plt.plot(hist.history['loss'])\n",
        "    plt.plot(hist.history['val_loss'])\n",
        "    plt.title('Model NN')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.ylim([0,1])\n",
        "    plt.legend(['Train','Val'])\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQppkzTWUjLm",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Fv4ErMY_vsQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#0: electricity, 1: chilledwater, 2: steam, 3: hotwater\n",
        "#  Подготовка данных\n",
        "  df = pd.read_csv(DIR + \"train.csv\", engine = 'python')\n",
        "  #df_test = pd.read_csv(DIR + \"test.csv\", engine = 'python')\n",
        "\n",
        "  df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
        "  #df_test['timestamp'] = pd.to_datetime(df_test['timestamp'])\n",
        "\n",
        "  #Очистка от корявых данных\n",
        "  #df = df.query('not (building_id <= 104 & meter == 0 & timestamp <= \"2016-05-20\")')\n",
        "\n",
        "  #df['meter_reading'] = np.log1p(df['meter_reading'])\n",
        "\n",
        "  #df = pd.concat([df_train, df_test], sort=False)\n",
        "\n",
        "  df['hour_cos'] = np.cos(df['timestamp'].dt.hour * 2 * np.pi / 24)\n",
        "  df['hour_sin'] = np.sin(df['timestamp'].dt.hour * 2 * np.pi / 24)\n",
        "\n",
        "  df['weekday_cos'] = np.cos(df['timestamp'].dt.weekday * 2 * np.pi / 7)\n",
        "  df['weekday_sin'] = np.sin(df['timestamp'].dt.weekday * 2 * np.pi / 7)\n",
        "\n",
        "  df['week_cos'] = np.cos(df['timestamp'].dt.week * 2 * np.pi / 53)\n",
        "  df['week_sin'] = np.sin(df['timestamp'].dt.week * 2 * np.pi / 53)\n",
        "\n",
        "  #df_train['weekends'] = (df_train['weekday'] >= 6) * 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3xRu7Y_2MP5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Очистка от подозрительных нулей\n",
        "  #print(df[df['building_id']==2][['timestamp','meter_reading','meter','ds_zero','de_zero','is_bad_zero']].head(20))\n",
        "  df = df.sort_values(by = ['meter','building_id','timestamp'])\n",
        "  df['meter_reading_prev'] = 0\n",
        "\n",
        "  #for bid in df['building_id'].unique():\n",
        "  #  for met in df['meter'].unique():\n",
        "  df['meter_reading_prev'] = df['meter_reading'].shift()\n",
        "  df['is_equal_prev']= (df['meter_reading_prev'] == df['meter_reading'] )*1\n",
        "\n",
        "  df['day'] = df['timestamp'].dt.dayofyear\n",
        "  df_bad_rows = df.groupby(by=['building_id','day','meter'], as_index = False)['is_equal_prev'].mean()\n",
        "  df_bad_rows.rename({\"is_equal_prev\": \"IS_BAD_PRCNT\"}, axis='columns', inplace=True)\n",
        "\n",
        "  df = pd.merge(df, df_bad_rows, how = 'inner', on = ['building_id','day','meter'])\n",
        "  #print(df_bad_rows[df_bad_rows['building_id']==109].head(365))\n",
        "  del df_bad_rows \n",
        "\n",
        "  #print(df[df['building_id']==2][['timestamp','meter_reading','is_equal_prev','IS_BAD_PRCNT','day']].head(30))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g52hlFMS2cpu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Добавление медианы по метрике постройки\n",
        "  df_median = df.groupby(by=['building_id','meter'])['meter_reading'].median()\n",
        "  df_median.name = 'building_meter_median'\n",
        "  df = pd.merge(df, df_median, how = 'inner', on = ['building_id','meter'])\n",
        "  del df_median \n",
        "# Добавление медианы по часу, по неделе, метрике постройки\n",
        "  df['hour'] = df['timestamp'].dt.hour\n",
        "  df_median = df.groupby(by=['building_id','hour','meter'])['meter_reading'].median()\n",
        "  df_median.name = 'building_meter_hour_median'\n",
        "  df = pd.merge(df, df_median, how = 'inner', on = ['building_id','hour','meter'])\n",
        "  del df_median \n",
        "\n",
        "  df['weekday'] = df['timestamp'].dt.weekday\n",
        "  df_median = df.groupby(by=['building_id','weekday','meter'])['meter_reading'].median()\n",
        "  df_median.name = 'building_meter_weekday_median'\n",
        "  df = pd.merge(df, df_median, how = 'inner', on = ['building_id','weekday','meter'])\n",
        "  del df_median \n",
        "#Подстановка параметров сооружения\n",
        "  building_df = pd.read_csv(DIR + \"building_metadata.csv\", engine = 'python')\n",
        "  from sklearn.preprocessing import LabelEncoder\n",
        "  le = LabelEncoder()\n",
        "  building_df[\"primary_use_ID\"] = le.fit_transform(building_df[\"primary_use\"])\n",
        "\n",
        "  building_df['primary_use'] = building_df['primary_use'].astype('category')\n",
        "  building_df = pd.get_dummies(building_df)\n",
        "\n",
        "  df = df.merge(building_df, left_on = \"building_id\", right_on = \"building_id\", how = \"left\")\n",
        "  df.head(5)\n",
        "  del building_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIDKj_YCb_bD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Вставка данных погоды\n",
        "#Восстановление пустых данных погоды через соседей по линейной инетрполяции\n",
        "  df_weather = pd.read_csv(DIR + \"weather_train.csv\", engine = 'python')\n",
        "  df_weather['timestamp'] = pd.to_datetime(df_weather['timestamp'])\n",
        "\n",
        "  #weather_train.groupby('site_id').apply(lambda group: group.isna().sum())\n",
        "  df_times = df.drop_duplicates(['site_id','timestamp'])[['site_id','timestamp']]\n",
        "  df_times = pd.merge(df_times, df_weather, how = 'left', on = ['site_id','timestamp'])\n",
        "  df_times = df_times.sort_values(by = ['site_id','timestamp'])\n",
        "  \n",
        "  df_times = df_times.groupby('site_id').apply(lambda group: group.interpolate(limit_direction='both'))\n",
        "  df = pd.merge(df, df_times, how = 'left', on = ['site_id','timestamp'])\n",
        "  #del df_weather"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vojXrtAOc0t",
        "colab_type": "code",
        "outputId": "89ed17d3-2e9a-4091-ebd8-2ac14f297858",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "#Инфо о корявости данных:\n",
        "  print('0 Всего:',df[df['meter']==0].shape, 'Откинуть:', df[(df['meter']==0) & (df['IS_BAD_PRCNT']>0.45)].shape)\n",
        "  print('1 Всего:',df[df['meter']==1].shape, 'Откинуть:', df[(df['meter']==1) & (df['IS_BAD_PRCNT']>0.75)].shape)\n",
        "  print('2 Всего:',df[df['meter']==2].shape, 'Откинуть:', df[(df['meter']==2) & (df['IS_BAD_PRCNT']>0.75)].shape)\n",
        "  print('3 Всего:',df[df['meter']==3].shape, 'Откинуть:', df[(df['meter']==3) & (df['IS_BAD_PRCNT']>0.75)].shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 Всего: (12060910, 47) Откинуть: (1401057, 47)\n",
            "1 Всего: (4182440, 47) Откинуть: (537615, 47)\n",
            "2 Всего: (2708713, 47) Откинуть: (223436, 47)\n",
            "3 Всего: (1264037, 47) Откинуть: (311410, 47)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2-83vuu0xOi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# df_times = df.drop_duplicates(['site_id','hour','dayofyear'])[['site_id','hour','dayofyear']]\n",
        "# df_times = pd.merge(df_times, df_weather, how = 'left', on = ['site_id','timestamp'])\n",
        "# df_times = df_times.sort_values(by = ['site_id','timestamp'])\n",
        "# df_times = df_times.groupby('site_id').apply(lambda group: group.interpolate(limit_direction='both'))\n",
        "# df_times.to_feather(DIR + 'DF_WEATHER_BY_DAY_and_HOUR.FTHR')\n",
        "# del df_times"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmQtkGKQCueL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Вывести кол-во пустот по полям. Затем заполнить из средним значением по полю\n",
        "  for col in df.columns:\n",
        "    print(col)\n",
        "    for met in df['meter'].unique():\n",
        "      if np.sum(df[col].isnull()) > 0:\n",
        "        print(met)\n",
        "        print(np.sum(df[col].isnull()))\n",
        "\n",
        "        df_col = df.groupby(by=['building_id','meter'], as_index = False)[col].mean()\n",
        "        df_col.rename({col: \"tmp\"}, axis='columns', inplace=True)\n",
        "        df = df.merge(df_col, left_on = ['building_id','meter'], right_on = ['building_id','meter'], how = \"left\")\n",
        "        df[col].fillna( df_col['tmp'], inplace = True)\n",
        "        df.drop(columns = ['tmp'],inplace = True)\n",
        "        del df_col\n",
        "\n",
        "        df_col = df.groupby(by=['meter'], as_index = False)[col].mean()\n",
        "        df_col.rename({col: \"tmp\"}, axis='columns', inplace=True)\n",
        "        df = df.merge(df_col, left_on = ['meter'], right_on = ['meter'], how = \"left\")\n",
        "        df[col].fillna( df_col['tmp'], inplace = True)\n",
        "        df.drop(columns = ['tmp'],inplace = True)\n",
        "        del df_col\n",
        "\n",
        "        df[col].fillna( df[col].mean(), inplace = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxPaU99v4PI-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#df.to_feather(DIR + 'DF_TRAIN_EXTENDED2.FTHR')\n",
        "#df = pd.read_feather(DIR + 'DF_TRAIN_EXTENDED2.FTHR')\n",
        "reduce_mem_usage(df)\n",
        "df.to_feather(DIR + 'DF_TRAIN_REDUCED2.FTHR')\n",
        "gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6XbWpxAUnQb",
        "colab_type": "text"
      },
      "source": [
        "  Скорость"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asr3-4DHF_sx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1cd7a8ee-cfcb-4c10-e361-2d04fe88e792"
      },
      "source": [
        "\n",
        "df = pd.read_feather(DIR + 'DF_TRAIN_REDUCED2.FTHR')\n",
        "gc.collect()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dKU2_Eb7NFo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRnpeXMU_vu5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "outputId": "e2f1acc2-4545-41a5-8663-0401e94a09ac"
      },
      "source": [
        "#Импорты Керас:\n",
        "  from keras.models import Sequential, load_model\n",
        "\n",
        "  from keras.layers import Dense\n",
        "  from keras.initializers import TruncatedNormal, Constant\n",
        "  from keras.regularizers import l1,l2,l1_l2\n",
        "  from keras.optimizers import Adam\n",
        "  import keras.backend as K\n",
        "\n",
        "  from keras. callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "  #from keras.utils import plot_model\n",
        "  from keras.losses import mean_squared_error as mse #, mean_absolute_percentage_error as mape\n",
        "\n",
        "  def RMSLE(y_true, y_pred):\n",
        "    return K.pow( K.mean( K.pow(K.log(y_true+1) - K.log(y_pred+1),2.00000)),0.5000)\n",
        "\n",
        "  def tweedieloss(y_true, y_pred):\n",
        "      return K.mean(  K.pow(    K.pow(backend.maximum(0.000,K.maximum(0.013000,y_true)),0.5)  -   K.pow(K.maximum(0.013000,y_pred),0.5)   , 2 ) / K.pow(K.maximum(0.013000,y_pred),0.5)\n",
        "                  )\n",
        "\n",
        "  def tweedieloss_bkp(y_true, y_pred):\n",
        "      p=1.5\n",
        "      dev = 2 * (K.pow(K.maximum(0.000,y_true), 2-p)/((1-p) * (2-p)) -\n",
        "                    y_true * K.pow(y_pred, 1-p)/(1-p) +\n",
        "                    K.pow(y_pred, 2-p)/(2-p))\n",
        "      return K.mean(dev)\n",
        "\n",
        "  def VAL_ (y_true, y_pred):\n",
        "      return  K.maximum(0.0330000, K.sum(y_pred))/ K.maximum(0.033000, K.sum(y_true)) \n",
        "      \n",
        "  def VAL_2 (y_true, y_pred):\n",
        "      return  K.minimum( 5.000000, K.exp ( K.abs( K.log( VAL_ (y_true, y_pred))))-1)\n",
        "  \n",
        "  def VAL_3 (y_true, y_pred):\n",
        "      return  K.exp ( K.abs( K.log( VAL_ (y_true, y_pred))))-1\n",
        "\n",
        "  def MAPE_ (y_true, y_pred):\n",
        "      return K.mean( K.minimum( 5.000000,  K.abs(y_true - y_pred)/ K.maximum(0.033000, y_true)) )\n",
        "      \n",
        "  def MAE_(y_true, y_pred):\n",
        "      return K.sum( K.abs(y_true - y_pred))/ K.maximum(0.033000, K.sum(y_true))\n",
        "\n",
        "  def MSE_(y_true, y_pred):\n",
        "      return K.sum( K.pow(y_true - y_pred,2.00000))/ K.maximum(0.033000,  K.sum(K.pow(y_true,2.00000)))\n",
        "\n",
        "  def MAE_MAPE(y_true, y_pred):\n",
        "      return (\n",
        "                        MAE_(y_true, y_pred)\n",
        "          +  0.250000 * MAPE_ (y_true, y_pred)\n",
        "      )\n",
        "              \n",
        "  def MAE_VAL_MAPE(y_true, y_pred):\n",
        "      return (\n",
        "                        MAE_(y_true, y_pred)\n",
        "          + 1.800000 *   VAL_2 (y_true, y_pred)          \n",
        "          + 0.950000 *   MAPE_ (y_true, y_pred)\n",
        "          )\n",
        "\n",
        "  def MAE_VAL(y_true, y_pred):\n",
        "      return (\n",
        "                        MAE_(y_true, y_pred)\n",
        "          + 0.800000 *   VAL_2 (y_true, y_pred)                     \n",
        "              )\n",
        "\n",
        "  def MAPE_VAL(y_true, y_pred):\n",
        "      return (\n",
        "                      MAPE_ (y_true, y_pred)\n",
        "          + 0.4000 *  VAL_2 (y_true, y_pred)             \n",
        "              )\n",
        "\n",
        "  def MSE_VAL_MAPE(y_true, y_pred):\n",
        "      return (\n",
        "            5.000000 *   MSE_(y_true, y_pred)\n",
        "          + 2.200000 *   VAL_2 (y_true, y_pred)          \n",
        "          + 0.750000 *   MAPE_ (y_true, y_pred)\n",
        "          )\n",
        "\n",
        "  def MASPE_VAL(y_true, y_pred):\n",
        "      return (\n",
        "                        MAE_(y_true, y_pred)               \n",
        "          + 0.500000 *   MSE_(y_true, y_pred)\n",
        "          + 1.200000 *   VAL_2 (y_true, y_pred)          \n",
        "          + 0.250000 *   MAPE_ (y_true, y_pred)\n",
        "          )\n",
        "  \n",
        "  def MAE_RMSLE(y_true, y_pred):\n",
        "      return (\n",
        "            1.000000 *   MAE_   (y_true, y_pred)\n",
        "          + 2.000000 *   RMSLE  (y_true, y_pred)          \n",
        "          )  \n",
        "\n",
        "  def MAPE_RMSLE(y_true, y_pred):\n",
        "      return (\n",
        "            1.000000 *   MAPE_   (y_true, y_pred)\n",
        "          + 0.100000 *   RMSLE  (y_true, y_pred)          \n",
        "          )  \n",
        "  \n",
        "  def MAPE_VAL_RMSLE(y_true, y_pred):\n",
        "      return (\n",
        "            1.000000 *   MAPE_   (y_true, y_pred)\n",
        "          + 1.000000 *   RMSLE   (y_true, y_pred)    \n",
        "          + 1.000000 *   VAL_2   (y_true, y_pred)      \n",
        "          )  \n",
        " \n",
        "  import keras.metrics\n",
        "  keras.metrics.MAE_ = MAE_\n",
        "  keras.metrics.VAL_ = VAL_\n",
        "  keras.metrics.VAL_2 = VAL_2\n",
        "  keras.metrics.MAPE_ = MAPE_\n",
        "  keras.metrics.MSE_ = MSE_\n",
        "  keras.metrics.tweedieloss = tweedieloss\n",
        "  keras.metrics.MAE_RMSLE = MAE_RMSLE\n",
        "  keras.metrics.MAPE_RMSLE = MAPE_RMSLE\n",
        "  keras.metrics.MAPE_VAL_RMSLE = MAPE_VAL_RMSLE\n",
        "  keras.metrics.RMSLE = RMSLE\n",
        "\n",
        "  import keras.losses\n",
        "  keras.losses.MAE_VAL_MAPE = MAE_VAL_MAPE\n",
        "  keras.losses.MSE_VAL_MAPE = MSE_VAL_MAPE\n",
        "  keras.losses.MAE_ = MAE_\n",
        "  keras.losses.MASPE_VAL = MASPE_VAL\n",
        "  keras.losses.tweedieloss = tweedieloss\n",
        "  keras.losses.MAE_RMSLE = MAE_RMSLE\n",
        "  keras.losses.MAPE_RMSLE = MAPE_RMSLE\n",
        "  keras.losses.MAPE_VAL_RMSLE = MAPE_VAL_RMSLE\n",
        "  keras.losses.RMSLE = RMSLE\n",
        "\n",
        "  class MyCustomCallback(keras.callbacks.Callback):\n",
        "    \n",
        "    def __init__(self, epochs, stats_print_step): \n",
        "        \n",
        "        self.__epochs = epochs\n",
        "        self.__stats_print_step = stats_print_step\n",
        "    \n",
        "    def on_train_begin(self, logs={}):\n",
        "        pass\n",
        "        #print('on_train_begin', logs)\n",
        " \n",
        "    def on_train_end(self, logs={}):\n",
        "        pass\n",
        "        #print('on_train_end', logs)\n",
        " \n",
        "    def on_epoch_begin(self, epoch, logs={}):\n",
        "        pass\n",
        " \n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if ((epoch < 5) or (epoch % self.__stats_print_step == 0)) :\n",
        "            print('# ' + str('{:04d}'.format(epoch + 1)) + ' | ' + self.get_stats_by_epoch(logs))\n",
        "        if epoch == 2:\n",
        "            print('.......')\n",
        "        if epoch == self.__epochs - 1:\n",
        "            print('# ' + str('{:04d}'.format(epoch + 1)) + ' | ' + self.get_stats_by_epoch(logs))\n",
        "        else:\n",
        "            print('# ' + str('{:04d}'.format(epoch + 1)) + ' | ' + self.get_stats_by_epoch(logs), end=\"\\r\")\n",
        " \n",
        "    def on_batch_begin(self, batch, logs={}):\n",
        "        pass\n",
        "        #print('on_batch_begin', batch, logs)\n",
        " \n",
        "    def on_batch_end(self, batch, logs={}):\n",
        "        pass\n",
        "        #print('on_batch_end', batch, logs)\n",
        "\n",
        "    def get_stats_by_epoch(self, logs):\n",
        "        \n",
        "        is_test = True\n",
        "        s = ''\n",
        "        \n",
        "        for key, value in logs.items(): \n",
        "            if is_test:\n",
        "                if 'val_' not in str(key):\n",
        "                    s += ' /// '\n",
        "                    is_test = False\n",
        "            if is_test:\n",
        "                s += ' ' + str(key).replace('val_', 'TST_') + ': ' + \"{0:.4f}\".format(value)\n",
        "            else:\n",
        "                s += ' ' + 'TRN_' + str(key) + ': ' + \"{0:.4f}\".format(value)\n",
        "\n",
        "        return s #'val_loss: ' + \"{0:.4f}\".format(logs['val_loss']) + ' | loss: ' + \"{0:.4f}\".format(logs['loss'])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfToQh4ArZ3R",
        "colab_type": "code",
        "outputId": "b4336bfe-17b9-4789-898a-31708d8d2ab0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "df.columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['building_id', 'meter', 'timestamp', 'meter_reading', 'hour_cos', 'hour_sin', 'weekday_cos',\n",
              "       'weekday_sin', 'week_cos', 'week_sin', 'meter_reading_prev', 'is_equal_prev', 'day',\n",
              "       'IS_BAD_PRCNT', 'building_meter_median', 'hour', 'building_meter_hour_median', 'weekday',\n",
              "       'building_meter_weekday_median', 'site_id', 'square_feet', 'year_built', 'floor_count',\n",
              "       'primary_use_ID', 'primary_use_Education', 'primary_use_Entertainment/public assembly',\n",
              "       'primary_use_Food sales and service', 'primary_use_Healthcare',\n",
              "       'primary_use_Lodging/residential', 'primary_use_Manufacturing/industrial',\n",
              "       'primary_use_Office', 'primary_use_Other', 'primary_use_Parking',\n",
              "       'primary_use_Public services', 'primary_use_Religious worship', 'primary_use_Retail',\n",
              "       'primary_use_Services', 'primary_use_Technology/science', 'primary_use_Utility',\n",
              "       'primary_use_Warehouse/storage', 'air_temperature', 'cloud_coverage', 'dew_temperature',\n",
              "       'precip_depth_1_hr', 'sea_level_pressure', 'wind_direction', 'wind_speed'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_Em3Xm6rdeV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "6e652571-dae0-48ce-bdfb-75cd667c0b51"
      },
      "source": [
        "Out_Columns = 'meter_reading'\n",
        "In_Columns = [ 'hour_cos','hour_sin', 'weekday_cos', 'weekday_sin', 'week_cos', 'week_sin',\n",
        "       'site_id', 'square_feet', 'year_built', 'floor_count', #'primary_use_ID',\n",
        "       'primary_use_Education', 'primary_use_Entertainment/public assembly',\n",
        "       'primary_use_Food sales and service', 'primary_use_Healthcare',\n",
        "       'primary_use_Lodging/residential',\n",
        "       'primary_use_Manufacturing/industrial', 'primary_use_Office',\n",
        "       'primary_use_Other', 'primary_use_Parking',\n",
        "       'primary_use_Public services', 'primary_use_Religious worship',\n",
        "       'primary_use_Retail', 'primary_use_Services',\n",
        "       'primary_use_Technology/science', 'primary_use_Utility',\n",
        "       'primary_use_Warehouse/storage', 'air_temperature', 'cloud_coverage',\n",
        "       'dew_temperature', 'precip_depth_1_hr', 'sea_level_pressure',\n",
        "       'wind_direction', 'wind_speed'\n",
        "       , 'building_meter_median','building_meter_hour_median','building_meter_weekday_median']\n",
        "# Нормализация\n",
        " if 1==1:\n",
        "  from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, OneHotEncoder\n",
        "  scaler =  MinMaxScaler (copy=True, feature_range=(0, 1))                                  #quantile_range  = (15.0,85.0)) #Normalizer #(copy=True, feature_range=(-1, 1)) # MinMaxScaler(copy=True, feature_range=(-1, 1)) #StandardScaler() #MinMaxScaler(copy=True, feature_range=(-1, 1)) # RobustScaler()\n",
        "  scaler.fit( df[In_Columns] )\n",
        "  df[In_Columns]     = pd.DataFrame(data = scaler.transform( df[In_Columns])    , columns = df[In_Columns].columns   , index=df.index) \n",
        "\n",
        "  df.fillna(0.33)\n",
        "  gc.collect()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-0cb13d57dbd0>\"\u001b[0;36m, line \u001b[0;32m17\u001b[0m\n\u001b[0;31m    from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, OneHotEncoder\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aup6pDdkDoZZ",
        "colab_type": "code",
        "outputId": "f675bbbe-f55c-4867-b17d-7a037afcc39c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#0: electricity, 1: chilledwater, 2: steam, 3: hotwater\n",
        "# РАСЧЁТ НЕЙРОНОК:\n",
        "  reg = 0.00001\n",
        "  batch_size = 2048\n",
        "  epochs = 50\n",
        "  meter = 0\n",
        "\n",
        "  earlyStopping = EarlyStopping(monitor='loss', patience=100, verbose=1, mode='min')\n",
        "  reduce_lr_loss = ReduceLROnPlateau(monitor='loss', factor=0.3, patience=5, verbose=1, min_delta=1e-3, mode='min')\n",
        "  model_checkpoint = ModelCheckpoint(monitor='loss', save_best_only=True, filepath = DIR + 'best_nn_' + str(meter) + '.model', save_weights_only = False, verbose=0, mode='min')\n",
        "\n",
        "  init = TruncatedNormal(mean=0.0, stddev=0.05, seed=159)\n",
        "  bias = Constant(value = 1e-3)\n",
        "  \n",
        "  if 0==0:\n",
        "    meter = 0\n",
        "    opt = Adam(lr = 0.009)\n",
        "\n",
        "    nn_0 = Sequential()\n",
        "    nn_0.add(Dense(60, input_shape = df[In_Columns].shape[1:], activation = 'tanh', kernel_regularizer=l1(reg), kernel_initializer = 'normal'))\n",
        "    nn_0.add(Dense(60, activation = 'tanh',  kernel_initializer = 'normal'))\n",
        "    nn_0.add(Dense(1, activation = 'relu', kernel_initializer = 'normal'))\n",
        "\n",
        "    nn_0.compile(optimizer = opt, loss = MAE_RMSLE, metrics=[ MAE_, RMSLE, VAL_, 'mse', MAPE_ ])\n",
        "    \n",
        "    val = df[(df['meter']==meter) & (df['day']%6==0)]\n",
        "    hist = nn_0.fit( df[(df['meter']==meter) & (df['IS_BAD_PRCNT']<0.45)][In_Columns], df[(df['meter']==meter) & (df['IS_BAD_PRCNT']<0.45)][Out_Columns], batch_size = batch_size, verbose = 1\n",
        "                    , epochs = epochs, shuffle = True, callbacks=[earlyStopping, reduce_lr_loss,model_checkpoint]\n",
        "                    , validation_data=(val[In_Columns], val[Out_Columns])\n",
        "                    ) \n",
        "    nn_0.save(DIR + str(meter) + 'HANDLY_SAVED2.MODEL')\n",
        "    gc.collect()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4409: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1702: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 10659833 samples, validate on 2010873 samples\n",
            "Epoch 1/50\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "10659833/10659833 [==============================] - 47s 4us/step - loss: 2.2828 - MAE_: 0.5814 - RMSLE: 0.8457 - VAL_: 0.5186 - mean_squared_error: 96750.6682 - val_loss: 1.9125 - val_MAE_: 0.3594 - val_RMSLE: 0.7690 - val_VAL_: 0.9697 - val_mean_squared_error: 109953.7138\n",
            "Epoch 2/50\n",
            "10659833/10659833 [==============================] - 37s 3us/step - loss: 1.3292 - MAE_: 0.3683 - RMSLE: 0.4719 - VAL_: 0.7129 - mean_squared_error: 69628.5752 - val_loss: 1.7638 - val_MAE_: 0.3043 - val_RMSLE: 0.7206 - val_VAL_: 0.9422 - val_mean_squared_error: 98766.7754\n",
            "Epoch 3/50\n",
            "10659833/10659833 [==============================] - 37s 4us/step - loss: 1.2114 - MAE_: 0.3237 - RMSLE: 0.4342 - VAL_: 0.7621 - mean_squared_error: 61632.4418 - val_loss: 1.8411 - val_MAE_: 0.3152 - val_RMSLE: 0.7530 - val_VAL_: 0.8593 - val_mean_squared_error: 92679.9907\n",
            "Epoch 4/50\n",
            "10659833/10659833 [==============================] - 37s 3us/step - loss: 1.1538 - MAE_: 0.2996 - RMSLE: 0.4168 - VAL_: 0.7884 - mean_squared_error: 56748.3699 - val_loss: 1.7811 - val_MAE_: 0.3056 - val_RMSLE: 0.7272 - val_VAL_: 1.0383 - val_mean_squared_error: 88475.1095\n",
            "Epoch 5/50\n",
            "10659833/10659833 [==============================] - 37s 3us/step - loss: 1.1166 - MAE_: 0.2831 - RMSLE: 0.4060 - VAL_: 0.8061 - mean_squared_error: 53229.6667 - val_loss: 1.7078 - val_MAE_: 0.2798 - val_RMSLE: 0.7031 - val_VAL_: 0.9672 - val_mean_squared_error: 85220.2171\n",
            "Epoch 6/50\n",
            "10659833/10659833 [==============================] - 37s 3us/step - loss: 1.0890 - MAE_: 0.2707 - RMSLE: 0.3981 - VAL_: 0.8194 - mean_squared_error: 50449.6909 - val_loss: 1.6930 - val_MAE_: 0.2765 - val_RMSLE: 0.6971 - val_VAL_: 0.9741 - val_mean_squared_error: 82559.9733\n",
            "Epoch 7/50\n",
            "10659833/10659833 [==============================] - 37s 3us/step - loss: 1.0653 - MAE_: 0.2606 - RMSLE: 0.3911 - VAL_: 0.8301 - mean_squared_error: 48151.5278 - val_loss: 1.8284 - val_MAE_: 0.3187 - val_RMSLE: 0.7435 - val_VAL_: 1.1150 - val_mean_squared_error: 80463.4367\n",
            "Epoch 8/50\n",
            "10659833/10659833 [==============================] - 37s 4us/step - loss: 1.0469 - MAE_: 0.2522 - RMSLE: 0.3859 - VAL_: 0.8392 - mean_squared_error: 46189.7077 - val_loss: 1.6885 - val_MAE_: 0.2725 - val_RMSLE: 0.6965 - val_VAL_: 1.0012 - val_mean_squared_error: 78469.1074\n",
            "Epoch 9/50\n",
            "10659833/10659833 [==============================] - 37s 3us/step - loss: 1.0311 - MAE_: 0.2449 - RMSLE: 0.3816 - VAL_: 0.8473 - mean_squared_error: 44481.5732 - val_loss: 1.6703 - val_MAE_: 0.2652 - val_RMSLE: 0.6911 - val_VAL_: 0.9968 - val_mean_squared_error: 76704.1822\n",
            "Epoch 10/50\n",
            "10659833/10659833 [==============================] - 38s 4us/step - loss: 1.0181 - MAE_: 0.2386 - RMSLE: 0.3782 - VAL_: 0.8545 - mean_squared_error: 42985.6934 - val_loss: 1.6787 - val_MAE_: 0.2686 - val_RMSLE: 0.6935 - val_VAL_: 0.9713 - val_mean_squared_error: 75183.4292\n",
            "Epoch 11/50\n",
            "10659833/10659833 [==============================] - 39s 4us/step - loss: 1.0062 - MAE_: 0.2334 - RMSLE: 0.3749 - VAL_: 0.8607 - mean_squared_error: 41681.7290 - val_loss: 1.6921 - val_MAE_: 0.2720 - val_RMSLE: 0.6985 - val_VAL_: 1.0355 - val_mean_squared_error: 73919.9385\n",
            "Epoch 12/50\n",
            "10659833/10659833 [==============================] - 44s 4us/step - loss: 0.9958 - MAE_: 0.2286 - RMSLE: 0.3720 - VAL_: 0.8662 - mean_squared_error: 40494.3126 - val_loss: 1.6801 - val_MAE_: 0.2687 - val_RMSLE: 0.6941 - val_VAL_: 1.0051 - val_mean_squared_error: 72801.8545\n",
            "Epoch 13/50\n",
            "10659833/10659833 [==============================] - 41s 4us/step - loss: 0.9866 - MAE_: 0.2242 - RMSLE: 0.3696 - VAL_: 0.8710 - mean_squared_error: 39417.5288 - val_loss: 1.6683 - val_MAE_: 0.2670 - val_RMSLE: 0.6892 - val_VAL_: 1.0122 - val_mean_squared_error: 71551.6512\n",
            "Epoch 14/50\n",
            "10659833/10659833 [==============================] - 38s 4us/step - loss: 0.9787 - MAE_: 0.2204 - RMSLE: 0.3676 - VAL_: 0.8753 - mean_squared_error: 38445.6551 - val_loss: 1.6727 - val_MAE_: 0.2658 - val_RMSLE: 0.6919 - val_VAL_: 1.0060 - val_mean_squared_error: 70712.8079\n",
            "Epoch 15/50\n",
            "10659833/10659833 [==============================] - 38s 4us/step - loss: 0.9725 - MAE_: 0.2171 - RMSLE: 0.3662 - VAL_: 0.8792 - mean_squared_error: 37577.9184 - val_loss: 1.6662 - val_MAE_: 0.2646 - val_RMSLE: 0.6893 - val_VAL_: 1.0104 - val_mean_squared_error: 69670.1008\n",
            "Epoch 16/50\n",
            "10659833/10659833 [==============================] - 37s 4us/step - loss: 0.9661 - MAE_: 0.2142 - RMSLE: 0.3644 - VAL_: 0.8825 - mean_squared_error: 36792.3459 - val_loss: 1.6914 - val_MAE_: 0.2687 - val_RMSLE: 0.6998 - val_VAL_: 0.9608 - val_mean_squared_error: 68811.2766\n",
            "Epoch 17/50\n",
            "10659833/10659833 [==============================] - 37s 4us/step - loss: 0.9604 - MAE_: 0.2114 - RMSLE: 0.3630 - VAL_: 0.8857 - mean_squared_error: 36044.7821 - val_loss: 1.6870 - val_MAE_: 0.2690 - val_RMSLE: 0.6975 - val_VAL_: 1.0398 - val_mean_squared_error: 68011.4696\n",
            "Epoch 18/50\n",
            "10659833/10659833 [==============================] - 38s 4us/step - loss: 0.9565 - MAE_: 0.2090 - RMSLE: 0.3623 - VAL_: 0.8885 - mean_squared_error: 35377.8290 - val_loss: 1.6569 - val_MAE_: 0.2613 - val_RMSLE: 0.6864 - val_VAL_: 0.9942 - val_mean_squared_error: 67349.5056\n",
            "Epoch 19/50\n",
            "10659833/10659833 [==============================] - 37s 4us/step - loss: 0.9512 - MAE_: 0.2068 - RMSLE: 0.3608 - VAL_: 0.8910 - mean_squared_error: 34769.6504 - val_loss: 1.6758 - val_MAE_: 0.2652 - val_RMSLE: 0.6939 - val_VAL_: 0.9836 - val_mean_squared_error: 66667.4943\n",
            "Epoch 20/50\n",
            "10659833/10659833 [==============================] - 37s 3us/step - loss: 0.9469 - MAE_: 0.2046 - RMSLE: 0.3598 - VAL_: 0.8932 - mean_squared_error: 34192.6220 - val_loss: 1.6617 - val_MAE_: 0.2629 - val_RMSLE: 0.6881 - val_VAL_: 0.9772 - val_mean_squared_error: 66019.9883\n",
            "Epoch 21/50\n",
            "10659833/10659833 [==============================] - 37s 3us/step - loss: 0.9429 - MAE_: 0.2026 - RMSLE: 0.3589 - VAL_: 0.8954 - mean_squared_error: 33650.5755 - val_loss: 1.6501 - val_MAE_: 0.2578 - val_RMSLE: 0.6849 - val_VAL_: 0.9775 - val_mean_squared_error: 65343.8718\n",
            "Epoch 22/50\n",
            "10659833/10659833 [==============================] - 37s 3us/step - loss: 0.9393 - MAE_: 0.2007 - RMSLE: 0.3581 - VAL_: 0.8975 - mean_squared_error: 33138.7166 - val_loss: 1.6592 - val_MAE_: 0.2619 - val_RMSLE: 0.6875 - val_VAL_: 0.9801 - val_mean_squared_error: 64894.6848\n",
            "Epoch 23/50\n",
            "10659833/10659833 [==============================] - 37s 4us/step - loss: 0.9362 - MAE_: 0.1990 - RMSLE: 0.3574 - VAL_: 0.8994 - mean_squared_error: 32660.3947 - val_loss: 1.6582 - val_MAE_: 0.2593 - val_RMSLE: 0.6882 - val_VAL_: 1.0273 - val_mean_squared_error: 64358.8014\n",
            "Epoch 24/50\n",
            "10659833/10659833 [==============================] - 37s 3us/step - loss: 0.9329 - MAE_: 0.1972 - RMSLE: 0.3567 - VAL_: 0.9012 - mean_squared_error: 32186.7645 - val_loss: 1.6509 - val_MAE_: 0.2558 - val_RMSLE: 0.6865 - val_VAL_: 1.0196 - val_mean_squared_error: 63837.5831\n",
            "Epoch 25/50\n",
            "10659833/10659833 [==============================] - 37s 4us/step - loss: 0.9298 - MAE_: 0.1956 - RMSLE: 0.3560 - VAL_: 0.9030 - mean_squared_error: 31745.5067 - val_loss: 1.6640 - val_MAE_: 0.2633 - val_RMSLE: 0.6892 - val_VAL_: 1.0310 - val_mean_squared_error: 63319.3430\n",
            "Epoch 26/50\n",
            "10659833/10659833 [==============================] - 39s 4us/step - loss: 0.9270 - MAE_: 0.1941 - RMSLE: 0.3553 - VAL_: 0.9046 - mean_squared_error: 31333.1415 - val_loss: 1.6837 - val_MAE_: 0.2679 - val_RMSLE: 0.6967 - val_VAL_: 1.0522 - val_mean_squared_error: 63083.4625\n",
            "Epoch 27/50\n",
            "10659833/10659833 [==============================] - 38s 4us/step - loss: 0.9247 - MAE_: 0.1929 - RMSLE: 0.3548 - VAL_: 0.9062 - mean_squared_error: 30937.0060 - val_loss: 1.6535 - val_MAE_: 0.2577 - val_RMSLE: 0.6868 - val_VAL_: 1.0167 - val_mean_squared_error: 62607.9162\n",
            "Epoch 28/50\n",
            "10659833/10659833 [==============================] - 38s 4us/step - loss: 0.9228 - MAE_: 0.1917 - RMSLE: 0.3544 - VAL_: 0.9077 - mean_squared_error: 30566.3815 - val_loss: 1.6505 - val_MAE_: 0.2576 - val_RMSLE: 0.6853 - val_VAL_: 1.0153 - val_mean_squared_error: 61997.2990\n",
            "Epoch 29/50\n",
            "10659833/10659833 [==============================] - 38s 4us/step - loss: 0.9200 - MAE_: 0.1906 - RMSLE: 0.3536 - VAL_: 0.9091 - mean_squared_error: 30201.7458 - val_loss: 1.6348 - val_MAE_: 0.2520 - val_RMSLE: 0.6803 - val_VAL_: 0.9982 - val_mean_squared_error: 61687.5743\n",
            "Epoch 30/50\n",
            "10659833/10659833 [==============================] - 41s 4us/step - loss: 0.9176 - MAE_: 0.1893 - RMSLE: 0.3530 - VAL_: 0.9103 - mean_squared_error: 29853.3352 - val_loss: 1.6614 - val_MAE_: 0.2613 - val_RMSLE: 0.6890 - val_VAL_: 1.0422 - val_mean_squared_error: 61400.4291\n",
            "Epoch 31/50\n",
            "10659833/10659833 [==============================] - 44s 4us/step - loss: 0.9153 - MAE_: 0.1882 - RMSLE: 0.3524 - VAL_: 0.9115 - mean_squared_error: 29523.1622 - val_loss: 1.6533 - val_MAE_: 0.2593 - val_RMSLE: 0.6858 - val_VAL_: 1.0236 - val_mean_squared_error: 60696.8367\n",
            "Epoch 32/50\n",
            "10659833/10659833 [==============================] - 40s 4us/step - loss: 0.9136 - MAE_: 0.1871 - RMSLE: 0.3521 - VAL_: 0.9127 - mean_squared_error: 29204.0703 - val_loss: 1.6510 - val_MAE_: 0.2571 - val_RMSLE: 0.6857 - val_VAL_: 1.0261 - val_mean_squared_error: 60660.1009\n",
            "Epoch 33/50\n",
            "10659833/10659833 [==============================] - 38s 4us/step - loss: 0.9116 - MAE_: 0.1861 - RMSLE: 0.3516 - VAL_: 0.9138 - mean_squared_error: 28899.2117 - val_loss: 1.6465 - val_MAE_: 0.2541 - val_RMSLE: 0.6850 - val_VAL_: 1.0019 - val_mean_squared_error: 60206.3560\n",
            "Epoch 34/50\n",
            "10659833/10659833 [==============================] - 38s 4us/step - loss: 0.9099 - MAE_: 0.1851 - RMSLE: 0.3512 - VAL_: 0.9148 - mean_squared_error: 28611.5193 - val_loss: 1.6701 - val_MAE_: 0.2623 - val_RMSLE: 0.6927 - val_VAL_: 1.0476 - val_mean_squared_error: 59720.0571\n",
            "Epoch 35/50\n",
            "10659833/10659833 [==============================] - 37s 4us/step - loss: 0.9085 - MAE_: 0.1841 - RMSLE: 0.3510 - VAL_: 0.9158 - mean_squared_error: 28329.4391 - val_loss: 1.6320 - val_MAE_: 0.2512 - val_RMSLE: 0.6791 - val_VAL_: 1.0050 - val_mean_squared_error: 59309.8484\n",
            "Epoch 36/50\n",
            "10659833/10659833 [==============================] - 37s 3us/step - loss: 0.9075 - MAE_: 0.1833 - RMSLE: 0.3509 - VAL_: 0.9168 - mean_squared_error: 28072.6846 - val_loss: 1.6478 - val_MAE_: 0.2534 - val_RMSLE: 0.6860 - val_VAL_: 1.0399 - val_mean_squared_error: 59344.0360\n",
            "Epoch 37/50\n",
            "10659833/10659833 [==============================] - 37s 3us/step - loss: 0.9054 - MAE_: 0.1825 - RMSLE: 0.3502 - VAL_: 0.9177 - mean_squared_error: 27821.3941 - val_loss: 1.6398 - val_MAE_: 0.2530 - val_RMSLE: 0.6821 - val_VAL_: 1.0007 - val_mean_squared_error: 58796.4329\n",
            "Epoch 38/50\n",
            "10659833/10659833 [==============================] - 37s 3us/step - loss: 0.9050 - MAE_: 0.1819 - RMSLE: 0.3503 - VAL_: 0.9186 - mean_squared_error: 27577.8607 - val_loss: 1.6422 - val_MAE_: 0.2547 - val_RMSLE: 0.6825 - val_VAL_: 1.0182 - val_mean_squared_error: 58597.7699\n",
            "Epoch 39/50\n",
            "10659833/10659833 [==============================] - 37s 3us/step - loss: 0.9035 - MAE_: 0.1810 - RMSLE: 0.3500 - VAL_: 0.9195 - mean_squared_error: 27338.5254 - val_loss: 1.6660 - val_MAE_: 0.2645 - val_RMSLE: 0.6894 - val_VAL_: 1.0395 - val_mean_squared_error: 58358.8043\n",
            "Epoch 40/50\n",
            "10659833/10659833 [==============================] - 37s 3us/step - loss: 0.9023 - MAE_: 0.1803 - RMSLE: 0.3497 - VAL_: 0.9202 - mean_squared_error: 27118.0557 - val_loss: 1.6579 - val_MAE_: 0.2571 - val_RMSLE: 0.6891 - val_VAL_: 0.9996 - val_mean_squared_error: 58020.1246\n",
            "Epoch 41/50\n",
            "10659833/10659833 [==============================] - 37s 4us/step - loss: 0.9013 - MAE_: 0.1797 - RMSLE: 0.3495 - VAL_: 0.9210 - mean_squared_error: 26904.7736 - val_loss: 1.6496 - val_MAE_: 0.2574 - val_RMSLE: 0.6848 - val_VAL_: 1.0214 - val_mean_squared_error: 57980.2620\n",
            "Epoch 42/50\n",
            "10659833/10659833 [==============================] - 37s 4us/step - loss: 0.9008 - MAE_: 0.1793 - RMSLE: 0.3494 - VAL_: 0.9218 - mean_squared_error: 26704.2174 - val_loss: 1.6798 - val_MAE_: 0.2658 - val_RMSLE: 0.6957 - val_VAL_: 1.0605 - val_mean_squared_error: 57787.6714\n",
            "Epoch 43/50\n",
            "10659833/10659833 [==============================] - 37s 3us/step - loss: 0.8992 - MAE_: 0.1785 - RMSLE: 0.3490 - VAL_: 0.9224 - mean_squared_error: 26494.8542 - val_loss: 1.6798 - val_MAE_: 0.2699 - val_RMSLE: 0.6937 - val_VAL_: 1.0539 - val_mean_squared_error: 57557.2774\n",
            "Epoch 44/50\n",
            "10659833/10659833 [==============================] - 37s 3us/step - loss: 0.8973 - MAE_: 0.1778 - RMSLE: 0.3484 - VAL_: 0.9231 - mean_squared_error: 26290.4533 - val_loss: 1.6554 - val_MAE_: 0.2597 - val_RMSLE: 0.6866 - val_VAL_: 1.0281 - val_mean_squared_error: 57280.0006\n",
            "Epoch 45/50\n",
            "10659833/10659833 [==============================] - 37s 3us/step - loss: 0.8983 - MAE_: 0.1777 - RMSLE: 0.3490 - VAL_: 0.9237 - mean_squared_error: 26104.7471 - val_loss: 1.6696 - val_MAE_: 0.2695 - val_RMSLE: 0.6886 - val_VAL_: 1.0184 - val_mean_squared_error: 57183.5497\n",
            "Epoch 46/50\n",
            "10659833/10659833 [==============================] - 37s 3us/step - loss: 0.8955 - MAE_: 0.1767 - RMSLE: 0.3480 - VAL_: 0.9242 - mean_squared_error: 25899.8771 - val_loss: 1.6810 - val_MAE_: 0.2692 - val_RMSLE: 0.6945 - val_VAL_: 1.0431 - val_mean_squared_error: 57129.9485\n",
            "Epoch 47/50\n",
            "10659833/10659833 [==============================] - 37s 4us/step - loss: 0.8952 - MAE_: 0.1763 - RMSLE: 0.3481 - VAL_: 0.9250 - mean_squared_error: 25712.1185 - val_loss: 1.6510 - val_MAE_: 0.2573 - val_RMSLE: 0.6855 - val_VAL_: 1.0165 - val_mean_squared_error: 56709.0714\n",
            "Epoch 48/50\n",
            "10659833/10659833 [==============================] - 42s 4us/step - loss: 0.8941 - MAE_: 0.1757 - RMSLE: 0.3478 - VAL_: 0.9257 - mean_squared_error: 25529.6681 - val_loss: 1.6681 - val_MAE_: 0.2622 - val_RMSLE: 0.6916 - val_VAL_: 1.0614 - val_mean_squared_error: 56599.2626\n",
            "Epoch 49/50\n",
            "10659833/10659833 [==============================] - 42s 4us/step - loss: 0.8935 - MAE_: 0.1753 - RMSLE: 0.3477 - VAL_: 0.9264 - mean_squared_error: 25361.2835 - val_loss: 1.6599 - val_MAE_: 0.2621 - val_RMSLE: 0.6875 - val_VAL_: 1.0450 - val_mean_squared_error: 56290.7938\n",
            "Epoch 50/50\n",
            "10659833/10659833 [==============================] - 38s 4us/step - loss: 0.8948 - MAE_: 0.1752 - RMSLE: 0.3484 - VAL_: 0.9271 - mean_squared_error: 25207.7605 - val_loss: 1.6474 - val_MAE_: 0.2577 - val_RMSLE: 0.6834 - val_VAL_: 1.0074 - val_mean_squared_error: 56050.2932\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nX1MEx4lPtK6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# hist = nn_0.fit( df[(df['meter']==meter) & (df['IS_BAD_PRCNT']<0.45)][In_Columns], df[(df['meter']==meter) & (df['IS_BAD_PRCNT']<0.45)][Out_Columns], batch_size = batch_size, verbose = 1\n",
        "#               , epochs = epochs, shuffle = True, callbacks=[earlyStopping, reduce_lr_loss,model_checkpoint]\n",
        "#               , validation_data=(val[In_Columns], val[Out_Columns])\n",
        "#               ) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diaTWlaXC4_H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " #Продолжение расчёта\n",
        " if 9==9:\n",
        "    # nn_0.optimizer.lr = 0.007\n",
        "    # nn_0.compile(optimizer = opt, loss = MAE_RMSLE, metrics=[ MAE_, RMSLE, VAL_, 'mse' ])\n",
        "    # batch_size = 2048\n",
        "    # epochs = 10\n",
        "    \n",
        "    # earlyStopping = EarlyStopping(monitor='loss', patience=100, verbose=1, mode='min',restore_best_weights = True)\n",
        "    # reduce_lr_loss = ReduceLROnPlateau(monitor='loss', factor=0.3, patience=5, verbose=1, min_delta=1e-3, mode='min')\n",
        "\n",
        "    # val = df[(df['meter']==meter) & (df['day']%6==0)]\n",
        "    # hist = nn_0.fit( df[(df['meter']==meter) & (df['IS_BAD_PRCNT']<0.45)][In_Columns], df[(df['meter']==meter) & (df['IS_BAD_PRCNT']<0.45)][Out_Columns], batch_size = batch_size, verbose = 1\n",
        "    #                 , epochs = epochs, shuffle = True, callbacks=[earlyStopping, reduce_lr_loss,model_checkpoint]\n",
        "    #                 , validation_data=(val[In_Columns], val[Out_Columns])\n",
        "    #                 ) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mf8-ceMw8N1q",
        "colab_type": "code",
        "outputId": "ea50d179-ae41-46ab-e7b3-d49fb7f08f3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "if 1==1:\n",
        "  reg = 0.00001\n",
        "  meter = 1\n",
        "  epochs = 100\n",
        "  batch_size = 512\n",
        "  opt = Adam(lr = 0.007)\n",
        "\n",
        "  earlyStopping = EarlyStopping(monitor='loss', patience=100, verbose=1, mode='min')\n",
        "  reduce_lr_loss = ReduceLROnPlateau(monitor='loss', factor=0.3, patience=5, verbose=1, min_delta=1e-3, mode='min')\n",
        "  model_checkpoint = ModelCheckpoint(monitor='loss', save_best_only=True, filepath = DIR + 'best_nn_' + str(meter) + '.model', save_weights_only = False, verbose=0, mode='min')\n",
        "\n",
        "  nn_1 = Sequential()\n",
        "  nn_1.add(Dense(90, input_shape = df[In_Columns].shape[1:], activation = 'tanh', kernel_regularizer=l1(reg), kernel_initializer = 'normal'))\n",
        "  nn_1.add(Dense(90, activation = 'tanh',  kernel_initializer = 'normal'))\n",
        "  nn_1.add(Dense(90, activation = 'relu',  kernel_initializer = 'normal'))\n",
        "  nn_1.add(Dense(90, activation = 'relu',  kernel_initializer = 'normal'))\n",
        "  nn_1.add(Dense(1, activation = 'relu', kernel_initializer = 'normal'))\n",
        "\n",
        "  nn_1.compile(optimizer = opt, loss = MAE_RMSLE, metrics=[ MAE_, RMSLE, VAL_, 'mse', MAPE_ ])\n",
        "  \n",
        "  val = df[(df['meter']==meter) & (df['day']%6==0)]\n",
        "  hist = nn_1.fit( df[(df['meter']==meter) & (df['IS_BAD_PRCNT']<0.45)][In_Columns], df[(df['meter']==meter) & (df['IS_BAD_PRCNT']<0.45)][Out_Columns], batch_size = batch_size, verbose = 1\n",
        "                  , epochs = epochs, shuffle = True, callbacks=[earlyStopping, reduce_lr_loss,model_checkpoint]\n",
        "                  , validation_data=(val[In_Columns], val[Out_Columns])\n",
        "                  ) \n",
        "  nn_1.save(DIR + str(meter) + 'HANDLY_SAVED2.MODEL')\n",
        "  gc.collect()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 3480650 samples, validate on 697348 samples\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "3480650/3480650 [==============================] - 39s 11us/step - loss: 2.6861 - MAE_: 0.4389 - RMSLE: 1.1175 - VAL_: 0.7426 - mean_squared_error: 74046388.2225 - MAPE_: 0.8844 - val_loss: 2509.1781 - val_MAE_: 2506.5146 - val_RMSLE: 1.3233 - val_VAL_: 2506.9814 - val_mean_squared_error: 62661875.2025 - val_MAPE_: 1.3179\n",
            "Epoch 2/100\n",
            "3480650/3480650 [==============================] - 33s 9us/step - loss: 2.1056 - MAE_: 0.3263 - RMSLE: 0.8802 - VAL_: 0.8469 - mean_squared_error: 72271500.8472 - MAPE_: 0.6802 - val_loss: 2461.9575 - val_MAE_: 2459.2906 - val_RMSLE: 1.3231 - val_VAL_: 2459.9241 - val_mean_squared_error: 61179016.9324 - val_MAPE_: 1.3326\n",
            "Epoch 3/100\n",
            "3480650/3480650 [==============================] - 33s 10us/step - loss: 2.0247 - MAE_: 0.3121 - RMSLE: 0.8452 - VAL_: 0.8562 - mean_squared_error: 67148874.8206 - MAPE_: 0.6502 - val_loss: 2753.2401 - val_MAE_: 2750.7069 - val_RMSLE: 1.2548 - val_VAL_: 2751.2381 - val_mean_squared_error: 53505119.8220 - val_MAPE_: 1.2452\n",
            "Epoch 4/100\n",
            "3480650/3480650 [==============================] - 33s 9us/step - loss: 1.9767 - MAE_: 0.2921 - RMSLE: 0.8299 - VAL_: 0.8752 - mean_squared_error: 45055889.2404 - MAPE_: 0.6367 - val_loss: 2031.4473 - val_MAE_: 2028.8516 - val_RMSLE: 1.2850 - val_VAL_: 2029.4643 - val_mean_squared_error: 61613327.0193 - val_MAPE_: 1.2780\n",
            "Epoch 5/100\n",
            "3480650/3480650 [==============================] - 33s 9us/step - loss: 1.9213 - MAE_: 0.2558 - RMSLE: 0.8193 - VAL_: 0.9203 - mean_squared_error: 12523664.8367 - MAPE_: 0.6278 - val_loss: 1542.3938 - val_MAE_: 1539.8715 - val_RMSLE: 1.2473 - val_VAL_: 1540.3084 - val_mean_squared_error: 178239426.4764 - val_MAPE_: 1.2203\n",
            "Epoch 6/100\n",
            "3480650/3480650 [==============================] - 32s 9us/step - loss: 1.9007 - MAE_: 0.2510 - RMSLE: 0.8106 - VAL_: 0.9269 - mean_squared_error: 11672411.8529 - MAPE_: 0.6201 - val_loss: 1602.7194 - val_MAE_: 1600.1981 - val_RMSLE: 1.2460 - val_VAL_: 1600.8031 - val_mean_squared_error: 158571410.1333 - val_MAPE_: 1.2448\n",
            "Epoch 7/100\n",
            "3480650/3480650 [==============================] - 33s 9us/step - loss: 1.8729 - MAE_: 0.2454 - RMSLE: 0.7988 - VAL_: 0.9308 - mean_squared_error: 9939170.1742 - MAPE_: 0.6101 - val_loss: 2319.4242 - val_MAE_: 2316.8575 - val_RMSLE: 1.2681 - val_VAL_: 2317.3517 - val_mean_squared_error: 188148998.8134 - val_MAPE_: 1.2391\n",
            "Epoch 8/100\n",
            "3480650/3480650 [==============================] - 33s 9us/step - loss: 1.8595 - MAE_: 0.2423 - RMSLE: 0.7931 - VAL_: 0.9353 - mean_squared_error: 9816469.2607 - MAPE_: 0.6060 - val_loss: 1456.5309 - val_MAE_: 1454.0039 - val_RMSLE: 1.2476 - val_VAL_: 1454.6201 - val_mean_squared_error: 244998099.8947 - val_MAPE_: 1.2425\n",
            "Epoch 9/100\n",
            "3480650/3480650 [==============================] - 32s 9us/step - loss: 1.8496 - MAE_: 0.2413 - RMSLE: 0.7881 - VAL_: 0.9332 - mean_squared_error: 10377928.9093 - MAPE_: 0.6015 - val_loss: 1078.9863 - val_MAE_: 1076.5109 - val_RMSLE: 1.2214 - val_VAL_: 1077.0894 - val_mean_squared_error: 192610470.2457 - val_MAPE_: 1.2199\n",
            "Epoch 10/100\n",
            "3480650/3480650 [==============================] - 33s 9us/step - loss: 1.8365 - MAE_: 0.2380 - RMSLE: 0.7827 - VAL_: 0.9359 - mean_squared_error: 9564943.6738 - MAPE_: 0.5956 - val_loss: 1475.2277 - val_MAE_: 1472.7363 - val_RMSLE: 1.2289 - val_VAL_: 1473.3098 - val_mean_squared_error: 183777190.1248 - val_MAPE_: 1.2109\n",
            "Epoch 11/100\n",
            "3480650/3480650 [==============================] - 34s 10us/step - loss: 1.8358 - MAE_: 0.2382 - RMSLE: 0.7818 - VAL_: 0.9365 - mean_squared_error: 10152027.0859 - MAPE_: 0.5953 - val_loss: 1270.7028 - val_MAE_: 1268.1741 - val_RMSLE: 1.2471 - val_VAL_: 1268.7775 - val_mean_squared_error: 168683832.1053 - val_MAPE_: 1.2403\n",
            "Epoch 12/100\n",
            "3480650/3480650 [==============================] - 34s 10us/step - loss: 1.8205 - MAE_: 0.2347 - RMSLE: 0.7756 - VAL_: 0.9380 - mean_squared_error: 9483398.3196 - MAPE_: 0.5893 - val_loss: 1250.3913 - val_MAE_: 1247.9376 - val_RMSLE: 1.2093 - val_VAL_: 1248.4846 - val_mean_squared_error: 173148902.2892 - val_MAPE_: 1.1985\n",
            "Epoch 13/100\n",
            "3480650/3480650 [==============================] - 32s 9us/step - loss: 1.8326 - MAE_: 0.2374 - RMSLE: 0.7798 - VAL_: 0.9373 - mean_squared_error: 9588107.3938 - MAPE_: 0.5937 - val_loss: 1353.8852 - val_MAE_: 1351.4077 - val_RMSLE: 1.2208 - val_VAL_: 1352.0396 - val_mean_squared_error: 254426173.0514 - val_MAPE_: 1.2019\n",
            "Epoch 14/100\n",
            "3480650/3480650 [==============================] - 32s 9us/step - loss: 1.8121 - MAE_: 0.2334 - RMSLE: 0.7713 - VAL_: 0.9392 - mean_squared_error: 9428309.3013 - MAPE_: 0.5858 - val_loss: 1954.6690 - val_MAE_: 1952.2168 - val_RMSLE: 1.2079 - val_VAL_: 1952.8126 - val_mean_squared_error: 215583861.2041 - val_MAPE_: 1.1993\n",
            "Epoch 15/100\n",
            "3480650/3480650 [==============================] - 32s 9us/step - loss: 1.8172 - MAE_: 0.2351 - RMSLE: 0.7726 - VAL_: 0.9359 - mean_squared_error: 10291291.4834 - MAPE_: 0.5876 - val_loss: 1383.6337 - val_MAE_: 1381.1675 - val_RMSLE: 1.2145 - val_VAL_: 1381.7676 - val_mean_squared_error: 251201240.1119 - val_MAPE_: 1.2026\n",
            "Epoch 16/100\n",
            "3480650/3480650 [==============================] - 33s 9us/step - loss: 1.8123 - MAE_: 0.2333 - RMSLE: 0.7708 - VAL_: 0.9398 - mean_squared_error: 9236156.3921 - MAPE_: 0.5864 - val_loss: 1701.7446 - val_MAE_: 1699.2567 - val_RMSLE: 1.2251 - val_VAL_: 1699.9168 - val_mean_squared_error: 271667841.1144 - val_MAPE_: 1.2267\n",
            "Epoch 17/100\n",
            "3480650/3480650 [==============================] - 32s 9us/step - loss: 1.8040 - MAE_: 0.2330 - RMSLE: 0.7665 - VAL_: 0.9388 - mean_squared_error: 9571053.0720 - MAPE_: 0.5818 - val_loss: 1398.2816 - val_MAE_: 1395.8603 - val_RMSLE: 1.1916 - val_VAL_: 1396.4303 - val_mean_squared_error: 295010589.2972 - val_MAPE_: 1.1858\n",
            "Epoch 18/100\n",
            "3480650/3480650 [==============================] - 32s 9us/step - loss: 1.8015 - MAE_: 0.2311 - RMSLE: 0.7660 - VAL_: 0.9397 - mean_squared_error: 9323699.6384 - MAPE_: 0.5816 - val_loss: 1693.4103 - val_MAE_: 1690.9396 - val_RMSLE: 1.2159 - val_VAL_: 1691.5519 - val_mean_squared_error: 200344339.9086 - val_MAPE_: 1.2037\n",
            "Epoch 19/100\n",
            "3480650/3480650 [==============================] - 32s 9us/step - loss: 1.8038 - MAE_: 0.2324 - RMSLE: 0.7662 - VAL_: 0.9383 - mean_squared_error: 9451141.2271 - MAPE_: 0.5810 - val_loss: 1367.9030 - val_MAE_: 1365.4381 - val_RMSLE: 1.2129 - val_VAL_: 1366.0414 - val_mean_squared_error: 194348318.2611 - val_MAPE_: 1.2042\n",
            "Epoch 20/100\n",
            "3480650/3480650 [==============================] - 32s 9us/step - loss: 1.8003 - MAE_: 0.2315 - RMSLE: 0.7647 - VAL_: 0.9394 - mean_squared_error: 9391155.2626 - MAPE_: 0.5797 - val_loss: 1540.9260 - val_MAE_: 1538.4513 - val_RMSLE: 1.2175 - val_VAL_: 1539.0904 - val_mean_squared_error: 211489065.7078 - val_MAPE_: 1.2088\n",
            "Epoch 21/100\n",
            "3480650/3480650 [==============================] - 32s 9us/step - loss: 1.8153 - MAE_: 0.2344 - RMSLE: 0.7705 - VAL_: 0.9378 - mean_squared_error: 9685033.3187 - MAPE_: 0.5847 - val_loss: 1205.3548 - val_MAE_: 1202.9230 - val_RMSLE: 1.1959 - val_VAL_: 1203.4921 - val_mean_squared_error: 182774446.6724 - val_MAPE_: 1.1902\n",
            "Epoch 22/100\n",
            "3480650/3480650 [==============================] - 32s 9us/step - loss: 1.7931 - MAE_: 0.2305 - RMSLE: 0.7611 - VAL_: 0.9407 - mean_squared_error: 9248736.7709 - MAPE_: 0.5774 - val_loss: 1403.5286 - val_MAE_: 1401.0950 - val_RMSLE: 1.1964 - val_VAL_: 1401.6652 - val_mean_squared_error: 237801739.3652 - val_MAPE_: 1.1813\n",
            "Epoch 23/100\n",
            "3480650/3480650 [==============================] - 32s 9us/step - loss: 1.7957 - MAE_: 0.2314 - RMSLE: 0.7617 - VAL_: 0.9398 - mean_squared_error: 9401737.2692 - MAPE_: 0.5781 - val_loss: 1456.9370 - val_MAE_: 1454.3826 - val_RMSLE: 1.2567 - val_VAL_: 1455.0599 - val_mean_squared_error: 220516851.7592 - val_MAPE_: 1.2501\n",
            "Epoch 24/100\n",
            "3480650/3480650 [==============================] - 32s 9us/step - loss: 1.7851 - MAE_: 0.2293 - RMSLE: 0.7573 - VAL_: 0.9407 - mean_squared_error: 9196443.7597 - MAPE_: 0.5735 - val_loss: 1192.4885 - val_MAE_: 1190.0766 - val_RMSLE: 1.1853 - val_VAL_: 1190.6581 - val_mean_squared_error: 222877215.2595 - val_MAPE_: 1.1789\n",
            "Epoch 25/100\n",
            "3480650/3480650 [==============================] - 32s 9us/step - loss: 1.7805 - MAE_: 0.2286 - RMSLE: 0.7552 - VAL_: 0.9415 - mean_squared_error: 9351877.8480 - MAPE_: 0.5709 - val_loss: 1438.9794 - val_MAE_: 1436.4961 - val_RMSLE: 1.2208 - val_VAL_: 1437.1088 - val_mean_squared_error: 216287421.9612 - val_MAPE_: 1.2130\n",
            "Epoch 26/100\n",
            "3480650/3480650 [==============================] - 33s 9us/step - loss: 1.7889 - MAE_: 0.2299 - RMSLE: 0.7584 - VAL_: 0.9398 - mean_squared_error: 9494639.7405 - MAPE_: 0.5744 - val_loss: 1768.3348 - val_MAE_: 1765.8214 - val_RMSLE: 1.2355 - val_VAL_: 1766.5171 - val_mean_squared_error: 223588041.6946 - val_MAPE_: 1.2264\n",
            "Epoch 27/100\n",
            "3480650/3480650 [==============================] - 34s 10us/step - loss: 1.7851 - MAE_: 0.2298 - RMSLE: 0.7564 - VAL_: 0.9410 - mean_squared_error: 9315317.5653 - MAPE_: 0.5728 - val_loss: 1871.7959 - val_MAE_: 1869.3488 - val_RMSLE: 1.2020 - val_VAL_: 1869.9639 - val_mean_squared_error: 176598523.7608 - val_MAPE_: 1.1932\n",
            "Epoch 28/100\n",
            "3480650/3480650 [==============================] - 33s 10us/step - loss: 1.7811 - MAE_: 0.2282 - RMSLE: 0.7550 - VAL_: 0.9409 - mean_squared_error: 9290857.7760 - MAPE_: 0.5717 - val_loss: 1501.4183 - val_MAE_: 1498.9170 - val_RMSLE: 1.2291 - val_VAL_: 1499.5348 - val_mean_squared_error: 216925889.3859 - val_MAPE_: 1.2306\n",
            "Epoch 29/100\n",
            "3480650/3480650 [==============================] - 32s 9us/step - loss: 1.7802 - MAE_: 0.2290 - RMSLE: 0.7540 - VAL_: 0.9411 - mean_squared_error: 9275958.4829 - MAPE_: 0.5710 - val_loss: 1156.2257 - val_MAE_: 1153.8020 - val_RMSLE: 1.1902 - val_VAL_: 1154.4220 - val_mean_squared_error: 171383157.9956 - val_MAPE_: 1.1791\n",
            "Epoch 30/100\n",
            "3480650/3480650 [==============================] - 32s 9us/step - loss: 1.7738 - MAE_: 0.2277 - RMSLE: 0.7513 - VAL_: 0.9417 - mean_squared_error: 9369798.1682 - MAPE_: 0.5683 - val_loss: 1669.3365 - val_MAE_: 1666.8527 - val_RMSLE: 1.2200 - val_VAL_: 1667.4969 - val_mean_squared_error: 234564780.1352 - val_MAPE_: 1.2093\n",
            "Epoch 31/100\n",
            "3480650/3480650 [==============================] - 32s 9us/step - loss: 1.7944 - MAE_: 0.2324 - RMSLE: 0.7591 - VAL_: 0.9388 - mean_squared_error: 9934130.8756 - MAPE_: 0.5763 - val_loss: 1598.2072 - val_MAE_: 1595.6258 - val_RMSLE: 1.2684 - val_VAL_: 1596.1516 - val_mean_squared_error: 168618048.9339 - val_MAPE_: 1.2880\n",
            "Epoch 32/100\n",
            "3480650/3480650 [==============================] - 33s 9us/step - loss: 1.7922 - MAE_: 0.2309 - RMSLE: 0.7585 - VAL_: 0.9410 - mean_squared_error: 9377299.7680 - MAPE_: 0.5752 - val_loss: 1126.1571 - val_MAE_: 1123.7460 - val_RMSLE: 1.1834 - val_VAL_: 1124.3255 - val_mean_squared_error: 208375651.6634 - val_MAPE_: 1.1732\n",
            "Epoch 33/100\n",
            "3480650/3480650 [==============================] - 32s 9us/step - loss: 1.7688 - MAE_: 0.2265 - RMSLE: 0.7489 - VAL_: 0.9417 - mean_squared_error: 9188492.3444 - MAPE_: 0.5668 - val_loss: 1218.6805 - val_MAE_: 1216.2481 - val_RMSLE: 1.1939 - val_VAL_: 1216.7828 - val_mean_squared_error: 269638726.2949 - val_MAPE_: 1.1746\n",
            "Epoch 34/100\n",
            "3480650/3480650 [==============================] - 32s 9us/step - loss: 1.7709 - MAE_: 0.2270 - RMSLE: 0.7496 - VAL_: 0.9421 - mean_squared_error: 9221351.1319 - MAPE_: 0.5674 - val_loss: 1337.0001 - val_MAE_: 1334.4743 - val_RMSLE: 1.2405 - val_VAL_: 1335.0873 - val_mean_squared_error: 211220190.7582 - val_MAPE_: 1.2273\n",
            "Epoch 35/100\n",
            "3480650/3480650 [==============================] - 33s 9us/step - loss: 1.7868 - MAE_: 0.2305 - RMSLE: 0.7556 - VAL_: 0.9404 - mean_squared_error: 9445609.2627 - MAPE_: 0.5738 - val_loss: 1265.2819 - val_MAE_: 1262.6963 - val_RMSLE: 1.2699 - val_VAL_: 1263.2705 - val_mean_squared_error: 120645644.4817 - val_MAPE_: 1.2678\n",
            "Epoch 36/100\n",
            "3480650/3480650 [==============================] - 33s 9us/step - loss: 1.7684 - MAE_: 0.2269 - RMSLE: 0.7481 - VAL_: 0.9424 - mean_squared_error: 9364216.8912 - MAPE_: 0.5658 - val_loss: 1514.2245 - val_MAE_: 1511.7599 - val_RMSLE: 1.2096 - val_VAL_: 1512.4078 - val_mean_squared_error: 244221872.6347 - val_MAPE_: 1.2005\n",
            "Epoch 37/100\n",
            "3480650/3480650 [==============================] - 33s 9us/step - loss: 1.7667 - MAE_: 0.2265 - RMSLE: 0.7474 - VAL_: 0.9422 - mean_squared_error: 9258625.0288 - MAPE_: 0.5648 - val_loss: 1579.2987 - val_MAE_: 1576.7319 - val_RMSLE: 1.2606 - val_VAL_: 1577.3291 - val_mean_squared_error: 204504170.5491 - val_MAPE_: 1.2646\n",
            "Epoch 38/100\n",
            "3480650/3480650 [==============================] - 33s 9us/step - loss: 1.7715 - MAE_: 0.2272 - RMSLE: 0.7493 - VAL_: 0.9406 - mean_squared_error: 9322347.6258 - MAPE_: 0.5675 - val_loss: 1680.2973 - val_MAE_: 1677.8426 - val_RMSLE: 1.2045 - val_VAL_: 1678.4889 - val_mean_squared_error: 225404327.1559 - val_MAPE_: 1.1926\n",
            "Epoch 39/100\n",
            "3480650/3480650 [==============================] - 33s 10us/step - loss: 1.7728 - MAE_: 0.2275 - RMSLE: 0.7496 - VAL_: 0.9419 - mean_squared_error: 9397899.1679 - MAPE_: 0.5677 - val_loss: 1423.9032 - val_MAE_: 1421.4473 - val_RMSLE: 1.2048 - val_VAL_: 1422.0424 - val_mean_squared_error: 244440875.8595 - val_MAPE_: 1.1943\n",
            "Epoch 40/100\n",
            "3480650/3480650 [==============================] - 35s 10us/step - loss: 1.7710 - MAE_: 0.2274 - RMSLE: 0.7486 - VAL_: 0.9421 - mean_squared_error: 9206414.3988 - MAPE_: 0.5671 - val_loss: 1499.3020 - val_MAE_: 1496.8525 - val_RMSLE: 1.2015 - val_VAL_: 1497.4945 - val_mean_squared_error: 170471553.3647 - val_MAPE_: 1.1948\n",
            "Epoch 41/100\n",
            "3480650/3480650 [==============================] - 33s 9us/step - loss: 1.7580 - MAE_: 0.2249 - RMSLE: 0.7433 - VAL_: 0.9424 - mean_squared_error: 9261375.7670 - MAPE_: 0.5609 - val_loss: 1185.6839 - val_MAE_: 1183.2551 - val_RMSLE: 1.1912 - val_VAL_: 1183.8430 - val_mean_squared_error: 214813964.7020 - val_MAPE_: 1.1781\n",
            "Epoch 42/100\n",
            "3480650/3480650 [==============================] - 33s 9us/step - loss: 1.7608 - MAE_: 0.2251 - RMSLE: 0.7445 - VAL_: 0.9419 - mean_squared_error: 9183333.5287 - MAPE_: 0.5625 - val_loss: 1509.5179 - val_MAE_: 1507.0888 - val_RMSLE: 1.1910 - val_VAL_: 1507.7015 - val_mean_squared_error: 289447660.7712 - val_MAPE_: 1.1794\n",
            "Epoch 43/100\n",
            "3480650/3480650 [==============================] - 33s 9us/step - loss: 1.7614 - MAE_: 0.2256 - RMSLE: 0.7443 - VAL_: 0.9432 - mean_squared_error: 9229022.4520 - MAPE_: 0.5636 - val_loss: 1697.0455 - val_MAE_: 1694.6277 - val_RMSLE: 1.1852 - val_VAL_: 1695.2602 - val_mean_squared_error: 251571499.8450 - val_MAPE_: 1.1822\n",
            "Epoch 44/100\n",
            "3480650/3480650 [==============================] - 33s 10us/step - loss: 1.7560 - MAE_: 0.2251 - RMSLE: 0.7417 - VAL_: 0.9421 - mean_squared_error: 9225301.4788 - MAPE_: 0.5608 - val_loss: 1333.0359 - val_MAE_: 1330.6196 - val_RMSLE: 1.1845 - val_VAL_: 1331.2156 - val_mean_squared_error: 186028290.6291 - val_MAPE_: 1.1798\n",
            "Epoch 45/100\n",
            "3480650/3480650 [==============================] - 33s 10us/step - loss: 1.7558 - MAE_: 0.2247 - RMSLE: 0.7417 - VAL_: 0.9425 - mean_squared_error: 9260129.6494 - MAPE_: 0.5613 - val_loss: 1664.2038 - val_MAE_: 1661.7258 - val_RMSLE: 1.2151 - val_VAL_: 1662.3860 - val_mean_squared_error: 214330084.9560 - val_MAPE_: 1.2140\n",
            "Epoch 46/100\n",
            "3480650/3480650 [==============================] - 33s 9us/step - loss: 1.7549 - MAE_: 0.2246 - RMSLE: 0.7412 - VAL_: 0.9431 - mean_squared_error: 8984047.6405 - MAPE_: 0.5615 - val_loss: 1473.9762 - val_MAE_: 1471.5056 - val_RMSLE: 1.2113 - val_VAL_: 1472.1490 - val_mean_squared_error: 204683921.9060 - val_MAPE_: 1.2031\n",
            "Epoch 47/100\n",
            "3480650/3480650 [==============================] - 33s 9us/step - loss: 1.7587 - MAE_: 0.2256 - RMSLE: 0.7425 - VAL_: 0.9430 - mean_squared_error: 9165927.7775 - MAPE_: 0.5630 - val_loss: 1771.9716 - val_MAE_: 1769.4581 - val_RMSLE: 1.2325 - val_VAL_: 1770.1258 - val_mean_squared_error: 182614202.6018 - val_MAPE_: 1.2296\n",
            "Epoch 48/100\n",
            "3480650/3480650 [==============================] - 33s 9us/step - loss: 1.7518 - MAE_: 0.2244 - RMSLE: 0.7395 - VAL_: 0.9432 - mean_squared_error: 9155927.8770 - MAPE_: 0.5592 - val_loss: 1291.6139 - val_MAE_: 1289.2108 - val_RMSLE: 1.1774 - val_VAL_: 1289.8055 - val_mean_squared_error: 188230266.7829 - val_MAPE_: 1.1707\n",
            "Epoch 49/100\n",
            "3480650/3480650 [==============================] - 33s 9us/step - loss: 1.7455 - MAE_: 0.2228 - RMSLE: 0.7371 - VAL_: 0.9433 - mean_squared_error: 9092735.4646 - MAPE_: 0.5572 - val_loss: 1521.9723 - val_MAE_: 1519.5491 - val_RMSLE: 1.1873 - val_VAL_: 1520.1939 - val_mean_squared_error: 226724780.0389 - val_MAPE_: 1.1735\n",
            "Epoch 50/100\n",
            "3480650/3480650 [==============================] - 33s 10us/step - loss: 1.7519 - MAE_: 0.2247 - RMSLE: 0.7393 - VAL_: 0.9430 - mean_squared_error: 9113468.6768 - MAPE_: 0.5594 - val_loss: 1324.0706 - val_MAE_: 1321.6055 - val_RMSLE: 1.2080 - val_VAL_: 1322.2199 - val_mean_squared_error: 182902242.3531 - val_MAPE_: 1.1930\n",
            "Epoch 51/100\n",
            "3480650/3480650 [==============================] - 33s 9us/step - loss: 1.7678 - MAE_: 0.2261 - RMSLE: 0.7464 - VAL_: 0.9421 - mean_squared_error: 9206688.8248 - MAPE_: 0.5657 - val_loss: 1412.3940 - val_MAE_: 1409.9579 - val_RMSLE: 1.1935 - val_VAL_: 1410.5794 - val_mean_squared_error: 187344151.7105 - val_MAPE_: 1.1899\n",
            "Epoch 52/100\n",
            "3480650/3480650 [==============================] - 33s 10us/step - loss: 1.7533 - MAE_: 0.2255 - RMSLE: 0.7393 - VAL_: 0.9419 - mean_squared_error: 9296764.5447 - MAPE_: 0.5598 - val_loss: 1779.3306 - val_MAE_: 1776.8501 - val_RMSLE: 1.2156 - val_VAL_: 1777.4962 - val_mean_squared_error: 233053290.6682 - val_MAPE_: 1.2090\n",
            "Epoch 53/100\n",
            "3480650/3480650 [==============================] - 33s 10us/step - loss: 1.7578 - MAE_: 0.2255 - RMSLE: 0.7414 - VAL_: 0.9423 - mean_squared_error: 9076746.9099 - MAPE_: 0.5619 - val_loss: 1457.9282 - val_MAE_: 1455.4960 - val_RMSLE: 1.1913 - val_VAL_: 1456.1501 - val_mean_squared_error: 252358335.4461 - val_MAPE_: 1.1865\n",
            "Epoch 54/100\n",
            "3480650/3480650 [==============================] - 34s 10us/step - loss: 1.7554 - MAE_: 0.2262 - RMSLE: 0.7398 - VAL_: 0.9421 - mean_squared_error: 9204476.2755 - MAPE_: 0.5603 - val_loss: 1483.2719 - val_MAE_: 1480.8338 - val_RMSLE: 1.1942 - val_VAL_: 1481.4936 - val_mean_squared_error: 166101538.8599 - val_MAPE_: 1.1896\n",
            "\n",
            "Epoch 00054: ReduceLROnPlateau reducing learning rate to 0.002100000064820051.\n",
            "Epoch 55/100\n",
            "3480650/3480650 [==============================] - 35s 10us/step - loss: 1.6546 - MAE_: 0.2104 - RMSLE: 0.6974 - VAL_: 0.9477 - mean_squared_error: 8881096.4660 - MAPE_: 0.5201 - val_loss: 1319.7315 - val_MAE_: 1317.3532 - val_RMSLE: 1.1646 - val_VAL_: 1318.0032 - val_mean_squared_error: 190930874.4118 - val_MAPE_: 1.1511\n",
            "Epoch 56/100\n",
            "3480650/3480650 [==============================] - 35s 10us/step - loss: 1.6387 - MAE_: 0.2080 - RMSLE: 0.6909 - VAL_: 0.9488 - mean_squared_error: 8801957.1645 - MAPE_: 0.5147 - val_loss: 1234.8866 - val_MAE_: 1232.5121 - val_RMSLE: 1.1629 - val_VAL_: 1233.1940 - val_mean_squared_error: 207246040.3128 - val_MAPE_: 1.1570\n",
            "Epoch 57/100\n",
            "3480650/3480650 [==============================] - 39s 11us/step - loss: 1.6310 - MAE_: 0.2061 - RMSLE: 0.6882 - VAL_: 0.9482 - mean_squared_error: 8733704.5392 - MAPE_: 0.5128 - val_loss: 1276.7935 - val_MAE_: 1274.4323 - val_RMSLE: 1.1564 - val_VAL_: 1275.0714 - val_mean_squared_error: 229775720.1717 - val_MAPE_: 1.1471\n",
            "Epoch 58/100\n",
            "3480650/3480650 [==============================] - 36s 10us/step - loss: 1.6272 - MAE_: 0.2059 - RMSLE: 0.6865 - VAL_: 0.9488 - mean_squared_error: 8741212.3463 - MAPE_: 0.5115 - val_loss: 1374.1757 - val_MAE_: 1371.8017 - val_RMSLE: 1.1629 - val_VAL_: 1372.4749 - val_mean_squared_error: 223456008.4458 - val_MAPE_: 1.1551\n",
            "Epoch 59/100\n",
            "3480650/3480650 [==============================] - 36s 10us/step - loss: 1.6255 - MAE_: 0.2058 - RMSLE: 0.6858 - VAL_: 0.9487 - mean_squared_error: 8692241.7454 - MAPE_: 0.5101 - val_loss: 1314.2100 - val_MAE_: 1311.8321 - val_RMSLE: 1.1649 - val_VAL_: 1312.4932 - val_mean_squared_error: 213096919.6068 - val_MAPE_: 1.1573\n",
            "Epoch 60/100\n",
            "3480650/3480650 [==============================] - 34s 10us/step - loss: 1.6221 - MAE_: 0.2052 - RMSLE: 0.6844 - VAL_: 0.9488 - mean_squared_error: 8726593.4391 - MAPE_: 0.5094 - val_loss: 1278.1557 - val_MAE_: 1275.7960 - val_RMSLE: 1.1559 - val_VAL_: 1276.4704 - val_mean_squared_error: 247603409.8822 - val_MAPE_: 1.1488\n",
            "Epoch 61/100\n",
            "3480650/3480650 [==============================] - 34s 10us/step - loss: 1.6208 - MAE_: 0.2053 - RMSLE: 0.6838 - VAL_: 0.9494 - mean_squared_error: 8727711.2964 - MAPE_: 0.5087 - val_loss: 1258.8513 - val_MAE_: 1256.4974 - val_RMSLE: 1.1530 - val_VAL_: 1257.1628 - val_mean_squared_error: 222746833.1634 - val_MAPE_: 1.1464\n",
            "Epoch 62/100\n",
            "3480650/3480650 [==============================] - 33s 10us/step - loss: 1.6198 - MAE_: 0.2046 - RMSLE: 0.6837 - VAL_: 0.9500 - mean_squared_error: 8652006.5649 - MAPE_: 0.5088 - val_loss: 1442.6636 - val_MAE_: 1440.3316 - val_RMSLE: 1.1421 - val_VAL_: 1440.9600 - val_mean_squared_error: 204407873.1034 - val_MAPE_: 1.1326\n",
            "Epoch 63/100\n",
            "3480650/3480650 [==============================] - 34s 10us/step - loss: 1.6170 - MAE_: 0.2047 - RMSLE: 0.6823 - VAL_: 0.9499 - mean_squared_error: 8705234.9289 - MAPE_: 0.5072 - val_loss: 1263.2724 - val_MAE_: 1260.9275 - val_RMSLE: 1.1487 - val_VAL_: 1261.5820 - val_mean_squared_error: 214048505.4931 - val_MAPE_: 1.1395\n",
            "Epoch 64/100\n",
            "3480650/3480650 [==============================] - 34s 10us/step - loss: 1.6134 - MAE_: 0.2033 - RMSLE: 0.6813 - VAL_: 0.9495 - mean_squared_error: 8644390.1802 - MAPE_: 0.5066 - val_loss: 1494.5391 - val_MAE_: 1492.1966 - val_RMSLE: 1.1475 - val_VAL_: 1492.8709 - val_mean_squared_error: 199565374.8616 - val_MAPE_: 1.1404\n",
            "Epoch 65/100\n",
            "3480650/3480650 [==============================] - 33s 9us/step - loss: 1.6131 - MAE_: 0.2034 - RMSLE: 0.6811 - VAL_: 0.9498 - mean_squared_error: 8652631.3927 - MAPE_: 0.5061 - val_loss: 1736.7863 - val_MAE_: 1734.4095 - val_RMSLE: 1.1647 - val_VAL_: 1735.1008 - val_mean_squared_error: 218924140.7049 - val_MAPE_: 1.1543\n",
            "Epoch 66/100\n",
            "3480650/3480650 [==============================] - 33s 10us/step - loss: 1.6124 - MAE_: 0.2041 - RMSLE: 0.6805 - VAL_: 0.9491 - mean_squared_error: 8710314.4550 - MAPE_: 0.5061 - val_loss: 1738.7987 - val_MAE_: 1736.4347 - val_RMSLE: 1.1582 - val_VAL_: 1737.1349 - val_mean_squared_error: 216453679.4494 - val_MAPE_: 1.1529\n",
            "Epoch 67/100\n",
            "3480650/3480650 [==============================] - 33s 9us/step - loss: 1.6114 - MAE_: 0.2041 - RMSLE: 0.6800 - VAL_: 0.9497 - mean_squared_error: 8695418.5679 - MAPE_: 0.5053 - val_loss: 1342.9753 - val_MAE_: 1340.6219 - val_RMSLE: 1.1531 - val_VAL_: 1341.2593 - val_mean_squared_error: 214623690.1675 - val_MAPE_: 1.1432\n",
            "Epoch 68/100\n",
            "3480650/3480650 [==============================] - 33s 9us/step - loss: 1.6083 - MAE_: 0.2032 - RMSLE: 0.6789 - VAL_: 0.9497 - mean_squared_error: 8599961.4731 - MAPE_: 0.5044 - val_loss: 1149.5815 - val_MAE_: 1147.2219 - val_RMSLE: 1.1562 - val_VAL_: 1147.8408 - val_mean_squared_error: 197915825.4426 - val_MAPE_: 1.1399\n",
            "Epoch 69/100\n",
            "3480650/3480650 [==============================] - 33s 9us/step - loss: 1.6078 - MAE_: 0.2032 - RMSLE: 0.6788 - VAL_: 0.9504 - mean_squared_error: 8681111.8028 - MAPE_: 0.5038 - val_loss: 1392.3072 - val_MAE_: 1389.9428 - val_RMSLE: 1.1586 - val_VAL_: 1390.6083 - val_mean_squared_error: 206827743.8320 - val_MAPE_: 1.1489\n",
            "Epoch 70/100\n",
            "3480650/3480650 [==============================] - 33s 9us/step - loss: 1.6085 - MAE_: 0.2035 - RMSLE: 0.6790 - VAL_: 0.9504 - mean_squared_error: 8623696.2402 - MAPE_: 0.5048 - val_loss: 1598.7662 - val_MAE_: 1596.4146 - val_RMSLE: 1.1523 - val_VAL_: 1597.0950 - val_mean_squared_error: 226998181.3494 - val_MAPE_: 1.1442\n",
            "Epoch 71/100\n",
            "3480650/3480650 [==============================] - 33s 9us/step - loss: 1.6072 - MAE_: 0.2035 - RMSLE: 0.6783 - VAL_: 0.9500 - mean_squared_error: 8679055.5325 - MAPE_: 0.5040 - val_loss: 1577.9474 - val_MAE_: 1575.5861 - val_RMSLE: 1.1572 - val_VAL_: 1576.2610 - val_mean_squared_error: 215507268.3166 - val_MAPE_: 1.1438\n",
            "Epoch 72/100\n",
            "3480650/3480650 [==============================] - 33s 9us/step - loss: 1.6063 - MAE_: 0.2025 - RMSLE: 0.6784 - VAL_: 0.9503 - mean_squared_error: 8573565.3839 - MAPE_: 0.5042 - val_loss: 1454.5817 - val_MAE_: 1452.2407 - val_RMSLE: 1.1470 - val_VAL_: 1452.9145 - val_mean_squared_error: 238142711.8072 - val_MAPE_: 1.1403\n",
            "Epoch 73/100\n",
            "3480650/3480650 [==============================] - 33s 9us/step - loss: 1.6064 - MAE_: 0.2027 - RMSLE: 0.6784 - VAL_: 0.9501 - mean_squared_error: 8824231.8484 - MAPE_: 0.5036 - val_loss: 1342.8975 - val_MAE_: 1340.5542 - val_RMSLE: 1.1483 - val_VAL_: 1341.2097 - val_mean_squared_error: 231551762.7675 - val_MAPE_: 1.1391\n",
            "Epoch 74/100\n",
            "3480650/3480650 [==============================] - 33s 10us/step - loss: 1.6057 - MAE_: 0.2029 - RMSLE: 0.6780 - VAL_: 0.9503 - mean_squared_error: 8679391.7936 - MAPE_: 0.5038 - val_loss: 1468.2230 - val_MAE_: 1465.8410 - val_RMSLE: 1.1676 - val_VAL_: 1466.5213 - val_mean_squared_error: 195456361.9928 - val_MAPE_: 1.1644\n",
            "Epoch 75/100\n",
            "3480650/3480650 [==============================] - 34s 10us/step - loss: 1.6030 - MAE_: 0.2027 - RMSLE: 0.6768 - VAL_: 0.9500 - mean_squared_error: 8832956.0705 - MAPE_: 0.5025 - val_loss: 1236.5713 - val_MAE_: 1234.2326 - val_RMSLE: 1.1459 - val_VAL_: 1234.8850 - val_mean_squared_error: 209060520.5223 - val_MAPE_: 1.1359\n",
            "Epoch 76/100\n",
            "3480650/3480650 [==============================] - 33s 9us/step - loss: 1.6009 - MAE_: 0.2023 - RMSLE: 0.6760 - VAL_: 0.9503 - mean_squared_error: 8663452.9344 - MAPE_: 0.5017 - val_loss: 1257.8226 - val_MAE_: 1255.4843 - val_RMSLE: 1.1458 - val_VAL_: 1256.1410 - val_mean_squared_error: 213080256.4465 - val_MAPE_: 1.1391\n",
            "Epoch 77/100\n",
            "3480650/3480650 [==============================] - 33s 9us/step - loss: 1.6013 - MAE_: 0.2022 - RMSLE: 0.6762 - VAL_: 0.9503 - mean_squared_error: 8594778.2046 - MAPE_: 0.5018 - val_loss: 1323.1107 - val_MAE_: 1320.7602 - val_RMSLE: 1.1520 - val_VAL_: 1321.4341 - val_mean_squared_error: 204610322.7116 - val_MAPE_: 1.1459\n",
            "Epoch 78/100\n",
            "3480650/3480650 [==============================] - 32s 9us/step - loss: 1.6059 - MAE_: 0.2030 - RMSLE: 0.6781 - VAL_: 0.9500 - mean_squared_error: 8705165.7737 - MAPE_: 0.5031 - val_loss: 1453.2905 - val_MAE_: 1450.9200 - val_RMSLE: 1.1620 - val_VAL_: 1451.6125 - val_mean_squared_error: 209226009.9564 - val_MAPE_: 1.1491\n",
            "Epoch 79/100\n",
            "3480650/3480650 [==============================] - 32s 9us/step - loss: 1.6037 - MAE_: 0.2029 - RMSLE: 0.6771 - VAL_: 0.9505 - mean_squared_error: 8668021.3804 - MAPE_: 0.5025 - val_loss: 1272.2430 - val_MAE_: 1269.8855 - val_RMSLE: 1.1556 - val_VAL_: 1270.5598 - val_mean_squared_error: 207091466.8950 - val_MAPE_: 1.1426\n",
            "Epoch 80/100\n",
            "3480650/3480650 [==============================] - 32s 9us/step - loss: 1.5967 - MAE_: 0.2017 - RMSLE: 0.6742 - VAL_: 0.9505 - mean_squared_error: 8629174.0865 - MAPE_: 0.5002 - val_loss: 1625.3072 - val_MAE_: 1622.9469 - val_RMSLE: 1.1569 - val_VAL_: 1623.6439 - val_mean_squared_error: 203874000.9130 - val_MAPE_: 1.1447\n",
            "Epoch 81/100\n",
            "3480650/3480650 [==============================] - 32s 9us/step - loss: 1.5974 - MAE_: 0.2021 - RMSLE: 0.6745 - VAL_: 0.9502 - mean_squared_error: 8727094.2651 - MAPE_: 0.5003 - val_loss: 1190.3078 - val_MAE_: 1187.9773 - val_RMSLE: 1.1421 - val_VAL_: 1188.6196 - val_mean_squared_error: 213014646.5908 - val_MAPE_: 1.1393\n",
            "Epoch 82/100\n",
            "3480650/3480650 [==============================] - 33s 9us/step - loss: 1.5982 - MAE_: 0.2013 - RMSLE: 0.6752 - VAL_: 0.9512 - mean_squared_error: 8747418.3194 - MAPE_: 0.5011 - val_loss: 1535.6715 - val_MAE_: 1533.3496 - val_RMSLE: 1.1378 - val_VAL_: 1534.0130 - val_mean_squared_error: 208641442.9639 - val_MAPE_: 1.1307\n",
            "Epoch 83/100\n",
            "3480650/3480650 [==============================] - 32s 9us/step - loss: 1.5981 - MAE_: 0.2019 - RMSLE: 0.6749 - VAL_: 0.9513 - mean_squared_error: 8660394.4844 - MAPE_: 0.5005 - val_loss: 1369.8663 - val_MAE_: 1367.5226 - val_RMSLE: 1.1488 - val_VAL_: 1368.2118 - val_mean_squared_error: 215084159.2788 - val_MAPE_: 1.1401\n",
            "Epoch 84/100\n",
            "3480650/3480650 [==============================] - 32s 9us/step - loss: 1.5970 - MAE_: 0.2022 - RMSLE: 0.6743 - VAL_: 0.9516 - mean_squared_error: 8645602.6366 - MAPE_: 0.5005 - val_loss: 1541.0967 - val_MAE_: 1538.7110 - val_RMSLE: 1.1697 - val_VAL_: 1539.3969 - val_mean_squared_error: 207625269.5035 - val_MAPE_: 1.1537\n",
            "Epoch 85/100\n",
            "3480650/3480650 [==============================] - 32s 9us/step - loss: 1.5984 - MAE_: 0.2017 - RMSLE: 0.6752 - VAL_: 0.9505 - mean_squared_error: 8586403.7832 - MAPE_: 0.5005 - val_loss: 1469.1650 - val_MAE_: 1466.8264 - val_RMSLE: 1.1462 - val_VAL_: 1467.4912 - val_mean_squared_error: 173260604.2604 - val_MAPE_: 1.1317\n",
            "\n",
            "Epoch 00085: ReduceLROnPlateau reducing learning rate to 0.0006300000473856926.\n",
            "Epoch 86/100\n",
            "3480650/3480650 [==============================] - 33s 9us/step - loss: 1.5582 - MAE_: 0.1965 - RMSLE: 0.6578 - VAL_: 0.9513 - mean_squared_error: 8529102.2672 - MAPE_: 0.4859 - val_loss: 1407.3779 - val_MAE_: 1405.0596 - val_RMSLE: 1.1362 - val_VAL_: 1405.7545 - val_mean_squared_error: 218109925.8664 - val_MAPE_: 1.1258\n",
            "Epoch 87/100\n",
            "3480650/3480650 [==============================] - 32s 9us/step - loss: 1.5534 - MAE_: 0.1956 - RMSLE: 0.6559 - VAL_: 0.9525 - mean_squared_error: 8463066.6921 - MAPE_: 0.4844 - val_loss: 1407.8305 - val_MAE_: 1405.5098 - val_RMSLE: 1.1373 - val_VAL_: 1406.1970 - val_mean_squared_error: 214105177.0045 - val_MAPE_: 1.1261\n",
            "Epoch 88/100\n",
            "3480650/3480650 [==============================] - 33s 9us/step - loss: 1.5509 - MAE_: 0.1955 - RMSLE: 0.6547 - VAL_: 0.9521 - mean_squared_error: 8461602.3309 - MAPE_: 0.4841 - val_loss: 1383.1771 - val_MAE_: 1380.8565 - val_RMSLE: 1.1374 - val_VAL_: 1381.5525 - val_mean_squared_error: 209615272.2188 - val_MAPE_: 1.1270\n",
            "Epoch 89/100\n",
            "3480650/3480650 [==============================] - 32s 9us/step - loss: 1.5503 - MAE_: 0.1954 - RMSLE: 0.6545 - VAL_: 0.9526 - mean_squared_error: 8433375.9939 - MAPE_: 0.4836 - val_loss: 1338.6953 - val_MAE_: 1336.3767 - val_RMSLE: 1.1364 - val_VAL_: 1337.0685 - val_mean_squared_error: 203912517.0245 - val_MAPE_: 1.1258\n",
            "Epoch 90/100\n",
            "3480650/3480650 [==============================] - 32s 9us/step - loss: 1.5504 - MAE_: 0.1954 - RMSLE: 0.6546 - VAL_: 0.9521 - mean_squared_error: 8478387.9178 - MAPE_: 0.4837 - val_loss: 1343.5241 - val_MAE_: 1341.2063 - val_RMSLE: 1.1360 - val_VAL_: 1341.8964 - val_mean_squared_error: 208807800.4999 - val_MAPE_: 1.1287\n",
            "Epoch 91/100\n",
            "3480650/3480650 [==============================] - 33s 9us/step - loss: 1.5495 - MAE_: 0.1952 - RMSLE: 0.6542 - VAL_: 0.9524 - mean_squared_error: 8427580.8543 - MAPE_: 0.4834 - val_loss: 1264.6096 - val_MAE_: 1262.2909 - val_RMSLE: 1.1365 - val_VAL_: 1262.9749 - val_mean_squared_error: 215838943.3263 - val_MAPE_: 1.1278\n",
            "Epoch 92/100\n",
            "3480650/3480650 [==============================] - 32s 9us/step - loss: 1.5474 - MAE_: 0.1948 - RMSLE: 0.6534 - VAL_: 0.9527 - mean_squared_error: 8453411.8029 - MAPE_: 0.4829 - val_loss: 1308.9913 - val_MAE_: 1306.6743 - val_RMSLE: 1.1356 - val_VAL_: 1307.3551 - val_mean_squared_error: 205416286.3613 - val_MAPE_: 1.1234\n",
            "Epoch 93/100\n",
            "3480650/3480650 [==============================] - 32s 9us/step - loss: 1.5472 - MAE_: 0.1948 - RMSLE: 0.6533 - VAL_: 0.9528 - mean_squared_error: 8419618.2700 - MAPE_: 0.4830 - val_loss: 1341.6787 - val_MAE_: 1339.3592 - val_RMSLE: 1.1369 - val_VAL_: 1340.0449 - val_mean_squared_error: 215837835.2763 - val_MAPE_: 1.1257\n",
            "Epoch 94/100\n",
            "3480650/3480650 [==============================] - 32s 9us/step - loss: 1.5466 - MAE_: 0.1950 - RMSLE: 0.6529 - VAL_: 0.9534 - mean_squared_error: 8463191.3068 - MAPE_: 0.4830 - val_loss: 1328.5705 - val_MAE_: 1326.2600 - val_RMSLE: 1.1324 - val_VAL_: 1326.9496 - val_mean_squared_error: 200030367.2673 - val_MAPE_: 1.1248\n",
            "Epoch 95/100\n",
            "3480650/3480650 [==============================] - 32s 9us/step - loss: 1.5448 - MAE_: 0.1950 - RMSLE: 0.6520 - VAL_: 0.9529 - mean_squared_error: 8434713.3877 - MAPE_: 0.4822 - val_loss: 1310.8799 - val_MAE_: 1308.5556 - val_RMSLE: 1.1393 - val_VAL_: 1309.2300 - val_mean_squared_error: 203406489.5011 - val_MAPE_: 1.1274\n",
            "Epoch 96/100\n",
            "3480650/3480650 [==============================] - 32s 9us/step - loss: 1.5447 - MAE_: 0.1945 - RMSLE: 0.6522 - VAL_: 0.9525 - mean_squared_error: 8425502.3767 - MAPE_: 0.4825 - val_loss: 1308.4502 - val_MAE_: 1306.1454 - val_RMSLE: 1.1296 - val_VAL_: 1306.8347 - val_mean_squared_error: 200196021.7580 - val_MAPE_: 1.1214\n",
            "Epoch 97/100\n",
            "3480650/3480650 [==============================] - 32s 9us/step - loss: 1.5450 - MAE_: 0.1950 - RMSLE: 0.6521 - VAL_: 0.9526 - mean_squared_error: 8451194.1461 - MAPE_: 0.4825 - val_loss: 1293.9051 - val_MAE_: 1291.6013 - val_RMSLE: 1.1291 - val_VAL_: 1292.2754 - val_mean_squared_error: 203345607.6517 - val_MAPE_: 1.1217\n",
            "Epoch 98/100\n",
            "3480650/3480650 [==============================] - 32s 9us/step - loss: 1.5432 - MAE_: 0.1944 - RMSLE: 0.6516 - VAL_: 0.9526 - mean_squared_error: 8378079.7617 - MAPE_: 0.4817 - val_loss: 1403.2717 - val_MAE_: 1400.9623 - val_RMSLE: 1.1319 - val_VAL_: 1401.6506 - val_mean_squared_error: 213648986.3051 - val_MAPE_: 1.1223\n",
            "Epoch 99/100\n",
            "3480650/3480650 [==============================] - 32s 9us/step - loss: 1.5437 - MAE_: 0.1947 - RMSLE: 0.6517 - VAL_: 0.9532 - mean_squared_error: 8421139.0434 - MAPE_: 0.4820 - val_loss: 1272.0884 - val_MAE_: 1269.7865 - val_RMSLE: 1.1282 - val_VAL_: 1270.4590 - val_mean_squared_error: 204923074.2411 - val_MAPE_: 1.1195\n",
            "Epoch 100/100\n",
            "3480650/3480650 [==============================] - 33s 9us/step - loss: 1.5433 - MAE_: 0.1946 - RMSLE: 0.6516 - VAL_: 0.9527 - mean_squared_error: 8368274.5773 - MAPE_: 0.4821 - val_loss: 1403.0245 - val_MAE_: 1400.7164 - val_RMSLE: 1.1313 - val_VAL_: 1401.4059 - val_mean_squared_error: 216440279.7817 - val_MAPE_: 1.1224\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHKu4TMG8ROI",
        "colab_type": "code",
        "outputId": "b96db1ea-2a20-4a11-c57e-2d40a97f3335",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "if 2==2:\n",
        "  reg = 0.000001\n",
        "  meter = 2\n",
        "  epochs = 30\n",
        "  batch_size = 200\n",
        "  opt = Adam(lr = 0.002)\n",
        "\n",
        "  earlyStopping = EarlyStopping(monitor='loss', patience=30, verbose=1, mode='min')\n",
        "  reduce_lr_loss = ReduceLROnPlateau(monitor='loss', factor=0.2, patience=55, verbose=1, min_delta=1e-3, mode='min')\n",
        "  model_checkpoint = ModelCheckpoint(monitor='loss', save_best_only=True, filepath = DIR + 'best_nn_' + str(meter) + '.model', save_weights_only = False, verbose=0, mode='min')\n",
        "\n",
        "  nn_2 = Sequential()\n",
        "  nn_2.add(Dense(90, input_shape = df[In_Columns].shape[1:], activation = 'tanh', kernel_regularizer=l1(reg), kernel_initializer = keras.initializers.RandomUniform(minval=-0.25, maxval=0.25, seed=None), bias_initializer=keras.initializers.Constant(0.1)))\n",
        "  nn_2.add(Dense(90, activation = 'tanh',  kernel_initializer = keras.initializers.RandomUniform(minval=-0.25, maxval=0.25, seed=None), bias_initializer=keras.initializers.Constant(0.1)))\n",
        "  nn_2.add(Dense( 1, activation = 'relu', kernel_initializer = 'normal'))\n",
        "\n",
        "  nn_2.compile(optimizer = opt, loss = RMSLE, metrics=[ MAE_, RMSLE, VAL_, 'mse', MAPE_ ])\n",
        "  \n",
        "  val = df[(df['meter']==meter) & (df['day']%6==0)]\n",
        "  hist = nn_2.fit( df[(df['meter']==meter) & (df['IS_BAD_PRCNT']<0.75)][In_Columns], df[(df['meter']==meter) & (df['IS_BAD_PRCNT']<0.75)][Out_Columns], batch_size = batch_size, verbose = 1\n",
        "                  , epochs = epochs, shuffle = True, callbacks=[earlyStopping, reduce_lr_loss,model_checkpoint]\n",
        "                  , validation_data=(val[In_Columns], val[Out_Columns])\n",
        "                  ) \n",
        "  nn_2.save(DIR + str(meter) + 'HANDLY_SAVED2.MODEL')\n",
        "  gc.collect()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2472929 samples, validate on 452118 samples\n",
            "Epoch 1/30\n",
            "2472929/2472929 [==============================] - 49s 20us/step - loss: 2.0180 - MAE_: 0.9270 - RMSLE: 2.0170 - VAL_: 0.0941 - mean_squared_error: 191872564395.5270 - MAPE_: 1.1104 - val_loss: 1.6678 - val_MAE_: 541.4093 - val_RMSLE: 1.6659 - val_VAL_: 541.2938 - val_mean_squared_error: 169433291613.2108 - val_MAPE_: 1.2422\n",
            "Epoch 2/30\n",
            "2472929/2472929 [==============================] - 48s 19us/step - loss: 1.5503 - MAE_: 0.8697 - RMSLE: 1.5481 - VAL_: 0.1540 - mean_squared_error: 191862971330.2757 - MAPE_: 0.9241 - val_loss: 1.5453 - val_MAE_: 464.9667 - val_RMSLE: 1.5428 - val_VAL_: 464.9392 - val_mean_squared_error: 169428064791.7653 - val_MAPE_: 1.1740\n",
            "Epoch 3/30\n",
            "2472929/2472929 [==============================] - 47s 19us/step - loss: 1.4483 - MAE_: 0.8475 - RMSLE: 1.4455 - VAL_: 0.1779 - mean_squared_error: 191858303957.0333 - MAPE_: 0.8800 - val_loss: 1.4738 - val_MAE_: 615.4066 - val_RMSLE: 1.4708 - val_VAL_: 615.4104 - val_mean_squared_error: 169424549232.2797 - val_MAPE_: 1.1220\n",
            "Epoch 4/30\n",
            "2472929/2472929 [==============================] - 47s 19us/step - loss: 1.3957 - MAE_: 0.8326 - RMSLE: 1.3924 - VAL_: 0.1953 - mean_squared_error: 191854947773.7390 - MAPE_: 0.8570 - val_loss: 1.4495 - val_MAE_: 800.4387 - val_RMSLE: 1.4461 - val_VAL_: 800.5197 - val_mean_squared_error: 169421859653.7607 - val_MAPE_: 1.1046\n",
            "Epoch 5/30\n",
            "2472929/2472929 [==============================] - 48s 19us/step - loss: 1.3633 - MAE_: 0.8217 - RMSLE: 1.3598 - VAL_: 0.2077 - mean_squared_error: 191852228842.6564 - MAPE_: 0.8409 - val_loss: 1.4175 - val_MAE_: 757.6064 - val_RMSLE: 1.4137 - val_VAL_: 757.7131 - val_mean_squared_error: 169419727047.9259 - val_MAPE_: 1.0795\n",
            "Epoch 6/30\n",
            "2472929/2472929 [==============================] - 48s 19us/step - loss: 1.3395 - MAE_: 0.8128 - RMSLE: 1.3357 - VAL_: 0.2178 - mean_squared_error: 191849945000.3514 - MAPE_: 0.8297 - val_loss: 1.3941 - val_MAE_: 935.4752 - val_RMSLE: 1.3901 - val_VAL_: 935.5850 - val_mean_squared_error: 169417781737.0968 - val_MAPE_: 1.0472\n",
            "Epoch 7/30\n",
            "2472929/2472929 [==============================] - 48s 19us/step - loss: 1.3201 - MAE_: 0.8056 - RMSLE: 1.3160 - VAL_: 0.2261 - mean_squared_error: 191847905660.4386 - MAPE_: 0.8201 - val_loss: 1.3948 - val_MAE_: 1292.9728 - val_RMSLE: 1.3907 - val_VAL_: 1293.1574 - val_mean_squared_error: 169416057880.9301 - val_MAPE_: 1.0686\n",
            "Epoch 8/30\n",
            "2472929/2472929 [==============================] - 50s 20us/step - loss: 1.3049 - MAE_: 0.7999 - RMSLE: 1.3006 - VAL_: 0.2327 - mean_squared_error: 191846136466.0785 - MAPE_: 0.8154 - val_loss: 1.3888 - val_MAE_: 1340.8168 - val_RMSLE: 1.3844 - val_VAL_: 1341.0054 - val_mean_squared_error: 169414523496.8567 - val_MAPE_: 1.0897\n",
            "Epoch 9/30\n",
            "2472929/2472929 [==============================] - 48s 19us/step - loss: 1.2911 - MAE_: 0.7945 - RMSLE: 1.2866 - VAL_: 0.2389 - mean_squared_error: 191844536055.2882 - MAPE_: 0.8068 - val_loss: 1.3744 - val_MAE_: 1138.8136 - val_RMSLE: 1.3699 - val_VAL_: 1138.9269 - val_mean_squared_error: 169413191738.1331 - val_MAPE_: 1.0577\n",
            "Epoch 10/30\n",
            "2472929/2472929 [==============================] - 47s 19us/step - loss: 1.2788 - MAE_: 0.7897 - RMSLE: 1.2742 - VAL_: 0.2444 - mean_squared_error: 191843101533.7103 - MAPE_: 0.7999 - val_loss: 1.3594 - val_MAE_: 1234.1283 - val_RMSLE: 1.3548 - val_VAL_: 1234.2777 - val_mean_squared_error: 169411892848.7751 - val_MAPE_: 1.0340\n",
            "Epoch 11/30\n",
            "2472929/2472929 [==============================] - 47s 19us/step - loss: 1.2692 - MAE_: 0.7851 - RMSLE: 1.2645 - VAL_: 0.2499 - mean_squared_error: 191841745232.3731 - MAPE_: 0.7944 - val_loss: 1.3520 - val_MAE_: 1201.6812 - val_RMSLE: 1.3472 - val_VAL_: 1201.8394 - val_mean_squared_error: 169410824359.9656 - val_MAPE_: 1.0478\n",
            "Epoch 12/30\n",
            "2472929/2472929 [==============================] - 48s 19us/step - loss: 1.2599 - MAE_: 0.7818 - RMSLE: 1.2550 - VAL_: 0.2539 - mean_squared_error: 191840474202.2989 - MAPE_: 0.7907 - val_loss: 1.3623 - val_MAE_: 1498.7125 - val_RMSLE: 1.3573 - val_VAL_: 1498.9471 - val_mean_squared_error: 169409634575.3047 - val_MAPE_: 1.0395\n",
            "Epoch 13/30\n",
            "2472929/2472929 [==============================] - 47s 19us/step - loss: 1.2539 - MAE_: 0.7775 - RMSLE: 1.2489 - VAL_: 0.2591 - mean_squared_error: 191839301064.7098 - MAPE_: 0.7873 - val_loss: 1.3391 - val_MAE_: 1391.7534 - val_RMSLE: 1.3340 - val_VAL_: 1391.9312 - val_mean_squared_error: 169408626082.6045 - val_MAPE_: 1.0197\n",
            "Epoch 14/30\n",
            "2472929/2472929 [==============================] - 48s 19us/step - loss: 1.2478 - MAE_: 0.7740 - RMSLE: 1.2427 - VAL_: 0.2632 - mean_squared_error: 191838192408.5338 - MAPE_: 0.7800 - val_loss: 1.3403 - val_MAE_: 1735.5570 - val_RMSLE: 1.3351 - val_VAL_: 1735.7816 - val_mean_squared_error: 169407658378.1137 - val_MAPE_: 1.0303\n",
            "Epoch 15/30\n",
            "2472929/2472929 [==============================] - 48s 19us/step - loss: 1.2399 - MAE_: 0.7714 - RMSLE: 1.2347 - VAL_: 0.2665 - mean_squared_error: 191837125711.0959 - MAPE_: 0.7804 - val_loss: 1.3432 - val_MAE_: 1798.7418 - val_RMSLE: 1.3379 - val_VAL_: 1798.9938 - val_mean_squared_error: 169406743103.9354 - val_MAPE_: 1.0488\n",
            "Epoch 16/30\n",
            "2472929/2472929 [==============================] - 50s 20us/step - loss: 1.2333 - MAE_: 0.7682 - RMSLE: 1.2280 - VAL_: 0.2701 - mean_squared_error: 191836127763.3065 - MAPE_: 0.7754 - val_loss: 1.3655 - val_MAE_: 2233.9974 - val_RMSLE: 1.3602 - val_VAL_: 2234.3425 - val_mean_squared_error: 169405846396.9702 - val_MAPE_: 1.0751\n",
            "Epoch 17/30\n",
            "2472929/2472929 [==============================] - 48s 19us/step - loss: 1.2282 - MAE_: 0.7658 - RMSLE: 1.2228 - VAL_: 0.2730 - mean_squared_error: 191835166378.9926 - MAPE_: 0.7738 - val_loss: 1.3340 - val_MAE_: 1871.8757 - val_RMSLE: 1.3285 - val_VAL_: 1872.1374 - val_mean_squared_error: 169405003658.0845 - val_MAPE_: 1.0375\n",
            "Epoch 18/30\n",
            "2472929/2472929 [==============================] - 48s 19us/step - loss: 1.2223 - MAE_: 0.7626 - RMSLE: 1.2168 - VAL_: 0.2768 - mean_squared_error: 191834204946.0751 - MAPE_: 0.7710 - val_loss: 1.3448 - val_MAE_: 2025.0714 - val_RMSLE: 1.3392 - val_VAL_: 2025.3867 - val_mean_squared_error: 169404181095.5714 - val_MAPE_: 1.0565\n",
            "Epoch 19/30\n",
            "2472929/2472929 [==============================] - 47s 19us/step - loss: 1.2185 - MAE_: 0.7613 - RMSLE: 1.2130 - VAL_: 0.2784 - mean_squared_error: 191833345731.4961 - MAPE_: 0.7678 - val_loss: 1.3195 - val_MAE_: 2063.8284 - val_RMSLE: 1.3139 - val_VAL_: 2064.0874 - val_mean_squared_error: 169403365830.1996 - val_MAPE_: 1.0190\n",
            "Epoch 20/30\n",
            "2472929/2472929 [==============================] - 47s 19us/step - loss: 1.2145 - MAE_: 0.7585 - RMSLE: 1.2088 - VAL_: 0.2821 - mean_squared_error: 191832500705.7356 - MAPE_: 0.7666 - val_loss: 1.3287 - val_MAE_: 2103.7359 - val_RMSLE: 1.3230 - val_VAL_: 2104.0334 - val_mean_squared_error: 169402685320.5582 - val_MAPE_: 1.0282\n",
            "Epoch 21/30\n",
            "2472929/2472929 [==============================] - 48s 19us/step - loss: 1.2099 - MAE_: 0.7570 - RMSLE: 1.2042 - VAL_: 0.2838 - mean_squared_error: 191831655779.6959 - MAPE_: 0.7629 - val_loss: 1.3038 - val_MAE_: 1978.2973 - val_RMSLE: 1.2981 - val_VAL_: 1978.5459 - val_mean_squared_error: 169401926520.5940 - val_MAPE_: 0.9929\n",
            "Epoch 22/30\n",
            "2472929/2472929 [==============================] - 49s 20us/step - loss: 1.2061 - MAE_: 0.7546 - RMSLE: 1.2003 - VAL_: 0.2869 - mean_squared_error: 191830871338.6986 - MAPE_: 0.7617 - val_loss: 1.3110 - val_MAE_: 1686.6271 - val_RMSLE: 1.3052 - val_VAL_: 1686.8622 - val_mean_squared_error: 169401286122.3091 - val_MAPE_: 1.0059\n",
            "Epoch 23/30\n",
            "2472929/2472929 [==============================] - 50s 20us/step - loss: 1.2037 - MAE_: 0.7532 - RMSLE: 1.1978 - VAL_: 0.2883 - mean_squared_error: 191830126879.5840 - MAPE_: 0.7605 - val_loss: 1.3222 - val_MAE_: 1901.2037 - val_RMSLE: 1.3163 - val_VAL_: 1901.4638 - val_mean_squared_error: 169400525950.6499 - val_MAPE_: 1.0371\n",
            "Epoch 24/30\n",
            "2472929/2472929 [==============================] - 54s 22us/step - loss: 1.1995 - MAE_: 0.7512 - RMSLE: 1.1936 - VAL_: 0.2906 - mean_squared_error: 191829405580.4193 - MAPE_: 0.7578 - val_loss: 1.3217 - val_MAE_: 2263.1605 - val_RMSLE: 1.3157 - val_VAL_: 2263.4974 - val_mean_squared_error: 169399979134.8419 - val_MAPE_: 1.0345\n",
            "Epoch 25/30\n",
            "2472929/2472929 [==============================] - 50s 20us/step - loss: 1.1956 - MAE_: 0.7485 - RMSLE: 1.1896 - VAL_: 0.2936 - mean_squared_error: 191828680122.4714 - MAPE_: 0.7557 - val_loss: 1.2947 - val_MAE_: 1767.3507 - val_RMSLE: 1.2886 - val_VAL_: 1767.5901 - val_mean_squared_error: 169399344908.7603 - val_MAPE_: 1.0099\n",
            "Epoch 26/30\n",
            "2472929/2472929 [==============================] - 47s 19us/step - loss: 1.1924 - MAE_: 0.7473 - RMSLE: 1.1864 - VAL_: 0.2951 - mean_squared_error: 191827993472.2451 - MAPE_: 0.7536 - val_loss: 1.2963 - val_MAE_: 1915.9916 - val_RMSLE: 1.2902 - val_VAL_: 1916.2529 - val_mean_squared_error: 169398687769.3315 - val_MAPE_: 1.0032\n",
            "Epoch 27/30\n",
            "2472929/2472929 [==============================] - 48s 19us/step - loss: 1.1908 - MAE_: 0.7451 - RMSLE: 1.1847 - VAL_: 0.2978 - mean_squared_error: 191827312144.4064 - MAPE_: 0.7537 - val_loss: 1.2969 - val_MAE_: 1828.8401 - val_RMSLE: 1.2907 - val_VAL_: 1829.1260 - val_mean_squared_error: 169398113225.6223 - val_MAPE_: 1.0045\n",
            "Epoch 28/30\n",
            "2472929/2472929 [==============================] - 47s 19us/step - loss: 1.1872 - MAE_: 0.7437 - RMSLE: 1.1811 - VAL_: 0.2998 - mean_squared_error: 191826685758.3571 - MAPE_: 0.7511 - val_loss: 1.3084 - val_MAE_: 2119.0382 - val_RMSLE: 1.3022 - val_VAL_: 2119.3632 - val_mean_squared_error: 169397477798.9009 - val_MAPE_: 1.0166\n",
            "Epoch 29/30\n",
            "2472929/2472929 [==============================] - 48s 19us/step - loss: 1.1845 - MAE_: 0.7425 - RMSLE: 1.1782 - VAL_: 0.3012 - mean_squared_error: 191826033072.8339 - MAPE_: 0.7489 - val_loss: 1.2916 - val_MAE_: 1911.8954 - val_RMSLE: 1.2853 - val_VAL_: 1912.1845 - val_mean_squared_error: 169396991761.7934 - val_MAPE_: 1.0064\n",
            "Epoch 30/30\n",
            "2472929/2472929 [==============================] - 47s 19us/step - loss: 1.1819 - MAE_: 0.7411 - RMSLE: 1.1756 - VAL_: 0.3031 - mean_squared_error: 191825448647.1233 - MAPE_: 0.7484 - val_loss: 1.2847 - val_MAE_: 1855.4563 - val_RMSLE: 1.2784 - val_VAL_: 1855.7257 - val_mean_squared_error: 169396484646.8224 - val_MAPE_: 0.9810\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PlNOAoppy96",
        "colab_type": "code",
        "outputId": "df3dfecb-85c9-40ba-fb3e-a064cc779c02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "source": [
        "# lr = 0.002 , 0.003, \n",
        "#nn_2 = keras.models.load_model (DIR + '2HANDLY_SAVED2.MODEL')\n",
        "opt = Adam(lr = 0.003)\n",
        "batch_size = 100\n",
        "epochs = 7\n",
        "nn_2.compile(optimizer = opt, loss = RMSLE, metrics=[ MAE_, RMSLE, VAL_, 'mse', MAPE_ ])\n",
        "hist = nn_2.fit( df[(df['meter']==meter) & (df['IS_BAD_PRCNT']<0.75)][In_Columns], df[(df['meter']==meter) & (df['IS_BAD_PRCNT']<0.75)][Out_Columns], batch_size = batch_size, verbose = 1\n",
        "                , epochs = epochs, shuffle = True, callbacks=[ earlyStopping, reduce_lr_loss,model_checkpoint] #MyCustomCallback(epochs, 1),\n",
        "                , validation_data=(val[In_Columns], val[Out_Columns])\n",
        "                ) \n",
        "#nn_2.save(DIR + str(meter) + 'HANDLY_SAVED2.MODEL')\n",
        "gc.collect()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2472929 samples, validate on 452118 samples\n",
            "Epoch 1/7\n",
            "2472929/2472929 [==============================] - 95s 38us/step - loss: 1.1182 - MAE_: 0.6283 - RMSLE: 1.1081 - VAL_: 0.4489 - mean_squared_error: 191791595936.2869 - MAPE_: 0.7218 - val_loss: 1.2308 - val_MAE_: 1932.1225 - val_RMSLE: 1.2206 - val_VAL_: 1932.5107 - val_mean_squared_error: 169366125348.6926 - val_MAPE_: 0.9620\n",
            "Epoch 2/7\n",
            "2472929/2472929 [==============================] - 91s 37us/step - loss: 1.1205 - MAE_: 0.6277 - RMSLE: 1.1103 - VAL_: 0.4499 - mean_squared_error: 191791394989.8452 - MAPE_: 0.7230 - val_loss: 1.2266 - val_MAE_: 1810.8363 - val_RMSLE: 1.2164 - val_VAL_: 1811.2358 - val_mean_squared_error: 169366073902.7854 - val_MAPE_: 0.9515\n",
            "Epoch 3/7\n",
            "2472929/2472929 [==============================] - 92s 37us/step - loss: 1.1216 - MAE_: 0.6277 - RMSLE: 1.1113 - VAL_: 0.4507 - mean_squared_error: 191791174908.4149 - MAPE_: 0.7246 - val_loss: 1.2402 - val_MAE_: 2236.8498 - val_RMSLE: 1.2299 - val_VAL_: 2237.2510 - val_mean_squared_error: 169365684840.5385 - val_MAPE_: 0.9521\n",
            "Epoch 4/7\n",
            "2472929/2472929 [==============================] - 91s 37us/step - loss: 1.1222 - MAE_: 0.6269 - RMSLE: 1.1118 - VAL_: 0.4514 - mean_squared_error: 191790657373.4933 - MAPE_: 0.7223 - val_loss: 1.2432 - val_MAE_: 2176.2326 - val_RMSLE: 1.2328 - val_VAL_: 2176.6292 - val_mean_squared_error: 169365477490.7056 - val_MAPE_: 0.9661\n",
            "Epoch 5/7\n",
            "2472929/2472929 [==============================] - 91s 37us/step - loss: 1.1242 - MAE_: 0.6274 - RMSLE: 1.1138 - VAL_: 0.4512 - mean_squared_error: 191790481057.0456 - MAPE_: 0.7258 - val_loss: 1.2190 - val_MAE_: 2176.6421 - val_RMSLE: 1.2085 - val_VAL_: 2177.0279 - val_mean_squared_error: 169365609914.7251 - val_MAPE_: 0.9350\n",
            "Epoch 6/7\n",
            "2472929/2472929 [==============================] - 92s 37us/step - loss: 1.1242 - MAE_: 0.6266 - RMSLE: 1.1137 - VAL_: 0.4523 - mean_squared_error: 191790045581.8690 - MAPE_: 0.7238 - val_loss: 1.2205 - val_MAE_: 2090.7500 - val_RMSLE: 1.2100 - val_VAL_: 2091.1403 - val_mean_squared_error: 169365083993.2913 - val_MAPE_: 0.9325\n",
            "Epoch 7/7\n",
            "2472929/2472929 [==============================] - 94s 38us/step - loss: 1.1227 - MAE_: 0.6261 - RMSLE: 1.1121 - VAL_: 0.4522 - mean_squared_error: 191789987548.4536 - MAPE_: 0.7235 - val_loss: 1.2352 - val_MAE_: 2177.7456 - val_RMSLE: 1.2245 - val_VAL_: 2178.2066 - val_mean_squared_error: 169364382973.8654 - val_MAPE_: 0.9752\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "46"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdad7yTx8Uri",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if 3==3:\n",
        "  meter = 3\n",
        "  epochs = 30\n",
        "  batch_size = 200\n",
        "  opt = Adam(lr = 0.00002)\n",
        "\n",
        "  earlyStopping = EarlyStopping(monitor='loss', patience=50, verbose=1, mode='min')\n",
        "  reduce_lr_loss = ReduceLROnPlateau(monitor='loss', factor=0.2, patience=10, verbose=1, min_delta=1e-3, mode='min')\n",
        "  model_checkpoint = ModelCheckpoint(monitor='loss', save_best_only=True, filepath = DIR + 'best_nn_' + str(meter) + '.model', save_weights_only = False, verbose=0, mode='min')\n",
        "\n",
        "  nn_3 = Sequential()\n",
        "  nn_3.add(Dense(45, input_shape = df[In_Columns].shape[1:], activation = 'relu', kernel_regularizer=l1(reg), kernel_initializer = 'normal', bias_initializer=keras.initializers.Constant(0.1)))\n",
        "  nn_3.add(Dense(45, activation = 'relu',  kernel_initializer = 'normal', bias_initializer=keras.initializers.Constant(0.1)))\n",
        "  nn_3.add(Dense(70, activation = 'relu',  kernel_initializer = 'normal', bias_initializer=keras.initializers.Constant(0.1)))\n",
        "  nn_3.add(Dense(1, activation = 'relu', kernel_initializer = 'normal'))\n",
        "\n",
        "  nn_3.compile(optimizer = opt, loss = RMSLE, metrics=[ MAE_, RMSLE, VAL_, 'mse', MAPE_ ])\n",
        "  \n",
        "  val = df[(df['meter']==meter) & (df['day']%6==0)]\n",
        "  hist = nn_3.fit( df[(df['meter']==meter) & (df['IS_BAD_PRCNT']<0.25)][In_Columns], df[(df['meter']==meter) & (df['IS_BAD_PRCNT']<0.25)][Out_Columns], batch_size = batch_size, verbose = 1\n",
        "                  , epochs = epochs, shuffle = True, callbacks=[earlyStopping, reduce_lr_loss]\n",
        "                  , validation_data=(val[In_Columns], val[Out_Columns])\n",
        "                  ) \n",
        "  nn_3.save(DIR + str(meter) + 'HANDLY_SAVED2.MODEL')\n",
        "  gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38XziDvm_mhH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for lr in [0.00004,0.00007,0.0002,0.0007]:\n",
        "  opt = Adam(lr = lr)\n",
        "  epochs = 50\n",
        "  nn_3.compile(optimizer = opt, loss = RMSLE, metrics=[ MAE_, RMSLE, VAL_, 'mse', MAPE_ ])\n",
        "  hist = nn_3.fit( df[(df['meter']==meter) & (df['IS_BAD_PRCNT']<0.25)][In_Columns], df[(df['meter']==meter) & (df['IS_BAD_PRCNT']<0.25)][Out_Columns], batch_size = batch_size, verbose = 1\n",
        "                  , epochs = epochs, shuffle = True, callbacks=[earlyStopping, reduce_lr_loss]\n",
        "                  , validation_data=(val[In_Columns], val[Out_Columns])\n",
        "                  ) \n",
        "  nn_3.save(DIR + str(meter) + 'HANDLY_SAVED3.MODEL')\n",
        "  gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H75KbUGtAdOG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#nn_3.save(DIR + str(meter) + 'HANDLY_SAVED.MODEL')\n",
        "# keras.initializers.RandomUniform(minval=-0.05, maxval=0.05, seed=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zWSKYPSOjpz",
        "colab_type": "code",
        "outputId": "c70e25c2-b1d6-46d7-9962-9809aadfa861",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "nn_0 = keras.models.load_model (DIR + '0HANDLY_SAVED2.MODEL')\n",
        "nn_1 = keras.models.load_model (DIR + '1HANDLY_SAVED2.MODEL')\n",
        "nn_2 = keras.models.load_model (DIR + '2HANDLY_SAVED2.MODEL')\n",
        "nn_3 = keras.models.load_model (DIR + '3HANDLY_SAVED3.MODEL')\n",
        "\n",
        "# score = model.evaluate(X, Y, verbose=0)\n",
        "# print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))\n",
        "gc.collect()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "907"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xsuPcIPCvW2",
        "colab_type": "code",
        "outputId": "baaeacd8-f9fe-49be-8491-b69d1ea8b605",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Предсказание из 4х значений:\n",
        "  df['NN_PRED'] = 0\n",
        "  df['NN_PRED_0'] = nn_0.predict(df[In_Columns], batch_size = 10000) \n",
        "  df['NN_PRED_1'] = nn_1.predict(df[In_Columns], batch_size = 10000) \n",
        "  df['NN_PRED_2'] = nn_2.predict(df[In_Columns], batch_size = 10000) \n",
        "  df['NN_PRED_3'] = nn_3.predict(df[In_Columns], batch_size = 10000) \n",
        "  df['NN_PRED'] = np.where(df['meter'] == 0, df['NN_PRED_0'], df['NN_PRED'])\n",
        "  df['NN_PRED'] = np.where(df['meter'] == 1, df['NN_PRED_1'], df['NN_PRED'])\n",
        "  df['NN_PRED'] = np.where(df['meter'] == 2, df['NN_PRED_2'], df['NN_PRED'])\n",
        "  df['NN_PRED'] = np.where(df['meter'] == 3, df['NN_PRED_3'], df['NN_PRED'])\n",
        "  df.drop(columns = ['NN_PRED_0', 'NN_PRED_1', 'NN_PRED_2', 'NN_PRED_3'], inplace = True)\n",
        "  #df.drop(columns = ['Value_x', 'Value_y'])\n",
        "  gc.collect()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9zp6mbpLAgV",
        "colab_type": "code",
        "outputId": "363f0f3a-0af2-403b-e812-bfb3cb4478f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "df.columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['building_id', 'meter', 'timestamp', 'meter_reading', 'hour_cos', 'hour_sin', 'weekday_cos',\n",
              "       'weekday_sin', 'week_cos', 'week_sin', 'meter_reading_prev', 'is_equal_prev', 'day',\n",
              "       'IS_BAD_PRCNT', 'building_meter_median', 'hour', 'building_meter_hour_median', 'weekday',\n",
              "       'building_meter_weekday_median', 'site_id', 'square_feet', 'year_built', 'floor_count',\n",
              "       'primary_use_ID', 'primary_use_Education', 'primary_use_Entertainment/public assembly',\n",
              "       'primary_use_Food sales and service', 'primary_use_Healthcare',\n",
              "       'primary_use_Lodging/residential', 'primary_use_Manufacturing/industrial',\n",
              "       'primary_use_Office', 'primary_use_Other', 'primary_use_Parking',\n",
              "       'primary_use_Public services', 'primary_use_Religious worship', 'primary_use_Retail',\n",
              "       'primary_use_Services', 'primary_use_Technology/science', 'primary_use_Utility',\n",
              "       'primary_use_Warehouse/storage', 'air_temperature', 'cloud_coverage', 'dew_temperature',\n",
              "       'precip_depth_1_hr', 'sea_level_pressure', 'wind_direction', 'wind_speed', 'NN_PRED'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1W6pmrQFgyS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df[['meter','meter_reading','NN_PRED','NN_PRED_0','NN_PRED_1','NN_PRED_2','NN_PRED_3']].head(-10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jV_7qcb1EK2t",
        "colab_type": "code",
        "outputId": "94525e46-75b2-4b86-f38c-04a5f963e176",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "df['NN_ERR'] = np.abs(df['NN_PRED']-df['meter_reading'])\n",
        "print( np.sqrt( np.mean( np.power(np.log(df['meter_reading']+1) - np.log(df['NN_ERR']+1),2.00000)))     )\n",
        "print('Ошибка 0: ', np.sqrt( np.mean( np.power(np.log(df[df['meter']==0]['meter_reading']+1) - np.log(df[df['meter']==0]['NN_ERR']+1),2.00000)))        )\n",
        "print('Ошибка 1: ', np.sqrt( np.mean( np.power(np.log(df[df['meter']==1]['meter_reading']+1) - np.log(df[df['meter']==1]['NN_ERR']+1),2.00000)))        )\n",
        "print('Ошибка 2: ', np.sqrt( np.mean( np.power(np.log(df[df['meter']==2]['meter_reading']+1) - np.log(df[df['meter']==2]['NN_ERR']+1),2.00000)))        )\n",
        "print('Ошибка 3: ', np.sqrt( np.mean( np.power(np.log(df[df['meter']==3]['meter_reading']+1) - np.log(df[df['meter']==3]['NN_ERR']+1),2.00000)))        )\n",
        "gc.collect()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.31600296573249\n",
            "Ошибка 0:  2.367548887649364\n",
            "Ошибка 1:  2.3341838812051288\n",
            "Ошибка 2:  2.0793432874515667\n",
            "Ошибка 3:  2.238230002103621\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSg8qh29X2xl",
        "colab_type": "code",
        "outputId": "8d729bd6-c18c-4fff-a056-6e29e7bbf0ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        }
      },
      "source": [
        "#Evaluate:\n",
        "  score = nn_0.evaluate(df[df['meter']==0][In_Columns], df[df['meter']==0][Out_Columns], verbose=1, batch_size = 30000)\n",
        "  print(0)\n",
        "  for i in range(len(nn_0.metrics_names)):\n",
        "    print(\"%s: %.2f%%\" % (nn_0.metrics_names[i], score[i]*100))\n",
        "\n",
        "  score = nn_1.evaluate(df[df['meter']==1][In_Columns], df[df['meter']==1][Out_Columns], verbose=1, batch_size = 30000)\n",
        "  print(1)\n",
        "  for i in range(len(nn_1.metrics_names)):\n",
        "    print(\"%s: %.2f%%\" % (nn_1.metrics_names[i], score[i]*100))\n",
        "\n",
        "  score = nn_2.evaluate(df[df['meter']==2][In_Columns], df[df['meter']==2][Out_Columns], verbose=1, batch_size = 30000)\n",
        "  print(2)\n",
        "  for i in range(len(nn_2.metrics_names)):\n",
        "    print(\"%s: %.2f%%\" % (nn_2.metrics_names[i], score[i]*100))\n",
        "\n",
        "  score = nn_3.evaluate(df[df['meter']==3][In_Columns], df[df['meter']==3][Out_Columns], verbose=1, batch_size = 30000)\n",
        "  print(3)\n",
        "  for i in range(len(nn_3.metrics_names)):\n",
        "    print(\"%s: %.2f%%\" % (nn_3.metrics_names[i], score[i]*100))\n",
        "  \n",
        "  gc.collect()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12060910/12060910 [==============================] - 8s 1us/step\n",
            "0\n",
            "loss: 170.45%\n",
            "MAE_: 24.68%\n",
            "RMSLE: 71.74%\n",
            "VAL_: 99.94%\n",
            "mean_squared_error: 5708678.46%\n",
            "4182440/4182440 [==============================] - 3s 1us/step\n",
            "1\n",
            "loss: 285.79%\n",
            "MAE_: 35.68%\n",
            "RMSLE: 122.78%\n",
            "VAL_: 106.37%\n",
            "mean_squared_error: 21240470135.76%\n",
            "MAPE_: 110.34%\n",
            "2708713/2708713 [==============================] - 3s 1us/step\n",
            "2\n",
            "loss: 144.15%\n",
            "MAE_: 44.32%\n",
            "RMSLE: 143.14%\n",
            "VAL_: 80.47%\n",
            "mean_squared_error: 17509703899499.42%\n",
            "MAPE_: 96.45%\n",
            "1264037/1264037 [==============================] - 2s 2us/step\n",
            "3\n",
            "loss: 183.52%\n",
            "MAE_: 72.77%\n",
            "RMSLE: 183.44%\n",
            "VAL_: 117.16%\n",
            "mean_squared_error: 512614985.23%\n",
            "MAPE_: 187.52%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "36"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1FvwRcpe45J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "outputId": "9e299df6-417a-447b-c6dd-b3bca18260f6"
      },
      "source": [
        "ИДЕИ:\n",
        "  1) Сделать не показатель, а его отклонение от медианы по строению/дню/часу\n",
        "  2) \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-14-08fa9165ed26>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    ИДЕИ:\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRkbaJjBUGZP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "0d9ed502-c07f-4eb5-b3f0-95d814a7150e"
      },
      "source": [
        "# Подготовка данных тест:\n",
        "  df_test = pd.read_csv(DIR + \"test.csv\", engine = 'python')\n",
        "  print('Забрали с диска')\n",
        "  df_test['timestamp'] = pd.to_datetime(df_test['timestamp'])\n",
        "\n",
        "  df_test['hour_cos'] = np.cos(df_test['timestamp'].dt.hour * 2 * np.pi / 24)\n",
        "  df_test['hour_sin'] = np.sin(df_test['timestamp'].dt.hour * 2 * np.pi / 24)\n",
        "\n",
        "  df_test['weekday_cos'] = np.cos(df_test['timestamp'].dt.weekday * 2 * np.pi / 7)\n",
        "  df_test['weekday_sin'] = np.sin(df_test['timestamp'].dt.weekday * 2 * np.pi / 7)\n",
        "\n",
        "  df_test['week_cos'] = np.cos(df_test['timestamp'].dt.week * 2 * np.pi / 53)\n",
        "  df_test['week_sin'] = np.sin(df_test['timestamp'].dt.week * 2 * np.pi / 53)\n",
        "# Добавление медианы по метрике постройки\n",
        "  df_median = df.groupby(by=['building_id','meter'])['meter_reading'].median()\n",
        "  df_median.name = 'building_meter_median'\n",
        "  df_test = pd.merge(df_test, df_median, how = 'inner', on = ['building_id','meter'])\n",
        "  del df_median \n",
        "  gc.collect()\n",
        "  print('Построены медианы по сооружению')\n",
        "# Добавление медианы по часу, по неделе, метрике постройки\n",
        "  df_test['hour'] = df_test['timestamp'].dt.hour\n",
        "  df_median = df.groupby(by=['building_id','hour','meter'])['meter_reading'].median()\n",
        "  df_median.name = 'building_meter_hour_median'\n",
        "  df_test = pd.merge(df_test, df_median, how = 'inner', on = ['building_id','hour','meter'])\n",
        "  del df_median \n",
        "  gc.collect()\n",
        "  df_test['weekday'] = df_test['timestamp'].dt.weekday\n",
        "  df_median = df.groupby(by=['building_id','weekday','meter'])['meter_reading'].median()\n",
        "  df_median.name = 'building_meter_weekday_median'\n",
        "  df_test = pd.merge(df_test, df_median, how = 'inner', on = ['building_id','weekday','meter'])\n",
        "  del df_median \n",
        "  print('Построены медианы по сооружению/часу')\n",
        "  gc.collect()\n",
        "# Подстановка параметров сооружения\n",
        "  building_df = pd.read_csv(DIR + \"building_metadata.csv\", engine = 'python')\n",
        "  from sklearn.preprocessing import LabelEncoder\n",
        "  le = LabelEncoder()\n",
        "  building_df[\"primary_use_ID\"] = le.fit_transform(building_df[\"primary_use\"])\n",
        "\n",
        "  building_df['primary_use'] = building_df['primary_use'].astype('category')\n",
        "  building_df = pd.get_dummies(building_df)\n",
        "\n",
        "  df_test = df_test.merge(building_df, left_on = \"building_id\", right_on = \"building_id\", how = \"left\")\n",
        "  del building_df\n",
        "  print('Подставлены данные по сооружению')\n",
        "  gc.collect()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Забрали с диска\n",
            "Построены медианы по сооружению\n",
            "Построены медианы по сооружению/часу\n",
            "Подставлены данные по сооружению\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gZDPAWaD0M5n",
        "colab": {}
      },
      "source": [
        "#Вставка данных погоды\n",
        "#Восстановление пустых данных погоды через соседей по линейной инетрполяции\n",
        "  df_weather = pd.read_csv(DIR + \"weather_test.csv\", engine = 'python')\n",
        "  df_weather['timestamp'] = pd.to_datetime(df_weather['timestamp'])\n",
        "\n",
        "  #weather_train.groupby('site_id').apply(lambda group: group.isna().sum())\n",
        "  df_times = df_test.drop_duplicates(['site_id','timestamp'])[['site_id','timestamp']]\n",
        "  df_times = pd.merge(df_times, df_weather, how = 'left', on = ['site_id','timestamp'])\n",
        "  df_times = df_times.sort_values(by = ['site_id','timestamp'])\n",
        "  \n",
        "  df_times = df_times.groupby('site_id').apply(lambda group: group.interpolate(limit_direction='both'))\n",
        "  df_test = pd.merge(df, df_times, how = 'left', on = ['site_id','timestamp'])\n",
        "  del df_weather, df_times"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "letD2V2gB_nm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Нормализация\n",
        "  df_test[In_Columns]     = pd.DataFrame(data = scaler.transform( df_test[In_Columns])    , columns = df_test[In_Columns].columns   , index=df_test.index) \n",
        "  df_test.fillna(0.33)\n",
        "  gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFdbTS8qCl8h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Выбор нейронок:\n",
        "  nn_0 = keras.models.load_model (DIR + '0HANDLY_SAVED.MODEL')\n",
        "  nn_1 = keras.models.load_model (DIR + '1HANDLY_SAVED.MODEL')\n",
        "  nn_2 = keras.models.load_model (DIR + '2HANDLY_SAVED.MODEL')\n",
        "  nn_3 = keras.models.load_model (DIR + '3HANDLY_SAVED.MODEL')\n",
        "  # score = model.evaluate(X, Y, verbose=0)\n",
        "  # print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))\n",
        "  gc.collect()\n",
        "#Предсказание из 4х значений:\n",
        "  df_test['NN_PRED'] = 0\n",
        "  df_test['NN_PRED_0'] = nn_0.predict(df_test[In_Columns], batch_size = 10000) \n",
        "  df_test['NN_PRED_1'] = nn_1.predict(df_test[In_Columns], batch_size = 10000) \n",
        "  df_test['NN_PRED_2'] = nn_2.predict(df_test[In_Columns], batch_size = 10000) \n",
        "  df_test['NN_PRED_3'] = nn_3.predict(df_test[In_Columns], batch_size = 10000) \n",
        "  df_test['NN_PRED'] = np.where(df_test['meter'] == 0, df_test['NN_PRED_0'], df_test['NN_PRED'])\n",
        "  df_test['NN_PRED'] = np.where(df_test['meter'] == 1, df_test['NN_PRED_1'], df_test['NN_PRED'])\n",
        "  df_test['NN_PRED'] = np.where(df_test['meter'] == 2, df_test['NN_PRED_2'], df_test['NN_PRED'])\n",
        "  df_test['NN_PRED'] = np.where(df_test['meter'] == 3, df_test['NN_PRED_3'], df_test['NN_PRED'])\n",
        "  df_test.drop(columns = ['NN_PRED_0', 'NN_PRED_1', 'NN_PRED_2', 'NN_PRED_3'], inplace = True)\n",
        "  #df.drop(columns = ['Value_x', 'Value_y'])\n",
        "  gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXmjfkrQC61e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_test['row_id']         = df_test['row_id'].astype('Int32')\n",
        "df_test['meter_reading']  = df_test['NN_PRED'].astype('float16')\n",
        "df_test[['row_id', 'meter_reading']].to_csv(DIR+'OUT_Ver0.2.csv', index = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQROkITbUGhO",
        "colab_type": "code",
        "outputId": "1b54844d-763e-44e2-8b1c-91621daa6d82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 813
        }
      },
      "source": [
        "df_test.head(-10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>row_id</th>\n",
              "      <th>building_id</th>\n",
              "      <th>meter</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>hour_cos</th>\n",
              "      <th>hour_sin</th>\n",
              "      <th>weekday_cos</th>\n",
              "      <th>weekday_sin</th>\n",
              "      <th>week_cos</th>\n",
              "      <th>week_sin</th>\n",
              "      <th>building_meter_median</th>\n",
              "      <th>hour</th>\n",
              "      <th>building_meter_hour_median</th>\n",
              "      <th>weekday</th>\n",
              "      <th>building_meter_weekday_median</th>\n",
              "      <th>site_id</th>\n",
              "      <th>square_feet</th>\n",
              "      <th>year_built</th>\n",
              "      <th>floor_count</th>\n",
              "      <th>primary_use_ID</th>\n",
              "      <th>primary_use_Education</th>\n",
              "      <th>primary_use_Entertainment/public assembly</th>\n",
              "      <th>primary_use_Food sales and service</th>\n",
              "      <th>primary_use_Healthcare</th>\n",
              "      <th>primary_use_Lodging/residential</th>\n",
              "      <th>primary_use_Manufacturing/industrial</th>\n",
              "      <th>primary_use_Office</th>\n",
              "      <th>primary_use_Other</th>\n",
              "      <th>primary_use_Parking</th>\n",
              "      <th>primary_use_Public services</th>\n",
              "      <th>primary_use_Religious worship</th>\n",
              "      <th>primary_use_Retail</th>\n",
              "      <th>primary_use_Services</th>\n",
              "      <th>primary_use_Technology/science</th>\n",
              "      <th>primary_use_Utility</th>\n",
              "      <th>primary_use_Warehouse/storage</th>\n",
              "      <th>air_temperature</th>\n",
              "      <th>cloud_coverage</th>\n",
              "      <th>dew_temperature</th>\n",
              "      <th>precip_depth_1_hr</th>\n",
              "      <th>sea_level_pressure</th>\n",
              "      <th>wind_direction</th>\n",
              "      <th>wind_speed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2017-01-01 00:00:00</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.623490</td>\n",
              "      <td>-0.781831</td>\n",
              "      <td>0.992981</td>\n",
              "      <td>-0.118273</td>\n",
              "      <td>189.751999</td>\n",
              "      <td>0.0</td>\n",
              "      <td>206.474503</td>\n",
              "      <td>4</td>\n",
              "      <td>183.608994</td>\n",
              "      <td>0</td>\n",
              "      <td>7432</td>\n",
              "      <td>2008.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>129</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2017-01-01 01:00:00</td>\n",
              "      <td>0.965926</td>\n",
              "      <td>2.588190e-01</td>\n",
              "      <td>0.623490</td>\n",
              "      <td>-0.781831</td>\n",
              "      <td>0.992981</td>\n",
              "      <td>-0.118273</td>\n",
              "      <td>189.751999</td>\n",
              "      <td>0.0</td>\n",
              "      <td>206.474503</td>\n",
              "      <td>4</td>\n",
              "      <td>183.608994</td>\n",
              "      <td>0</td>\n",
              "      <td>7432</td>\n",
              "      <td>2008.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>258</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2017-01-01 02:00:00</td>\n",
              "      <td>0.866025</td>\n",
              "      <td>5.000000e-01</td>\n",
              "      <td>0.623490</td>\n",
              "      <td>-0.781831</td>\n",
              "      <td>0.992981</td>\n",
              "      <td>-0.118273</td>\n",
              "      <td>189.751999</td>\n",
              "      <td>0.0</td>\n",
              "      <td>206.474503</td>\n",
              "      <td>4</td>\n",
              "      <td>183.608994</td>\n",
              "      <td>0</td>\n",
              "      <td>7432</td>\n",
              "      <td>2008.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>387</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2017-01-01 03:00:00</td>\n",
              "      <td>0.707107</td>\n",
              "      <td>7.071068e-01</td>\n",
              "      <td>0.623490</td>\n",
              "      <td>-0.781831</td>\n",
              "      <td>0.992981</td>\n",
              "      <td>-0.118273</td>\n",
              "      <td>189.751999</td>\n",
              "      <td>0.0</td>\n",
              "      <td>206.474503</td>\n",
              "      <td>4</td>\n",
              "      <td>183.608994</td>\n",
              "      <td>0</td>\n",
              "      <td>7432</td>\n",
              "      <td>2008.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>516</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2017-01-01 04:00:00</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>8.660254e-01</td>\n",
              "      <td>0.623490</td>\n",
              "      <td>-0.781831</td>\n",
              "      <td>0.992981</td>\n",
              "      <td>-0.118273</td>\n",
              "      <td>189.751999</td>\n",
              "      <td>0.0</td>\n",
              "      <td>206.474503</td>\n",
              "      <td>4</td>\n",
              "      <td>183.608994</td>\n",
              "      <td>0</td>\n",
              "      <td>7432</td>\n",
              "      <td>2008.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20216085</th>\n",
              "      <td>20980340</td>\n",
              "      <td>886</td>\n",
              "      <td>2</td>\n",
              "      <td>2017-06-29 11:00:00</td>\n",
              "      <td>-0.965926</td>\n",
              "      <td>2.588190e-01</td>\n",
              "      <td>-0.900969</td>\n",
              "      <td>0.433884</td>\n",
              "      <td>-0.998244</td>\n",
              "      <td>0.059241</td>\n",
              "      <td>48.799999</td>\n",
              "      <td>7.0</td>\n",
              "      <td>79.300003</td>\n",
              "      <td>2</td>\n",
              "      <td>42.700001</td>\n",
              "      <td>9</td>\n",
              "      <td>69799</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20216086</th>\n",
              "      <td>20980647</td>\n",
              "      <td>886</td>\n",
              "      <td>2</td>\n",
              "      <td>2017-06-29 12:00:00</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>1.224647e-16</td>\n",
              "      <td>-0.900969</td>\n",
              "      <td>0.433884</td>\n",
              "      <td>-0.998244</td>\n",
              "      <td>0.059241</td>\n",
              "      <td>48.799999</td>\n",
              "      <td>7.0</td>\n",
              "      <td>79.300003</td>\n",
              "      <td>2</td>\n",
              "      <td>42.700001</td>\n",
              "      <td>9</td>\n",
              "      <td>69799</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20216087</th>\n",
              "      <td>20980952</td>\n",
              "      <td>886</td>\n",
              "      <td>2</td>\n",
              "      <td>2017-06-29 13:00:00</td>\n",
              "      <td>-0.965926</td>\n",
              "      <td>-2.588190e-01</td>\n",
              "      <td>-0.900969</td>\n",
              "      <td>0.433884</td>\n",
              "      <td>-0.998244</td>\n",
              "      <td>0.059241</td>\n",
              "      <td>48.799999</td>\n",
              "      <td>7.0</td>\n",
              "      <td>79.300003</td>\n",
              "      <td>2</td>\n",
              "      <td>42.700001</td>\n",
              "      <td>9</td>\n",
              "      <td>69799</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20216088</th>\n",
              "      <td>20981258</td>\n",
              "      <td>886</td>\n",
              "      <td>2</td>\n",
              "      <td>2017-06-29 14:00:00</td>\n",
              "      <td>-0.866025</td>\n",
              "      <td>-5.000000e-01</td>\n",
              "      <td>-0.900969</td>\n",
              "      <td>0.433884</td>\n",
              "      <td>-0.998244</td>\n",
              "      <td>0.059241</td>\n",
              "      <td>48.799999</td>\n",
              "      <td>7.0</td>\n",
              "      <td>79.300003</td>\n",
              "      <td>2</td>\n",
              "      <td>42.700001</td>\n",
              "      <td>9</td>\n",
              "      <td>69799</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20216089</th>\n",
              "      <td>21290624</td>\n",
              "      <td>886</td>\n",
              "      <td>2</td>\n",
              "      <td>2017-08-10 19:00:00</td>\n",
              "      <td>0.258819</td>\n",
              "      <td>-9.659258e-01</td>\n",
              "      <td>-0.900969</td>\n",
              "      <td>0.433884</td>\n",
              "      <td>-0.794854</td>\n",
              "      <td>-0.606800</td>\n",
              "      <td>48.799999</td>\n",
              "      <td>7.0</td>\n",
              "      <td>79.300003</td>\n",
              "      <td>2</td>\n",
              "      <td>42.700001</td>\n",
              "      <td>9</td>\n",
              "      <td>69799</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20216090 rows × 43 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            row_id  building_id  meter           timestamp  hour_cos      hour_sin  weekday_cos  \\\n",
              "0                0            0      0 2017-01-01 00:00:00  1.000000  0.000000e+00     0.623490   \n",
              "1              129            0      0 2017-01-01 01:00:00  0.965926  2.588190e-01     0.623490   \n",
              "2              258            0      0 2017-01-01 02:00:00  0.866025  5.000000e-01     0.623490   \n",
              "3              387            0      0 2017-01-01 03:00:00  0.707107  7.071068e-01     0.623490   \n",
              "4              516            0      0 2017-01-01 04:00:00  0.500000  8.660254e-01     0.623490   \n",
              "...            ...          ...    ...                 ...       ...           ...          ...   \n",
              "20216085  20980340          886      2 2017-06-29 11:00:00 -0.965926  2.588190e-01    -0.900969   \n",
              "20216086  20980647          886      2 2017-06-29 12:00:00 -1.000000  1.224647e-16    -0.900969   \n",
              "20216087  20980952          886      2 2017-06-29 13:00:00 -0.965926 -2.588190e-01    -0.900969   \n",
              "20216088  20981258          886      2 2017-06-29 14:00:00 -0.866025 -5.000000e-01    -0.900969   \n",
              "20216089  21290624          886      2 2017-08-10 19:00:00  0.258819 -9.659258e-01    -0.900969   \n",
              "\n",
              "          weekday_sin  week_cos  week_sin  building_meter_median  hour  \\\n",
              "0           -0.781831  0.992981 -0.118273             189.751999   0.0   \n",
              "1           -0.781831  0.992981 -0.118273             189.751999   0.0   \n",
              "2           -0.781831  0.992981 -0.118273             189.751999   0.0   \n",
              "3           -0.781831  0.992981 -0.118273             189.751999   0.0   \n",
              "4           -0.781831  0.992981 -0.118273             189.751999   0.0   \n",
              "...               ...       ...       ...                    ...   ...   \n",
              "20216085     0.433884 -0.998244  0.059241              48.799999   7.0   \n",
              "20216086     0.433884 -0.998244  0.059241              48.799999   7.0   \n",
              "20216087     0.433884 -0.998244  0.059241              48.799999   7.0   \n",
              "20216088     0.433884 -0.998244  0.059241              48.799999   7.0   \n",
              "20216089     0.433884 -0.794854 -0.606800              48.799999   7.0   \n",
              "\n",
              "          building_meter_hour_median  weekday  building_meter_weekday_median  site_id  \\\n",
              "0                         206.474503        4                     183.608994        0   \n",
              "1                         206.474503        4                     183.608994        0   \n",
              "2                         206.474503        4                     183.608994        0   \n",
              "3                         206.474503        4                     183.608994        0   \n",
              "4                         206.474503        4                     183.608994        0   \n",
              "...                              ...      ...                            ...      ...   \n",
              "20216085                   79.300003        2                      42.700001        9   \n",
              "20216086                   79.300003        2                      42.700001        9   \n",
              "20216087                   79.300003        2                      42.700001        9   \n",
              "20216088                   79.300003        2                      42.700001        9   \n",
              "20216089                   79.300003        2                      42.700001        9   \n",
              "\n",
              "          square_feet  year_built  floor_count  primary_use_ID  primary_use_Education  \\\n",
              "0                7432      2008.0          NaN               0                      1   \n",
              "1                7432      2008.0          NaN               0                      1   \n",
              "2                7432      2008.0          NaN               0                      1   \n",
              "3                7432      2008.0          NaN               0                      1   \n",
              "4                7432      2008.0          NaN               0                      1   \n",
              "...               ...         ...          ...             ...                    ...   \n",
              "20216085        69799         NaN          NaN               0                      1   \n",
              "20216086        69799         NaN          NaN               0                      1   \n",
              "20216087        69799         NaN          NaN               0                      1   \n",
              "20216088        69799         NaN          NaN               0                      1   \n",
              "20216089        69799         NaN          NaN               0                      1   \n",
              "\n",
              "          primary_use_Entertainment/public assembly  primary_use_Food sales and service  \\\n",
              "0                                                 0                                   0   \n",
              "1                                                 0                                   0   \n",
              "2                                                 0                                   0   \n",
              "3                                                 0                                   0   \n",
              "4                                                 0                                   0   \n",
              "...                                             ...                                 ...   \n",
              "20216085                                          0                                   0   \n",
              "20216086                                          0                                   0   \n",
              "20216087                                          0                                   0   \n",
              "20216088                                          0                                   0   \n",
              "20216089                                          0                                   0   \n",
              "\n",
              "          primary_use_Healthcare  primary_use_Lodging/residential  \\\n",
              "0                              0                                0   \n",
              "1                              0                                0   \n",
              "2                              0                                0   \n",
              "3                              0                                0   \n",
              "4                              0                                0   \n",
              "...                          ...                              ...   \n",
              "20216085                       0                                0   \n",
              "20216086                       0                                0   \n",
              "20216087                       0                                0   \n",
              "20216088                       0                                0   \n",
              "20216089                       0                                0   \n",
              "\n",
              "          primary_use_Manufacturing/industrial  primary_use_Office  primary_use_Other  \\\n",
              "0                                            0                   0                  0   \n",
              "1                                            0                   0                  0   \n",
              "2                                            0                   0                  0   \n",
              "3                                            0                   0                  0   \n",
              "4                                            0                   0                  0   \n",
              "...                                        ...                 ...                ...   \n",
              "20216085                                     0                   0                  0   \n",
              "20216086                                     0                   0                  0   \n",
              "20216087                                     0                   0                  0   \n",
              "20216088                                     0                   0                  0   \n",
              "20216089                                     0                   0                  0   \n",
              "\n",
              "          primary_use_Parking  primary_use_Public services  primary_use_Religious worship  \\\n",
              "0                           0                            0                              0   \n",
              "1                           0                            0                              0   \n",
              "2                           0                            0                              0   \n",
              "3                           0                            0                              0   \n",
              "4                           0                            0                              0   \n",
              "...                       ...                          ...                            ...   \n",
              "20216085                    0                            0                              0   \n",
              "20216086                    0                            0                              0   \n",
              "20216087                    0                            0                              0   \n",
              "20216088                    0                            0                              0   \n",
              "20216089                    0                            0                              0   \n",
              "\n",
              "          primary_use_Retail  primary_use_Services  primary_use_Technology/science  \\\n",
              "0                          0                     0                               0   \n",
              "1                          0                     0                               0   \n",
              "2                          0                     0                               0   \n",
              "3                          0                     0                               0   \n",
              "4                          0                     0                               0   \n",
              "...                      ...                   ...                             ...   \n",
              "20216085                   0                     0                               0   \n",
              "20216086                   0                     0                               0   \n",
              "20216087                   0                     0                               0   \n",
              "20216088                   0                     0                               0   \n",
              "20216089                   0                     0                               0   \n",
              "\n",
              "          primary_use_Utility  primary_use_Warehouse/storage  air_temperature  cloud_coverage  \\\n",
              "0                           0                              0              NaN             NaN   \n",
              "1                           0                              0              NaN             NaN   \n",
              "2                           0                              0              NaN             NaN   \n",
              "3                           0                              0              NaN             NaN   \n",
              "4                           0                              0              NaN             NaN   \n",
              "...                       ...                            ...              ...             ...   \n",
              "20216085                    0                              0              NaN             NaN   \n",
              "20216086                    0                              0              NaN             NaN   \n",
              "20216087                    0                              0              NaN             NaN   \n",
              "20216088                    0                              0              NaN             NaN   \n",
              "20216089                    0                              0              NaN             NaN   \n",
              "\n",
              "          dew_temperature  precip_depth_1_hr  sea_level_pressure  wind_direction  wind_speed  \n",
              "0                     NaN                NaN                 NaN             NaN         NaN  \n",
              "1                     NaN                NaN                 NaN             NaN         NaN  \n",
              "2                     NaN                NaN                 NaN             NaN         NaN  \n",
              "3                     NaN                NaN                 NaN             NaN         NaN  \n",
              "4                     NaN                NaN                 NaN             NaN         NaN  \n",
              "...                   ...                ...                 ...             ...         ...  \n",
              "20216085              NaN                NaN                 NaN             NaN         NaN  \n",
              "20216086              NaN                NaN                 NaN             NaN         NaN  \n",
              "20216087              NaN                NaN                 NaN             NaN         NaN  \n",
              "20216088              NaN                NaN                 NaN             NaN         NaN  \n",
              "20216089              NaN                NaN                 NaN             NaN         NaN  \n",
              "\n",
              "[20216090 rows x 43 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HcOED4IDv0k",
        "colab_type": "code",
        "outputId": "125bad6b-9605-4831-d451-f1428d5e1b45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 863
        }
      },
      "source": [
        "show_plot(hist) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEaCAYAAAD+E0veAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deXyTZb7//9edpFnatGnT0JaWtQjI\nIoKAIDvSwd3hi4o66qgHZ2QQd1H0zCgu4/SMVtFzYETwiHo8Z/SnM+Iy6ljZBBd0iiIgUKCspWtK\n16TNcv3+SAmttNA1Kc3n+Xj00TT3ks9VQt69rnu5NKWUQgghhAB04S5ACCFE1yGhIIQQIkhCQQgh\nRJCEghBCiCAJBSGEEEESCkIIIYIkFIRoo1WrVmEwGFq1zeLFiznrrLM6qSIh2k9CQXQ7t9xyC5qm\nMXv27JOWrV69Gk3TWv1hHkrTpk1D0zSWLVvW6PmNGzeiaRr79+8HYP/+/WiaRmxsLIWFhY3Wve22\n25g2bVqIKhbdiYSC6Jb69OnDhx9+eNKH5fLly+nbt2+Yqmo5s9nM448/TmVl5WnX9Xq9PPbYYyGo\nSkQCCQXRLQ0cOJDx48ezatWq4HMHDx7ks88+49Zbbz1p/X/84x+MHj0ak8lEUlIS8+fPp7q6Orjc\n7/fzhz/8gaSkJKxWK9deey1lZWUn7eezzz5j4sSJWCwW0tLSuPXWWyktLW11/VdddRUmk4nMzMzT\nrnvPPfewcuVKfvrpp1a/jhA/J6Eguq3f/va3rFy5kuN3clm5ciUzZsw4qaewdetWrrzySqZMmcIP\nP/zAa6+9xocffsi8efOC6/znf/4nzz33HM888ww5OTmMHj2axx9/vNF+1qxZwy9/+Uuuu+46tm7d\nynvvvcf+/fuZPXs2rb2bjNls5o9//CPPP/88hw8fPuW6l112GVOnTuXBBx9s1WsI0SQlRDdz8803\nqxkzZiiXy6Xsdrtas2aN8nq9Ki0tTb377rvq1VdfVXq9Prj+jTfeqMaOHdtoH++9957SNE3t379f\nKaVUWlqaeuSRRxqtc9VVVzXaz9SpU9VDDz3UaJ0DBw4oQG3ZskUppdRjjz2mBgwYcMr6p06dqubO\nnav8fr8677zz1K9//WullFJffPGFAlReXp5SSqm8vDwFqC+++ELl5OQoTdPUmjVrlFJKzZ07V02d\nOrWFvzEhTpCegui2zGYzN910EytWrOCjjz7C6/VyxRVXnLTe9u3bmTJlSqPnpk6dilKKHTt2UFFR\nwZEjR5gwYUKjdSZNmtTo52+//ZYlS5ZgtVqDX0OHDgUgNze31fVrmsYzzzzD//zP//D999+fct1R\no0Zx4403snDhwlb3SoRoqOuegiFEB/jtb3/Leeedx6FDh7j11luJiorqtNfy+/089NBD3HTTTSct\nS0lJadM+L7zwQi655BIWLlx42oPJf/zjHxk8eDBvvvlmm15LCJBQEN3c0KFDGTt2LJs2bWp00Lmh\nYcOGsWHDhkbPrV+/Hk3TGDZsGHFxcaSlpfHll19y2WWXBdfZtGlTo23GjBnD9u3bO/w6hD//+c+M\nGDGCsWPHnnK93r17c8899/Dv//7vTJ48uUNrEJFDho9Et/fpp59SUlLCgAEDmly+cOFCcnJyuPfe\ne9m5cyeffPIJd955JzfccAN9+vQB4P777+eFF17gjTfeIDc3l6ysLLKzsxvt54knnmD16tXcd999\nfP/99+zdu5dPPvmEuXPn4nK52lz/0KFDmTt3LkuWLDntuosWLcLlcvG3v/2tza8nIpuEguj2oqOj\nsdvtzS4fMWIE77//Phs2bODcc8/lpptu4rLLLuOll14KrnP33Xdz1113ce+99zJy5Ei++uorHn30\n0Ub7mT59OmvWrGHr1q1MnjyZESNGcO+99xIbG9vuYasnnngCvV5/2vXi4uJ47LHH2hVCIrJpSo5K\nCSGEqCc9BSGEEEESCkIIIYIkFIQQQgRJKAghhAiSUBBCCBF0xl+8lp+f36btHA4HJSUlHVzNmSFS\n2y7tjizS7ualpqY2u0x6CkIIIYIkFIQQQgRJKAghhAg6448pCCFESymlcLvd+P1+NE0LdzmdorCw\nkNraWpRS6HQ6zGZzq9oqoSCEiBhut5uoqCgMhu770WcwGIL3yfJ6vbjdbiwWS4u3l+EjIUTE8Pv9\n3ToQfs5gMOD3+1u1jYSCECJidNcho1NpbZsjMhTUkQNUvbkcVVkR7lKEEKJLiZx+VEMFR6h+5zV0\nw86D2LhwVyOEiABOp5Nrr70WgOLiYvR6fXCej48++gij0Xjafdx7773ccccdHT67X0ORGQomc+B7\nbW146xBCRAy73c5nn30GQFZWFjExMcybN6/ROkqp4FlDTXn++ec7vc6IHD7CfDwUZHYqIUR45eXl\nMW3aNBYsWMD06dMpLCzkwQcf5JJLLmH69OmNgmDWrFls27YNr9fLkCFDePrpp8nIyOCKK67osFt6\nRGZPwSg9BSEinf+vK1CH8jp0n1rv/uiu+02rt9uzZw8vvPAC5557LgAPP/wwCQkJeL1errnmGi67\n7DIGDRrUaJuKigrGjx/PI488wuLFi/nrX//KggUL2t2GiO4pKOkpCCG6gL59+wYDAWD16tVcdNFF\nXHzxxeTm5rJ79+6TtjGbzVx44YVAYJ7xQ4cOdUgt0lMQQkSktvxF31mio6ODj/ft28fKlSv56KOP\nsNls3HnnndQ28VnV8MC0Xq/H5/N1SC0R3VOQYwpCiK6mqqoKq9VKbGwshYWFrFu3LqSvH6E9BVPg\nu/QUhBBdzDnnnMPAgQOZMmUKvXr1YuzYsSF9fU0ppUL6ih2srZPs+O64Bm36peiuvrWDK+r6ZPKR\nyCLtPqGmpqbRUE13ZDAY8Hq9wZ+barNMstMEzWyBWne4yxBCiC5FQkEIIURQ5IaCyYySUBBCiEYi\nNhR0lmjpKQghxM+E5OyjkpISli5dyrFjx9A0jYyMDC699NJG63zxxResXr0apRQWi4XbbruNfv36\ndVpNmskMrppO278QQpyJQhIKer2em266ifT0dFwuF4sWLWLEiBH06tUruE5SUhKLFy/GarWyZcsW\nXn75ZZ5++ulOq0kzW+CYs9P2L4QQZ6KQDB8lJCSQnp4OgMViIS0tDaez8Qfy4MGDsVqtAAwcOJDS\n0tJOrUkONAshQu3qq68+6WK0FStWsGjRoma3GThwYCdX1VjIL14rKioiLy/vlPcDX7NmDaNGjWpy\nWXZ2NtnZ2QBkZmbicDjaVEdldAw6j6fN25/JDAaDtDuCSLtPKCwsDOt0nLNnz+aDDz4gIyMj+Nz7\n77/Po48+esq6Wltzw/VNJlOr/v1D+ttxu91kZWVxyy23NHsBybZt21i7di1PPPFEk8szMjIa/ULb\nelGOyWjC76qWi3oiiLQ7sjTV7tra2uCk9uFwySWXkJmZSU1NDUajkUOHDlFQUMCQIUOYPXs25eXl\neL1eHnzwQS666KLgdg0vRjudn1+8Vltbe9Lv4VQXr4UsFLxeL1lZWUyePJlx48Y1uc6BAwdYvnw5\nDz/8MLGxsZ1aT2D4qBalVETO2ypEpFv5XSF5ZR07hNw/wcxtY5KbXZ6QkMDIkSNZu3YtF110EatX\nr+aKK67AbDbzyiuvEBsbi9Pp5IorrmDmzJlh+WwKyTEFpRQvvfQSaWlpXH755U2uU1JSwrPPPsuC\nBQtOmWIdRTNbQPnBU9fpryWEEMfNmjWL1atXA4FbZM+aNQulFJmZmWRkZHDttddSUFBAcXFxWOoL\nSU9h165dbNiwgT59+rBw4UIArr/++mCXZubMmbzzzjtUVVWxcuVKIHDGUmZmZqfVpJktgQe17hM3\nyBNCRIxT/UXfmS666CIWL17Mjz/+iMvlYsSIEbz11luUlpby8ccfExUVxbhx45q8XXYohCQUzj77\nbN5+++1TrjNv3ryT5ivtTI1CIdYWstcVQkS2mJgYJkyYwH333cesWbMAqKysxOFwEBUVxaZNmzh8\n+HDY6ovYK5o1U4NQEEKIEJo1axY7duwIhsLs2bP54YcfmDFjBu+8884pz87sbJE5nwI/6ykIIUQI\nXXzxxRw5ciT4s91u54MPPmhy3dzc3FCVBURyTyE4+5qEghBCHBfBoVB/nYSEghBCBEVwKAR6CnL7\nbCEixxk+0WSbtLbNERwK0lMQItLodLpWXR18pvN6veh0rfuYj+ADzXJMQYhIYzabcbvd1NbWdts7\nGZhMJmrr79ag0+kwH/+sa6HIDQU5JVWIiKNpGhaLJdxldKr23usqcoePDAYwGCQUhBCigYgNBQBM\nMqeCEEI0FOGhYJJQEEKIBiI8FCyoWle4qxBCiC4jskPBaIIw3YlQCCG6osgOBbMFpKcghBBBkR0K\nJrP0FIQQooGIDgXNZJYDzUII0UBEhwISCkII0YiEgoSCEEIESSjUuSPyzolCCNGUkNz7qKSkhKVL\nl3Ls2DE0TSMjI4NLL7200TpKKV599VW2bNmCyWRi/vz5pKend25hRhP4fOD1QlRU576WEEKcAUIS\nCnq9nptuuon09HRcLheLFi1ixIgR9OrVK7jOli1bKCgo4MUXXyQ3N5eVK1fy9NNPd25hx6fkrHNL\nKAghBCEaPkpISAj+1W+xWEhLS8PpdDZa57vvvmPKlClomsagQYOorq6mrKyscwszmgLf3XJcQQgh\nIAy3zi4qKiIvL4+zzjqr0fNOpxOHwxH8OTExEafTSUJCQqP1srOzyc7OBiAzM7PRNq1hMBiI65FE\nOZAQbcHQxv2ciQwGQ5t/b2cyaXdkkXa3cfsOrOW03G43WVlZ3HLLLURHR7dpHxkZGWRkZAR/but9\nwx0OB5W1HgDKCo6iWaxt2s+ZqL33Wz9TSbsji7S7eampqc0uC9nZR16vl6ysLCZPnsy4ceNOWm63\n2xs1pLS0FLvd3rlFBWdfk1tdCCEEhCgUlFK89NJLpKWlcfnllze5zpgxY9iwYQNKKXbv3k10dPRJ\nQ0cdzng8FORWF0IIASEaPtq1axcbNmygT58+LFy4EIDrr78+2DOYOXMmo0aNIicnh7vuuguj0cj8\n+fM7v7D6noKqddE9Z2sVQojWCUkonH322bz99tunXEfTNG677bZQlHNCsKcgZx8JIQRE+hXNZgkF\nIYRoKLJDQXoKQgjRSGSHgsEAer2EghBC1IvoUNA0rf6meHL2kRBCQISHAhAYQnLLdQpCCAESCoGD\nzdJTEEIIQEIBjGaU9BSEEAKQUJCeghBCNCChIMcUhBAiKOJDQZN5moUQIijiQ+H4PM1CCCEkFAKh\n0GDmNZfHj1IqjAUJIUT4hHzmtS7HZEbVudlaUM37O518d6SaPjYTlw6OZ1p/G2aD5KYQInJEdCh4\nfH7Waz35YOQC9n9+CJtJz+VnJ7CtsIa/bC7k9S3FzBhg49JBCfSMNYa7XCGE6HQRGQrlbi/vf3OQ\nd78/wjF3H/pwlAWjEpg6uAdGvQ6lFDuLXXy0u4yPdpXx/s4yRqfG8G/nJdHLZgp3+UII0WkiMhR+\nKKjhla/zGZ0awxWefZyz7nn01/w3mj4wVKRpGkOSohmSFI3T5eWfucd4f6eTl78r5IkZfcJcvRBC\ndJ6IDIUJfWIZnX4eMf4a/N/sQ0GzZyDZLQauG+HAj+LtH0spqfHgiI4Kab1CCBEqEXkU1aDT6GuP\nBuqvU4DTXqswvb8NBazPq+jk6oQQInwiMhQaaWEo9Iw1crbDwtq8cjllVQjRbYVk+GjZsmXk5ORg\ns9nIyso6aXlNTQ0vvvgipaWl+Hw+rrjiCqZPnx6K0locCgDT+sfx0reF7CurZYDd3MmFCSFE6IWk\npzBt2jQeeeSRZpd/8skn9OrVi2eeeYbFixfz+uuv4/V6Q1EamCyB7y0IhUl94zDoNNbuK+/kooQQ\nIjxCEgpDhw7FarU2u1zTNNxuN0op3G43VqsVnS5EI1umwCmmqgWhEGvSMzbNyoYDFXj9MoQkhOh+\nusTZRxdffDF//vOfuf3223G5XNx7773NhkJ2djbZ2dkAZGZm4nA42vSaBoMBh8OB32igGLAa9ES3\nYF+/PFfjqw9/Yl+1ngn97W167XA73vZII+2OLNLuNm7fgbW02Q8//EDfvn159NFHKSws5Mknn+Ts\ns88mOjr6pHUzMjLIyMgI/lxSUtKm13Q4HJSUlKDq51KocpZS04J9nWVVxJr0vPf9IQbF+tv02uF2\nvO2RRtodWaTdzUtNTW12WZc4+2jt2rWMGzcOTdNISUkhKSmJ/Pz80Lx4lBE0XaOb4p1ydb3GlL6x\nbD5cRVWdr5OLE0KI0OoSoeBwOPjxxx8BOHbsGPn5+SQlJYXktTVNCxxXaMXts6f1t+HxK748WNmJ\nlQkhROiFZPhoyZIl7Nixg8rKSubNm8ecOXOCZxfNnDmTq666imXLlnH//fcDcMMNNxAXFxeK0gJM\nllZNtDMw0UxanJG1+8qZeVZ8h5VxtLKOpJgo9Dqtw/YphBCtEZJQuOeee0653G638/vf/z4UpTTN\nZGpVKGiaxvT+cfzPDyUUVtWRbG3/HVQ/zT3Gss0FXDY4gd+OSW73/oQQoi26xPBR2JnMLToltaGp\n/WwArOuA2158klvGss0FxBp1fLy7jL1OmQlOCBEeEgoQuKq5laGQZI1ieHJ0u2978fHuMv6yuZAx\nqTH81xXpxJn0/GVzAX65lYYQIgwkFKBNoQAwvX8cRys97C5tetvThcVHu8p46dtCxqZZWTQljXiz\ngVvPSyK31M1ne+SqaSFE6HWJ6xTCzmSGstJWbzahTyzLvy1kxXeFpMYaqaj1UVHro7LWS0WtD52m\nMapnDOf3sjIm1YrVpA9u+9GuMl7+rpDze1l5cFIqUfVzOUztF8dne8t5/fsixve2YjPLP5EQInTk\nE4fA7bNbe0wBIDpKz8yz4lmzr5zKWh+xJj3xZj29bUbiTHpqPH6+O1LFpoOV6DUYlhzNuF5W3F7F\nG98XM66XlYWT0ojSnzjbSNM05o1N5u6P8li1pZi7L+jZkU0VQohTklCA+uEjV5s2/c2YZH5zirOF\n/EqRW+rm60OVbD5cxYrvigAY39vKAxMbB8JxvW0mZg2x8+4OJxkDbAxLOvnKbiGE6AwSClAfCrWd\nsmudpjHYYWGww8LNo5I4UlHHkYpaRvW0NhkIx805x8GG/RUs31zIc5f2w9DFrl1QSuFXyDUVQnQz\ncqAZwGgGTx3K3/m3rUiLM3J+r9hTBgKA2aDjN2OSOVBey4e7nO1+3ZIaD/+7tZgHPtnPf399kIra\ntrc1v6KOhz87yK1/28OmgzITnRDdifQUAMzHJ9qpBUvXGao5v5eVsWkx/N/WEs7raSXGqMOvwOdX\neJXC7wejXqNHM1dB+5Via0ENH+eWsflwFUpBvwQTr3xzkDf/pTHzrHh+OcTe4jmn/Urx0a4yXv++\nmCi9Ro/oKP78RT6T+lZy+5hk4uSguBBnPPlfDA0m2nF1qVDQNI3fjElmwYd53PlRXrPr6TVItkbR\nM9ZISqyRntYoPH7FZ3uOkV/pIc6kZ9YQOxcPjCfZaqQCC698uZcPd5Xxj91lTO1nY/ZQO71spmZf\no7Cqjhe/LmBbYQ2jU2O4Y1wKNrOBv20v5a1tJfxYWMP881MY3zu2M34VQogQkVCA4EQ7nXVcoT2S\nrUae/kUfdpe40evAoNPQaRp6LfC4xuOnoMrD0co6jlbWsaPIhcsbuKX32Q4L157jYEKfWIz6EyOF\n6Y4Y7p2Qyq9GOFi9s4zP9hxjzb5y0uKM9I030TfeRJ94E/3iTSTFRPHZ3mO8mlOMBiwYl0LGAFvg\nRoIEjn2M7WXlha+O8qcNR5jWL47bxiQT2+D02+7O41PsLnFxuKKOiX1jsRq7dts9PsX2ohpsZj39\nE9o3rewPBdWsyiliTJqV/zfUTnTUqdvu8yu+PlyJzx84pTuUx8pKazx8uKsMl8fPrCF2UmLbf3ua\n7khCAdBMFhS0+QykzjYw0cLAREuL1lVKUV7ro9brP+09mZKtRn47Jplrhyfyzz3HyC11s9fpZlOD\nu78adOD1w4iUaO4c15Mk68lDTf0TzDxzUT/e2V7C/7etlC0F1fxiQDzT0+PoFdd876OjKKX4qdjF\n5/vK2VHkYkRKNJP7xjE0yYJO6/gPHaUUB8vr+P5oNT8UVLO9qAa3N3Ch4jvbS7hnQmpIzxhTSlFc\n7SXGqCOmmUBye/1sya/mq0OVfHukihpP4A+HjAE2bhrZg/hWDv35/Iq3tpXw9o+l2Mx63t5Wyqd7\njnHdOQ5mnhV/0oe9169Yn1fOO9tLya/0APDmD1FcPSyR6em2Tg2H/Io6/rajlLV5FfiVQq9p/HPP\nMTIGxHPN8ER6xDQ9fKqUIq+sll0lLtLtZs6ymyPixApNtfAeDR9++CHDhw+nX79+7N69m+effx6d\nTsfdd9/NoEGDOrvOZrV13oWGE1GoHVvwP/8Yugcz0QYO7cjyuqTTTcLh8vg5VF7LgWO1HCyvpW+8\niQvTbS36gN3rdPPmD8VsOVqNX8Fgh5kL021M6hvX6C/oYy4v++v3f7i8jhRrFBP7xrbq5oIlNR7W\n7itnzb5y8is9mA0aZzss/FTsotanSLQYmNg3lin94jjLbqZHjx7tmnTF51es3unk/Z+clLkDB+pT\nY42cmxLNyJ4xREfpWPpNAUXVHq4amsh1Ixwt/rDz+RX7ytxsK6xhe5ELj8/PuN6xXNA7lgRL0x/Y\nFW4v6/dX8Nnecg4cC/RyY4w6kmKi6BETRVJMFHaLgf2Vfr7e76TOF5ggalwvK+N6Wfmp2MXqn5yY\nDTquH+Hg0kEJLfrQK63x8NyXR9lWWMOF6TZuH5vMwWO1rNpSxPYiF6mxRn49qgfje1nx+mHNvnLe\n3VFKYZWH/gkm5gxPxKDTeOvHUvY43STFBMLhwnTbaU/AaA2n38zKTXv58mAlBp1GxgAbs4bYidJr\nvLO9lH/uOQZoXDwwnquHJZJgMeD1B3pR3xyuYvOhSoprTswVH2vUMbJnDOelWhnZMwZ7M/8uJ9Xh\n8rLP6WZfmRuNwK33mwuijtDeSXZaHAq/+93vyMrKIjo6mscff5wxY8ZgsVjIzs7m6aefbl3VHahD\nQmHvTvyZD6K7+zG04aM7srwuKRQzUjldXtbnBT6wD5bXEaXTOC81BpfHz4FjtZQ3OPvJatRRVRf4\ny3VQoplJfeOY2De20QFwv1IUV3s4VF7HofJathbU8H1BIHiGJVmYkW5jQp84LFE63F4/mw9XsfFA\nBf/Kr8brVyTFRJEcZ6bO44VAv5Dj7/yze1iYNcRO4ikOuOeVufnPrwvY63QzqmcMk/rGcm5KzEn/\nuWs8PlZ+V8Tn+8oZmGjmvgmppMadHHQuj599ZW5+KnKxraiGn4pduOuH/VJjjeg0OFxRhwYMTbIw\nsU8c43tbiTcb+KGgmuy95XxzuAqvX3GW3cyUfnH46n9HxdUeiqq8FFV7cHn99LAaOT81mvG9YxmW\nFN3og/9weS0r/lXE90er6Wsz8ZuxSZyTHNPs72HL0Wqe35SP2+tn3vkpXJhuCy5TSvHdkWpWbSni\ncEUdgxLNlLq8lNZ4GZho5trhDsakxQSHHpVS/Cu/mr/+WEJuqZse0QZmDLCh1zQ8fkWdT+HxKzw+\nP34FdoshGHiOGAM9oqMwGXTU+fwcrfSQX1HHkco68ivqOFheS26pG4tBxyWD4rnybPtJ4VpU5eHt\nbSV8vq8cg07j3JRodhS7qK7zY9RrnJsSw7heVoYlRbPH6WbL0Spy8qs5Vv8HQf8EE8nWKCwGHZYo\nHdFR+uBjp8tLXlmg5318fQAN0DQ4r2cMMwfGMybVesogVkrh8vqprvNTXeej2uOnqs5HdZ2f3jZj\nkyMIIQuFm2++mddeew2Xy8X8+fN55ZVX0Ol03HLLLaxataolu+gUHRIKh/PwP343unmL0EZP6Mjy\nuqRQTlOolGKP083afeVsPlxFvMVA3/rjFcePXcSbDRRW1bHxQCUbD1SwryzwV++QHhaSYqI4XBHo\nTdT6TrxVk2KimNY/jgvTbfQ8xdhwVZ0veOGgTzPg8QQ+aKn/YPLV/2Wo0zRmpNu4api9UW/F4/Pz\n9rZS3t1eitWk5/axyUzoHRv8YGvOpoMVLPumAK9fMXd0MqmxRvY63exxutnndHOkoo7jreljMzIs\nKTrwlRwd/Av04LFaNh2s4MuDlRwsD9Qda9JTUX/1/LR+cWQMsNGvmeMCSilqPH5690zCWdr8bVyU\nUnxzuIpX/lVIUbWX4cnRJMUYiDXqiTWd+NpT6ubvO5z0sZlYODmV3s2cmODzKz7fV86720uxWwzM\nOcfByJToZn9nSim2HK3mrz+WsqskMISrEZjlMEqvEaXT0IDyWh/+n31aWY06quv8NHw6wWIgNTaK\nSWclMSXNeNpjPEcr6/jr1hJ2FNcwPDkQBCN7xmA2nHzGvl8p9pfVklM/dHjM5cXl8ePy+nF5/Bx/\ni+q0wEWo6QkmBtjNpCeY6ZdgoqrOR/becj7bW06Zy4vdYiBjgI0LesdyzO3laOWJ44P5lR6Kquvw\nNjPr7/8bYueW806ejCxkoXDfffdx++23c+jQIXJycnjwwQepqalhwYIF/Pd//3dLdtEpOiQUigvw\nP/JbtFvvRjdhRkeW1yV19blr8yvq2Hiwgk0HKqmq89HLZqK3zUgfm4necUZ62UxtOpDdXLsLq+r4\n2w4n2XvL8SvFlH5xXD0skao6H//1dQGHK+qY3j+OfxudTFwrXrekxsMLXx5la2FN8LlEi4EBiWYG\n1I9RD0w0t+j+VofKa9l0sJLD5bVc0DuW83tZg/fLamu7f67W6+fvO5x8fbiSyloflbW+RkEM8IsB\nNn4zJhlTEx+YHaHW60evC5xI8fMQ8foVpTUeSqoDvaDiGg/OGi/xZgOpcUZSY42kxkUFD3aH+n2u\nVKBnU+PxEx2la3Ryx8/5/Ipvj1Txzz3HyMmvbhRqZoMWOJPQaqRnbBRxJj0xRj3W+mNGMVF6Yow6\nbGZ9kwf2QxYKOTk5LF++HIPBwP333096ejobN25kw4YNPPLIIy3ZRafokFCoKMN//81ov5qHbvql\nHVlel9TVQ6GznK7dpTUe3swLbJ0AABtXSURBVPvJyae5x6ir/zB0RBuYPy6F81KtbXpNv1J8c6iK\nKL3GWXYz8S0ch+5I7fn3rvP5gwGhaRp94zv/xIGOcqa8z4uqPOworqFHdBQ944wkmPWn7YmeSntD\nocXv0PPOO4/ly5c3em78+PGMHz++pbvouhpepyAiVmJ0FHNHJ3P1sEQ+2l2GUrToNMtT0WkaF/Q5\nc6/dMOp1JEbrTnm8RbRPkjWKJKvt9CuGSItD4fDhw1itVuLj43G73bz//vtomsaVV16JwXDq3Sxb\ntoycnBxsNhtZWVlNrrN9+3ZWrVqFz+cjNjaWxx9/vHUtaY+o+jHkNtwpVXQ/NrOBX43oEe4yhAiL\nFg8MvvDCC9TUBMZGX3/9dX766Sdyc3N5+eWXT7vttGnTTjnEVF1dzcqVK3nooYd47rnnuO+++1pa\nVofQdLo2T7QjhBDdSYt7CkVFRaSmpqKUYvPmzTz33HMYjUYWLFhw2m2HDh1KUVFRs8s3btzIuHHj\ncDgcANhsYehKGU0SCkKIiNfiUDAajbhcLg4fPozD4SAuLg6fz4fH42l3EUePHsXr9bJ48WJcLheX\nXnopU6dObfd+W8VskVAQQkS8FofCxIkTeeKJJ3C5XFx88cUA5OXlkZR08nmyreXz+cjLy+MPf/gD\ndXV1/P73v2fgwIFNHiHPzs4mOzsbgMzMzGDvorUMBkOjbUujY9ArP/Ft3N+Z5OdtjxTS7sgi7W7j\n9i1d8ZZbbuGHH35Ar9czfPhwIHAe8c0339zmFz8uMTGR2NhYzGYzZrOZIUOGcODAgSZDISMjg4yM\njODPbT3l7OenbfkMUXgrK86IU9ja60w5Va+jSbsji7S7eac6JbVVV6Cce+65pKSksHv3bkpKShgw\nYEAwINpjzJgx7Ny5E5/PR21tLXv27CEtLa3d+20VOaYghBAt7ymUlZWxZMkScnNzsVqtVFZWMmjQ\nIO6++27sdvspt12yZAk7duygsrKSefPmMWfOHLzewI2mZs6cSa9evRg5ciQPPPAAOp2OCy+8kD59\n+rSvZa1lskDFsdC+phBCdDEtDoUVK1bQt29fHn74YcxmM263m//7v/9jxYoVPPTQQ6fc9p577jnt\n/q+88kquvPLKlpbT4TSzGSU9BSFEhGvx8NGuXbv49a9/jbl+6kqz2cyNN97I7t27O624kDLKdQpC\nCNHiUIiJieHw4cONnsvPzyc6uutMX9kuZgkFIYRo8fDRlVdeyZNPPsmFF15Ijx49KC4uZt26dVx7\n7bWdWV/oGM1QV4vy+wNXOAshRARqcShkZGSQkpLCxo0bOXjwIAkJCdx1113s2LGjM+sLnfphMepq\nAxeyCSFEBGrVfXyHDx/e6BRUj8fDU0891T16C8b6UKh1SygIISKWjJMcZ2oQCkIIEaEkFOppEgpC\nCHH64aNt27Y1u+z4BWjdgoSCEEKcPhT+8pe/nHJ5t7nhlISCEEKcPhSWLl0aijrCT0JBCCHkmEJQ\nfSjIrS6EEJFMQuE46SkIIYSEQpCEghBCSCgEmUyB7xIKQogIJqFQT9PpIcoooSCEiGgSCg2ZzFAn\noSCEiFwSCg2ZzOCWUBBCRC4JhYZMZlStK9xVCCFE2EgoNGQyQ21tuKsQQoiwCUkoLFu2jNtuu437\n77//lOvt2bOH6667jq+//joUZZ3MZAbpKQghIlhIQmHatGk88sgjp1zH7/fz5ptvcu6554aipKZJ\nT0EIEeFCEgpDhw7FarWecp2PP/6YcePGERcXF4qSmqRJT0EIEeG6xDEFp9PJ5s2bmTlzZngLMQXm\naRZCiEjVquk4O8uqVau44YYb0OlOn1HZ2dlkZ2cDkJmZ2eZbdxsMhpO2rYxPwFVb231uB96Mptoe\nCaTdkUXa3cbtO7CWNtu7dy8vvPACABUVFWzZsgWdTsf5559/0roZGRlkZGQEfy4pKWnTazocjpO2\n9fsVqtZFcXExmqa1ab9ngqbaHgmk3ZFF2t281NTUZpd1iVBoOGfD0qVLGT16dJOB0OlMZlAK6upO\n3AtJCCEiSEhCYcmSJezYsYPKykrmzZvHnDlzglN5hv04QkPH75Ra55ZQEEJEpJCEwj333NPide+4\n445OrOQ0joeC2wWxtvDVIYQQYdIlzj7qKrRgT0HOQBJCRCYJhYYa9hSEECICSSg0JLOvCSEinIRC\nQw0PNAshRASSUGioPhSUzKkghIhQEgoNxScGpuTc+1O4KxFCiLCQUGhAM1vQRk9AfbMBJWcgCSEi\nkITCz2gTM8BVjcr5KtylCCFEyEko/Nyg4eBIRm3KDnclQggRchIKP6PpdGgTZ8DOrajignCXI4QQ\nISWh0ATtghmgaagv14S7FCGECCkJhSZoiT1gyEjUl9kovy/c5QghRMhIKDRDm/QLcJbAzq3hLkUI\nIUJGQqEZ2shxEBOL2igHnIUQkUNCoRlaVBTauKmoLV+jqivDXY4QQoSEhMIpaBMzwOtBfbM+3KUI\nIURISCicgtYnHfqkyzULQoiIIaFwGtrEDDi4D3Vwb7hLEUKITiehcBrauKlgMKA2fR7uUoQQotOF\nZI7mZcuWkZOTg81mIysr66TlX3zxBatXr0YphcVi4bbbbqNfv36hKO20tJhYtFEXoL5eh7r6FrQo\nY7hLEkKIThOSnsK0adN45JFHml2elJTE4sWLycrK4qqrruLll18ORVktpk3MgJoq1PffhLsUIYTo\nVCEJhaFDh2K1WptdPnjw4ODygQMHUlpaGoqyWm7ICOiRgnr3NTk9VQjRrYVk+Kg11qxZw6hRo5pd\nnp2dTXZ24GygzMxMHA5Hm17HYDC0alvPA0/h/Pd5GF7/L+L//Rk03Zl7OKa1be8upN2RRdrdxu07\nsJZ227ZtG2vXruWJJ55odp2MjAwyMjKCP5eUlLTptRwOR+u2tSehXXsbdW++RPHry9Bdfl2bXrcr\naHXbuwlpd2SRdjcvNTW12WVd5s/dAwcOsHz5chYuXEhsbGy4y2mSNvUStPHTUO//H2rHlnCXI4QQ\nHa5LhEJJSQnPPvssCxYsOGWChZumaWg3zoeevfGveBZVWhzukoQQokOFZPhoyZIl7Nixg8rKSubN\nm8ecOXPwer0AzJw5k3feeYeqqipWrlwJgF6vJzMzMxSltZpmMqP73SL8f7wf//L/QPfgn9AMUeEu\nSwghOoSmlFLhLqI98vPz27Rde8cb1b++xP9SJtr0y9D96vY27yccZKw1ski7I0u3OaZwptFGT0D7\nxS9Raz/C//W6cJcjhBAdQkKhHbTZN8PAoahXl+Df8Em4yxFCiHaTUGgHzWBAd9ejMHQk6o1l+N99\nDeX3h7ssIYRoMwmFdtLM0egW/AFt6sWoT95FrXgW5akLd1lCCNEmXeritTOVptfDDb8L3ArjnVWo\nshJ0d/weLTYu3KUJIUSrSE+hg2iahu6i2ehufxAO7MWfuRBV2LYzo4QQIlwkFDqYNmYSuvufgppq\n/E/fj//LNZzhZ/0KISKIhEIn0M4agu6RZyG1T+DMpBcfl6ufhRBnBAmFTqL1SEG38E9o1/8Wcnfg\nf2wB/nUfy9lJQoguTUKhE2k6HboLL0f32IuQPgj15l/wZ/0eVSTHGoQQXZOEQghoPVLQ3fsE2q8X\nwKF9+Bffhf+tlShn5F2CL4To2uSU1BDRNA1t8kzU8NGov7+BWvMhau0/0CZciHbxbLSkrnt3WCFE\n5JBQCDEtIRHt3+5BXXk96tO/oTZmozZmo42djHbp1WhpfcNdohAigkkohInmSEa74Xeoy65FfbYa\ntf5j1Ob1MHQkuqkXw4jz0QzyzyOECC351AkzLd6Ods2tqEuuQq37B2rDP/H/JRPi7WiTZqJN/gWa\nvUe4yxRCRAgJhS5Cs8ahXX4d6pJr4Mfv8K//BPXRW6iP3oYRY9BNngnDRsmEPkKITiWh0MVoej2M\nHId+5DhUcQHqi3+iNn6G/4fNYI1FGzMJbdw0GHA2mqaFu1whRDcjodCFaT1S0Gb/GnXlr2DHFtTX\n61CbPket+xh6pKCdPwVtzCRI6ysBIYToEBIKZwDNYIARY9FGjEW5alBbvkJ9sx71j3cCw0uxNrRB\nw+Hsc9AGj4CUNAkJIUSbhCQUli1bRk5ODjabjaysrJOWK6V49dVX2bJlCyaTifnz55Oenh6K0s44\nmiUabcIMmDADdawUtX0L7PwRtetH+NcmFIDNjjb4HBh6LtqQkWh2R7jLFkKcIUISCtOmTePiiy9m\n6dKlTS7fsmULBQUFvPjii+Tm5rJy5UqefvrpUJR2RtPiE9EmZsDEjMCdWIuPonb+CLt+RO38ATav\nD4REz95oQ0eiDRkJg4eFu2whRBcWklAYOnQoRUVFzS7/7rvvmDJlCpqmMWjQIKqrqykrKyMhISEU\n5XULmqZBUmrgyugpFwVC4sh+1I7vA19ffIr6/APQ6yntOwB/r3ToPxCt/yDo2QtNpw93E4QQXUCX\nOKbgdDpxOE4McSQmJuJ0OpsMhezsbLKzswHIzMxstF1rGAyGNm97xujRA0aOBUDV1eLZ+SN1W7/D\nu3cnvu82ojZ8ggI0swV9+mCiBgzG0HcAhn4DMfTuh2Y0hbf+DhYR/+ZNkHZHlva2u0uEQmtkZGSQ\nkZER/LmkpG03lXM4HG3e9oyV2g9S++FwOCguKkIrykfl5cL+XDx5u/F8+neoq59fWqeD5DS0Xv2g\nVz+03v2hV//ARXVn6EHsiPw3R9odaVrS7tTU5u+11iVCwW63N2pEaWkpdrs9jBV1f5pOBym90FJ6\nwQXTAVB+HxQVBIadDuWhDu9H7dsF335BcO44axz07n8iLNL6QkpvNFP36lUIEam6RCiMGTOGTz75\nhIkTJ5Kbm0t0dLQcTwgDTaeHlLTAKa2jJwafVzVVcHg/6tB+OJwXCIx1H4OnLhAWmgY9UiC1D1pq\nX0jtjdYjBRzJgdNlz9CehRCRKCShsGTJEnbs2EFlZSXz5s1jzpw5eL1eAGbOnMmoUaPIycnhrrvu\nwmg0Mn/+/FCUJVpIi7bCoOGBayHqKZ8Pio5C/kFU/kE4cgCVfxC19Vvw+0/0LExmSEwKXGznSAZ7\nD7TEJEjsAfYeEhpCdDGaOsNnlc/Pb9ssZpE63gid23bl8QTCoqQQVVIIJQWB78UFUFIEta7GG0QZ\nA+EQb0ez2SE+AWwJEJeAZkuAWBtExwS+TJZ2BUik/ptLuyNLtzimILoPLSoK0vpAWh9+/vGtlIKa\naigtAmcxqrQYnMVQWoQqd6LydkG5M3iw+6S/VjTdiYCIiQW7I3AH2QQH2vGeR3xiYLnRJD0QIdpA\nQkGEjKZpEGMNfPVJPyk0oD44XDVQXhYIiOpKVE11IExqqsEV+FIV5XD0cOCK7lp30wFitoDFAuZo\nsERzLDkVf6wNEpPRHEmBYx72JDlILkQDEgqiS9E07URvoGevwHOnWD/Y+3AGeh2qrBTcNeByBYaq\nXDUodw3UVOPdvwdVlA9eb+MQMZkDAWKy1AdJNJgtaGZLoA6LNViTZokODmUdXw9zNJjNcgGg6BYk\nFMQZrVHvo3f/UwbI8eszqCiDkiJUaRGUFEJ1Jbhd4Hah3IEgobQY5aoOPHbVgPIDTQxpNWQyB3sl\nwS9zdCBITGYwmcBoAqM58N1kDvRSTJb6bc0NHlsgyihDYCLkJBRERNF0usBxh/hEtLOGtGgbpVSg\n11FTHxI11ScCxF0TCBRXzYnHNdWB3omrBspKA+FSVwu1teDzNt73qV7YYABLTH3A1PeezBa0KCNE\nRQUO0huiAo8NxsB6x3szx9e3ROM36FB1tRIyokUkFIQ4DU3T6oeIohs/34Z9Ka83EBB1tVDnDgRF\nrQvc7sCxkVoX1LpP9FDqeyvq+PGUimMoTx14POD1wPHHDcLm50FTfPyBTte4J2IyB4LFaAKjMXBb\nE6MpEDR6feC4jE4Heh1o+sBzjYbXogPHbEyWwHoAPz+Z0WSGaCtYogOBLLo8CQUhQkgzGAI9gOiY\nppe3cb/K7wscR3FVn+jRuKpQNdVYDXqqSksCvZhaN7hrAr2curpAOLmqoaIs0JuoqwNvHfj94POD\n8jV47G/8mq1quBbovcRYAyFhtgR7OFrDXo/xeEgFhteCw2xGU/36P+8hRQUq8fsDX+rEY0/VMVR1\nTX2vyhTsXWl6OfZzKhIKQnQDmk5/4thKw+eBaIeDmg44X1/5fYEeTaMhs8CxmMYRcTzaFKrWDTVV\nUH3iS9VUBntGeOoC17YEez11gd5TewKonrO5BVp970enB73hxGNDVP3vMBYtJjZw2rM19kSAHw8e\nny9Qn//nX74Tj42mwLaxcWjWuMDtYWJtgd6mVl+Dpp34gsD2vvr9+Lz1j/2BY1GW6MB1OobO/8iW\nUBBCtIim0584M6yl27ThdZRS4PWeGF47/t17PDw84K1DebyBENG0wPCVThcYoqr/OTYmhorS0hNh\nE/zy1n+A+wIf8Mc/jD21gWG6qgrUkQOBExCqKwMfzE2pf83Al/7EY00X6HHVX6jZoVcHG43BoUxt\n6sXoZs7qyL0DEgpCiC5G07T6oZ6owF/rza13mv2YHQ6q2tlDCp5kgNboOEtLjo+oulqoqoSqikDQ\nVFUEelmKQE+j4XdUfc+l/uv4Y00XCMXjJzK46k9ucNUErvzvBBIKQgjRjOBJBm3Z1mgCuwnqp8M9\nU877ktMBhBBCBEkoCCGECJJQEEIIESShIIQQIkhCQQghRJCEghBCiCAJBSGEEEESCkIIIYLO+Dma\nhRBCdJyI7SksWrQo3CWETaS2XdodWaTdbROxoSCEEOJkEgpCCCGC9IsXL14c7iLCJT09PdwlhE2k\ntl3aHVmk3a0nB5qFEEIEyfCREEKIIAkFIYQQQRE5yc7333/Pq6++it/vZ8aMGcya1fFT2nUFy5Yt\nIycnB5vNRlZWFgBVVVU8//zzFBcX06NHD+69916sVutp9nRmKSkpYenSpRw7dgxN08jIyODSSy/t\n9m2vq6vjsccew+v14vP5GD9+PHPmzKGoqIglS5ZQWVlJeno6d955J4YQzPUban6/n0WLFmG321m0\naFFEtPuOO+7AbDaj0+nQ6/VkZma2/32uIozP51MLFixQBQUFyuPxqAceeEAdOnQo3GV1iu3bt6u9\ne/eq++67L/jcG2+8of7+978rpZT6+9//rt54441wlddpnE6n2rt3r1JKqZqaGnXXXXepQ4cOdfu2\n+/1+5XK5lFJKeTwe9fDDD6tdu3aprKwstXHjRqWUUsuXL1effvppOMvsNB988IFasmSJ+tOf/qSU\nUhHR7vnz56vy8vJGz7X3fR5xw0d79uwhJSWF5ORkDAYDEyZM4Ntvvw13WZ1i6NChJ/2F8O233zJ1\n6lQApk6d2i3bnpCQEDz7wmKxkJaWhtPp7PZt1zQNs9kMgM/nw+fzoWka27dvZ/z48QBMmzat27Ub\noLS0lJycHGbMmAEE5laOhHY3pb3v8+7Vl2oBp9NJYmJi8OfExERyc3PDWFFolZeXk5AQmPA7Pj6e\n8vLyMFfUuYqKisjLy+Oss86KiLb7/X4eeughCgoKuOiii0hOTiY6Ohq9Xg+A3W7H6XSGucqOt2rV\nKm688UZcLhcAlZWVEdFugD/+8Y8A/OIXvyAjI6Pd7/OICwVxgqZpgYnJuym3201WVha33HIL0dGN\nJ1/vrm3X6XQ888wzVFdX8+yzz5Kfnx/ukjrdv/71L2w2G+np6Wzfvj3c5YTUk08+id1up7y8nKee\neorU1NRGy9vyPo+4ULDb7ZSWlgZ/Li0txW63h7Gi0LLZbJSVlZGQkEBZWRlxcXHhLqlTeL1esrKy\nmDx5MuPGjQMip+0AMTExDBs2jN27d1NTU4PP50Ov1+N0Orvd+33Xrl189913bNmyhbq6OlwuF6tW\nrer27QaCbbLZbIwdO5Y9e/a0+30ecccUBgwYwNGjRykqKsLr9fLll18yZsyYcJcVMmPGjGH9+vUA\nrF+/nrFjx4a5oo6nlOKll14iLS2Nyy+/PPh8d297RUUF1dXVQOBMpK1bt5KWlsawYcP4+uuvAVi3\nbl23e7//6le/4qWXXmLp0qXcc889DB8+nLvuuqvbt9vtdgeHy9xuN1u3bqVPnz7tfp9H5BXNOTk5\nvPbaa/j9fqZPn87s2bPDXVKnWLJkCTt27KCyshKbzcacOXMYO3Yszz//PCUlJd3ytEyAnTt38uij\nj9KnT59g1/n6669n4MCB3brtBw4cYOnSpfj9fpRSXHDBBVx99dUUFhayZMkSqqqq6N+/P3feeSdR\nUVHhLrdTbN++nQ8++IBFixZ1+3YXFhby7LPPAoETCyZNmsTs2bOprKxs1/s8IkNBCCFE0yJu+EgI\nIUTzJBSEEEIESSgIIYQIklAQQggRJKEghBAiSEJBiDCbM2cOBQUF4S5DCCACr2gW4nTuuOMOjh07\nhk534m+madOmMXfu3DBWJURoSCgI0YSHHnqIESNGhLsMIUJOQkGIFlq3bh2ff/45/fr1Y8OGDSQk\nJDB37lzOOeccIHAH3hUrVrBz506sViu//OUvycjIAAJ3L33vvfdYu3Yt5eXl9OzZk4ULF+JwOADY\nunUrTz/9NBUVFUyaNIm5c+d2yxv2ia5PQkGIVsjNzWXcuHG88sorbN68mWeffZalS5ditVp54YUX\n6N27N8uXLyc/P58nn3ySlJQUhg8fzocffsimTZt4+OGH6dmzJwcOHMBkMgX3m5OTw5/+9CdcLhcP\nPfQQY8aMYeTIkWFsqYhUEgpCNOGZZ54J3osf4MYbb8RgMGCz2bjsssvQNI0JEybwwQcfkJOTw9Ch\nQ9m5cyeLFi3CaDTSr18/ZsyYwfr16xk+fDiff/45N954Y/DWxv369Wv0erNmzSImJiZ4d9P9+/dL\nKIiwkFAQogkLFy486ZjCunXrsNvtjYZ1evTogdPppKysDKvVisViCS5zOBzs3bsXCNyiPTk5udnX\ni4+PDz42mUy43e6OaooQrSKnpArRCk6nk4b3kCwpKcFut5OQkEBVVVXwVsYNl0Fghr/CwsKQ1ytE\na0koCNEK5eXlfPzxx3i9Xr766iuOHDnCqFGjcDgcDB48mP/93/+lrq6OAwcOsHbtWiZPngzAjBkz\neOuttzh69ChKKQ4cOEBlZWWYWyPEyWT4SIgm/Md//Eej6xRGjBjB2LFjGThwIEePHmXu3LnEx8dz\n3333ERsbC8Ddd9/NihUruP3227FarVxzzTXBIajLL78cj8fDU089RWVlJWlpaTzwwANhaZsQpyLz\nKQjRQsdPSX3yySfDXYoQnUaGj4QQQgRJKAghhAiS4SMhhBBB0lMQQggRJKEghBAiSEJBCCFEkISC\nEEKIIAkFIYQQQf8/SUfcsaGe3N8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEaCAYAAAD+E0veAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhBAuEgpCCCFc/j9ULh4wOxXj0AAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEaCAYAAAD+E0veAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEXEoFERExPF/kJ9R/u9OhAEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3y8HyLW1fPvb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsYpyA4omuiY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import model_from_json\n",
        "\n",
        "def load_model(dir = os.getcwd(), name = 'model'):\n",
        "  json_file = open(os.path.join(dir,name+'.json'), 'r')\n",
        "  loaded_model_json = json_file.read()\n",
        "  json_file.close()\n",
        "  model = model_from_json(loaded_model_json)\n",
        "  model.load_weights(os.path.join(dir,name+'.h5'))\n",
        "  print(\"Loading is complete.\")\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvoCZeopmulB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nn = load_model(DIR, 'model_nn')\n",
        "opt = Adam(lr = 0.05)\n",
        "nn.compile(optimizer = opt, loss = mse)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vze6V-2Dv3R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwGQ3nubDv6C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "\n",
        "k = nn.evaluate(X_val, y_val, batch_size = 800000, verbose = 0)\n",
        "print(k)\n",
        "for i in range(X_val.shape[1]):\n",
        "    X_val_2 = X_val.copy()\n",
        "    s = shuffle(X_val_2.iloc[:,i])\n",
        "    s.index = X_val_2.index\n",
        "    X_val_2.iloc[:, i] = s\n",
        "    print('{}: {:2.5}'.format(cols[i], nn.evaluate(X_val_2, y_val, batch_size = 800000, verbose = 0) - k))\n",
        "    X_val_2 = None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7cW0BjWDog5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rglOCdGlDojs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "p = nn.predict(X_test, batch_size = 100000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHSFbHZiq7Of",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuyutB_Z1pu4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_sample_submission.to_csv(DIR+'out_file_int.csv', index = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gQzWTyi1Vjb",
        "colab_type": "code",
        "outputId": "4a1a4271-a100-49b4-8b17-4effad4507ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df_sample_submission.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>row_id</th>\n",
              "      <th>meter_reading</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8784</th>\n",
              "      <td>0</td>\n",
              "      <td>187.721802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8785</th>\n",
              "      <td>129</td>\n",
              "      <td>170.970444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8786</th>\n",
              "      <td>258</td>\n",
              "      <td>158.120926</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8787</th>\n",
              "      <td>387</td>\n",
              "      <td>150.405380</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8788</th>\n",
              "      <td>516</td>\n",
              "      <td>149.041794</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      row_id  meter_reading\n",
              "8784       0     187.721802\n",
              "8785     129     170.970444\n",
              "8786     258     158.120926\n",
              "8787     387     150.405380\n",
              "8788     516     149.041794"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaKZlONMsta8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_sample_submission['row_id'] = df_sample_submission['row_id'].astype('Int32')\n",
        "df_sample_submission['meter_reading'] = df_sample_submission['meter_reading'].astype('float16')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOIMC9y_steQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}