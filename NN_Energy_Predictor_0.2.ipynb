{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of NN Energy Predictor.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yovelop/NN/blob/master/NN_Energy_Predictor_0.2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zO1azhvf_t9_",
        "colab_type": "code",
        "outputId": "973cd904-03ff-494e-d7a4-ec00651305b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "DIR = '/content/drive/My Drive/Colab Notebooks/ENSaver/'"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laCRJiQ_DGO8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "drive.flush_and_unmount()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRgT9oDx_vpi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "bdf2e772-2a05-4a32-8677-112ed1f1bade"
      },
      "source": [
        "#Импорты\n",
        "  import numpy as np # linear algebra\n",
        "  import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "  import matplotlib.pyplot as plt\n",
        "  import matplotlib.style\n",
        "  matplotlib.style.use('ggplot')\n",
        "\n",
        "  from sys import getsizeof\n",
        "\n",
        "  import os\n",
        "  for dirname, _, filenames in os.walk(DIR):\n",
        "      for filename in filenames:\n",
        "          print(os.path.join(dirname, filename))\n",
        "\n",
        "  pd.options.mode.chained_assignment = None  # default='warn'\n",
        "  import warnings\n",
        "  pd.set_option('display.max_rows', 500)\n",
        "  pd.set_option('display.max_columns', 500)\n",
        "  pd.set_option('display.width', 100)\n",
        "  warnings.filterwarnings('ignore')\n",
        "  np.set_printoptions (precision = 4, suppress  = True)\n",
        "\n",
        "  def reduce_mem_usage(df):\n",
        "      start_mem_usg = df.memory_usage().sum() / 1024**2 \n",
        "      print(\"Memory usage of properties dataframe is :\",start_mem_usg,\" MB\")\n",
        "      NAlist = [] # Keeps track of columns that have missing values filled in. \n",
        "      for col in df.columns:\n",
        "          if (df[col].dtype != object) &  (df[col].dtype != 'datetime64[ns]'):  # Exclude strings            \n",
        "              # Print current column type\n",
        "              print(\"******************************\")\n",
        "              print(\"Column: \",col)\n",
        "              print(\"dtype before: \",df[col].dtype)            \n",
        "              # make variables for Int, max and min\n",
        "              IsInt = False\n",
        "              mx = df[col].max()\n",
        "              mn = df[col].min()\n",
        "              print(\"min for this col: \",mn)\n",
        "              print(\"max for this col: \",mx)\n",
        "              # Integer does not support NA, therefore, NA needs to be filled\n",
        "              if not np.isfinite(df[col]).all(): \n",
        "                  NAlist.append(col)\n",
        "                  df[col].fillna(mn-1,inplace=True)  \n",
        "                    \n",
        "              # test if column can be converted to an integer\n",
        "              asint = df[col].fillna(0).astype(np.int64)\n",
        "              result = (df[col] - asint)\n",
        "              result = result.sum()\n",
        "              if result > -0.01 and result < 0.01:\n",
        "                  IsInt = True            \n",
        "              # Make Integer/unsigned Integer datatypes\n",
        "              if IsInt:\n",
        "                  if mn >= 0:\n",
        "                      if mx < 255:\n",
        "                          df[col] = df[col].astype(np.uint8)\n",
        "                      elif mx < 65535:\n",
        "                          df[col] = df[col].astype(np.uint16)\n",
        "                      elif mx < 4294967295:\n",
        "                          df[col] = df[col].astype(np.uint32)\n",
        "                      else:\n",
        "                          df[col] = df[col].astype(np.uint64)\n",
        "                  else:\n",
        "                      if mn > np.iinfo(np.int8).min and mx < np.iinfo(np.int8).max:\n",
        "                          df[col] = df[col].astype(np.int8)\n",
        "                      elif mn > np.iinfo(np.int16).min and mx < np.iinfo(np.int16).max:\n",
        "                          df[col] = df[col].astype(np.int16)\n",
        "                      elif mn > np.iinfo(np.int32).min and mx < np.iinfo(np.int32).max:\n",
        "                          df[col] = df[col].astype(np.int32)\n",
        "                      elif mn > np.iinfo(np.int64).min and mx < np.iinfo(np.int64).max:\n",
        "                          df[col] = df[col].astype(np.int64)    \n",
        "              # Make float datatypes 32 bit\n",
        "              else:\n",
        "                  df[col] = df[col].astype(np.float32)\n",
        "              \n",
        "              # Print new column type\n",
        "              print(\"dtype after: \",df[col].dtype)\n",
        "              print(\"******************************\")\n",
        "      # Print final result\n",
        "      print(\"___MEMORY USAGE AFTER COMPLETION:___\")\n",
        "      mem_usg = df.memory_usage().sum() / 1024**2 \n",
        "      print(\"Memory usage is: \",mem_usg,\" MB\")\n",
        "      print(\"This is \",100*mem_usg/start_mem_usg,\"% of the initial size\")\n",
        "      return df, NAlist\n",
        "\n",
        "  def show_plot(hist):\n",
        "    plt.plot(hist.history['loss'])\n",
        "    plt.plot(hist.history['val_loss'])\n",
        "    plt.title('Model NN')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend(['Train','Val'])\n",
        "    plt.show()\n",
        "    \n",
        "    plt.plot(hist.history['loss'])\n",
        "    plt.plot(hist.history['val_loss'])\n",
        "    plt.title('Model NN')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.ylim([1,2])\n",
        "    plt.legend(['Train','Val'])\n",
        "    plt.show()\n",
        "\n",
        "    plt.plot(hist.history['loss'])\n",
        "    plt.plot(hist.history['val_loss'])\n",
        "    plt.title('Model NN')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.ylim([0,1])\n",
        "    plt.legend(['Train','Val'])\n",
        "    plt.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/ENSaver/building_metadata.csv\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/model_nn.h5\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/model_nn.json\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/out_file_int.csv\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/sample_submission (1).csv\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/sample_submission.csv\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/test.csv\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/train.csv\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/weather_test.csv\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/weather_train.csv\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/DF_TRAIN_EXTENDED.FTHR\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/0HANDLY_SAVED.MODEL\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/1HANDLY_SAVED.MODEL\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/best_nn_0.model\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/2HANDLY_SAVED.MODEL\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/3HANDLY_SAVED.MODEL\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/best_nn_2.model\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/DF_TRAIN_REDUCED2.FTHR\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQppkzTWUjLm",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Fv4ErMY_vsQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#0: electricity, 1: chilledwater, 2: steam, 3: hotwater\n",
        "#  Подготовка данных\n",
        "  df = pd.read_csv(DIR + \"train.csv\", engine = 'python')\n",
        "  #df_test = pd.read_csv(DIR + \"test.csv\", engine = 'python')\n",
        "\n",
        "  df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
        "  #df_test['timestamp'] = pd.to_datetime(df_test['timestamp'])\n",
        "\n",
        "  #Очистка от корявых данных\n",
        "  #df = df.query('not (building_id <= 104 & meter == 0 & timestamp <= \"2016-05-20\")')\n",
        "\n",
        "  #df['meter_reading'] = np.log1p(df['meter_reading'])\n",
        "\n",
        "  #df = pd.concat([df_train, df_test], sort=False)\n",
        "\n",
        "  df['hour_cos'] = np.cos(df['timestamp'].dt.hour * 2 * np.pi / 24)\n",
        "  df['hour_sin'] = np.sin(df['timestamp'].dt.hour * 2 * np.pi / 24)\n",
        "\n",
        "  df['weekday_cos'] = np.cos(df['timestamp'].dt.weekday * 2 * np.pi / 7)\n",
        "  df['weekday_sin'] = np.sin(df['timestamp'].dt.weekday * 2 * np.pi / 7)\n",
        "\n",
        "  df['week_cos'] = np.cos(df['timestamp'].dt.week * 2 * np.pi / 53)\n",
        "  df['week_sin'] = np.sin(df['timestamp'].dt.week * 2 * np.pi / 53)\n",
        "\n",
        "  #df_train['weekends'] = (df_train['weekday'] >= 6) * 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3xRu7Y_2MP5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Очистка от подозрительных нулей\n",
        "  #print(df[df['building_id']==2][['timestamp','meter_reading','meter','ds_zero','de_zero','is_bad_zero']].head(20))\n",
        "  df = df.sort_values(by = ['meter','building_id','timestamp'])\n",
        "  df['meter_reading_prev'] = 0\n",
        "\n",
        "  #for bid in df['building_id'].unique():\n",
        "  #  for met in df['meter'].unique():\n",
        "  df['meter_reading_prev'] = df['meter_reading'].shift()\n",
        "  df['is_equal_prev']= (df['meter_reading_prev'] == df['meter_reading'] )*1\n",
        "\n",
        "  df['day'] = df['timestamp'].dt.dayofyear\n",
        "  df_bad_rows = df.groupby(by=['building_id','day','meter'], as_index = False)['is_equal_prev'].mean()\n",
        "  df_bad_rows.rename({\"is_equal_prev\": \"IS_BAD_PRCNT\"}, axis='columns', inplace=True)\n",
        "\n",
        "  df = pd.merge(df, df_bad_rows, how = 'inner', on = ['building_id','day','meter'])\n",
        "  #print(df_bad_rows[df_bad_rows['building_id']==109].head(365))\n",
        "  del df_bad_rows \n",
        "\n",
        "  #print(df[df['building_id']==2][['timestamp','meter_reading','is_equal_prev','IS_BAD_PRCNT','day']].head(30))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g52hlFMS2cpu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Добавление медианы по метрике постройки\n",
        "  df_median = df.groupby(by=['building_id','meter'])['meter_reading'].median()\n",
        "  df_median.name = 'building_meter_median'\n",
        "  df = pd.merge(df, df_median, how = 'inner', on = ['building_id','meter'])\n",
        "  del df_median \n",
        "# Добавление медианы по часу, по неделе, метрике постройки\n",
        "  df['hour'] = df['timestamp'].dt.hour\n",
        "  df_median = df.groupby(by=['building_id','hour','meter'])['meter_reading'].median()\n",
        "  df_median.name = 'building_meter_hour_median'\n",
        "  df = pd.merge(df, df_median, how = 'inner', on = ['building_id','hour','meter'])\n",
        "  del df_median \n",
        "\n",
        "  df['weekday'] = df['timestamp'].dt.weekday\n",
        "  df_median = df.groupby(by=['building_id','weekday','meter'])['meter_reading'].median()\n",
        "  df_median.name = 'building_meter_weekday_median'\n",
        "  df = pd.merge(df, df_median, how = 'inner', on = ['building_id','weekday','meter'])\n",
        "  del df_median \n",
        "#Подстановка параметров сооружения\n",
        "  building_df = pd.read_csv(DIR + \"building_metadata.csv\", engine = 'python')\n",
        "  from sklearn.preprocessing import LabelEncoder\n",
        "  le = LabelEncoder()\n",
        "  building_df[\"primary_use_ID\"] = le.fit_transform(building_df[\"primary_use\"])\n",
        "\n",
        "  building_df['primary_use'] = building_df['primary_use'].astype('category')\n",
        "  building_df = pd.get_dummies(building_df)\n",
        "\n",
        "  df = df.merge(building_df, left_on = \"building_id\", right_on = \"building_id\", how = \"left\")\n",
        "  df.head(5)\n",
        "  del building_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIDKj_YCb_bD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Вставка данных погоды\n",
        "#Восстановление пустых данных погоды через соседей по линейной инетрполяции\n",
        "  df_weather = pd.read_csv(DIR + \"weather_train.csv\", engine = 'python')\n",
        "  df_weather['timestamp'] = pd.to_datetime(df_weather['timestamp'])\n",
        "\n",
        "  #weather_train.groupby('site_id').apply(lambda group: group.isna().sum())\n",
        "  df_times = df.drop_duplicates(['site_id','timestamp'])[['site_id','timestamp']]\n",
        "  df_times = pd.merge(df_times, df_weather, how = 'left', on = ['site_id','timestamp'])\n",
        "  df_times = df_times.sort_values(by = ['site_id','timestamp'])\n",
        "  \n",
        "  df_times = df_times.groupby('site_id').apply(lambda group: group.interpolate(limit_direction='both'))\n",
        "  df = pd.merge(df, df_times, how = 'left', on = ['site_id','timestamp'])\n",
        "  #del df_weather"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vojXrtAOc0t",
        "colab_type": "code",
        "outputId": "9b4fc03f-52d7-4fe4-8a3c-3a26e1b59d6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "#Инфо о корявости данных:\n",
        "  print('0 Всего:',df[df['meter']==0].shape, 'Откинуть:', df[(df['meter']==0) & (df['IS_BAD_PRCNT']>0.45)].shape)\n",
        "  print('1 Всего:',df[df['meter']==1].shape, 'Откинуть:', df[(df['meter']==1) & (df['IS_BAD_PRCNT']>0.75)].shape)\n",
        "  print('2 Всего:',df[df['meter']==2].shape, 'Откинуть:', df[(df['meter']==2) & (df['IS_BAD_PRCNT']>0.75)].shape)\n",
        "  print('3 Всего:',df[df['meter']==3].shape, 'Откинуть:', df[(df['meter']==3) & (df['IS_BAD_PRCNT']>0.75)].shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 Всего: (12060910, 47) Откинуть: (1401057, 47)\n",
            "1 Всего: (4182440, 47) Откинуть: (537615, 47)\n",
            "2 Всего: (2708713, 47) Откинуть: (223436, 47)\n",
            "3 Всего: (1264037, 47) Откинуть: (311410, 47)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmQtkGKQCueL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Вывести кол-во пустот по полям. Затем заполнить из средним значением по полю\n",
        "  for col in df.columns:\n",
        "    print(col)\n",
        "    for met in df['meter'].unique():\n",
        "      if np.sum(df[col].isnull()) > 0:\n",
        "        print(met)\n",
        "        print(np.sum(df[col].isnull()))\n",
        "\n",
        "        df_col = df.groupby(by=['building_id','meter'], as_index = False)[col].mean()\n",
        "        df_col.rename({col: \"tmp\"}, axis='columns', inplace=True)\n",
        "        df = df.merge(df_col, left_on = ['building_id','meter'], right_on = ['building_id','meter'], how = \"left\")\n",
        "        df[col].fillna( df_col['tmp'], inplace = True)\n",
        "        df.drop(columns = ['tmp'],inplace = True)\n",
        "        del df_col\n",
        "\n",
        "        df_col = df.groupby(by=['meter'], as_index = False)[col].mean()\n",
        "        df_col.rename({col: \"tmp\"}, axis='columns', inplace=True)\n",
        "        df = df.merge(df_col, left_on = ['meter'], right_on = ['meter'], how = \"left\")\n",
        "        df[col].fillna( df_col['tmp'], inplace = True)\n",
        "        df.drop(columns = ['tmp'],inplace = True)\n",
        "        del df_col\n",
        "\n",
        "        df[col].fillna( df[col].mean(), inplace = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxPaU99v4PI-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.to_feather(DIR + 'DF_TRAIN_EXTENDED2.FTHR')\n",
        "#df = pd.read_feather(DIR + 'DF_TRAIN_EXTENDED2.FTHR')\n",
        "reduce_mem_usage(df)\n",
        "df.to_feather(DIR + 'DF_TRAIN_REDUCED2.FTHR')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6XbWpxAUnQb",
        "colab_type": "text"
      },
      "source": [
        "  Скорость"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asr3-4DHF_sx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "df = pd.read_feather(DIR + 'DF_TRAIN_REDUCED2.FTHR')\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dKU2_Eb7NFo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRnpeXMU_vu5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "d5720701-0834-4d8f-b3a5-ed58d56dfa8d"
      },
      "source": [
        "#Импорты Керас:\n",
        "  from keras.models import Sequential, load_model\n",
        "\n",
        "  from keras.layers import Dense\n",
        "  from keras.initializers import TruncatedNormal, Constant\n",
        "  from keras.regularizers import l1,l2,l1_l2\n",
        "  from keras.optimizers import Adam\n",
        "  import keras.backend as K\n",
        "\n",
        "  from keras. callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "  #from keras.utils import plot_model\n",
        "  from keras.losses import mean_squared_error as mse #, mean_absolute_percentage_error as mape\n",
        "\n",
        "  def RMSLE(y_true, y_pred):\n",
        "    return K.pow( K.mean( K.pow(K.log(y_true+1) - K.log(y_pred+1),2.00000)),0.5000)\n",
        "\n",
        "  def tweedieloss(y_true, y_pred):\n",
        "      return K.mean(  K.pow(    K.pow(backend.maximum(0.000,K.maximum(0.013000,y_true)),0.5)  -   K.pow(K.maximum(0.013000,y_pred),0.5)   , 2 ) / K.pow(K.maximum(0.013000,y_pred),0.5)\n",
        "                  )\n",
        "\n",
        "  def tweedieloss_bkp(y_true, y_pred):\n",
        "      p=1.5\n",
        "      dev = 2 * (K.pow(K.maximum(0.000,y_true), 2-p)/((1-p) * (2-p)) -\n",
        "                    y_true * K.pow(y_pred, 1-p)/(1-p) +\n",
        "                    K.pow(y_pred, 2-p)/(2-p))\n",
        "      return K.mean(dev)\n",
        "\n",
        "  def VAL_ (y_true, y_pred):\n",
        "      return  K.maximum(0.0330000, K.sum(y_pred))/ K.maximum(0.033000, K.sum(y_true)) \n",
        "      \n",
        "  def VAL_2 (y_true, y_pred):\n",
        "      return  K.minimum( 5.000000, K.exp ( K.abs( K.log( VAL_ (y_true, y_pred))))-1)\n",
        "  \n",
        "  def VAL_3 (y_true, y_pred):\n",
        "      return  K.exp ( K.abs( K.log( VAL_ (y_true, y_pred))))-1\n",
        "\n",
        "  def MAPE_ (y_true, y_pred):\n",
        "      return K.mean( K.minimum( 5.000000,  K.abs(y_true - y_pred)/ K.maximum(0.033000, y_true)) )\n",
        "      \n",
        "  def MAE_(y_true, y_pred):\n",
        "      return K.sum( K.abs(y_true - y_pred))/ K.maximum(0.033000, K.sum(y_true))\n",
        "\n",
        "  def MSE_(y_true, y_pred):\n",
        "      return K.sum( K.pow(y_true - y_pred,2.00000))/ K.maximum(0.033000,  K.sum(K.pow(y_true,2.00000)))\n",
        "\n",
        "  def MAE_MAPE(y_true, y_pred):\n",
        "      return (\n",
        "                        MAE_(y_true, y_pred)\n",
        "          +  0.250000 * MAPE_ (y_true, y_pred)\n",
        "      )\n",
        "              \n",
        "  def MAE_VAL_MAPE(y_true, y_pred):\n",
        "      return (\n",
        "                        MAE_(y_true, y_pred)\n",
        "          + 1.800000 *   VAL_2 (y_true, y_pred)          \n",
        "          + 0.950000 *   MAPE_ (y_true, y_pred)\n",
        "          )\n",
        "\n",
        "  def MAE_VAL(y_true, y_pred):\n",
        "      return (\n",
        "                        MAE_(y_true, y_pred)\n",
        "          + 0.800000 *   VAL_2 (y_true, y_pred)                     \n",
        "              )\n",
        "\n",
        "  def MAPE_VAL(y_true, y_pred):\n",
        "      return (\n",
        "                      MAPE_ (y_true, y_pred)\n",
        "          + 0.4000 *  VAL_2 (y_true, y_pred)             \n",
        "              )\n",
        "\n",
        "  def MSE_VAL_MAPE(y_true, y_pred):\n",
        "      return (\n",
        "            5.000000 *   MSE_(y_true, y_pred)\n",
        "          + 2.200000 *   VAL_2 (y_true, y_pred)          \n",
        "          + 0.750000 *   MAPE_ (y_true, y_pred)\n",
        "          )\n",
        "\n",
        "  def MASPE_VAL(y_true, y_pred):\n",
        "      return (\n",
        "                        MAE_(y_true, y_pred)               \n",
        "          + 0.500000 *   MSE_(y_true, y_pred)\n",
        "          + 1.200000 *   VAL_2 (y_true, y_pred)          \n",
        "          + 0.250000 *   MAPE_ (y_true, y_pred)\n",
        "          )\n",
        "  \n",
        "  def MAE_RMSLE(y_true, y_pred):\n",
        "      return (\n",
        "            1.000000 *   MAE_   (y_true, y_pred)\n",
        "          + 2.000000 *   RMSLE  (y_true, y_pred)          \n",
        "          )  \n",
        "\n",
        "  def MAPE_RMSLE(y_true, y_pred):\n",
        "      return (\n",
        "            1.000000 *   MAPE_   (y_true, y_pred)\n",
        "          + 1.000000 *   RMSLE  (y_true, y_pred)          \n",
        "          )  \n",
        "  \n",
        "  def MAPE_VAL_RMSLE(y_true, y_pred):\n",
        "      return (\n",
        "            1.000000 *   MAPE_   (y_true, y_pred)\n",
        "          + 1.000000 *   RMSLE   (y_true, y_pred)    \n",
        "          + 1.000000 *   VAL_2   (y_true, y_pred)      \n",
        "          )  \n",
        "\n",
        "  import keras.metrics\n",
        "  keras.metrics.MAE_ = MAE_\n",
        "  keras.metrics.VAL_ = VAL_\n",
        "  keras.metrics.VAL_2 = VAL_2\n",
        "  keras.metrics.MAPE_ = MAPE_\n",
        "  keras.metrics.MSE_ = MSE_\n",
        "  keras.metrics.tweedieloss = tweedieloss\n",
        "  keras.metrics.MAE_RMSLE = MAE_RMSLE\n",
        "  keras.metrics.MAPE_RMSLE = MAPE_RMSLE\n",
        "  keras.metrics.MAPE_VAL_RMSLE = MAPE_VAL_RMSLE\n",
        "  keras.metrics.RMSLE = RMSLE\n",
        "\n",
        "  import keras.losses\n",
        "  keras.losses.MAE_VAL_MAPE = MAE_VAL_MAPE\n",
        "  keras.losses.MSE_VAL_MAPE = MSE_VAL_MAPE\n",
        "  keras.losses.MAE_ = MAE_\n",
        "  keras.losses.MASPE_VAL = MASPE_VAL\n",
        "  keras.losses.tweedieloss = tweedieloss\n",
        "  keras.losses.MAE_RMSLE = MAE_RMSLE\n",
        "  keras.losses.MAPE_RMSLE = MAPE_RMSLE\n",
        "  keras.losses.MAPE_VAL_RMSLE = MAPE_VAL_RMSLE\n",
        "  keras.losses.RMSLE = RMSLE"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfToQh4ArZ3R",
        "colab_type": "code",
        "outputId": "dedd2b82-5ad4-4c97-d70a-5fa1509c1e8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "df.columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['building_id', 'meter', 'timestamp', 'meter_reading', 'hour_cos', 'hour_sin', 'weekday_cos',\n",
              "       'weekday_sin', 'week_cos', 'week_sin', 'meter_reading_prev', 'is_equal_prev', 'day',\n",
              "       'IS_BAD_PRCNT', 'building_meter_median', 'hour', 'building_meter_hour_median', 'weekday',\n",
              "       'building_meter_weekday_median', 'site_id', 'square_feet', 'year_built', 'floor_count',\n",
              "       'primary_use_ID', 'primary_use_Education', 'primary_use_Entertainment/public assembly',\n",
              "       'primary_use_Food sales and service', 'primary_use_Healthcare',\n",
              "       'primary_use_Lodging/residential', 'primary_use_Manufacturing/industrial',\n",
              "       'primary_use_Office', 'primary_use_Other', 'primary_use_Parking',\n",
              "       'primary_use_Public services', 'primary_use_Religious worship', 'primary_use_Retail',\n",
              "       'primary_use_Services', 'primary_use_Technology/science', 'primary_use_Utility',\n",
              "       'primary_use_Warehouse/storage', 'air_temperature_x', 'cloud_coverage_x',\n",
              "       'dew_temperature_x', 'precip_depth_1_hr_x', 'sea_level_pressure_x', 'wind_direction_x',\n",
              "       'wind_speed_x', 'air_temperature_y', 'cloud_coverage_y', 'dew_temperature_y',\n",
              "       'precip_depth_1_hr_y', 'sea_level_pressure_y', 'wind_direction_y', 'wind_speed_y'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_Em3Xm6rdeV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Out_Columns = 'meter_reading'\n",
        "In_Columns = [ 'hour_cos','hour_sin', 'weekday_cos', 'weekday_sin', 'week_cos', 'week_sin',\n",
        "       'site_id', 'square_feet', 'year_built', 'floor_count', #'primary_use_ID',\n",
        "       'primary_use_Education', 'primary_use_Entertainment/public assembly',\n",
        "       'primary_use_Food sales and service', 'primary_use_Healthcare',\n",
        "       'primary_use_Lodging/residential',\n",
        "       'primary_use_Manufacturing/industrial', 'primary_use_Office',\n",
        "       'primary_use_Other', 'primary_use_Parking',\n",
        "       'primary_use_Public services', 'primary_use_Religious worship',\n",
        "       'primary_use_Retail', 'primary_use_Services',\n",
        "       'primary_use_Technology/science', 'primary_use_Utility',\n",
        "       'primary_use_Warehouse/storage', 'air_temperature', 'cloud_coverage',\n",
        "       'dew_temperature', 'precip_depth_1_hr', 'sea_level_pressure',\n",
        "       'wind_direction', 'wind_speed'\n",
        "       , 'building_meter_median','building_meter_hour_median','building_meter_weekday_median']\n",
        "# Нормализация\n",
        "if 1==1:\n",
        "  from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, OneHotEncoder\n",
        "  scaler =  MinMaxScaler (copy=True, feature_range=(0, 1))                                  #quantile_range  = (15.0,85.0)) #Normalizer #(copy=True, feature_range=(-1, 1)) # MinMaxScaler(copy=True, feature_range=(-1, 1)) #StandardScaler() #MinMaxScaler(copy=True, feature_range=(-1, 1)) # RobustScaler()\n",
        "  scaler.fit( df[In_Columns] )\n",
        "  df[In_Columns]     = pd.DataFrame(data = scaler.transform( df[In_Columns])    , columns = df[In_Columns].columns   , index=df.index) \n",
        "\n",
        "  df.fillna(0.33)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aup6pDdkDoZZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f675bbbe-f55c-4867-b17d-7a037afcc39c"
      },
      "source": [
        "#0: electricity, 1: chilledwater, 2: steam, 3: hotwater\n",
        "# РАСЧЁТ НЕЙРОНОК:\n",
        "  reg = 0.00001\n",
        "  batch_size = 2048\n",
        "  epochs = 50\n",
        "  meter = 0\n",
        "\n",
        "  earlyStopping = EarlyStopping(monitor='loss', patience=100, verbose=1, mode='min')\n",
        "  reduce_lr_loss = ReduceLROnPlateau(monitor='loss', factor=0.3, patience=5, verbose=1, min_delta=1e-3, mode='min')\n",
        "  model_checkpoint = ModelCheckpoint(monitor='loss', save_best_only=True, filepath = DIR + 'best_nn_' + str(meter) + '.model', save_weights_only = False, verbose=0, mode='min')\n",
        "\n",
        "  init = TruncatedNormal(mean=0.0, stddev=0.05, seed=159)\n",
        "  bias = Constant(value = 1e-3)\n",
        "  \n",
        "  if 0==0:\n",
        "    meter = 0\n",
        "    opt = Adam(lr = 0.009)\n",
        "\n",
        "    nn_0 = Sequential()\n",
        "    nn_0.add(Dense(60, input_shape = df[In_Columns].shape[1:], activation = 'tanh', kernel_regularizer=l1(reg), kernel_initializer = 'normal'))\n",
        "    nn_0.add(Dense(60, activation = 'tanh',  kernel_initializer = 'normal'))\n",
        "    nn_0.add(Dense(1, activation = 'relu', kernel_initializer = 'normal'))\n",
        "\n",
        "    nn_0.compile(optimizer = opt, loss = MAE_RMSLE, metrics=[ MAE_, RMSLE, VAL_, 'mse' ])\n",
        "    \n",
        "    val = df[(df['meter']==meter) & (df['day']%6==0)]\n",
        "    hist = nn_0.fit( df[(df['meter']==meter) & (df['IS_BAD_PRCNT']<0.45)][In_Columns], df[(df['meter']==meter) & (df['IS_BAD_PRCNT']<0.45)][Out_Columns], batch_size = batch_size, verbose = 1\n",
        "                    , epochs = epochs, shuffle = True, callbacks=[earlyStopping, reduce_lr_loss,model_checkpoint]\n",
        "                    , validation_data=(val[In_Columns], val[Out_Columns])\n",
        "                    ) \n",
        "    nn_0.save(DIR + str(meter) + 'HANDLY_SAVED2.MODEL')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4409: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1702: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 10659833 samples, validate on 2010873 samples\n",
            "Epoch 1/50\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "10659833/10659833 [==============================] - 47s 4us/step - loss: 2.2828 - MAE_: 0.5814 - RMSLE: 0.8457 - VAL_: 0.5186 - mean_squared_error: 96750.6682 - val_loss: 1.9125 - val_MAE_: 0.3594 - val_RMSLE: 0.7690 - val_VAL_: 0.9697 - val_mean_squared_error: 109953.7138\n",
            "Epoch 2/50\n",
            "10659833/10659833 [==============================] - 37s 3us/step - loss: 1.3292 - MAE_: 0.3683 - RMSLE: 0.4719 - VAL_: 0.7129 - mean_squared_error: 69628.5752 - val_loss: 1.7638 - val_MAE_: 0.3043 - val_RMSLE: 0.7206 - val_VAL_: 0.9422 - val_mean_squared_error: 98766.7754\n",
            "Epoch 3/50\n",
            "10659833/10659833 [==============================] - 37s 4us/step - loss: 1.2114 - MAE_: 0.3237 - RMSLE: 0.4342 - VAL_: 0.7621 - mean_squared_error: 61632.4418 - val_loss: 1.8411 - val_MAE_: 0.3152 - val_RMSLE: 0.7530 - val_VAL_: 0.8593 - val_mean_squared_error: 92679.9907\n",
            "Epoch 4/50\n",
            "10659833/10659833 [==============================] - 37s 3us/step - loss: 1.1538 - MAE_: 0.2996 - RMSLE: 0.4168 - VAL_: 0.7884 - mean_squared_error: 56748.3699 - val_loss: 1.7811 - val_MAE_: 0.3056 - val_RMSLE: 0.7272 - val_VAL_: 1.0383 - val_mean_squared_error: 88475.1095\n",
            "Epoch 5/50\n",
            "10659833/10659833 [==============================] - 37s 3us/step - loss: 1.1166 - MAE_: 0.2831 - RMSLE: 0.4060 - VAL_: 0.8061 - mean_squared_error: 53229.6667 - val_loss: 1.7078 - val_MAE_: 0.2798 - val_RMSLE: 0.7031 - val_VAL_: 0.9672 - val_mean_squared_error: 85220.2171\n",
            "Epoch 6/50\n",
            "10659833/10659833 [==============================] - 37s 3us/step - loss: 1.0890 - MAE_: 0.2707 - RMSLE: 0.3981 - VAL_: 0.8194 - mean_squared_error: 50449.6909 - val_loss: 1.6930 - val_MAE_: 0.2765 - val_RMSLE: 0.6971 - val_VAL_: 0.9741 - val_mean_squared_error: 82559.9733\n",
            "Epoch 7/50\n",
            "10659833/10659833 [==============================] - 37s 3us/step - loss: 1.0653 - MAE_: 0.2606 - RMSLE: 0.3911 - VAL_: 0.8301 - mean_squared_error: 48151.5278 - val_loss: 1.8284 - val_MAE_: 0.3187 - val_RMSLE: 0.7435 - val_VAL_: 1.1150 - val_mean_squared_error: 80463.4367\n",
            "Epoch 8/50\n",
            "10659833/10659833 [==============================] - 37s 4us/step - loss: 1.0469 - MAE_: 0.2522 - RMSLE: 0.3859 - VAL_: 0.8392 - mean_squared_error: 46189.7077 - val_loss: 1.6885 - val_MAE_: 0.2725 - val_RMSLE: 0.6965 - val_VAL_: 1.0012 - val_mean_squared_error: 78469.1074\n",
            "Epoch 9/50\n",
            "10659833/10659833 [==============================] - 37s 3us/step - loss: 1.0311 - MAE_: 0.2449 - RMSLE: 0.3816 - VAL_: 0.8473 - mean_squared_error: 44481.5732 - val_loss: 1.6703 - val_MAE_: 0.2652 - val_RMSLE: 0.6911 - val_VAL_: 0.9968 - val_mean_squared_error: 76704.1822\n",
            "Epoch 10/50\n",
            "10659833/10659833 [==============================] - 38s 4us/step - loss: 1.0181 - MAE_: 0.2386 - RMSLE: 0.3782 - VAL_: 0.8545 - mean_squared_error: 42985.6934 - val_loss: 1.6787 - val_MAE_: 0.2686 - val_RMSLE: 0.6935 - val_VAL_: 0.9713 - val_mean_squared_error: 75183.4292\n",
            "Epoch 11/50\n",
            "10659833/10659833 [==============================] - 39s 4us/step - loss: 1.0062 - MAE_: 0.2334 - RMSLE: 0.3749 - VAL_: 0.8607 - mean_squared_error: 41681.7290 - val_loss: 1.6921 - val_MAE_: 0.2720 - val_RMSLE: 0.6985 - val_VAL_: 1.0355 - val_mean_squared_error: 73919.9385\n",
            "Epoch 12/50\n",
            "10659833/10659833 [==============================] - 44s 4us/step - loss: 0.9958 - MAE_: 0.2286 - RMSLE: 0.3720 - VAL_: 0.8662 - mean_squared_error: 40494.3126 - val_loss: 1.6801 - val_MAE_: 0.2687 - val_RMSLE: 0.6941 - val_VAL_: 1.0051 - val_mean_squared_error: 72801.8545\n",
            "Epoch 13/50\n",
            "10659833/10659833 [==============================] - 41s 4us/step - loss: 0.9866 - MAE_: 0.2242 - RMSLE: 0.3696 - VAL_: 0.8710 - mean_squared_error: 39417.5288 - val_loss: 1.6683 - val_MAE_: 0.2670 - val_RMSLE: 0.6892 - val_VAL_: 1.0122 - val_mean_squared_error: 71551.6512\n",
            "Epoch 14/50\n",
            "10659833/10659833 [==============================] - 38s 4us/step - loss: 0.9787 - MAE_: 0.2204 - RMSLE: 0.3676 - VAL_: 0.8753 - mean_squared_error: 38445.6551 - val_loss: 1.6727 - val_MAE_: 0.2658 - val_RMSLE: 0.6919 - val_VAL_: 1.0060 - val_mean_squared_error: 70712.8079\n",
            "Epoch 15/50\n",
            "10659833/10659833 [==============================] - 38s 4us/step - loss: 0.9725 - MAE_: 0.2171 - RMSLE: 0.3662 - VAL_: 0.8792 - mean_squared_error: 37577.9184 - val_loss: 1.6662 - val_MAE_: 0.2646 - val_RMSLE: 0.6893 - val_VAL_: 1.0104 - val_mean_squared_error: 69670.1008\n",
            "Epoch 16/50\n",
            "10659833/10659833 [==============================] - 37s 4us/step - loss: 0.9661 - MAE_: 0.2142 - RMSLE: 0.3644 - VAL_: 0.8825 - mean_squared_error: 36792.3459 - val_loss: 1.6914 - val_MAE_: 0.2687 - val_RMSLE: 0.6998 - val_VAL_: 0.9608 - val_mean_squared_error: 68811.2766\n",
            "Epoch 17/50\n",
            "10659833/10659833 [==============================] - 37s 4us/step - loss: 0.9604 - MAE_: 0.2114 - RMSLE: 0.3630 - VAL_: 0.8857 - mean_squared_error: 36044.7821 - val_loss: 1.6870 - val_MAE_: 0.2690 - val_RMSLE: 0.6975 - val_VAL_: 1.0398 - val_mean_squared_error: 68011.4696\n",
            "Epoch 18/50\n",
            "10659833/10659833 [==============================] - 38s 4us/step - loss: 0.9565 - MAE_: 0.2090 - RMSLE: 0.3623 - VAL_: 0.8885 - mean_squared_error: 35377.8290 - val_loss: 1.6569 - val_MAE_: 0.2613 - val_RMSLE: 0.6864 - val_VAL_: 0.9942 - val_mean_squared_error: 67349.5056\n",
            "Epoch 19/50\n",
            "10659833/10659833 [==============================] - 37s 4us/step - loss: 0.9512 - MAE_: 0.2068 - RMSLE: 0.3608 - VAL_: 0.8910 - mean_squared_error: 34769.6504 - val_loss: 1.6758 - val_MAE_: 0.2652 - val_RMSLE: 0.6939 - val_VAL_: 0.9836 - val_mean_squared_error: 66667.4943\n",
            "Epoch 20/50\n",
            "10659833/10659833 [==============================] - 37s 3us/step - loss: 0.9469 - MAE_: 0.2046 - RMSLE: 0.3598 - VAL_: 0.8932 - mean_squared_error: 34192.6220 - val_loss: 1.6617 - val_MAE_: 0.2629 - val_RMSLE: 0.6881 - val_VAL_: 0.9772 - val_mean_squared_error: 66019.9883\n",
            "Epoch 21/50\n",
            "10659833/10659833 [==============================] - 37s 3us/step - loss: 0.9429 - MAE_: 0.2026 - RMSLE: 0.3589 - VAL_: 0.8954 - mean_squared_error: 33650.5755 - val_loss: 1.6501 - val_MAE_: 0.2578 - val_RMSLE: 0.6849 - val_VAL_: 0.9775 - val_mean_squared_error: 65343.8718\n",
            "Epoch 22/50\n",
            "10659833/10659833 [==============================] - 37s 3us/step - loss: 0.9393 - MAE_: 0.2007 - RMSLE: 0.3581 - VAL_: 0.8975 - mean_squared_error: 33138.7166 - val_loss: 1.6592 - val_MAE_: 0.2619 - val_RMSLE: 0.6875 - val_VAL_: 0.9801 - val_mean_squared_error: 64894.6848\n",
            "Epoch 23/50\n",
            "10659833/10659833 [==============================] - 37s 4us/step - loss: 0.9362 - MAE_: 0.1990 - RMSLE: 0.3574 - VAL_: 0.8994 - mean_squared_error: 32660.3947 - val_loss: 1.6582 - val_MAE_: 0.2593 - val_RMSLE: 0.6882 - val_VAL_: 1.0273 - val_mean_squared_error: 64358.8014\n",
            "Epoch 24/50\n",
            "10659833/10659833 [==============================] - 37s 3us/step - loss: 0.9329 - MAE_: 0.1972 - RMSLE: 0.3567 - VAL_: 0.9012 - mean_squared_error: 32186.7645 - val_loss: 1.6509 - val_MAE_: 0.2558 - val_RMSLE: 0.6865 - val_VAL_: 1.0196 - val_mean_squared_error: 63837.5831\n",
            "Epoch 25/50\n",
            "10659833/10659833 [==============================] - 37s 4us/step - loss: 0.9298 - MAE_: 0.1956 - RMSLE: 0.3560 - VAL_: 0.9030 - mean_squared_error: 31745.5067 - val_loss: 1.6640 - val_MAE_: 0.2633 - val_RMSLE: 0.6892 - val_VAL_: 1.0310 - val_mean_squared_error: 63319.3430\n",
            "Epoch 26/50\n",
            "10659833/10659833 [==============================] - 39s 4us/step - loss: 0.9270 - MAE_: 0.1941 - RMSLE: 0.3553 - VAL_: 0.9046 - mean_squared_error: 31333.1415 - val_loss: 1.6837 - val_MAE_: 0.2679 - val_RMSLE: 0.6967 - val_VAL_: 1.0522 - val_mean_squared_error: 63083.4625\n",
            "Epoch 27/50\n",
            "10659833/10659833 [==============================] - 38s 4us/step - loss: 0.9247 - MAE_: 0.1929 - RMSLE: 0.3548 - VAL_: 0.9062 - mean_squared_error: 30937.0060 - val_loss: 1.6535 - val_MAE_: 0.2577 - val_RMSLE: 0.6868 - val_VAL_: 1.0167 - val_mean_squared_error: 62607.9162\n",
            "Epoch 28/50\n",
            "10659833/10659833 [==============================] - 38s 4us/step - loss: 0.9228 - MAE_: 0.1917 - RMSLE: 0.3544 - VAL_: 0.9077 - mean_squared_error: 30566.3815 - val_loss: 1.6505 - val_MAE_: 0.2576 - val_RMSLE: 0.6853 - val_VAL_: 1.0153 - val_mean_squared_error: 61997.2990\n",
            "Epoch 29/50\n",
            "10659833/10659833 [==============================] - 38s 4us/step - loss: 0.9200 - MAE_: 0.1906 - RMSLE: 0.3536 - VAL_: 0.9091 - mean_squared_error: 30201.7458 - val_loss: 1.6348 - val_MAE_: 0.2520 - val_RMSLE: 0.6803 - val_VAL_: 0.9982 - val_mean_squared_error: 61687.5743\n",
            "Epoch 30/50\n",
            "10659833/10659833 [==============================] - 41s 4us/step - loss: 0.9176 - MAE_: 0.1893 - RMSLE: 0.3530 - VAL_: 0.9103 - mean_squared_error: 29853.3352 - val_loss: 1.6614 - val_MAE_: 0.2613 - val_RMSLE: 0.6890 - val_VAL_: 1.0422 - val_mean_squared_error: 61400.4291\n",
            "Epoch 31/50\n",
            "10659833/10659833 [==============================] - 44s 4us/step - loss: 0.9153 - MAE_: 0.1882 - RMSLE: 0.3524 - VAL_: 0.9115 - mean_squared_error: 29523.1622 - val_loss: 1.6533 - val_MAE_: 0.2593 - val_RMSLE: 0.6858 - val_VAL_: 1.0236 - val_mean_squared_error: 60696.8367\n",
            "Epoch 32/50\n",
            "10659833/10659833 [==============================] - 40s 4us/step - loss: 0.9136 - MAE_: 0.1871 - RMSLE: 0.3521 - VAL_: 0.9127 - mean_squared_error: 29204.0703 - val_loss: 1.6510 - val_MAE_: 0.2571 - val_RMSLE: 0.6857 - val_VAL_: 1.0261 - val_mean_squared_error: 60660.1009\n",
            "Epoch 33/50\n",
            "10659833/10659833 [==============================] - 38s 4us/step - loss: 0.9116 - MAE_: 0.1861 - RMSLE: 0.3516 - VAL_: 0.9138 - mean_squared_error: 28899.2117 - val_loss: 1.6465 - val_MAE_: 0.2541 - val_RMSLE: 0.6850 - val_VAL_: 1.0019 - val_mean_squared_error: 60206.3560\n",
            "Epoch 34/50\n",
            "10659833/10659833 [==============================] - 38s 4us/step - loss: 0.9099 - MAE_: 0.1851 - RMSLE: 0.3512 - VAL_: 0.9148 - mean_squared_error: 28611.5193 - val_loss: 1.6701 - val_MAE_: 0.2623 - val_RMSLE: 0.6927 - val_VAL_: 1.0476 - val_mean_squared_error: 59720.0571\n",
            "Epoch 35/50\n",
            "10659833/10659833 [==============================] - 37s 4us/step - loss: 0.9085 - MAE_: 0.1841 - RMSLE: 0.3510 - VAL_: 0.9158 - mean_squared_error: 28329.4391 - val_loss: 1.6320 - val_MAE_: 0.2512 - val_RMSLE: 0.6791 - val_VAL_: 1.0050 - val_mean_squared_error: 59309.8484\n",
            "Epoch 36/50\n",
            "10659833/10659833 [==============================] - 37s 3us/step - loss: 0.9075 - MAE_: 0.1833 - RMSLE: 0.3509 - VAL_: 0.9168 - mean_squared_error: 28072.6846 - val_loss: 1.6478 - val_MAE_: 0.2534 - val_RMSLE: 0.6860 - val_VAL_: 1.0399 - val_mean_squared_error: 59344.0360\n",
            "Epoch 37/50\n",
            "10659833/10659833 [==============================] - 37s 3us/step - loss: 0.9054 - MAE_: 0.1825 - RMSLE: 0.3502 - VAL_: 0.9177 - mean_squared_error: 27821.3941 - val_loss: 1.6398 - val_MAE_: 0.2530 - val_RMSLE: 0.6821 - val_VAL_: 1.0007 - val_mean_squared_error: 58796.4329\n",
            "Epoch 38/50\n",
            "10659833/10659833 [==============================] - 37s 3us/step - loss: 0.9050 - MAE_: 0.1819 - RMSLE: 0.3503 - VAL_: 0.9186 - mean_squared_error: 27577.8607 - val_loss: 1.6422 - val_MAE_: 0.2547 - val_RMSLE: 0.6825 - val_VAL_: 1.0182 - val_mean_squared_error: 58597.7699\n",
            "Epoch 39/50\n",
            "10659833/10659833 [==============================] - 37s 3us/step - loss: 0.9035 - MAE_: 0.1810 - RMSLE: 0.3500 - VAL_: 0.9195 - mean_squared_error: 27338.5254 - val_loss: 1.6660 - val_MAE_: 0.2645 - val_RMSLE: 0.6894 - val_VAL_: 1.0395 - val_mean_squared_error: 58358.8043\n",
            "Epoch 40/50\n",
            "10659833/10659833 [==============================] - 37s 3us/step - loss: 0.9023 - MAE_: 0.1803 - RMSLE: 0.3497 - VAL_: 0.9202 - mean_squared_error: 27118.0557 - val_loss: 1.6579 - val_MAE_: 0.2571 - val_RMSLE: 0.6891 - val_VAL_: 0.9996 - val_mean_squared_error: 58020.1246\n",
            "Epoch 41/50\n",
            "10659833/10659833 [==============================] - 37s 4us/step - loss: 0.9013 - MAE_: 0.1797 - RMSLE: 0.3495 - VAL_: 0.9210 - mean_squared_error: 26904.7736 - val_loss: 1.6496 - val_MAE_: 0.2574 - val_RMSLE: 0.6848 - val_VAL_: 1.0214 - val_mean_squared_error: 57980.2620\n",
            "Epoch 42/50\n",
            "10659833/10659833 [==============================] - 37s 4us/step - loss: 0.9008 - MAE_: 0.1793 - RMSLE: 0.3494 - VAL_: 0.9218 - mean_squared_error: 26704.2174 - val_loss: 1.6798 - val_MAE_: 0.2658 - val_RMSLE: 0.6957 - val_VAL_: 1.0605 - val_mean_squared_error: 57787.6714\n",
            "Epoch 43/50\n",
            "10659833/10659833 [==============================] - 37s 3us/step - loss: 0.8992 - MAE_: 0.1785 - RMSLE: 0.3490 - VAL_: 0.9224 - mean_squared_error: 26494.8542 - val_loss: 1.6798 - val_MAE_: 0.2699 - val_RMSLE: 0.6937 - val_VAL_: 1.0539 - val_mean_squared_error: 57557.2774\n",
            "Epoch 44/50\n",
            "10659833/10659833 [==============================] - 37s 3us/step - loss: 0.8973 - MAE_: 0.1778 - RMSLE: 0.3484 - VAL_: 0.9231 - mean_squared_error: 26290.4533 - val_loss: 1.6554 - val_MAE_: 0.2597 - val_RMSLE: 0.6866 - val_VAL_: 1.0281 - val_mean_squared_error: 57280.0006\n",
            "Epoch 45/50\n",
            "10659833/10659833 [==============================] - 37s 3us/step - loss: 0.8983 - MAE_: 0.1777 - RMSLE: 0.3490 - VAL_: 0.9237 - mean_squared_error: 26104.7471 - val_loss: 1.6696 - val_MAE_: 0.2695 - val_RMSLE: 0.6886 - val_VAL_: 1.0184 - val_mean_squared_error: 57183.5497\n",
            "Epoch 46/50\n",
            "10659833/10659833 [==============================] - 37s 3us/step - loss: 0.8955 - MAE_: 0.1767 - RMSLE: 0.3480 - VAL_: 0.9242 - mean_squared_error: 25899.8771 - val_loss: 1.6810 - val_MAE_: 0.2692 - val_RMSLE: 0.6945 - val_VAL_: 1.0431 - val_mean_squared_error: 57129.9485\n",
            "Epoch 47/50\n",
            "10659833/10659833 [==============================] - 37s 4us/step - loss: 0.8952 - MAE_: 0.1763 - RMSLE: 0.3481 - VAL_: 0.9250 - mean_squared_error: 25712.1185 - val_loss: 1.6510 - val_MAE_: 0.2573 - val_RMSLE: 0.6855 - val_VAL_: 1.0165 - val_mean_squared_error: 56709.0714\n",
            "Epoch 48/50\n",
            "10659833/10659833 [==============================] - 42s 4us/step - loss: 0.8941 - MAE_: 0.1757 - RMSLE: 0.3478 - VAL_: 0.9257 - mean_squared_error: 25529.6681 - val_loss: 1.6681 - val_MAE_: 0.2622 - val_RMSLE: 0.6916 - val_VAL_: 1.0614 - val_mean_squared_error: 56599.2626\n",
            "Epoch 49/50\n",
            "10659833/10659833 [==============================] - 42s 4us/step - loss: 0.8935 - MAE_: 0.1753 - RMSLE: 0.3477 - VAL_: 0.9264 - mean_squared_error: 25361.2835 - val_loss: 1.6599 - val_MAE_: 0.2621 - val_RMSLE: 0.6875 - val_VAL_: 1.0450 - val_mean_squared_error: 56290.7938\n",
            "Epoch 50/50\n",
            "10659833/10659833 [==============================] - 38s 4us/step - loss: 0.8948 - MAE_: 0.1752 - RMSLE: 0.3484 - VAL_: 0.9271 - mean_squared_error: 25207.7605 - val_loss: 1.6474 - val_MAE_: 0.2577 - val_RMSLE: 0.6834 - val_VAL_: 1.0074 - val_mean_squared_error: 56050.2932\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nX1MEx4lPtK6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# hist = nn_0.fit( df[(df['meter']==meter) & (df['IS_BAD_PRCNT']<0.45)][In_Columns], df[(df['meter']==meter) & (df['IS_BAD_PRCNT']<0.45)][Out_Columns], batch_size = batch_size, verbose = 1\n",
        "#               , epochs = epochs, shuffle = True, callbacks=[earlyStopping, reduce_lr_loss,model_checkpoint]\n",
        "#               , validation_data=(val[In_Columns], val[Out_Columns])\n",
        "#               ) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diaTWlaXC4_H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " #Продолжение расчёта\n",
        " if 9==9:\n",
        "    # nn_0.optimizer.lr = 0.007\n",
        "    # nn_0.compile(optimizer = opt, loss = MAE_RMSLE, metrics=[ MAE_, RMSLE, VAL_, 'mse' ])\n",
        "    # batch_size = 2048\n",
        "    # epochs = 10\n",
        "    \n",
        "    # earlyStopping = EarlyStopping(monitor='loss', patience=100, verbose=1, mode='min',restore_best_weights = True)\n",
        "    # reduce_lr_loss = ReduceLROnPlateau(monitor='loss', factor=0.3, patience=5, verbose=1, min_delta=1e-3, mode='min')\n",
        "\n",
        "    # val = df[(df['meter']==meter) & (df['day']%6==0)]\n",
        "    # hist = nn_0.fit( df[(df['meter']==meter) & (df['IS_BAD_PRCNT']<0.45)][In_Columns], df[(df['meter']==meter) & (df['IS_BAD_PRCNT']<0.45)][Out_Columns], batch_size = batch_size, verbose = 1\n",
        "    #                 , epochs = epochs, shuffle = True, callbacks=[earlyStopping, reduce_lr_loss,model_checkpoint]\n",
        "    #                 , validation_data=(val[In_Columns], val[Out_Columns])\n",
        "    #                 ) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mf8-ceMw8N1q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1972ea26-51a8-49c1-a7bc-111c949b4308"
      },
      "source": [
        "if 1==1:\n",
        "  meter = 1\n",
        "  epochs = 100\n",
        "  batch_size = 512\n",
        "  opt = Adam(lr = 0.007)\n",
        "\n",
        "  nn_1 = Sequential()\n",
        "  nn_1.add(Dense(90, input_shape = df[In_Columns].shape[1:], activation = 'tanh', kernel_regularizer=l1(reg), kernel_initializer = 'normal'))\n",
        "  nn_1.add(Dense(90, activation = 'tanh',  kernel_initializer = 'normal'))\n",
        "  nn_1.add(Dense(90, activation = 'relu',  kernel_initializer = 'normal'))\n",
        "  nn_1.add(Dense(90, activation = 'relu',  kernel_initializer = 'normal'))\n",
        "  nn_1.add(Dense(1, activation = 'relu', kernel_initializer = 'normal'))\n",
        "\n",
        "  nn_1.compile(optimizer = opt, loss = MASPE_VAL, metrics=[ MAE_, RMSLE, VAL_, 'mse' ])\n",
        "  \n",
        "  val = df[(df['meter']==meter) & (df['day']%6==0)]\n",
        "  hist = nn_1.fit( df[(df['meter']==meter) & (df['IS_BAD_PRCNT']<0.45)][In_Columns], df[(df['meter']==meter) & (df['IS_BAD_PRCNT']<0.45)][Out_Columns], batch_size = batch_size, verbose = 1\n",
        "                  , epochs = epochs, shuffle = True, callbacks=[earlyStopping, reduce_lr_loss,model_checkpoint]\n",
        "                  , validation_data=(val[In_Columns], val[Out_Columns])\n",
        "                  ) \n",
        "  nn_1.save(DIR + str(meter) + 'HANDLY_SAVED2.MODEL')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 3480650 samples, validate on 697348 samples\n",
            "Epoch 1/100\n",
            "3480650/3480650 [==============================] - 43s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3307 - VAL_: 1.0040e-07 - mean_squared_error: 75775338.0179 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "Epoch 2/100\n",
            "3480650/3480650 [==============================] - 43s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3307 - VAL_: 9.9758e-08 - mean_squared_error: 75775337.4560 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "Epoch 3/100\n",
            "3480650/3480650 [==============================] - 43s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3307 - VAL_: 9.9616e-08 - mean_squared_error: 75775337.8332 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "Epoch 4/100\n",
            "3480650/3480650 [==============================] - 43s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3307 - VAL_: 9.9561e-08 - mean_squared_error: 75775337.7651 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "Epoch 5/100\n",
            "3480650/3480650 [==============================] - 42s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3307 - VAL_: 9.9694e-08 - mean_squared_error: 75775337.4651 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "Epoch 6/100\n",
            "3480650/3480650 [==============================] - 42s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3307 - VAL_: 9.9776e-08 - mean_squared_error: 75775337.8059 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.002100000064820051.\n",
            "Epoch 7/100\n",
            "3480650/3480650 [==============================] - 43s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3307 - VAL_: 9.9631e-08 - mean_squared_error: 75775337.8303 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "Epoch 8/100\n",
            "3480650/3480650 [==============================] - 42s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3307 - VAL_: 9.9676e-08 - mean_squared_error: 75775337.2510 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "Epoch 9/100\n",
            "3480650/3480650 [==============================] - 42s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3307 - VAL_: 9.9606e-08 - mean_squared_error: 75775337.7967 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "Epoch 10/100\n",
            "3480650/3480650 [==============================] - 42s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3307 - VAL_: 9.9565e-08 - mean_squared_error: 75775337.5601 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "Epoch 11/100\n",
            "3480650/3480650 [==============================] - 42s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3307 - VAL_: 9.9728e-08 - mean_squared_error: 75775337.7720 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0006300000473856926.\n",
            "Epoch 12/100\n",
            "3480650/3480650 [==============================] - 46s 13us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3307 - VAL_: 9.9688e-08 - mean_squared_error: 75775337.2575 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "Epoch 13/100\n",
            "3480650/3480650 [==============================] - 51s 15us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3307 - VAL_: 9.9721e-08 - mean_squared_error: 75775337.1718 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "Epoch 14/100\n",
            "3480650/3480650 [==============================] - 42s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3307 - VAL_: 9.9566e-08 - mean_squared_error: 75775337.7010 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "Epoch 15/100\n",
            "3480650/3480650 [==============================] - 42s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3307 - VAL_: 9.9551e-08 - mean_squared_error: 75775337.4690 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "Epoch 16/100\n",
            "3480650/3480650 [==============================] - 42s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3307 - VAL_: 9.9629e-08 - mean_squared_error: 75775337.8343 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "\n",
            "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.00018900000723078846.\n",
            "Epoch 17/100\n",
            "3480650/3480650 [==============================] - 41s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3307 - VAL_: 9.9541e-08 - mean_squared_error: 75775337.5548 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "Epoch 18/100\n",
            "3480650/3480650 [==============================] - 41s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3307 - VAL_: 9.9646e-08 - mean_squared_error: 75775338.0821 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "Epoch 19/100\n",
            "3480650/3480650 [==============================] - 41s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3308 - VAL_: 9.9557e-08 - mean_squared_error: 75775337.7350 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "Epoch 20/100\n",
            "3480650/3480650 [==============================] - 41s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3308 - VAL_: 9.9696e-08 - mean_squared_error: 75775337.3850 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "Epoch 21/100\n",
            "3480650/3480650 [==============================] - 41s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3307 - VAL_: 9.9651e-08 - mean_squared_error: 75775337.4285 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "\n",
            "Epoch 00021: ReduceLROnPlateau reducing learning rate to 5.670000391546636e-05.\n",
            "Epoch 22/100\n",
            "3480650/3480650 [==============================] - 42s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3307 - VAL_: 9.9784e-08 - mean_squared_error: 75775337.0727 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "Epoch 23/100\n",
            "3480650/3480650 [==============================] - 42s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3307 - VAL_: 9.9861e-08 - mean_squared_error: 75775337.9116 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "Epoch 24/100\n",
            "3480650/3480650 [==============================] - 42s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3307 - VAL_: 9.9645e-08 - mean_squared_error: 75775337.5633 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "Epoch 25/100\n",
            "3480650/3480650 [==============================] - 43s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3307 - VAL_: 9.9668e-08 - mean_squared_error: 75775337.5108 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "Epoch 26/100\n",
            "3480650/3480650 [==============================] - 42s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3307 - VAL_: 9.9633e-08 - mean_squared_error: 75775337.7267 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "\n",
            "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.701000073808245e-05.\n",
            "Epoch 27/100\n",
            "3480650/3480650 [==============================] - 42s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3307 - VAL_: 9.9752e-08 - mean_squared_error: 75775337.5905 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "Epoch 28/100\n",
            "3480650/3480650 [==============================] - 49s 14us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3307 - VAL_: 9.9706e-08 - mean_squared_error: 75775337.4558 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "Epoch 29/100\n",
            "3480650/3480650 [==============================] - 49s 14us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3307 - VAL_: 9.9643e-08 - mean_squared_error: 75775337.8716 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "Epoch 30/100\n",
            "3480650/3480650 [==============================] - 42s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3308 - VAL_: 9.9562e-08 - mean_squared_error: 75775337.6413 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "Epoch 31/100\n",
            "3480650/3480650 [==============================] - 42s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3307 - VAL_: 9.9633e-08 - mean_squared_error: 75775337.8944 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "\n",
            "Epoch 00031: ReduceLROnPlateau reducing learning rate to 5.1030003305641005e-06.\n",
            "Epoch 32/100\n",
            "3480650/3480650 [==============================] - 42s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3307 - VAL_: 9.9712e-08 - mean_squared_error: 75775337.5486 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "Epoch 33/100\n",
            "3480650/3480650 [==============================] - 42s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3307 - VAL_: 9.9700e-08 - mean_squared_error: 75775337.7897 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "Epoch 34/100\n",
            "3480650/3480650 [==============================] - 42s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3307 - VAL_: 9.9607e-08 - mean_squared_error: 75775337.4366 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "Epoch 35/100\n",
            "3480650/3480650 [==============================] - 42s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3307 - VAL_: 9.9652e-08 - mean_squared_error: 75775337.5524 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "Epoch 36/100\n",
            "3480650/3480650 [==============================] - 42s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3307 - VAL_: 9.9744e-08 - mean_squared_error: 75775337.5954 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "\n",
            "Epoch 00036: ReduceLROnPlateau reducing learning rate to 1.530900044599548e-06.\n",
            "Epoch 37/100\n",
            "3480650/3480650 [==============================] - 42s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3307 - VAL_: 9.9880e-08 - mean_squared_error: 75775337.4872 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "Epoch 38/100\n",
            "3480650/3480650 [==============================] - 42s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3308 - VAL_: 9.9641e-08 - mean_squared_error: 75775337.5240 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "Epoch 39/100\n",
            "3480650/3480650 [==============================] - 42s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3307 - VAL_: 9.9791e-08 - mean_squared_error: 75775337.3853 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "Epoch 40/100\n",
            "3480650/3480650 [==============================] - 42s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3307 - VAL_: 9.9666e-08 - mean_squared_error: 75775337.8392 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "Epoch 41/100\n",
            "3480650/3480650 [==============================] - 42s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3308 - VAL_: 9.9729e-08 - mean_squared_error: 75775337.9499 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "\n",
            "Epoch 00041: ReduceLROnPlateau reducing learning rate to 4.592700065586541e-07.\n",
            "Epoch 42/100\n",
            "3480650/3480650 [==============================] - 42s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3307 - VAL_: 9.9708e-08 - mean_squared_error: 75775337.5674 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "Epoch 43/100\n",
            "3480650/3480650 [==============================] - 41s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3307 - VAL_: 9.9598e-08 - mean_squared_error: 75775337.6578 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "Epoch 44/100\n",
            "3480650/3480650 [==============================] - 42s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3308 - VAL_: 9.9627e-08 - mean_squared_error: 75775337.5069 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "Epoch 45/100\n",
            "3480650/3480650 [==============================] - 41s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3308 - VAL_: 9.9733e-08 - mean_squared_error: 75775337.6187 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "Epoch 46/100\n",
            "3480650/3480650 [==============================] - 41s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3307 - VAL_: 9.9674e-08 - mean_squared_error: 75775337.6443 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "\n",
            "Epoch 00046: ReduceLROnPlateau reducing learning rate to 1.377810036728988e-07.\n",
            "Epoch 47/100\n",
            "3480650/3480650 [==============================] - 41s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3307 - VAL_: 9.9556e-08 - mean_squared_error: 75775338.0314 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "Epoch 48/100\n",
            "3480650/3480650 [==============================] - 41s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3307 - VAL_: 9.9638e-08 - mean_squared_error: 75775337.5333 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "Epoch 49/100\n",
            "3480650/3480650 [==============================] - 41s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3308 - VAL_: 9.9596e-08 - mean_squared_error: 75775337.9411 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "Epoch 50/100\n",
            "3480650/3480650 [==============================] - 41s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3307 - VAL_: 9.9677e-08 - mean_squared_error: 75775337.9242 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "Epoch 51/100\n",
            "3480650/3480650 [==============================] - 41s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3307 - VAL_: 9.9643e-08 - mean_squared_error: 75775337.4325 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "\n",
            "Epoch 00051: ReduceLROnPlateau reducing learning rate to 4.1334300249218356e-08.\n",
            "Epoch 52/100\n",
            "3480650/3480650 [==============================] - 40s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3307 - VAL_: 9.9675e-08 - mean_squared_error: 75775337.7026 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "Epoch 53/100\n",
            "3480650/3480650 [==============================] - 41s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3307 - VAL_: 9.9773e-08 - mean_squared_error: 75775337.5874 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "Epoch 54/100\n",
            "3480650/3480650 [==============================] - 41s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3308 - VAL_: 9.9636e-08 - mean_squared_error: 75775337.7093 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "Epoch 55/100\n",
            "3480650/3480650 [==============================] - 41s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3307 - VAL_: 9.9697e-08 - mean_squared_error: 75775337.6937 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "Epoch 56/100\n",
            "3480650/3480650 [==============================] - 41s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3307 - VAL_: 9.9745e-08 - mean_squared_error: 75775337.5988 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "\n",
            "Epoch 00056: ReduceLROnPlateau reducing learning rate to 1.2400289861602686e-08.\n",
            "Epoch 57/100\n",
            "3480650/3480650 [==============================] - 42s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3308 - VAL_: 9.9551e-08 - mean_squared_error: 75775337.8603 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "Epoch 58/100\n",
            "3480650/3480650 [==============================] - 49s 14us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3307 - VAL_: 9.9701e-08 - mean_squared_error: 75775337.4316 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "Epoch 59/100\n",
            "3480650/3480650 [==============================] - 49s 14us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3307 - VAL_: 9.9668e-08 - mean_squared_error: 75775337.9289 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "Epoch 60/100\n",
            "3480650/3480650 [==============================] - 43s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3307 - VAL_: 9.9596e-08 - mean_squared_error: 75775337.3900 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "Epoch 61/100\n",
            "3480650/3480650 [==============================] - 42s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3307 - VAL_: 9.9625e-08 - mean_squared_error: 75775337.4608 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "\n",
            "Epoch 00061: ReduceLROnPlateau reducing learning rate to 3.720086905190101e-09.\n",
            "Epoch 62/100\n",
            "3480650/3480650 [==============================] - 44s 13us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3308 - VAL_: 9.9648e-08 - mean_squared_error: 75775337.5637 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "Epoch 63/100\n",
            "3480650/3480650 [==============================] - 42s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3307 - VAL_: 9.9551e-08 - mean_squared_error: 75775337.7999 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "Epoch 64/100\n",
            "3480650/3480650 [==============================] - 43s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3308 - VAL_: 9.9773e-08 - mean_squared_error: 75775337.4828 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "Epoch 65/100\n",
            "3480650/3480650 [==============================] - 42s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3308 - VAL_: 9.9769e-08 - mean_squared_error: 75775337.4898 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "Epoch 66/100\n",
            "3480650/3480650 [==============================] - 42s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3307 - VAL_: 9.9632e-08 - mean_squared_error: 75775337.6388 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "\n",
            "Epoch 00066: ReduceLROnPlateau reducing learning rate to 1.1160260715570302e-09.\n",
            "Epoch 67/100\n",
            "3480650/3480650 [==============================] - 42s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3307 - VAL_: 9.9717e-08 - mean_squared_error: 75775337.7290 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "Epoch 68/100\n",
            "3480650/3480650 [==============================] - 42s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3307 - VAL_: 9.9778e-08 - mean_squared_error: 75775337.6571 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "Epoch 69/100\n",
            "3480650/3480650 [==============================] - 43s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3307 - VAL_: 9.9643e-08 - mean_squared_error: 75775337.6652 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "Epoch 70/100\n",
            "3480650/3480650 [==============================] - 44s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3307 - VAL_: 9.9727e-08 - mean_squared_error: 75775337.3540 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "Epoch 71/100\n",
            "3480650/3480650 [==============================] - 43s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3308 - VAL_: 9.9649e-08 - mean_squared_error: 75775337.6016 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "\n",
            "Epoch 00071: ReduceLROnPlateau reducing learning rate to 3.348078148057709e-10.\n",
            "Epoch 72/100\n",
            "3480650/3480650 [==============================] - 42s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3307 - VAL_: 9.9824e-08 - mean_squared_error: 75775337.6047 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "Epoch 73/100\n",
            "3480650/3480650 [==============================] - 42s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3307 - VAL_: 9.9676e-08 - mean_squared_error: 75775338.0060 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "Epoch 74/100\n",
            "3480650/3480650 [==============================] - 42s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3307 - VAL_: 9.9545e-08 - mean_squared_error: 75775337.7638 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "Epoch 75/100\n",
            "3480650/3480650 [==============================] - 42s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3307 - VAL_: 9.9580e-08 - mean_squared_error: 75775337.5967 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "Epoch 76/100\n",
            "3480650/3480650 [==============================] - 42s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3307 - VAL_: 9.9655e-08 - mean_squared_error: 75775337.2816 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "\n",
            "Epoch 00076: ReduceLROnPlateau reducing learning rate to 1.0044234610706581e-10.\n",
            "Epoch 77/100\n",
            "3480650/3480650 [==============================] - 43s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3307 - VAL_: 9.9792e-08 - mean_squared_error: 75775337.9032 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "Epoch 78/100\n",
            "3480650/3480650 [==============================] - 43s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3307 - VAL_: 9.9741e-08 - mean_squared_error: 75775337.2655 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "Epoch 79/100\n",
            "3480650/3480650 [==============================] - 42s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3307 - VAL_: 9.9623e-08 - mean_squared_error: 75775337.4971 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "Epoch 80/100\n",
            "3480650/3480650 [==============================] - 43s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3307 - VAL_: 9.9675e-08 - mean_squared_error: 75775337.6889 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "Epoch 81/100\n",
            "3480650/3480650 [==============================] - 43s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3308 - VAL_: 9.9615e-08 - mean_squared_error: 75775338.0628 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "\n",
            "Epoch 00081: ReduceLROnPlateau reducing learning rate to 3.013270466478701e-11.\n",
            "Epoch 82/100\n",
            "3480650/3480650 [==============================] - 42s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3307 - VAL_: 9.9586e-08 - mean_squared_error: 75775337.8875 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "Epoch 83/100\n",
            "3480650/3480650 [==============================] - 42s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3308 - VAL_: 9.9515e-08 - mean_squared_error: 75775337.5984 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "Epoch 84/100\n",
            "3480650/3480650 [==============================] - 43s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3307 - VAL_: 9.9702e-08 - mean_squared_error: 75775337.6272 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "Epoch 85/100\n",
            "3480650/3480650 [==============================] - 46s 13us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3307 - VAL_: 9.9675e-08 - mean_squared_error: 75775337.7805 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "Epoch 86/100\n",
            "3480650/3480650 [==============================] - 49s 14us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3308 - VAL_: 9.9744e-08 - mean_squared_error: 75775337.9246 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "\n",
            "Epoch 00086: ReduceLROnPlateau reducing learning rate to 9.03981160760292e-12.\n",
            "Epoch 87/100\n",
            "3480650/3480650 [==============================] - 45s 13us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3307 - VAL_: 9.9577e-08 - mean_squared_error: 75775337.8152 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "Epoch 88/100\n",
            "3480650/3480650 [==============================] - 42s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3307 - VAL_: 9.9649e-08 - mean_squared_error: 75775337.5696 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "Epoch 89/100\n",
            "3480650/3480650 [==============================] - 42s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3307 - VAL_: 9.9734e-08 - mean_squared_error: 75775338.0568 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "Epoch 90/100\n",
            "3480650/3480650 [==============================] - 43s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3307 - VAL_: 9.9680e-08 - mean_squared_error: 75775337.4782 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "Epoch 91/100\n",
            "3480650/3480650 [==============================] - 42s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3307 - VAL_: 9.9656e-08 - mean_squared_error: 75775337.6338 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "\n",
            "Epoch 00091: ReduceLROnPlateau reducing learning rate to 2.711943430239172e-12.\n",
            "Epoch 92/100\n",
            "3480650/3480650 [==============================] - 42s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3307 - VAL_: 9.9661e-08 - mean_squared_error: 75775337.5542 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "Epoch 93/100\n",
            "3480650/3480650 [==============================] - 42s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3307 - VAL_: 9.9756e-08 - mean_squared_error: 75775337.5556 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "Epoch 94/100\n",
            "3480650/3480650 [==============================] - 42s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3307 - VAL_: 9.9671e-08 - mean_squared_error: 75775337.6853 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "Epoch 95/100\n",
            "3480650/3480650 [==============================] - 43s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3307 - VAL_: 9.9638e-08 - mean_squared_error: 75775337.6722 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "Epoch 96/100\n",
            "3480650/3480650 [==============================] - 43s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3307 - VAL_: 9.9607e-08 - mean_squared_error: 75775337.7865 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "\n",
            "Epoch 00096: ReduceLROnPlateau reducing learning rate to 8.135830550926038e-13.\n",
            "Epoch 97/100\n",
            "3480650/3480650 [==============================] - 43s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3307 - VAL_: 9.9635e-08 - mean_squared_error: 75775337.6164 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "Epoch 98/100\n",
            "3480650/3480650 [==============================] - 42s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3307 - VAL_: 9.9729e-08 - mean_squared_error: 75775337.3996 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "Epoch 99/100\n",
            "3480650/3480650 [==============================] - 43s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3307 - VAL_: 9.9804e-08 - mean_squared_error: 75775337.8241 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n",
            "Epoch 100/100\n",
            "3480650/3480650 [==============================] - 43s 12us/step - loss: 7.7437 - MAE_: 1.0000 - RMSLE: 5.3307 - VAL_: 9.9660e-08 - mean_squared_error: 75775337.6280 - val_loss: 7.6797 - val_MAE_: 0.9971 - val_RMSLE: 4.6687 - val_VAL_: 0.0037 - val_mean_squared_error: 64764827.3119\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHKu4TMG8ROI",
        "colab_type": "code",
        "outputId": "a7ad1f97-8b62-4ccc-a200-b27713f27538",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "if 2==2:\n",
        "  reg = 0.00001\n",
        "  meter = 2\n",
        "  epochs = 600\n",
        "  batch_size = 3333\n",
        "  opt = Adam(lr = 0.04)\n",
        "\n",
        "  earlyStopping = EarlyStopping(monitor='loss', patience=50, verbose=1, mode='min')\n",
        "  reduce_lr_loss = ReduceLROnPlateau(monitor='loss', factor=0.2, patience=25, verbose=1, min_delta=1e-3, mode='min')\n",
        "  model_checkpoint = ModelCheckpoint(monitor='loss', save_best_only=True, filepath = DIR + 'best_nn_' + str(meter) + '.model', save_weights_only = False, verbose=0, mode='min')\n",
        "\n",
        "  nn_2 = Sequential()\n",
        "  nn_2.add(Dense(30, input_shape = df[In_Columns].shape[1:], activation = 'tanh', kernel_regularizer=l2(reg), kernel_initializer = 'glorot_uniform', bias_initializer=keras.initializers.Constant(0.1)))\n",
        "  nn_2.add(Dense(30, activation = 'tanh',  kernel_initializer = 'normal'))\n",
        "  nn_2.add(Dense(30, activation = 'tanh',  kernel_initializer = 'normal'))\n",
        "  nn_2.add(Dense(30, activation = 'tanh',  kernel_initializer = 'glorot_uniform'))\n",
        "  nn_2.add(Dense( 1, activation = 'relu', kernel_initializer = 'normal'))\n",
        "\n",
        "  nn_2.compile(optimizer = opt, loss = MSE_, metrics=[ MAE_, RMSLE, VAL_, 'mse', MAPE_ ])\n",
        "  \n",
        "  val = df[(df['meter']==meter) & (df['day']%6==0)]\n",
        "  hist = nn_2.fit( df[(df['meter']==meter) & (df['IS_BAD_PRCNT']<0.75)][In_Columns], df[(df['meter']==meter) & (df['IS_BAD_PRCNT']<0.75)][Out_Columns], batch_size = batch_size, verbose = 1\n",
        "                  , epochs = epochs, shuffle = True, callbacks=[earlyStopping, reduce_lr_loss,model_checkpoint]\n",
        "                  , validation_data=(val[In_Columns], val[Out_Columns])\n",
        "                  ) \n",
        "  nn_2.save(DIR + str(meter) + 'HANDLY_SAVED2.MODEL')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "Train on 2472929 samples, validate on 452118 samples\n",
            "Epoch 1/600\n",
            "2472929/2472929 [==============================] - 9s 3us/step - loss: 0.9999 - MAE_: 0.9959 - RMSLE: 2.9642 - VAL_: 0.0063 - mean_squared_error: 191879428328.8654 - MAPE_: 1.2243 - val_loss: 0.8649 - val_MAE_: 0.9779 - val_RMSLE: 2.5201 - val_VAL_: 0.5384 - val_mean_squared_error: 169442881078.5690 - val_MAPE_: 1.7075\n",
            "Epoch 2/600\n",
            "2472929/2472929 [==============================] - 8s 3us/step - loss: 0.9998 - MAE_: 0.9916 - RMSLE: 2.3022 - VAL_: 0.0179 - mean_squared_error: 191875671949.6269 - MAPE_: 1.5381 - val_loss: 1.0410 - val_MAE_: 1.1163 - val_RMSLE: 2.5289 - val_VAL_: 0.8431 - val_mean_squared_error: 169440560313.5116 - val_MAPE_: 1.9046\n",
            "Epoch 3/600\n",
            "2472929/2472929 [==============================] - 8s 3us/step - loss: 0.9993 - MAE_: 0.9902 - RMSLE: 2.2972 - VAL_: 0.0324 - mean_squared_error: 191871540440.8484 - MAPE_: 1.8321 - val_loss: 1.9537 - val_MAE_: 1.5175 - val_RMSLE: 2.6281 - val_VAL_: 1.4586 - val_mean_squared_error: 169435950413.1707 - val_MAPE_: 2.2024\n",
            "Epoch 4/600\n",
            "2472929/2472929 [==============================] - 9s 4us/step - loss: 0.9994 - MAE_: 0.9917 - RMSLE: 2.3547 - VAL_: 0.0436 - mean_squared_error: 191867581481.8272 - MAPE_: 2.0566 - val_loss: 2.8488 - val_MAE_: 1.7938 - val_RMSLE: 2.6960 - val_VAL_: 1.8243 - val_mean_squared_error: 169433251826.5968 - val_MAPE_: 2.3435\n",
            "Epoch 5/600\n",
            "2472929/2472929 [==============================] - 8s 3us/step - loss: 0.9992 - MAE_: 0.9936 - RMSLE: 2.4149 - VAL_: 0.0540 - mean_squared_error: 191864454217.3248 - MAPE_: 2.2077 - val_loss: 4.1236 - val_MAE_: 2.1128 - val_RMSLE: 2.7687 - val_VAL_: 2.2228 - val_mean_squared_error: 169430306177.8807 - val_MAPE_: 2.4800\n",
            "Epoch 6/600\n",
            "2472929/2472929 [==============================] - 8s 3us/step - loss: 0.9992 - MAE_: 0.9964 - RMSLE: 2.4796 - VAL_: 0.0643 - mean_squared_error: 191861131012.2560 - MAPE_: 2.3465 - val_loss: 5.6738 - val_MAE_: 2.4375 - val_RMSLE: 2.8367 - val_VAL_: 2.6128 - val_mean_squared_error: 169427458466.7047 - val_MAPE_: 2.5965\n",
            "Epoch 7/600\n",
            "2472929/2472929 [==============================] - 9s 3us/step - loss: 0.9992 - MAE_: 0.9995 - RMSLE: 2.5387 - VAL_: 0.0741 - mean_squared_error: 191858154197.1535 - MAPE_: 2.4590 - val_loss: 7.5229 - val_MAE_: 2.7716 - val_RMSLE: 2.9011 - val_VAL_: 3.0028 - val_mean_squared_error: 169424653724.7039 - val_MAPE_: 2.6990\n",
            "Epoch 8/600\n",
            "2472929/2472929 [==============================] - 9s 4us/step - loss: 0.9993 - MAE_: 1.0030 - RMSLE: 2.5930 - VAL_: 0.0818 - mean_squared_error: 191855291372.5649 - MAPE_: 2.5537 - val_loss: 9.2694 - val_MAE_: 3.0523 - val_RMSLE: 2.9515 - val_VAL_: 3.3238 - val_mean_squared_error: 169422355106.5223 - val_MAPE_: 2.7741\n",
            "Epoch 9/600\n",
            "2472929/2472929 [==============================] - 9s 4us/step - loss: 0.9990 - MAE_: 1.0073 - RMSLE: 2.6483 - VAL_: 0.0936 - mean_squared_error: 191852330785.1798 - MAPE_: 2.6449 - val_loss: 11.9965 - val_MAE_: 3.4441 - val_RMSLE: 3.0169 - val_VAL_: 3.7644 - val_mean_squared_error: 169419216484.5990 - val_MAPE_: 2.8696\n",
            "Epoch 10/600\n",
            "2472929/2472929 [==============================] - 9s 4us/step - loss: 0.9988 - MAE_: 1.0131 - RMSLE: 2.7129 - VAL_: 0.1067 - mean_squared_error: 191848676003.3980 - MAPE_: 2.7488 - val_loss: 15.0243 - val_MAE_: 3.8326 - val_RMSLE: 3.0768 - val_VAL_: 4.1942 - val_mean_squared_error: 169416168101.2920 - val_MAPE_: 2.9557\n",
            "Epoch 11/600\n",
            "2472929/2472929 [==============================] - 9s 4us/step - loss: 0.9978 - MAE_: 1.0220 - RMSLE: 2.7870 - VAL_: 0.1296 - mean_squared_error: 191844253223.3349 - MAPE_: 2.8640 - val_loss: 20.1358 - val_MAE_: 4.4121 - val_RMSLE: 3.1586 - val_VAL_: 4.8260 - val_mean_squared_error: 169411776143.8832 - val_MAPE_: 3.0683\n",
            "Epoch 12/600\n",
            "2472929/2472929 [==============================] - 9s 4us/step - loss: 0.9980 - MAE_: 1.0287 - RMSLE: 2.8487 - VAL_: 0.1385 - mean_squared_error: 191840294316.3565 - MAPE_: 2.9551 - val_loss: 24.2239 - val_MAE_: 4.8265 - val_RMSLE: 3.2125 - val_VAL_: 5.2728 - val_mean_squared_error: 169408685938.1378 - val_MAPE_: 3.1394\n",
            "Epoch 13/600\n",
            "2472929/2472929 [==============================] - 9s 4us/step - loss: 0.9987 - MAE_: 1.0330 - RMSLE: 2.8939 - VAL_: 0.1411 - mean_squared_error: 191837289708.1273 - MAPE_: 3.0197 - val_loss: 27.4657 - val_MAE_: 5.1319 - val_RMSLE: 3.2500 - val_VAL_: 5.5999 - val_mean_squared_error: 169406469614.0221 - val_MAPE_: 3.1877\n",
            "Epoch 14/600\n",
            "2472929/2472929 [==============================] - 9s 4us/step - loss: 0.9989 - MAE_: 1.0377 - RMSLE: 2.9292 - VAL_: 0.1477 - mean_squared_error: 191834897894.4565 - MAPE_: 3.0686 - val_loss: 31.1438 - val_MAE_: 5.4584 - val_RMSLE: 3.2884 - val_VAL_: 5.9478 - val_mean_squared_error: 169404101338.2034 - val_MAPE_: 3.2356\n",
            "Epoch 15/600\n",
            "2472929/2472929 [==============================] - 9s 3us/step - loss: 0.9981 - MAE_: 1.0457 - RMSLE: 2.9664 - VAL_: 0.1664 - mean_squared_error: 191832249900.1696 - MAPE_: 3.1191 - val_loss: 34.2579 - val_MAE_: 5.7208 - val_RMSLE: 3.3179 - val_VAL_: 6.2261 - val_mean_squared_error: 169402238018.8535 - val_MAPE_: 3.2719\n",
            "Epoch 16/600\n",
            "2472929/2472929 [==============================] - 8s 3us/step - loss: 0.9987 - MAE_: 1.0487 - RMSLE: 2.9882 - VAL_: 0.1703 - mean_squared_error: 191830642853.2520 - MAPE_: 3.1482 - val_loss: 36.8785 - val_MAE_: 5.9328 - val_RMSLE: 3.3411 - val_VAL_: 6.4503 - val_mean_squared_error: 169400753172.8046 - val_MAPE_: 3.3000\n",
            "Epoch 17/600\n",
            "2472929/2472929 [==============================] - 8s 3us/step - loss: 0.9990 - MAE_: 1.0496 - RMSLE: 3.0110 - VAL_: 0.1662 - mean_squared_error: 191828931516.9205 - MAPE_: 3.1783 - val_loss: 37.1307 - val_MAE_: 5.9529 - val_RMSLE: 3.3432 - val_VAL_: 6.4715 - val_mean_squared_error: 169400609558.9525 - val_MAPE_: 3.3026\n",
            "Epoch 18/600\n",
            "2472929/2472929 [==============================] - 8s 3us/step - loss: 0.9986 - MAE_: 1.0521 - RMSLE: 3.0106 - VAL_: 0.1752 - mean_squared_error: 191828960016.8560 - MAPE_: 3.1779 - val_loss: 38.2810 - val_MAE_: 6.0434 - val_RMSLE: 3.3529 - val_VAL_: 6.5670 - val_mean_squared_error: 169399983533.0952 - val_MAPE_: 3.3142\n",
            "Epoch 19/600\n",
            "2472929/2472929 [==============================] - 8s 3us/step - loss: 0.9989 - MAE_: 1.0522 - RMSLE: 3.0201 - VAL_: 0.1722 - mean_squared_error: 191828238884.6608 - MAPE_: 3.1904 - val_loss: 39.9519 - val_MAE_: 6.1726 - val_RMSLE: 3.3665 - val_VAL_: 6.7032 - val_mean_squared_error: 169399065109.2250 - val_MAPE_: 3.3305\n",
            "Epoch 20/600\n",
            "2472929/2472929 [==============================] - 8s 3us/step - loss: 0.9984 - MAE_: 1.0555 - RMSLE: 3.0264 - VAL_: 0.1808 - mean_squared_error: 191827769064.0526 - MAPE_: 3.1986 - val_loss: 39.2688 - val_MAE_: 6.1201 - val_RMSLE: 3.3610 - val_VAL_: 6.6479 - val_mean_squared_error: 169399437390.0000 - val_MAPE_: 3.3239\n",
            "Epoch 21/600\n",
            "2472929/2472929 [==============================] - 8s 3us/step - loss: 0.9992 - MAE_: 1.0527 - RMSLE: 3.0255 - VAL_: 0.1721 - mean_squared_error: 191827809899.1190 - MAPE_: 3.1975 - val_loss: 41.6353 - val_MAE_: 6.3002 - val_RMSLE: 3.3797 - val_VAL_: 6.8375 - val_mean_squared_error: 169398183948.5645 - val_MAPE_: 3.3462\n",
            "Epoch 22/600\n",
            "2472929/2472929 [==============================] - 8s 3us/step - loss: 0.9988 - MAE_: 1.0563 - RMSLE: 3.0347 - VAL_: 0.1810 - mean_squared_error: 191827130542.3995 - MAPE_: 3.2094 - val_loss: 41.8009 - val_MAE_: 6.3126 - val_RMSLE: 3.3810 - val_VAL_: 6.8506 - val_mean_squared_error: 169398101704.4818 - val_MAPE_: 3.3477\n",
            "Epoch 23/600\n",
            "2472929/2472929 [==============================] - 8s 3us/step - loss: 0.9990 - MAE_: 1.0568 - RMSLE: 3.0389 - VAL_: 0.1815 - mean_squared_error: 191826804096.3873 - MAPE_: 3.2149 - val_loss: 42.1463 - val_MAE_: 6.3385 - val_RMSLE: 3.3837 - val_VAL_: 6.8777 - val_mean_squared_error: 169397914332.7860 - val_MAPE_: 3.3508\n",
            "Epoch 24/600\n",
            "2472929/2472929 [==============================] - 8s 3us/step - loss: 0.9986 - MAE_: 1.0583 - RMSLE: 3.0456 - VAL_: 0.1842 - mean_squared_error: 191826286259.1666 - MAPE_: 3.2235 - val_loss: 41.4445 - val_MAE_: 6.2859 - val_RMSLE: 3.3783 - val_VAL_: 6.8224 - val_mean_squared_error: 169398273523.3355 - val_MAPE_: 3.3444\n",
            "Epoch 25/600\n",
            "2472929/2472929 [==============================] - 8s 3us/step - loss: 0.9987 - MAE_: 1.0568 - RMSLE: 3.0359 - VAL_: 0.1818 - mean_squared_error: 191827027860.2040 - MAPE_: 3.2109 - val_loss: 40.3266 - val_MAE_: 6.2012 - val_RMSLE: 3.3695 - val_VAL_: 6.7334 - val_mean_squared_error: 169398862241.5496 - val_MAPE_: 3.3341\n",
            "Epoch 26/600\n",
            "2472929/2472929 [==============================] - 8s 3us/step - loss: 0.9988 - MAE_: 1.0546 - RMSLE: 3.0328 - VAL_: 0.1759 - mean_squared_error: 191827288959.3159 - MAPE_: 3.2069 - val_loss: 40.4978 - val_MAE_: 6.2143 - val_RMSLE: 3.3708 - val_VAL_: 6.7471 - val_mean_squared_error: 169398787648.0859 - val_MAPE_: 3.3357\n",
            "Epoch 27/600\n",
            "2472929/2472929 [==============================] - 8s 3us/step - loss: 0.9980 - MAE_: 1.0575 - RMSLE: 3.0215 - VAL_: 0.1891 - mean_squared_error: 191828130753.0533 - MAPE_: 3.1922 - val_loss: 38.0963 - val_MAE_: 6.0289 - val_RMSLE: 3.3514 - val_VAL_: 6.5518 - val_mean_squared_error: 169400065983.7523 - val_MAPE_: 3.3124\n",
            "Epoch 28/600\n",
            "2472929/2472929 [==============================] - 8s 3us/step - loss: 0.9987 - MAE_: 1.0538 - RMSLE: 3.0145 - VAL_: 0.1789 - mean_squared_error: 191828672873.0558 - MAPE_: 3.1830 - val_loss: 38.1128 - val_MAE_: 6.0302 - val_RMSLE: 3.3515 - val_VAL_: 6.5531 - val_mean_squared_error: 169400054619.6824 - val_MAPE_: 3.3125\n",
            "Epoch 29/600\n",
            "2472929/2472929 [==============================] - 8s 3us/step - loss: 0.9983 - MAE_: 1.0539 - RMSLE: 3.0100 - VAL_: 0.1809 - mean_squared_error: 191829015891.6328 - MAPE_: 3.1770 - val_loss: 38.2974 - val_MAE_: 6.0447 - val_RMSLE: 3.3530 - val_VAL_: 6.5684 - val_mean_squared_error: 169399948976.4254 - val_MAPE_: 3.3144\n",
            "Epoch 30/600\n",
            "2472929/2472929 [==============================] - 8s 3us/step - loss: 0.9988 - MAE_: 1.0528 - RMSLE: 3.0175 - VAL_: 0.1749 - mean_squared_error: 191828436123.7112 - MAPE_: 3.1870 - val_loss: 39.4592 - val_MAE_: 6.1348 - val_RMSLE: 3.3625 - val_VAL_: 6.6634 - val_mean_squared_error: 169399324288.9152 - val_MAPE_: 3.3258\n",
            "Epoch 31/600\n",
            "2472929/2472929 [==============================] - 8s 3us/step - loss: 0.9988 - MAE_: 1.0547 - RMSLE: 3.0249 - VAL_: 0.1787 - mean_squared_error: 191827888769.2458 - MAPE_: 3.1966 - val_loss: 39.9287 - val_MAE_: 6.1708 - val_RMSLE: 3.3663 - val_VAL_: 6.7013 - val_mean_squared_error: 169399080211.9966 - val_MAPE_: 3.3303\n",
            "Epoch 32/600\n",
            "2472929/2472929 [==============================] - 8s 3us/step - loss: 0.9985 - MAE_: 1.0557 - RMSLE: 3.0225 - VAL_: 0.1826 - mean_squared_error: 191828060110.2707 - MAPE_: 3.1936 - val_loss: 39.2847 - val_MAE_: 6.1213 - val_RMSLE: 3.3611 - val_VAL_: 6.6492 - val_mean_squared_error: 169399437625.7484 - val_MAPE_: 3.3241\n",
            "Epoch 33/600\n",
            "2472929/2472929 [==============================] - 8s 3us/step - loss: 0.9984 - MAE_: 1.0545 - RMSLE: 3.0185 - VAL_: 0.1804 - mean_squared_error: 191828363069.3645 - MAPE_: 3.1882 - val_loss: 38.7198 - val_MAE_: 6.0776 - val_RMSLE: 3.3565 - val_VAL_: 6.6031 - val_mean_squared_error: 169399723090.1077 - val_MAPE_: 3.3186\n",
            "Epoch 34/600\n",
            "2472929/2472929 [==============================] - 8s 3us/step - loss: 0.9986 - MAE_: 1.0530 - RMSLE: 3.0120 - VAL_: 0.1768 - mean_squared_error: 191828859023.3419 - MAPE_: 3.1798 - val_loss: 38.0901 - val_MAE_: 6.0285 - val_RMSLE: 3.3513 - val_VAL_: 6.5513 - val_mean_squared_error: 169400065898.5265 - val_MAPE_: 3.3123\n",
            "Epoch 35/600\n",
            "2472929/2472929 [==============================] - 8s 3us/step - loss: 0.9987 - MAE_: 1.0511 - RMSLE: 3.0128 - VAL_: 0.1711 - mean_squared_error: 191828788016.6895 - MAPE_: 3.1808 - val_loss: 39.4633 - val_MAE_: 6.1351 - val_RMSLE: 3.3626 - val_VAL_: 6.6637 - val_mean_squared_error: 169399324349.2276 - val_MAPE_: 3.3258\n",
            "Epoch 36/600\n",
            "2472929/2472929 [==============================] - 8s 3us/step - loss: 0.9982 - MAE_: 1.0545 - RMSLE: 3.0197 - VAL_: 0.1796 - mean_squared_error: 191828278502.4562 - MAPE_: 3.1898 - val_loss: 39.2354 - val_MAE_: 6.1175 - val_RMSLE: 3.3607 - val_VAL_: 6.6452 - val_mean_squared_error: 169399452352.4328 - val_MAPE_: 3.3236\n",
            "\n",
            "Epoch 00036: ReduceLROnPlateau reducing learning rate to 0.007999999821186066.\n",
            "Epoch 37/600\n",
            "2472929/2472929 [==============================] - 8s 3us/step - loss: 0.9981 - MAE_: 1.0551 - RMSLE: 3.0197 - VAL_: 0.1815 - mean_squared_error: 191828280336.4566 - MAPE_: 3.1898 - val_loss: 38.7432 - val_MAE_: 6.0794 - val_RMSLE: 3.3567 - val_VAL_: 6.6050 - val_mean_squared_error: 169399715697.9353 - val_MAPE_: 3.3188\n",
            "Epoch 38/600\n",
            "2472929/2472929 [==============================] - 8s 3us/step - loss: 0.9984 - MAE_: 1.0514 - RMSLE: 3.0169 - VAL_: 0.1707 - mean_squared_error: 191828487471.7059 - MAPE_: 3.1862 - val_loss: 38.7361 - val_MAE_: 6.0788 - val_RMSLE: 3.3567 - val_VAL_: 6.6044 - val_mean_squared_error: 169399723323.6412 - val_MAPE_: 3.3187\n",
            "Epoch 39/600\n",
            "2472929/2472929 [==============================] - 8s 3us/step - loss: 0.9981 - MAE_: 1.0552 - RMSLE: 3.0144 - VAL_: 0.1839 - mean_squared_error: 191828678255.2883 - MAPE_: 3.1829 - val_loss: 38.4305 - val_MAE_: 6.0551 - val_RMSLE: 3.3541 - val_VAL_: 6.5793 - val_mean_squared_error: 169399885150.1130 - val_MAPE_: 3.3157\n",
            "Epoch 40/600\n",
            "2472929/2472929 [==============================] - 8s 3us/step - loss: 0.9988 - MAE_: 1.0537 - RMSLE: 3.0159 - VAL_: 0.1784 - mean_squared_error: 191828562494.4779 - MAPE_: 3.1849 - val_loss: 38.7269 - val_MAE_: 6.0781 - val_RMSLE: 3.3566 - val_VAL_: 6.6037 - val_mean_squared_error: 169399723191.3713 - val_MAPE_: 3.3186\n",
            "Epoch 41/600\n",
            "1533180/2472929 [=================>............] - ETA: 3s - loss: 0.9988 - MAE_: 1.0507 - RMSLE: 3.0173 - VAL_: 0.1683 - mean_squared_error: 192885770926.6000 - MAPE_: 3.1847"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdad7yTx8Uri",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if 3==3:\n",
        "  meter = 3\n",
        "  epochs = 200\n",
        "  batch_size = 10000\n",
        "  opt = Adam(lr = 0.001)\n",
        "\n",
        "  earlyStopping = EarlyStopping(monitor='loss', patience=100, verbose=1, mode='min')\n",
        "  reduce_lr_loss = ReduceLROnPlateau(monitor='loss', factor=0.3, patience=5, verbose=1, min_delta=1e-3, mode='min')\n",
        "  model_checkpoint = ModelCheckpoint(monitor='loss', save_best_only=True, filepath = DIR + 'best_nn_' + str(meter) + '.model', save_weights_only = False, verbose=0, mode='min')\n",
        "\n",
        "  nn_3 = Sequential()\n",
        "  nn_3.add(Dense(30, input_shape = df[In_Columns].shape[1:], activation = 'tanh', kernel_regularizer=l1(reg), kernel_initializer = 'normal'))\n",
        "  nn_3.add(Dense(30, activation = 'relu',  kernel_initializer = 'normal'))\n",
        "  nn_3.add(Dense(60, activation = 'tanh',  kernel_initializer = 'normal'))\n",
        "  nn_3.add(Dense(90, activation = 'tanh',  kernel_initializer = 'normal'))\n",
        "  nn_3.add(Dense(1, activation = 'relu', kernel_initializer = 'normal'))\n",
        "\n",
        "  nn_3.compile(optimizer = opt, loss = MAPE_VAL_RMSLE, metrics=[ MAE_, RMSLE, VAL_, 'mse', MAPE_ ])\n",
        "  \n",
        "  val = df[(df['meter']==meter) & (df['day']%6==0)]\n",
        "  hist = nn_3.fit( df[(df['meter']==meter) & (df['IS_BAD_PRCNT']<0.25)][In_Columns], df[(df['meter']==meter) & (df['IS_BAD_PRCNT']<0.25)][Out_Columns], batch_size = batch_size, verbose = 1\n",
        "                  , epochs = epochs, shuffle = True, callbacks=[earlyStopping, reduce_lr_loss]\n",
        "                  , validation_data=(val[In_Columns], val[Out_Columns])\n",
        "                  ) \n",
        "  nn_3.save(DIR + str(meter) + 'HANDLY_SAVED2.MODEL')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38XziDvm_mhH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 200\n",
        "batch_size = 10000\n",
        "opt = Adam(lr = 0.001)\n",
        "nn_3.compile(optimizer = opt, loss = MAPE_VAL_RMSLE, metrics=[ MAE_, RMSLE, VAL_, 'mse', MAPE_ ])\n",
        "\n",
        "reduce_lr_loss = ReduceLROnPlateau(monitor='loss', factor=0.3, patience=15, verbose=1, min_delta=1e-3, mode='min')\n",
        "hist = nn_3.fit( df[(df['meter']==meter) & (df['IS_BAD_PRCNT']<0.25)][In_Columns], df[(df['meter']==meter) & (df['IS_BAD_PRCNT']<0.25)][Out_Columns], batch_size = batch_size, verbose = 1\n",
        "                  , epochs = epochs, shuffle = True, callbacks=[earlyStopping, reduce_lr_loss]\n",
        "                  , validation_data=(val[In_Columns], val[Out_Columns])\n",
        "                  ) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H75KbUGtAdOG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#nn_3.save(DIR + str(meter) + 'HANDLY_SAVED.MODEL')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zWSKYPSOjpz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nn_0 = keras.models.load_model (DIR + '0HANDLY_SAVED.MODEL')\n",
        "nn_1 = keras.models.load_model (DIR + '1HANDLY_SAVED.MODEL')\n",
        "nn_2 = keras.models.load_model (DIR + '2HANDLY_SAVED.MODEL')\n",
        "nn_3 = keras.models.load_model (DIR + '3HANDLY_SAVED.MODEL')\n",
        "\n",
        "# score = model.evaluate(X, Y, verbose=0)\n",
        "# print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xsuPcIPCvW2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Предсказание из 4х значений:\n",
        "  df['NN_PRED'] = 0\n",
        "  df['NN_PRED_0'] = nn_0.predict(df[In_Columns], batch_size = 10000) \n",
        "  df['NN_PRED_1'] = nn_1.predict(df[In_Columns], batch_size = 10000) \n",
        "  df['NN_PRED_2'] = nn_2.predict(df[In_Columns], batch_size = 10000) \n",
        "  df['NN_PRED_3'] = nn_3.predict(df[In_Columns], batch_size = 10000) \n",
        "  df['NN_PRED'] = np.where(df['meter'] == 0, df['NN_PRED_0'], df['NN_PRED'])\n",
        "  df['NN_PRED'] = np.where(df['meter'] == 1, df['NN_PRED_1'], df['NN_PRED'])\n",
        "  df['NN_PRED'] = np.where(df['meter'] == 2, df['NN_PRED_2'], df['NN_PRED'])\n",
        "  df['NN_PRED'] = np.where(df['meter'] == 3, df['NN_PRED_3'], df['NN_PRED'])\n",
        "  df.drop(columns = ['NN_PRED_0', 'NN_PRED_1', 'NN_PRED_2', 'NN_PRED_3'], inplace = True)\n",
        "  #df.drop(columns = ['Value_x', 'Value_y'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9zp6mbpLAgV",
        "colab_type": "code",
        "outputId": "363f0f3a-0af2-403b-e812-bfb3cb4478f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "df.columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['building_id', 'meter', 'timestamp', 'meter_reading', 'hour_cos', 'hour_sin', 'weekday_cos',\n",
              "       'weekday_sin', 'week_cos', 'week_sin', 'meter_reading_prev', 'is_equal_prev', 'day',\n",
              "       'IS_BAD_PRCNT', 'building_meter_median', 'hour', 'building_meter_hour_median', 'weekday',\n",
              "       'building_meter_weekday_median', 'site_id', 'square_feet', 'year_built', 'floor_count',\n",
              "       'primary_use_ID', 'primary_use_Education', 'primary_use_Entertainment/public assembly',\n",
              "       'primary_use_Food sales and service', 'primary_use_Healthcare',\n",
              "       'primary_use_Lodging/residential', 'primary_use_Manufacturing/industrial',\n",
              "       'primary_use_Office', 'primary_use_Other', 'primary_use_Parking',\n",
              "       'primary_use_Public services', 'primary_use_Religious worship', 'primary_use_Retail',\n",
              "       'primary_use_Services', 'primary_use_Technology/science', 'primary_use_Utility',\n",
              "       'primary_use_Warehouse/storage', 'air_temperature', 'cloud_coverage', 'dew_temperature',\n",
              "       'precip_depth_1_hr', 'sea_level_pressure', 'wind_direction', 'wind_speed', 'NN_PRED'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1W6pmrQFgyS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df[['meter','meter_reading','NN_PRED','NN_PRED_0','NN_PRED_1','NN_PRED_2','NN_PRED_3']].head(-10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jV_7qcb1EK2t",
        "colab_type": "code",
        "outputId": "ad221c19-6d21-480e-cd60-70d500f171a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "df['NN_ERR'] = np.abs(df['NN_PRED']-df['meter_reading'])\n",
        "print( np.sqrt( np.mean( np.power(np.log(df['meter_reading']+1) - np.log(df['NN_ERR']+1),2.00000)))     )\n",
        "print('Ошибка 0: ', np.sqrt( np.mean( np.power(np.log(df[df['meter']==0]['meter_reading']+1) - np.log(df[df['meter']==0]['NN_ERR']+1),2.00000)))        )\n",
        "print('Ошибка 1: ', np.sqrt( np.mean( np.power(np.log(df[df['meter']==1]['meter_reading']+1) - np.log(df[df['meter']==1]['NN_ERR']+1),2.00000)))        )\n",
        "print('Ошибка 2: ', np.sqrt( np.mean( np.power(np.log(df[df['meter']==2]['meter_reading']+1) - np.log(df[df['meter']==2]['NN_ERR']+1),2.00000)))        )\n",
        "print('Ошибка 3: ', np.sqrt( np.mean( np.power(np.log(df[df['meter']==3]['meter_reading']+1) - np.log(df[df['meter']==3]['NN_ERR']+1),2.00000)))        )\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.304333602122642\n",
            "Ошибка 0:  2.3900365524310576\n",
            "Ошибка 1:  2.2201315882080976\n",
            "Ошибка 2:  2.0922975715434347\n",
            "Ошибка 3:  2.1747259066748708\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSg8qh29X2xl",
        "colab_type": "code",
        "outputId": "cf3d8b99-5978-4a3b-cdad-97082fcdb8db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "#Evaluate:\n",
        "score = nn_0.evaluate(df[df['meter']==0][In_Columns], df[df['meter']==0][Out_Columns], verbose=1, batch_size = 30000)\n",
        "print(0)\n",
        "for i in range(len(nn_0.metrics_names)):\n",
        "  print(\"%s: %.2f%%\" % (nn_0.metrics_names[i], score[i]*100))\n",
        "\n",
        "score = nn_1.evaluate(df[df['meter']==1][In_Columns], df[df['meter']==1][Out_Columns], verbose=1, batch_size = 30000)\n",
        "print(1)\n",
        "for i in range(len(nn_1.metrics_names)):\n",
        "  print(\"%s: %.2f%%\" % (nn_1.metrics_names[i], score[i]*100))\n",
        "\n",
        "score = nn_2.evaluate(df[df['meter']==2][In_Columns], df[df['meter']==2][Out_Columns], verbose=1, batch_size = 30000)\n",
        "print(2)\n",
        "for i in range(len(nn_2.metrics_names)):\n",
        "  print(\"%s: %.2f%%\" % (nn_2.metrics_names[i], score[i]*100))\n",
        "\n",
        "score = nn_3.evaluate(df[df['meter']==3][In_Columns], df[df['meter']==3][Out_Columns], verbose=1, batch_size = 30000)\n",
        "print(3)\n",
        "for i in range(len(nn_3.metrics_names)):\n",
        "  print(\"%s: %.2f%%\" % (nn_3.metrics_names[i], score[i]*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12060910/12060910 [==============================] - 6s 0us/step\n",
            "0\n",
            "loss: 170.83%\n",
            "MAE_: 24.30%\n",
            "RMSLE: 72.08%\n",
            "VAL_: 101.43%\n",
            "mean_squared_error: 5733258.70%\n",
            "4182440/4182440 [==============================] - 2s 0us/step\n",
            "1\n",
            "loss: 106.79%\n",
            "MAE_: 36.88%\n",
            "RMSLE: 149.71%\n",
            "VAL_: 97.85%\n",
            "mean_squared_error: 6239965033.12%\n",
            "2708713/2708713 [==============================] - 1s 1us/step\n",
            "2\n",
            "loss: 338.62%\n",
            "MAE_: 57.65%\n",
            "RMSLE: 164.40%\n",
            "VAL_: 102.62%\n",
            "mean_squared_error: 17498761144725.12%\n",
            "MAPE_: 123.09%\n",
            "1264037/1264037 [==============================] - 1s 1us/step\n",
            "3\n",
            "loss: 399.29%\n",
            "MAE_: 79.27%\n",
            "RMSLE: 185.31%\n",
            "VAL_: 126.99%\n",
            "mean_squared_error: 576059037.88%\n",
            "MAPE_: 164.83%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZGHtjH4Yg6a",
        "colab_type": "code",
        "outputId": "a70a7ba9-1d46-4e9d-aae2-d3a3825c1934",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "for i in range(len(nn_0.metrics_names)):\n",
        "  print(\"%s: %.2f%%\" % (nn_0.metrics_names[i], score[i]*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss: 176.21%\n",
            "MAE_: 23.09%\n",
            "RMSLE: 75.37%\n",
            "VAL_: 100.42%\n",
            "mean_squared_error: 5733258.54%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1FvwRcpe45J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ИДЕИ:\n",
        "  1) Сделать не показатель, а его отклонение от медианы по строению/дню/часу\n",
        "  2) \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRkbaJjBUGZP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Подготовка данных тест:\n",
        "  df_test = pd.read_csv(DIR + \"test.csv\", engine = 'python')\n",
        "  print('Забрали с диска')\n",
        "  df_test['timestamp'] = pd.to_datetime(df_test['timestamp'])\n",
        "\n",
        "  df_test['hour_cos'] = np.cos(df_test['timestamp'].dt.hour * 2 * np.pi / 24)\n",
        "  df_test['hour_sin'] = np.sin(df_test['timestamp'].dt.hour * 2 * np.pi / 24)\n",
        "\n",
        "  df_test['weekday_cos'] = np.cos(df_test['timestamp'].dt.weekday * 2 * np.pi / 7)\n",
        "  df_test['weekday_sin'] = np.sin(df_test['timestamp'].dt.weekday * 2 * np.pi / 7)\n",
        "\n",
        "  df_test['week_cos'] = np.cos(df_test['timestamp'].dt.week * 2 * np.pi / 53)\n",
        "  df_test['week_sin'] = np.sin(df_test['timestamp'].dt.week * 2 * np.pi / 53)\n",
        "# Добавление медианы по метрике постройки\n",
        "  df_median = df.groupby(by=['building_id','meter'])['meter_reading'].median()\n",
        "  df_median.name = 'building_meter_median'\n",
        "  df_test = pd.merge(df_test, df_median, how = 'inner', on = ['building_id','meter'])\n",
        "  del df_median \n",
        "  print('Построены медианы по сооружению')\n",
        "# Добавление медианы по часу, по неделе, метрике постройки\n",
        "  df_test['hour'] = df['timestamp'].dt.hour\n",
        "  df_median = df.groupby(by=['building_id','hour','meter'])['meter_reading'].median()\n",
        "  df_median.name = 'building_meter_hour_median'\n",
        "  df_test = pd.merge(df_test, df_median, how = 'inner', on = ['building_id','hour','meter'])\n",
        "  del df_median \n",
        "\n",
        "  df_test['weekday'] = df['timestamp'].dt.weekday\n",
        "  df_median = df.groupby(by=['building_id','weekday','meter'])['meter_reading'].median()\n",
        "  df_median.name = 'building_meter_weekday_median'\n",
        "  df_test = pd.merge(df_test, df_median, how = 'inner', on = ['building_id','weekday','meter'])\n",
        "  del df_median \n",
        "  print('Построены медианы по сооружению/часу')\n",
        "# Подстановка параметров сооружения\n",
        "  building_df = pd.read_csv(DIR + \"building_metadata.csv\", engine = 'python')\n",
        "  from sklearn.preprocessing import LabelEncoder\n",
        "  le = LabelEncoder()\n",
        "  building_df[\"primary_use_ID\"] = le.fit_transform(building_df[\"primary_use\"])\n",
        "\n",
        "  building_df['primary_use'] = building_df['primary_use'].astype('category')\n",
        "  building_df = pd.get_dummies(building_df)\n",
        "\n",
        "  df_test = df_test.merge(building_df, left_on = \"building_id\", right_on = \"building_id\", how = \"left\")\n",
        "  del building_df\n",
        "  print('Подставлены данные по сооружению')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAPjxPKDUGeS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Вставка данных погоды\n",
        "# Восстановление пустых данных погоды через соседей по линейной инетрполяции\n",
        "  df_weather = pd.read_csv(DIR + \"weather_train.csv\", engine = 'python')\n",
        "  df_weather['timestamp'] = pd.to_datetime(df_weather['timestamp'])\n",
        "  #weather_train.groupby('site_id').apply(lambda group: group.isna().sum())\n",
        "  df_weather = df_weather.groupby('site_id').apply(lambda group: group.interpolate(limit_direction='both'))\n",
        "  df_test = pd.merge(df_test, df_weather, how = 'left', on = ['site_id','timestamp'])\n",
        "  del df_weather"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQROkITbUGhO",
        "colab_type": "code",
        "outputId": "1b54844d-763e-44e2-8b1c-91621daa6d82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 813
        }
      },
      "source": [
        "df_test.head(-10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>row_id</th>\n",
              "      <th>building_id</th>\n",
              "      <th>meter</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>hour_cos</th>\n",
              "      <th>hour_sin</th>\n",
              "      <th>weekday_cos</th>\n",
              "      <th>weekday_sin</th>\n",
              "      <th>week_cos</th>\n",
              "      <th>week_sin</th>\n",
              "      <th>building_meter_median</th>\n",
              "      <th>hour</th>\n",
              "      <th>building_meter_hour_median</th>\n",
              "      <th>weekday</th>\n",
              "      <th>building_meter_weekday_median</th>\n",
              "      <th>site_id</th>\n",
              "      <th>square_feet</th>\n",
              "      <th>year_built</th>\n",
              "      <th>floor_count</th>\n",
              "      <th>primary_use_ID</th>\n",
              "      <th>primary_use_Education</th>\n",
              "      <th>primary_use_Entertainment/public assembly</th>\n",
              "      <th>primary_use_Food sales and service</th>\n",
              "      <th>primary_use_Healthcare</th>\n",
              "      <th>primary_use_Lodging/residential</th>\n",
              "      <th>primary_use_Manufacturing/industrial</th>\n",
              "      <th>primary_use_Office</th>\n",
              "      <th>primary_use_Other</th>\n",
              "      <th>primary_use_Parking</th>\n",
              "      <th>primary_use_Public services</th>\n",
              "      <th>primary_use_Religious worship</th>\n",
              "      <th>primary_use_Retail</th>\n",
              "      <th>primary_use_Services</th>\n",
              "      <th>primary_use_Technology/science</th>\n",
              "      <th>primary_use_Utility</th>\n",
              "      <th>primary_use_Warehouse/storage</th>\n",
              "      <th>air_temperature</th>\n",
              "      <th>cloud_coverage</th>\n",
              "      <th>dew_temperature</th>\n",
              "      <th>precip_depth_1_hr</th>\n",
              "      <th>sea_level_pressure</th>\n",
              "      <th>wind_direction</th>\n",
              "      <th>wind_speed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2017-01-01 00:00:00</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.623490</td>\n",
              "      <td>-0.781831</td>\n",
              "      <td>0.992981</td>\n",
              "      <td>-0.118273</td>\n",
              "      <td>189.751999</td>\n",
              "      <td>0.0</td>\n",
              "      <td>206.474503</td>\n",
              "      <td>4</td>\n",
              "      <td>183.608994</td>\n",
              "      <td>0</td>\n",
              "      <td>7432</td>\n",
              "      <td>2008.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>129</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2017-01-01 01:00:00</td>\n",
              "      <td>0.965926</td>\n",
              "      <td>2.588190e-01</td>\n",
              "      <td>0.623490</td>\n",
              "      <td>-0.781831</td>\n",
              "      <td>0.992981</td>\n",
              "      <td>-0.118273</td>\n",
              "      <td>189.751999</td>\n",
              "      <td>0.0</td>\n",
              "      <td>206.474503</td>\n",
              "      <td>4</td>\n",
              "      <td>183.608994</td>\n",
              "      <td>0</td>\n",
              "      <td>7432</td>\n",
              "      <td>2008.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>258</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2017-01-01 02:00:00</td>\n",
              "      <td>0.866025</td>\n",
              "      <td>5.000000e-01</td>\n",
              "      <td>0.623490</td>\n",
              "      <td>-0.781831</td>\n",
              "      <td>0.992981</td>\n",
              "      <td>-0.118273</td>\n",
              "      <td>189.751999</td>\n",
              "      <td>0.0</td>\n",
              "      <td>206.474503</td>\n",
              "      <td>4</td>\n",
              "      <td>183.608994</td>\n",
              "      <td>0</td>\n",
              "      <td>7432</td>\n",
              "      <td>2008.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>387</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2017-01-01 03:00:00</td>\n",
              "      <td>0.707107</td>\n",
              "      <td>7.071068e-01</td>\n",
              "      <td>0.623490</td>\n",
              "      <td>-0.781831</td>\n",
              "      <td>0.992981</td>\n",
              "      <td>-0.118273</td>\n",
              "      <td>189.751999</td>\n",
              "      <td>0.0</td>\n",
              "      <td>206.474503</td>\n",
              "      <td>4</td>\n",
              "      <td>183.608994</td>\n",
              "      <td>0</td>\n",
              "      <td>7432</td>\n",
              "      <td>2008.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>516</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2017-01-01 04:00:00</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>8.660254e-01</td>\n",
              "      <td>0.623490</td>\n",
              "      <td>-0.781831</td>\n",
              "      <td>0.992981</td>\n",
              "      <td>-0.118273</td>\n",
              "      <td>189.751999</td>\n",
              "      <td>0.0</td>\n",
              "      <td>206.474503</td>\n",
              "      <td>4</td>\n",
              "      <td>183.608994</td>\n",
              "      <td>0</td>\n",
              "      <td>7432</td>\n",
              "      <td>2008.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20216085</th>\n",
              "      <td>20980340</td>\n",
              "      <td>886</td>\n",
              "      <td>2</td>\n",
              "      <td>2017-06-29 11:00:00</td>\n",
              "      <td>-0.965926</td>\n",
              "      <td>2.588190e-01</td>\n",
              "      <td>-0.900969</td>\n",
              "      <td>0.433884</td>\n",
              "      <td>-0.998244</td>\n",
              "      <td>0.059241</td>\n",
              "      <td>48.799999</td>\n",
              "      <td>7.0</td>\n",
              "      <td>79.300003</td>\n",
              "      <td>2</td>\n",
              "      <td>42.700001</td>\n",
              "      <td>9</td>\n",
              "      <td>69799</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20216086</th>\n",
              "      <td>20980647</td>\n",
              "      <td>886</td>\n",
              "      <td>2</td>\n",
              "      <td>2017-06-29 12:00:00</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>1.224647e-16</td>\n",
              "      <td>-0.900969</td>\n",
              "      <td>0.433884</td>\n",
              "      <td>-0.998244</td>\n",
              "      <td>0.059241</td>\n",
              "      <td>48.799999</td>\n",
              "      <td>7.0</td>\n",
              "      <td>79.300003</td>\n",
              "      <td>2</td>\n",
              "      <td>42.700001</td>\n",
              "      <td>9</td>\n",
              "      <td>69799</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20216087</th>\n",
              "      <td>20980952</td>\n",
              "      <td>886</td>\n",
              "      <td>2</td>\n",
              "      <td>2017-06-29 13:00:00</td>\n",
              "      <td>-0.965926</td>\n",
              "      <td>-2.588190e-01</td>\n",
              "      <td>-0.900969</td>\n",
              "      <td>0.433884</td>\n",
              "      <td>-0.998244</td>\n",
              "      <td>0.059241</td>\n",
              "      <td>48.799999</td>\n",
              "      <td>7.0</td>\n",
              "      <td>79.300003</td>\n",
              "      <td>2</td>\n",
              "      <td>42.700001</td>\n",
              "      <td>9</td>\n",
              "      <td>69799</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20216088</th>\n",
              "      <td>20981258</td>\n",
              "      <td>886</td>\n",
              "      <td>2</td>\n",
              "      <td>2017-06-29 14:00:00</td>\n",
              "      <td>-0.866025</td>\n",
              "      <td>-5.000000e-01</td>\n",
              "      <td>-0.900969</td>\n",
              "      <td>0.433884</td>\n",
              "      <td>-0.998244</td>\n",
              "      <td>0.059241</td>\n",
              "      <td>48.799999</td>\n",
              "      <td>7.0</td>\n",
              "      <td>79.300003</td>\n",
              "      <td>2</td>\n",
              "      <td>42.700001</td>\n",
              "      <td>9</td>\n",
              "      <td>69799</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20216089</th>\n",
              "      <td>21290624</td>\n",
              "      <td>886</td>\n",
              "      <td>2</td>\n",
              "      <td>2017-08-10 19:00:00</td>\n",
              "      <td>0.258819</td>\n",
              "      <td>-9.659258e-01</td>\n",
              "      <td>-0.900969</td>\n",
              "      <td>0.433884</td>\n",
              "      <td>-0.794854</td>\n",
              "      <td>-0.606800</td>\n",
              "      <td>48.799999</td>\n",
              "      <td>7.0</td>\n",
              "      <td>79.300003</td>\n",
              "      <td>2</td>\n",
              "      <td>42.700001</td>\n",
              "      <td>9</td>\n",
              "      <td>69799</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20216090 rows × 43 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            row_id  building_id  meter           timestamp  hour_cos      hour_sin  weekday_cos  \\\n",
              "0                0            0      0 2017-01-01 00:00:00  1.000000  0.000000e+00     0.623490   \n",
              "1              129            0      0 2017-01-01 01:00:00  0.965926  2.588190e-01     0.623490   \n",
              "2              258            0      0 2017-01-01 02:00:00  0.866025  5.000000e-01     0.623490   \n",
              "3              387            0      0 2017-01-01 03:00:00  0.707107  7.071068e-01     0.623490   \n",
              "4              516            0      0 2017-01-01 04:00:00  0.500000  8.660254e-01     0.623490   \n",
              "...            ...          ...    ...                 ...       ...           ...          ...   \n",
              "20216085  20980340          886      2 2017-06-29 11:00:00 -0.965926  2.588190e-01    -0.900969   \n",
              "20216086  20980647          886      2 2017-06-29 12:00:00 -1.000000  1.224647e-16    -0.900969   \n",
              "20216087  20980952          886      2 2017-06-29 13:00:00 -0.965926 -2.588190e-01    -0.900969   \n",
              "20216088  20981258          886      2 2017-06-29 14:00:00 -0.866025 -5.000000e-01    -0.900969   \n",
              "20216089  21290624          886      2 2017-08-10 19:00:00  0.258819 -9.659258e-01    -0.900969   \n",
              "\n",
              "          weekday_sin  week_cos  week_sin  building_meter_median  hour  \\\n",
              "0           -0.781831  0.992981 -0.118273             189.751999   0.0   \n",
              "1           -0.781831  0.992981 -0.118273             189.751999   0.0   \n",
              "2           -0.781831  0.992981 -0.118273             189.751999   0.0   \n",
              "3           -0.781831  0.992981 -0.118273             189.751999   0.0   \n",
              "4           -0.781831  0.992981 -0.118273             189.751999   0.0   \n",
              "...               ...       ...       ...                    ...   ...   \n",
              "20216085     0.433884 -0.998244  0.059241              48.799999   7.0   \n",
              "20216086     0.433884 -0.998244  0.059241              48.799999   7.0   \n",
              "20216087     0.433884 -0.998244  0.059241              48.799999   7.0   \n",
              "20216088     0.433884 -0.998244  0.059241              48.799999   7.0   \n",
              "20216089     0.433884 -0.794854 -0.606800              48.799999   7.0   \n",
              "\n",
              "          building_meter_hour_median  weekday  building_meter_weekday_median  site_id  \\\n",
              "0                         206.474503        4                     183.608994        0   \n",
              "1                         206.474503        4                     183.608994        0   \n",
              "2                         206.474503        4                     183.608994        0   \n",
              "3                         206.474503        4                     183.608994        0   \n",
              "4                         206.474503        4                     183.608994        0   \n",
              "...                              ...      ...                            ...      ...   \n",
              "20216085                   79.300003        2                      42.700001        9   \n",
              "20216086                   79.300003        2                      42.700001        9   \n",
              "20216087                   79.300003        2                      42.700001        9   \n",
              "20216088                   79.300003        2                      42.700001        9   \n",
              "20216089                   79.300003        2                      42.700001        9   \n",
              "\n",
              "          square_feet  year_built  floor_count  primary_use_ID  primary_use_Education  \\\n",
              "0                7432      2008.0          NaN               0                      1   \n",
              "1                7432      2008.0          NaN               0                      1   \n",
              "2                7432      2008.0          NaN               0                      1   \n",
              "3                7432      2008.0          NaN               0                      1   \n",
              "4                7432      2008.0          NaN               0                      1   \n",
              "...               ...         ...          ...             ...                    ...   \n",
              "20216085        69799         NaN          NaN               0                      1   \n",
              "20216086        69799         NaN          NaN               0                      1   \n",
              "20216087        69799         NaN          NaN               0                      1   \n",
              "20216088        69799         NaN          NaN               0                      1   \n",
              "20216089        69799         NaN          NaN               0                      1   \n",
              "\n",
              "          primary_use_Entertainment/public assembly  primary_use_Food sales and service  \\\n",
              "0                                                 0                                   0   \n",
              "1                                                 0                                   0   \n",
              "2                                                 0                                   0   \n",
              "3                                                 0                                   0   \n",
              "4                                                 0                                   0   \n",
              "...                                             ...                                 ...   \n",
              "20216085                                          0                                   0   \n",
              "20216086                                          0                                   0   \n",
              "20216087                                          0                                   0   \n",
              "20216088                                          0                                   0   \n",
              "20216089                                          0                                   0   \n",
              "\n",
              "          primary_use_Healthcare  primary_use_Lodging/residential  \\\n",
              "0                              0                                0   \n",
              "1                              0                                0   \n",
              "2                              0                                0   \n",
              "3                              0                                0   \n",
              "4                              0                                0   \n",
              "...                          ...                              ...   \n",
              "20216085                       0                                0   \n",
              "20216086                       0                                0   \n",
              "20216087                       0                                0   \n",
              "20216088                       0                                0   \n",
              "20216089                       0                                0   \n",
              "\n",
              "          primary_use_Manufacturing/industrial  primary_use_Office  primary_use_Other  \\\n",
              "0                                            0                   0                  0   \n",
              "1                                            0                   0                  0   \n",
              "2                                            0                   0                  0   \n",
              "3                                            0                   0                  0   \n",
              "4                                            0                   0                  0   \n",
              "...                                        ...                 ...                ...   \n",
              "20216085                                     0                   0                  0   \n",
              "20216086                                     0                   0                  0   \n",
              "20216087                                     0                   0                  0   \n",
              "20216088                                     0                   0                  0   \n",
              "20216089                                     0                   0                  0   \n",
              "\n",
              "          primary_use_Parking  primary_use_Public services  primary_use_Religious worship  \\\n",
              "0                           0                            0                              0   \n",
              "1                           0                            0                              0   \n",
              "2                           0                            0                              0   \n",
              "3                           0                            0                              0   \n",
              "4                           0                            0                              0   \n",
              "...                       ...                          ...                            ...   \n",
              "20216085                    0                            0                              0   \n",
              "20216086                    0                            0                              0   \n",
              "20216087                    0                            0                              0   \n",
              "20216088                    0                            0                              0   \n",
              "20216089                    0                            0                              0   \n",
              "\n",
              "          primary_use_Retail  primary_use_Services  primary_use_Technology/science  \\\n",
              "0                          0                     0                               0   \n",
              "1                          0                     0                               0   \n",
              "2                          0                     0                               0   \n",
              "3                          0                     0                               0   \n",
              "4                          0                     0                               0   \n",
              "...                      ...                   ...                             ...   \n",
              "20216085                   0                     0                               0   \n",
              "20216086                   0                     0                               0   \n",
              "20216087                   0                     0                               0   \n",
              "20216088                   0                     0                               0   \n",
              "20216089                   0                     0                               0   \n",
              "\n",
              "          primary_use_Utility  primary_use_Warehouse/storage  air_temperature  cloud_coverage  \\\n",
              "0                           0                              0              NaN             NaN   \n",
              "1                           0                              0              NaN             NaN   \n",
              "2                           0                              0              NaN             NaN   \n",
              "3                           0                              0              NaN             NaN   \n",
              "4                           0                              0              NaN             NaN   \n",
              "...                       ...                            ...              ...             ...   \n",
              "20216085                    0                              0              NaN             NaN   \n",
              "20216086                    0                              0              NaN             NaN   \n",
              "20216087                    0                              0              NaN             NaN   \n",
              "20216088                    0                              0              NaN             NaN   \n",
              "20216089                    0                              0              NaN             NaN   \n",
              "\n",
              "          dew_temperature  precip_depth_1_hr  sea_level_pressure  wind_direction  wind_speed  \n",
              "0                     NaN                NaN                 NaN             NaN         NaN  \n",
              "1                     NaN                NaN                 NaN             NaN         NaN  \n",
              "2                     NaN                NaN                 NaN             NaN         NaN  \n",
              "3                     NaN                NaN                 NaN             NaN         NaN  \n",
              "4                     NaN                NaN                 NaN             NaN         NaN  \n",
              "...                   ...                ...                 ...             ...         ...  \n",
              "20216085              NaN                NaN                 NaN             NaN         NaN  \n",
              "20216086              NaN                NaN                 NaN             NaN         NaN  \n",
              "20216087              NaN                NaN                 NaN             NaN         NaN  \n",
              "20216088              NaN                NaN                 NaN             NaN         NaN  \n",
              "20216089              NaN                NaN                 NaN             NaN         NaN  \n",
              "\n",
              "[20216090 rows x 43 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HcOED4IDv0k",
        "colab_type": "code",
        "outputId": "125bad6b-9605-4831-d451-f1428d5e1b45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 863
        }
      },
      "source": [
        "show_plot(hist) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEaCAYAAAD+E0veAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEEKIIAkFIYQQQf8/SUfcsaGe3N8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEaCAYAAAD+E0veAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhBAuEgpCCCFc/j9ULh4wOxXj0AAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEaCAYAAAD+E0veAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEXEoFERExPF/kJ9R/u9OhAEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3y8HyLW1fPvb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsYpyA4omuiY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import model_from_json\n",
        "\n",
        "def load_model(dir = os.getcwd(), name = 'model'):\n",
        "  json_file = open(os.path.join(dir,name+'.json'), 'r')\n",
        "  loaded_model_json = json_file.read()\n",
        "  json_file.close()\n",
        "  model = model_from_json(loaded_model_json)\n",
        "  model.load_weights(os.path.join(dir,name+'.h5'))\n",
        "  print(\"Loading is complete.\")\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvoCZeopmulB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nn = load_model(DIR, 'model_nn')\n",
        "opt = Adam(lr = 0.05)\n",
        "nn.compile(optimizer = opt, loss = mse)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vze6V-2Dv3R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwGQ3nubDv6C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "\n",
        "k = nn.evaluate(X_val, y_val, batch_size = 800000, verbose = 0)\n",
        "print(k)\n",
        "for i in range(X_val.shape[1]):\n",
        "    X_val_2 = X_val.copy()\n",
        "    s = shuffle(X_val_2.iloc[:,i])\n",
        "    s.index = X_val_2.index\n",
        "    X_val_2.iloc[:, i] = s\n",
        "    print('{}: {:2.5}'.format(cols[i], nn.evaluate(X_val_2, y_val, batch_size = 800000, verbose = 0) - k))\n",
        "    X_val_2 = None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7cW0BjWDog5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rglOCdGlDojs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "p = nn.predict(X_test, batch_size = 100000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHSFbHZiq7Of",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuyutB_Z1pu4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_sample_submission.to_csv(DIR+'out_file_int.csv', index = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gQzWTyi1Vjb",
        "colab_type": "code",
        "outputId": "4a1a4271-a100-49b4-8b17-4effad4507ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df_sample_submission.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>row_id</th>\n",
              "      <th>meter_reading</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8784</th>\n",
              "      <td>0</td>\n",
              "      <td>187.721802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8785</th>\n",
              "      <td>129</td>\n",
              "      <td>170.970444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8786</th>\n",
              "      <td>258</td>\n",
              "      <td>158.120926</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8787</th>\n",
              "      <td>387</td>\n",
              "      <td>150.405380</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8788</th>\n",
              "      <td>516</td>\n",
              "      <td>149.041794</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      row_id  meter_reading\n",
              "8784       0     187.721802\n",
              "8785     129     170.970444\n",
              "8786     258     158.120926\n",
              "8787     387     150.405380\n",
              "8788     516     149.041794"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaKZlONMsta8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_sample_submission['row_id'] = df_sample_submission['row_id'].astype('Int32')\n",
        "df_sample_submission['meter_reading'] = df_sample_submission['meter_reading'].astype('float16')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOIMC9y_steQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}