{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of NN Energy Predictor.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yovelop/NN/blob/master/NN_Energy_Predictor_0.31.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zO1azhvf_t9_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "5efb96db-239f-4b7c-e8ba-45ceb42c0db4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "DIR = '/content/drive/My Drive/Colab Notebooks/ENSaver/'\n",
        "DIR_SAVE = '/content/drive/My Drive/Colab Notebooks/ENSaver/31/'\n",
        "#drive.flush_and_unmount()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRgT9oDx_vpi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 969
        },
        "outputId": "9ab9d77c-2d58-4795-de16-4827c17afa85"
      },
      "source": [
        "#Импорты\n",
        "  import numpy as np # linear algebra\n",
        "  import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "  import gc\n",
        "\n",
        "  import matplotlib.pyplot as plt\n",
        "  import matplotlib.style\n",
        "  matplotlib.style.use('ggplot')\n",
        "\n",
        "  from sys import getsizeof\n",
        "\n",
        "  import os\n",
        "  for dirname, _, filenames in os.walk(DIR):\n",
        "      for filename in filenames:\n",
        "          print(os.path.join(dirname, filename))\n",
        "\n",
        "  pd.options.mode.chained_assignment = None  # default='warn'\n",
        "  import warnings\n",
        "  pd.set_option('display.max_rows', 500)\n",
        "  pd.set_option('display.max_columns', 500)\n",
        "  pd.set_option('display.width', 100)\n",
        "  warnings.filterwarnings('ignore')\n",
        "  np.set_printoptions(precision = 3, suppress  = True)\n",
        "  pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
        "\n",
        "  def reduce_mem_usage(df, verbose = False):\n",
        "      start_mem_usg = df.memory_usage().sum() / 1024**2 \n",
        "      print(\"Memory usage of properties dataframe is :\",start_mem_usg,\" MB\")\n",
        "      NAlist = [] # Keeps track of columns that have missing values filled in. \n",
        "      for col in df.columns:\n",
        "          if (df[col].dtype != object) &  (df[col].dtype != 'datetime64[ns]'):  # Exclude strings            \n",
        "              # Print current column type\n",
        "              if verbose:  \n",
        "                print(\"******************************\")\n",
        "                print(\"Column: \",col)\n",
        "                print(\"dtype before: \",df[col].dtype)            \n",
        "              # make variables for Int, max and min\n",
        "              IsInt = False\n",
        "              mx = df[col].max()\n",
        "              mn = df[col].min()\n",
        "              if verbose:\n",
        "                print(\"min for this col: \",mn)\n",
        "                print(\"max for this col: \",mx)\n",
        "              # Integer does not support NA, therefore, NA needs to be filled\n",
        "              if not np.isfinite(df[col]).all(): \n",
        "                  NAlist.append(col)\n",
        "                  df[col].fillna(mn-1,inplace=True)  \n",
        "                    \n",
        "              # test if column can be converted to an integer\n",
        "              asint = df[col].fillna(0).astype(np.int64)\n",
        "              result = abs(df[col] - asint)\n",
        "              result = result.sum()\n",
        "              if result > -0.01 and result < 0.01:\n",
        "                  IsInt = True            \n",
        "              # Make Integer/unsigned Integer datatypes\n",
        "              if IsInt:\n",
        "                  if mn >= 0:\n",
        "                      if mx < 255:\n",
        "                          df[col] = df[col].astype(np.uint8)\n",
        "                      elif mx < 65535:\n",
        "                          df[col] = df[col].astype(np.uint16)\n",
        "                      elif mx < 4294967295:\n",
        "                          df[col] = df[col].astype(np.uint32)\n",
        "                      else:\n",
        "                          df[col] = df[col].astype(np.uint64)\n",
        "                  else:\n",
        "                      if mn > np.iinfo(np.int8).min and mx < np.iinfo(np.int8).max:\n",
        "                          df[col] = df[col].astype(np.int8)\n",
        "                      elif mn > np.iinfo(np.int16).min and mx < np.iinfo(np.int16).max:\n",
        "                          df[col] = df[col].astype(np.int16)\n",
        "                      elif mn > np.iinfo(np.int32).min and mx < np.iinfo(np.int32).max:\n",
        "                          df[col] = df[col].astype(np.int32)\n",
        "                      elif mn > np.iinfo(np.int64).min and mx < np.iinfo(np.int64).max:\n",
        "                          df[col] = df[col].astype(np.int64)    \n",
        "              # Make float datatypes 32 bit\n",
        "              else:\n",
        "                  df[col] = df[col].astype(np.float32)\n",
        "              \n",
        "              # Print new column type\n",
        "              if verbose:\n",
        "                print(\"dtype after: \",df[col].dtype)\n",
        "                print(\"******************************\")\n",
        "      # Print final result\n",
        "      print(\"___MEMORY USAGE AFTER COMPLETION:___\")\n",
        "      mem_usg = df.memory_usage().sum() / 1024**2 \n",
        "      print(\"Memory usage is: \",mem_usg,\" MB\")\n",
        "      print(\"This is \",100*mem_usg/start_mem_usg,\"% of the initial size\")\n",
        "      return df, NAlist\n",
        "\n",
        "  def show_plot(hist):\n",
        "    plt.plot(hist.history['loss'])\n",
        "    plt.plot(hist.history['val_loss'])\n",
        "    plt.title('Model NN')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend(['Train','Val'])\n",
        "    plt.show()\n",
        "    \n",
        "    plt.plot(hist.history['loss'])\n",
        "    plt.plot(hist.history['val_loss'])\n",
        "    plt.title('Model NN')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.ylim([1,2])\n",
        "    plt.legend(['Train','Val'])\n",
        "    plt.show()\n",
        "\n",
        "    plt.plot(hist.history['loss'])\n",
        "    plt.plot(hist.history['val_loss'])\n",
        "    plt.title('Model NN')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.ylim([0,1])\n",
        "    plt.legend(['Train','Val'])\n",
        "    plt.show()\n",
        "\n",
        "  #Импорты Керас:\n",
        "  from keras.models import Sequential, load_model\n",
        "\n",
        "  from keras.layers import Dense\n",
        "  from keras.initializers import TruncatedNormal, Constant\n",
        "  from keras.regularizers import l1,l2,l1_l2\n",
        "  from keras.optimizers import Adam\n",
        "  import keras.backend as K\n",
        "\n",
        "  from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "  #from keras.utils import plot_model\n",
        "  from keras.losses import mean_squared_error as mse #, mean_absolute_percentage_error as mape\n",
        "\n",
        "  def RMSLE(y_true, y_pred):\n",
        "    return K.pow( K.mean( K.pow(K.log(y_true+1) - K.log(y_pred+1),2.00000)),0.5000)\n",
        "\n",
        "  def MSLE(y_true, y_pred):\n",
        "    return K.mean( K.pow(K.log(y_true+1) - K.log(y_pred+1),2.00000))\n",
        "\n",
        "  def MALE(y_true, y_pred):\n",
        "    return K.mean( K.abs(K.log(y_true+1) - K.log(y_pred+1)))\n",
        "\n",
        "  def tweedieloss(y_true, y_pred):\n",
        "      return K.mean(  K.pow(    K.pow(backend.maximum(0.000,K.maximum(0.013000,y_true)),0.5)  -   K.pow(K.maximum(0.013000,y_pred),0.5)   , 2 ) / K.pow(K.maximum(0.013000,y_pred),0.5)\n",
        "                  )\n",
        "\n",
        "  def tweedieloss_bkp(y_true, y_pred):\n",
        "      p=1.5\n",
        "      dev = 2 * (K.pow(K.maximum(0.000,y_true), 2-p)/((1-p) * (2-p)) -\n",
        "                    y_true * K.pow(y_pred, 1-p)/(1-p) +\n",
        "                    K.pow(y_pred, 2-p)/(2-p))\n",
        "      return K.mean(dev)\n",
        "\n",
        "  def VAL_ (y_true, y_pred):\n",
        "      return  K.maximum(0.0330000, K.sum(y_pred))/ K.maximum(0.033000, K.sum(y_true)) \n",
        "      \n",
        "  def VAL_2 (y_true, y_pred):\n",
        "      return  K.minimum( 5.000000, K.exp ( K.abs( K.log( VAL_ (y_true, y_pred))))-1)\n",
        "  \n",
        "  def VAL_3 (y_true, y_pred):\n",
        "      return  K.exp ( K.abs( K.log( VAL_ (y_true, y_pred))))-1\n",
        "\n",
        "  def MAPE_ (y_true, y_pred):\n",
        "      return K.mean( K.minimum( 5.000000,  K.abs(y_true - y_pred)/ K.maximum(0.033000, y_true)) )\n",
        "      \n",
        "  def MAE_(y_true, y_pred):\n",
        "      return K.sum( K.abs(y_true - y_pred))/ K.maximum(0.033000, K.sum(y_true))\n",
        "\n",
        "  def MSE_(y_true, y_pred):\n",
        "      return K.sum( K.pow(y_true - y_pred,2.00000))/ K.maximum(0.033000,  K.sum(K.pow(y_true,2.00000)))\n",
        "\n",
        "  def MAE_MAPE(y_true, y_pred):\n",
        "      return (\n",
        "                        MAE_(y_true, y_pred)\n",
        "          +  0.250000 * MAPE_ (y_true, y_pred)\n",
        "      )\n",
        "              \n",
        "  def MAE_VAL_MAPE(y_true, y_pred):\n",
        "      return (\n",
        "                        MAE_(y_true, y_pred)\n",
        "          + 1.800000 *   VAL_2 (y_true, y_pred)          \n",
        "          + 0.950000 *   MAPE_ (y_true, y_pred)\n",
        "          )\n",
        "\n",
        "  def MAE_VAL(y_true, y_pred):\n",
        "      return (\n",
        "                        MAE_(y_true, y_pred)\n",
        "          + 0.800000 *   VAL_2 (y_true, y_pred)                     \n",
        "              )\n",
        "\n",
        "  def MAPE_VAL(y_true, y_pred):\n",
        "      return (\n",
        "                      MAPE_ (y_true, y_pred)\n",
        "          + 0.4000 *  VAL_2 (y_true, y_pred)             \n",
        "              )\n",
        "\n",
        "  def MSE_VAL_MAPE(y_true, y_pred):\n",
        "      return (\n",
        "            5.000000 *   MSE_(y_true, y_pred)\n",
        "          + 2.200000 *   VAL_2 (y_true, y_pred)          \n",
        "          + 0.750000 *   MAPE_ (y_true, y_pred)\n",
        "          )\n",
        "\n",
        "  def MASPE_VAL(y_true, y_pred):\n",
        "      return (\n",
        "                        MAE_(y_true, y_pred)               \n",
        "          + 0.500000 *   MSE_(y_true, y_pred)\n",
        "          + 1.200000 *   VAL_2 (y_true, y_pred)          \n",
        "          + 0.250000 *   MAPE_ (y_true, y_pred)\n",
        "          )\n",
        "  \n",
        "  def MAE_RMSLE(y_true, y_pred):\n",
        "      return (\n",
        "            1.000000 *   MAE_   (y_true, y_pred)\n",
        "          + 2.000000 *   MSLE  (y_true, y_pred)          \n",
        "          )  \n",
        "\n",
        "  def MAPE_RMSLE(y_true, y_pred):\n",
        "      return (\n",
        "            1.000000 *   MAPE_   (y_true, y_pred)\n",
        "          + 0.100000 *   MSLE  (y_true, y_pred)          \n",
        "          )  \n",
        "  \n",
        "  def MAPE_VAL_RMSLE(y_true, y_pred):\n",
        "      return (\n",
        "            0.500000 *   MAPE_   (y_true, y_pred)\n",
        "          + 1.500000 *   MSLE   (y_true, y_pred)    \n",
        "          + 0.300000 *   VAL_2   (y_true, y_pred)      \n",
        "          )  \n",
        " \n",
        "  import keras.metrics\n",
        "  keras.metrics.MAE_ = MAE_\n",
        "  keras.metrics.VAL_ = VAL_\n",
        "  keras.metrics.VAL_2 = VAL_2\n",
        "  keras.metrics.MAPE_ = MAPE_\n",
        "  keras.metrics.MSE_ = MSE_\n",
        "  keras.metrics.tweedieloss = tweedieloss\n",
        "  keras.metrics.MAE_RMSLE = MAE_RMSLE\n",
        "  keras.metrics.MAPE_RMSLE = MAPE_RMSLE\n",
        "  keras.metrics.MAPE_VAL_RMSLE = MAPE_VAL_RMSLE\n",
        "  keras.metrics.RMSLE = RMSLE\n",
        "  keras.metrics.MSLE = MSLE\n",
        "  keras.metrics.MALE = MALE\n",
        "\n",
        "  import keras.losses\n",
        "  keras.losses.MAE_VAL_MAPE = MAE_VAL_MAPE\n",
        "  keras.losses.MSE_VAL_MAPE = MSE_VAL_MAPE\n",
        "  keras.losses.MAE_ = MAE_\n",
        "  keras.losses.MASPE_VAL = MASPE_VAL\n",
        "  keras.losses.tweedieloss = tweedieloss\n",
        "  keras.losses.MAE_RMSLE = MAE_RMSLE\n",
        "  keras.losses.MAPE_RMSLE = MAPE_RMSLE\n",
        "  keras.losses.MAPE_VAL_RMSLE = MAPE_VAL_RMSLE\n",
        "  keras.losses.RMSLE = RMSLE\n",
        "  keras.losses.MSLE = MSLE\n",
        "  keras.losses.MALE = MALE\n",
        "\n",
        "  class MyCustomCallback(keras.callbacks.Callback):\n",
        "    \n",
        "    def __init__(self, epochs, stats_print_step): \n",
        "        \n",
        "        self.__epochs = epochs\n",
        "        self.__stats_print_step = stats_print_step\n",
        "    \n",
        "    def on_train_begin(self, logs={}):\n",
        "        pass\n",
        "        #print('on_train_begin', logs)\n",
        " \n",
        "    def on_train_end(self, logs={}):\n",
        "        pass\n",
        "        #print('on_train_end', logs)\n",
        " \n",
        "    def on_epoch_begin(self, epoch, logs={}):\n",
        "        pass\n",
        " \n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if ((epoch < 5) or (epoch % self.__stats_print_step == 0)) :\n",
        "            print('# ' + str('{:04d}'.format(epoch + 1)) + ' | ' + self.get_stats_by_epoch(logs))\n",
        "        if epoch == 2:\n",
        "            print('.......')\n",
        "        if epoch == self.__epochs - 1:\n",
        "            print('# ' + str('{:04d}'.format(epoch + 1)) + ' | ' + self.get_stats_by_epoch(logs))\n",
        "        else:\n",
        "            print('# ' + str('{:04d}'.format(epoch + 1)) + ' | ' + self.get_stats_by_epoch(logs), end=\"\\r\")\n",
        " \n",
        "    def on_batch_begin(self, batch, logs={}):\n",
        "        pass\n",
        "        #print('on_batch_begin', batch, logs)\n",
        " \n",
        "    def on_batch_end(self, batch, logs={}):\n",
        "        pass\n",
        "        #print('on_batch_end', batch, logs)\n",
        "\n",
        "    def get_stats_by_epoch(self, logs):\n",
        "        \n",
        "        is_test = True\n",
        "        s = ''\n",
        "        \n",
        "        for key, value in logs.items(): \n",
        "            if is_test:\n",
        "                if 'val_' not in str(key):\n",
        "                    s += ' /// '\n",
        "                    is_test = False\n",
        "            if is_test:\n",
        "                s += ' ' + str(key).replace('val_', 'TST_') + ': ' + \"{0:.4f}\".format(value)\n",
        "            else:\n",
        "                s += ' ' + 'TRN_' + str(key) + ': ' + \"{0:.4f}\".format(value)\n",
        "\n",
        "        return s #'val_loss: ' + \"{0:.4f}\".format(logs['val_loss']) + ' | loss: ' + \"{0:.4f}\".format(logs['loss'])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/ENSaver/building_metadata.csv\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/model_nn.h5\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/model_nn.json\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/test.csv\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/train.csv\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/weather_test.csv\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/weather_train.csv\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/0HANDLY_SAVED.MODEL\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/1HANDLY_SAVED.MODEL\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/2HANDLY_SAVED.MODEL\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/3HANDLY_SAVED.MODEL\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/0HANDLY_SAVED2.MODEL\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/1HANDLY_SAVED2.MODEL\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/3HANDLY_SAVED2.MODEL\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/3HANDLY_SAVED3.MODEL\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/2HANDLY_SAVED2.MODEL\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/scaler.pickle\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/3HANDLY_SAVED03.MODEL\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/2HANDLY_SAVED03.MODEL\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/2HANDLY_SAVED3.MODEL\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/0HANDLY_SAVED3.MODEL\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/1HANDLY_SAVED_3.MODEL\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/3HANDLY_SAVED0_3.MODEL\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/2HANDLY_SAVED_3.MODEL\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/3HANDLY_SAVED_3best.MODEL\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/3HANDLY_SAVED_3.MODEL\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/0HANDLY_SAVED_3.MODEL\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/0HANDLY_SAVED_0best.MODEL\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/0HANDLY_SAVED_3best.MODEL\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/1HANDLY_SAVED_3best.MODEL\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/2HANDLY_SAVED_3best.MODEL\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/DF_TRAIN_REDUCED3.FTHR\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/scaler3.pickle\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/1HANDLY_SAVED3.MODEL\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/best_nn_2.model\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/best_nn_3.model\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/best_nn_0.model\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/best_nn_1.model\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/31/1HANDLY_SAVED3best-.MODEL\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/31/DF_TRAIN_REDUCED3.FTHR\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/31/DF_TEST_REDUCED3.FTHR\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/31/0HANDLY_SAVED3.MODEL\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/31/0HANDLY_SAVED3best.MODEL\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/31/3HANDLY_SAVED3bestMALE.MODEL\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/31/3HANDLY_SAVED3best.MODEL\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/31/3HANDLY_SAVED3.MODEL\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/31/2HANDLY_SAVED3.MODEL\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/31/2HANDLY_SAVED3best.MODEL\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/31/1HANDLY_SAVED3best.MODEL\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/31/1HANDLY_SAVED3.MODEL\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/31/0HANDLY_SAVED_3best.MODEL\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/31/0HANDLY_SAVED_3.MODEL\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/31/scaler31.pickle\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/31/1HANDLY_SAVED_3best.MODEL\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/31/1HANDLY_SAVED_3.MODEL\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/31/1HANDLY_SAVED_3bestMSLEVAL.MODEL\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Fv4ErMY_vsQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#0: electricity, 1: chilledwater, 2: steam, 3: hotwater\n",
        "#  Подготовка данных\n",
        "  df = pd.read_csv(DIR + \"train.csv\", engine = 'python')\n",
        "  df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
        "\n",
        "  df['hour_cos'] = np.cos(df['timestamp'].dt.hour * 2 * np.pi / 24)\n",
        "  df['hour_sin'] = np.sin(df['timestamp'].dt.hour * 2 * np.pi / 24)\n",
        "\n",
        "  df['weekday_cos'] = np.cos(df['timestamp'].dt.weekday * 2 * np.pi / 7)\n",
        "  df['weekday_sin'] = np.sin(df['timestamp'].dt.weekday * 2 * np.pi / 7)\n",
        "\n",
        "  df['week_cos'] = np.cos(df['timestamp'].dt.week * 2 * np.pi / 53)\n",
        "  df['week_sin'] = np.sin(df['timestamp'].dt.week * 2 * np.pi / 53)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g52hlFMS2cpu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Очистка от подозрительных нулей\n",
        "  #print(df[df['building_id']==2][['timestamp','meter_reading','meter','ds_zero','de_zero','is_bad_zero']].head(20))\n",
        "  df = df.sort_values(by = ['meter','building_id','timestamp'])\n",
        "  df['meter_reading_prev'] = 0\n",
        "\n",
        "  #for bid in df['building_id'].unique():\n",
        "  #  for met in df['meter'].unique():\n",
        "  df['meter_reading_prev'] = df['meter_reading'].shift()\n",
        "  df['is_equal_prev']= (df['meter_reading_prev'] == df['meter_reading'] )*1\n",
        "\n",
        "  df['day'] = df['timestamp'].dt.dayofyear\n",
        "  df_bad_rows = df.groupby(by=['building_id','day','meter'], as_index = False)['is_equal_prev'].mean()\n",
        "  df_bad_rows.rename({\"is_equal_prev\": \"IS_BAD_PRCNT\"}, axis='columns', inplace=True)\n",
        "\n",
        "  df = pd.merge(df, df_bad_rows, how = 'inner', on = ['building_id','day','meter'])\n",
        "  #print(df_bad_rows[df_bad_rows['building_id']==109].head(365))\n",
        "  del df_bad_rows \n",
        "\n",
        "  #print(df[df['building_id']==2][['timestamp','meter_reading','is_equal_prev','IS_BAD_PRCNT','day']].head(30))\n",
        "# Добавление медиан\n",
        "  # Добавление медианы по метрике постройки\n",
        "  if 1==1:\n",
        "    #df_tmp = df[df['IS_BAD_PRCNT']<0.45]\n",
        "    df_median = df.groupby(by=['building_id','meter']) ['meter_reading'].median()\n",
        "    df_median.name = 'building_meter_median'\n",
        "    df_mean = df.groupby(by=['building_id','meter']) ['meter_reading'].mean()\n",
        "    df_mean.name = 'building_meter_mean'\n",
        "    df_median = pd.merge(df_median, df_mean, how = 'inner', on = ['building_id','meter'])\n",
        "    df_median['building_meter_median'] = ( df_median['building_meter_median'] * 27.000 + df_median['building_meter_mean'])/28.000\n",
        "    \n",
        "    df_median2 = df[df['IS_BAD_PRCNT']<0.45].groupby(by=['building_id','meter']) ['meter_reading'].median()\n",
        "    df_median2.name = 'building_meter_median_45'\n",
        "    df_mean2 = df[df['IS_BAD_PRCNT']<0.45].groupby(by=['building_id','meter']) ['meter_reading'].mean()\n",
        "    df_mean2.name = 'building_meter_mean_45'\n",
        "    df_median2 = pd.merge(df_median2, df_mean2, how = 'inner', on = ['building_id','meter'])\n",
        "    df_median2['building_meter_median_45'] = ( df_median2['building_meter_median_45'] * 27.000 + df_median2['building_meter_mean_45'])/28.000\n",
        "    df_median = pd.merge(df_median, df_median2, how = 'left', on = ['building_id','meter'])\n",
        "\n",
        "    df_median['building_meter_median'] = np.where(df_median['building_meter_median_45'] >= 0, df_median['building_meter_median_45'], df_median['building_meter_median'])\n",
        "    df_median.drop(columns=['building_meter_median_45'], inplace = True)\n",
        "\n",
        "    df = pd.merge(df, df_median, how = 'inner', on = ['building_id','meter'])\n",
        "    del df_median , df_mean, df_median2, df_mean2\n",
        "    gc.collect()\n",
        "    #print(len(df))\n",
        "  # Добавление медианы по часу, по неделе, метрике постройки\n",
        "  if 1==1:\n",
        "    df['hour'] = df['timestamp'].dt.hour\n",
        "    df_median = df.groupby(by=['building_id','hour','meter'])['meter_reading'].median()\n",
        "    df_median.name = 'building_meter_hour_median'\n",
        "    df_mean = df.groupby (by=['building_id','hour','meter']) ['meter_reading'].mean()\n",
        "    df_mean.name = 'building_meter_hour_mean'\n",
        "    df_median = pd.merge(df_median, df_mean, how = 'inner', on = ['building_id','hour','meter'])\n",
        "    df_median['building_meter_hour_median'] = (df_median['building_meter_hour_median'] * 9.000000 + df_median['building_meter_hour_mean'])/10.000000\n",
        "    #print(len(df))\n",
        "\n",
        "    df_median2 = df[df['IS_BAD_PRCNT']<0.75].groupby(by=['building_id','hour','meter'])['meter_reading'].median()\n",
        "    df_median2.name = 'building_meter_hour_median_all'\n",
        "    df_mean2 = df[df['IS_BAD_PRCNT']<0.75].groupby (by=['building_id','hour','meter']) ['meter_reading'].mean()\n",
        "    df_mean2.name = 'building_meter_hour_mean_all'\n",
        "    df_median2 = pd.merge(df_median2, df_mean2, how = 'inner', on = ['building_id','hour','meter'])\n",
        "    df_median2['building_meter_hour_median_all'] = (df_median2['building_meter_hour_median_all'] * 9.000000 + df_median2['building_meter_hour_mean_all'])/10.000000\n",
        "    df_median2.drop(columns=['building_meter_hour_mean_all'], inplace = True)\n",
        "    df_median = pd.merge(df_median, df_median2, how = 'left', on = ['building_id','hour','meter'])\n",
        "    \n",
        "    df_median['building_meter_hour_median'] = np.where(df_median['building_meter_hour_median_all'] >= 0, df_median['building_meter_hour_median_all'], df_median['building_meter_hour_median'])\n",
        "    #print(len(df))\n",
        "\n",
        "    df_median.drop(columns=['building_meter_hour_median_all'], inplace = True)\n",
        "    df_median2 = df[df['IS_BAD_PRCNT']<0.45].groupby(by=['building_id','hour','meter'])['meter_reading'].median()\n",
        "    df_median2.name = 'building_meter_hour_median_45'\n",
        "    df_mean2 = df[df['IS_BAD_PRCNT']<0.45].groupby (by=['building_id','hour','meter']) ['meter_reading'].mean()\n",
        "    df_mean2.name = 'building_meter_hour_mean_45'\n",
        "    df_median2 = pd.merge(df_median2, df_mean2, how = 'inner', on = ['building_id','hour','meter'])\n",
        "    df_median2['building_meter_hour_median_45'] = (df_median2['building_meter_hour_median_45'] * 9.000000 + df_median2['building_meter_hour_mean_45'])/10.000000\n",
        "    df_median2.drop(columns=['building_meter_hour_mean_45'], inplace = True)\n",
        "    df_median = pd.merge(df_median, df_median2, how = 'left', on = ['building_id','hour','meter'])\n",
        "    \n",
        "    df_median['building_meter_hour_median'] = np.where(df_median['building_meter_hour_median_45'] >= 0, df_median['building_meter_hour_median_45'], df_median['building_meter_hour_median'])\n",
        "    df_median.drop(columns=['building_meter_hour_median_45'], inplace = True)\n",
        "\n",
        "    df = pd.merge(df, df_median, how = 'left', on = ['building_id','hour','meter'])\n",
        "    #print(len(df))\n",
        "\n",
        "    del df_median , df_mean, df_median2, df_mean2\n",
        "    gc.collect()\n",
        "    df['k_fact_med_hour']=np.exp( np.abs( np.log( (df['meter_reading']+0.01)/(df['building_meter_hour_median']+0.01)) ) )\n",
        "\n",
        "    df['weekday'] = df['timestamp'].dt.weekday\n",
        "    df_median = df.groupby(by=['building_id','weekday','meter'])['meter_reading'].median()\n",
        "    df_median.name = 'building_meter_weekday_median'\n",
        "    df = pd.merge(df, df_median, how = 'inner', on = ['building_id','weekday','meter'])\n",
        "    del df_median \n",
        "\n",
        "    holidays = [\"2016-01-01\", \"2016-01-18\", \"2016-02-15\", \"2016-05-30\", \"2016-07-04\",\n",
        "                      \"2016-09-05\", \"2016-10-10\", \"2016-11-11\", \"2016-11-24\", \"2016-12-26\",\n",
        "                      \"2017-01-02\", \"2017-01-16\", \"2017-02-20\", \"2017-05-29\", \"2017-07-04\",\n",
        "                      \"2017-09-04\", \"2017-10-09\", \"2017-11-10\", \"2017-11-23\", \"2017-12-25\",\n",
        "                      \"2018-01-01\", \"2018-01-15\", \"2018-02-19\", \"2018-05-28\", \"2018-07-04\",\n",
        "                      \"2018-09-03\", \"2018-10-08\", \"2018-11-12\", \"2018-11-22\", \"2018-12-25\",\n",
        "                      \"2019-01-01\"]\n",
        "    df[\"is_holiday\"] = (df.timestamp.isin(holidays)).astype(int)\n",
        "    del holidays\n",
        "    #print(len(df))\n",
        "  # Подстановка параметров сооружения\n",
        "  if 1==1:\n",
        "    building_df = pd.read_csv(DIR + \"building_metadata.csv\", engine = 'python')\n",
        "    from sklearn.preprocessing import LabelEncoder\n",
        "    le = LabelEncoder()\n",
        "    building_df[\"primary_use_ID\"] = le.fit_transform(building_df[\"primary_use\"])\n",
        "    #building_df['floor_count'].fillna(building_df['floor_count'].mean(), inplace= True)\n",
        "    #building_df['year_built'].fillna(building_df['year_built'].mean, inplace= True)\n",
        "    #building_df['primary_use'] = building_df['primary_use'].astype('category')\n",
        "    #building_df = pd.get_dummies(building_df)\n",
        "\n",
        "    df = df.merge(building_df, left_on = \"building_id\", right_on = \"building_id\", how = \"left\")\n",
        "    df.head(5)\n",
        "    del building_df\n",
        "    gc.collect()\n",
        "\n",
        "    # Деление по магазинам на обучающую и тестовую выборки\n",
        "      # building_df = pd.read_csv(DIR + \"building_metadata.csv\", engine = 'python')\n",
        "      # building_df = building_df.sort_values(by = ['site_id','primary_use'])\n",
        "      # building_df['is_val'] = np.where(building_df['building_id'] % 5 == 0 , 1 , 0)\n",
        "      # print(building_df.groupby(['primary_use','site_id'])['is_val'].agg(['count', 'sum']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIDKj_YCb_bD",
        "colab_type": "code",
        "outputId": "5798e17f-7eea-4992-ff0a-fcaefc886871",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Вставка данных погоды\n",
        "#Восстановление пустых данных погоды через соседей по линейной инетрполяции\n",
        "  df_weather = pd.read_csv(DIR + \"weather_train.csv\", engine = 'python')\n",
        "  df_weather['timestamp'] = pd.to_datetime(df_weather['timestamp'])\n",
        "\n",
        "  #weather_train.groupby('site_id').apply(lambda group: group.isna().sum())\n",
        "  df_times = df.drop_duplicates(['site_id','timestamp'])[['site_id','timestamp']]\n",
        "  df_times = pd.merge(df_times, df_weather, how = 'left', on = ['site_id','timestamp'])\n",
        "  df_times = df_times.sort_values(by = ['site_id','timestamp'])\n",
        "  \n",
        "  df_times = df_times.groupby('site_id').apply(lambda group: group.interpolate(limit_direction='both'))\n",
        "  df_times = df_times.groupby('timestamp').apply(lambda group: group.interpolate(limit_direction='both'))\n",
        "  df = pd.merge(df, df_times, how = 'left', on = ['site_id','timestamp'])\n",
        "  #print(df_times.describe())\n",
        "  del df_weather, df_times\n",
        "  gc.collect()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxPaU99v4PI-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Сохранение выборки\n",
        "  #reduce_mem_usage(df)\n",
        "  df.to_feather(DIR_SAVE + 'DF_TRAIN_REDUCED3.FTHR')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6XbWpxAUnQb",
        "colab_type": "text"
      },
      "source": [
        "  Скорость"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asr3-4DHF_sx",
        "colab_type": "code",
        "outputId": "4a1da19a-8839-4f75-e863-b27c472b0cb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "# Загрузка выборки\n",
        "  df = pd.read_feather(DIR_SAVE + 'DF_TRAIN_REDUCED3.FTHR')\n",
        "  gc.collect()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ArrowInvalid",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mArrowInvalid\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-e8939c6eeff1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_feather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDIR_SAVE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'DF_TRAIN_REDUCED3.FTHR'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/feather_format.py\u001b[0m in \u001b[0;36mread_feather\u001b[0;34m(path, columns, use_threads)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfeather\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_feather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnthreads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint_use_threads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfeather\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_feather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_threads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muse_threads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyarrow/feather.py\u001b[0m in \u001b[0;36mread_feather\u001b[0;34m(source, columns, use_threads)\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \"\"\"\n\u001b[0;32m--> 213\u001b[0;31m     \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFeatherReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_threads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_threads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyarrow/feather.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, source)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0m_check_pandas_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyarrow/feather.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.FeatherReader.open\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyarrow/error.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mArrowInvalid\u001b[0m: File is too small to be a well-formed file"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_Em3Xm6rdeV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Out_Columns = 'meter_reading'\n",
        "In_Columns = [ 'hour_cos','hour_sin', 'weekday_cos', 'weekday_sin', 'week_cos', 'week_sin',\n",
        "       'site_id', 'square_feet',\n",
        "       'primary_use_ID', 'is_holiday',\n",
        "       'air_temperature', 'cloud_coverage',\n",
        "       'dew_temperature', 'sea_level_pressure',\n",
        "       'wind_direction', 'wind_speed',\n",
        "       'building_meter_median','building_meter_hour_median','building_meter_weekday_median',\n",
        "       #КАНДИДАТЫ нА ИСКЛЮЧЕНИЕ:\n",
        "          #'year_built', 'floor_count', 'precip_depth_1_hr',\n",
        "          #  'primary_use_Education', 'primary_use_Entertainment/public assembly', 'primary_use_Food sales and service', 'primary_use_Healthcare',\n",
        "          #  'primary_use_Lodging/residential','primary_use_Manufacturing/industrial', 'primary_use_Office',\n",
        "          #  'primary_use_Other', 'primary_use_Parking', 'primary_use_Public services', 'primary_use_Religious worship',\n",
        "          #  'primary_use_Retail', 'primary_use_Services', 'primary_use_Technology/science', 'primary_use_Utility','primary_use_Warehouse/storage',\n",
        "       ]\n",
        "# Нормализация\n",
        "if 1==1:\n",
        "  df.dropna(subset = In_Columns + [Out_Columns], inplace=True)\n",
        "\n",
        "  #print(df[['air_temperature', 'cloud_coverage','dew_temperature', 'sea_level_pressure','wind_direction', 'wind_speed']].describe())\n",
        "  from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, OneHotEncoder\n",
        "  scaler =  MinMaxScaler (copy=True, feature_range=(0, 1))                                  #quantile_range  = (15.0,85.0)) #Normalizer #(copy=True, feature_range=(-1, 1)) # MinMaxScaler(copy=True, feature_range=(-1, 1)) #StandardScaler() #MinMaxScaler(copy=True, feature_range=(-1, 1)) # RobustScaler()\n",
        "  scaler.fit( df[In_Columns] )\n",
        "  df[In_Columns]     = pd.DataFrame(data = scaler.transform( df[In_Columns]) , columns = df[In_Columns].columns   ) \n",
        "  gc.collect()\n",
        "\n",
        "  #print(df[['air_temperature', 'cloud_coverage','dew_temperature', 'sea_level_pressure','wind_direction', 'wind_speed']].describe())\n",
        "\n",
        "  import pickle\n",
        "  with open(DIR_SAVE+'scaler31.pickle', 'wb') as handle:\n",
        "    pickle.dump(scaler, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "    pickle.dump(In_Columns, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "    pickle.dump(Out_Columns, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "  \n",
        "  #with open('filename.pickle', 'rb') as handle:\n",
        "  #  b = pickle.load(handle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laaKxqJQn2XC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "9f74968c-3fbd-4e26-a54b-d071bcd3e33d"
      },
      "source": [
        "#Всякое инфо:\n",
        "  #df[['building_id','hour','meter','building_meter_hour_mean','building_meter_hour_median','meter_reading','k_fact_med_hour']].head(10)\n",
        "  #Инфо о корявости данных:\n",
        "  if 1== 1:\n",
        "    print('0 Всего:',df[df['meter']==0].shape, 'Откинуть:', df[(df['meter']==0) & (df['IS_BAD_PRCNT']>0.45)].shape)\n",
        "    print('1 Всего:',df[df['meter']==1].shape, 'Откинуть:', df[(df['meter']==1) & (df['IS_BAD_PRCNT']>0.75)].shape)\n",
        "    print('2 Всего:',df[df['meter']==2].shape, 'Откинуть:', df[(df['meter']==2) & (df['IS_BAD_PRCNT']>0.75)].shape)\n",
        "    print('3 Всего:',df[df['meter']==3].shape, 'Откинуть:', df[(df['meter']==3) & (df['IS_BAD_PRCNT']>0.75)].shape)\n",
        "    # #Вывести кол-во пустот по полям. Затем заполнить из средним значением по полю\n",
        "    #   for col in df.columns:\n",
        "    #     print(col)\n",
        "    #     for met in df['meter'].unique():\n",
        "    #       if np.sum(df[col].isnull()) > 0:\n",
        "    #         print(met)\n",
        "    #         print(np.sum(df[col].isnull()))\n",
        "\n",
        "    #         df_col = df.groupby(by=['building_id','meter'], as_index = False)[col].mean()\n",
        "    #         df_col.rename({col: \"tmp\"}, axis='columns', inplace=True)\n",
        "    #         df = df.merge(df_col, left_on = ['building_id','meter'], right_on = ['building_id','meter'], how = \"left\")\n",
        "    #         df[col].fillna( df_col['tmp'], inplace = True)\n",
        "    #         df.drop(columns = ['tmp'],inplace = True)\n",
        "    #         del df_col\n",
        "\n",
        "    #         df_col = df.groupby(by=['meter'], as_index = False)[col].mean()\n",
        "    #         df_col.rename({col: \"tmp\"}, axis='columns', inplace=True)\n",
        "    #         df = df.merge(df_col, left_on = ['meter'], right_on = ['meter'], how = \"left\")\n",
        "    #         df[col].fillna( df_col['tmp'], inplace = True)\n",
        "    #         df.drop(columns = ['tmp'],inplace = True)\n",
        "    #         del df_col\n",
        "\n",
        "    #         df[col].fillna( df[col].mean(), inplace = True)\n",
        "\n",
        "  print(len(df[df['IS_BAD_PRCNT']<0.45]), len(df))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-616cbc0d2c67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'0 Всего:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'meter'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Откинуть:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'meter'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'IS_BAD_PRCNT'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0.45\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'1 Всего:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'meter'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Откинуть:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'meter'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'IS_BAD_PRCNT'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0.75\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'2 Всего:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'meter'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Откинуть:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'meter'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'IS_BAD_PRCNT'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0.75\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'3 Всего:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'meter'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Откинуть:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'meter'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'IS_BAD_PRCNT'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0.75\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WwbRnvu0Vfb",
        "colab_type": "text"
      },
      "source": [
        "**-- -- -- -- -- -- -- -- --РАСЧЁТ НЕЙРОНОК -- -- -- -- -- -- -- -- --**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aup6pDdkDoZZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#0: electricity, 1: chilledwater, 2: steam, 3: hotwater\n",
        "# РАСЧЁТ НЕЙРОНОК:\n",
        "  reg = 0.00001\n",
        "  batch_size = 2048\n",
        "  epochs = 12\n",
        "  meter = 0\n",
        "\n",
        "  earlyStopping = EarlyStopping(monitor='loss', patience=100, verbose=1, mode='min')\n",
        "  reduce_lr_loss = ReduceLROnPlateau(monitor='loss', factor=0.3, patience=7, verbose=1, min_delta=1e-3, mode='min')\n",
        "  model_checkpoint = ModelCheckpoint(monitor='loss', save_best_only=True, filepath = DIR + 'best_nn_' + str(meter) + '.model', save_weights_only = False, verbose=0, mode='min')\n",
        "\n",
        "  init = TruncatedNormal(mean=0.0, stddev=0.05, seed=159)\n",
        "  bias = Constant(value = 1e-3)\n",
        "  \n",
        "  if 0==0:\n",
        "    meter = 0\n",
        "    opt = Adam(lr = 0.0009)\n",
        "    bias = Constant(value = 0.1)\n",
        "\n",
        "    nn_0 = Sequential()\n",
        "    nn_0.add(Dense(60, input_shape = df[In_Columns].shape[1:], activation = 'tanh', kernel_regularizer=l2(reg), kernel_initializer = 'normal'))\n",
        "    nn_0.add(Dense(60, activation = 'tanh',  kernel_initializer = 'normal'))\n",
        "    nn_0.add(Dense(60, activation = 'tanh',  kernel_initializer = 'normal', kernel_regularizer=l1(reg)))\n",
        "    nn_0.add(Dense(60, activation = 'tanh',  kernel_initializer = 'normal'))\n",
        "    nn_0.add(Dense(1, activation = 'relu', kernel_initializer = 'normal'))\n",
        "\n",
        "    nn_0.compile(optimizer = opt, loss = RMSLE, metrics=[ MAE_, RMSLE, VAL_, 'mse', MAPE_ ])\n",
        "    \n",
        "    val = df[(df['meter']==meter) & (df['day']%6==0)]\n",
        "    hist = nn_0.fit( df[(df['meter']==meter) & (df['IS_BAD_PRCNT']<0.45)][In_Columns], df[(df['meter']==meter) & (df['IS_BAD_PRCNT']<0.45)][Out_Columns], batch_size = batch_size, verbose = 0\n",
        "                    , epochs = epochs, shuffle = True, callbacks=[MyCustomCallback(epochs, 1), earlyStopping, reduce_lr_loss,model_checkpoint]\n",
        "                    , validation_data=(val[In_Columns], val[Out_Columns])\n",
        "                    ) \n",
        "    nn_0.save(DIR_SAVE + str(meter) + 'HANDLY_SAVED3.MODEL')\n",
        "    gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3l71K063-sz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Дообучение!\n",
        "  meter = 0\n",
        "  nn_tmp = keras.models.load_model (DIR_SAVE + str(meter) + 'HANDLY_SAVED3best.MODEL')\n",
        "  \n",
        "  earlyStopping = EarlyStopping(monitor='loss', patience=100, verbose=1, mode='min')\n",
        "  reduce_lr_loss = ReduceLROnPlateau(monitor='loss', factor=0.3, patience=7, verbose=1, min_delta=1e-3, mode='min')\n",
        "  model_checkpoint = ModelCheckpoint(monitor='loss', save_best_only=True, filepath = DIR + 'best_nn_' + str(meter) + '.model', save_weights_only = False, verbose=0, mode='min')\n",
        "\n",
        "  for lr in [0.007]:\n",
        "    opt = Adam(lr = lr)\n",
        "    epochs = 20\n",
        "    batch_size = 2048\n",
        "    \n",
        "    val = df[ ( df['meter'] == meter ) & ( df['day']%6 == 0 ) & ( df['IS_BAD_PRCNT'] < 0.25 ) ]\n",
        "    tar = df[ ( df['meter'] == meter ) & ( df['day']%6 != 0 ) & ( df['IS_BAD_PRCNT'] < 0.25 ) ]\n",
        "\n",
        "    print('*'*9, lr, '*'*33)\n",
        "    nn_tmp.compile(optimizer = opt, loss = MSLE, metrics=[ MAE_, RMSLE, VAL_, 'mse', MAPE_ ])\n",
        "    hist = nn_tmp.fit( tar[In_Columns], tar[Out_Columns], batch_size = batch_size, verbose = 0\n",
        "                    , epochs = epochs, shuffle = True, callbacks=[ MyCustomCallback(epochs, 1), earlyStopping, reduce_lr_loss]\n",
        "                    , validation_data=(val[In_Columns], val[Out_Columns])\n",
        "                  )\n",
        "    \n",
        "    nn_tmp.save(DIR_SAVE + str(meter) + 'HANDLY_SAVED3.MODEL')\n",
        "    del val, tar\n",
        "    gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YIKx_MLrPz1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#История ошибок:\n",
        "    # 0 - 0.0009|  TST_loss: 0.3072 TST_MAE_: 0.1830 TST_RMSLE: 0.2885 TST_VAL_: 0.9286 TST_mean_squared_error: 27367.7978 TST_MAPE_: 0.2095 ///  TRN_loss: 0.3087 TRN_MAE_: 0.1822 TRN_RMSLE: 0.2900 TRN_VAL_: 0.9145 TRN_mean_squared_error: 28093.1744 TRN_MAPE_: 0.2099\n",
        "    #Ошибка 0:  1.0561841191435806 Ошибка 0 (VAL):  1.0494709359899506 Ошибка 0 (VAL_чист):  0.3156408787681845 Ошибка 0 (VAL_чист):  0.2912135296204619\n",
        "    #Ошибка 0:  1.089517078219136  Ошибка 0 (VAL):  1.0830665788767133 Ошибка 0 (VAL_чист):  0.32307141312090654 Ошибка 0 (VAL_чист):  0.2984998363948374\n",
        "      #Ошибка 0:  1.1066134245452997 Ошибка 0 (VAL):  1.100076285523506  Ошибка 0 (VAL_чист):  0.3034311145371631  Ошибка 0 (VAL_чист):  0.2775469766783069\n",
        "      #Ошибка 0:  1.1030193587492334 Ошибка 0 (VAL):  1.0966634328629619 Ошибка 0 (VAL_чист):  0.31766628931864216 Ошибка 0 (VAL_чист):  0.2947707690483286\n",
        "      #Ошибка 0:  1.11466815037453   Ошибка 0 (VAL):  1.1077580860952245 Ошибка 0 (VAL_чист):  0.36128705026829394 Ошибка 0 (VAL_чист):  0.3413465001124272\n",
        "      #Ошибка 0:  1.1159494605817608 Ошибка 0 (VAL):  1.108724065391442  Ошибка 0 (VAL_чист):  0.41233170157550914 Ошибка 0 (VAL_чист):  0.39348967701947696\n",
        "      #Ошибка 0:  1.1161679797276878 Ошибка 0 (VAL):  1.1092097596156938 Ошибка 0 (VAL_чист):  0.44160974266951963 Ошибка 0 (VAL_чист):  0.42010303885086286\n",
        "\n",
        "    # 1 - 0.0005|  TST_loss: 0.8377 TST_MAE_: 0.3466 TST_RMSLE: 0.8257 TST_VAL_: 0.8746 TST_mean_squared_error: 73145611.7727 TST_MAPE_: 0.7010 ///  TRN_loss: 0.7481 TRN_MAE_: 0.4902 TRN_RMSLE: 0.8462 TRN_VAL_: 0.6074 TRN_mean_squared_error: 72128872.1765 TRN_MAPE_: 0.6687\n",
        "      # 1 - 0.0001|TST_loss: 0.7542 TST_MAE_: 0.3283 TST_RMSLE: 0.7290 TST_VAL_: 0.8683 TST_mean_squared_error: 76403735.2854 TST_MAPE_: 0.6021 ///  TRN_loss: 0.7802 TRN_MAE_: 0.4676 TRN_RMSLE: 0.7550 TRN_VAL_: 0.6303 TRN_mean_squared_error: 73674603.6638 TRN_MAPE_: 0.5863\n",
        "    #Ошибка 1:  1.3667812429174853 Ошибка 1 (VAL):  1.4029945499659757 Ошибка 1 (VAL_чист):  0.7281895570502563 Ошибка 1 (VAL_чист):  0.6149901419154421\n",
        "    #Ошибка 1:  1.4674246744239359 Ошибка 1 (VAL):  1.4998371692364791 Ошибка 1 (VAL_чист):  0.7936248109822508 Ошибка 1 (VAL_чист):  0.6763456453516548\n",
        "      #Ошибка 1:  1.4093558221005378 Ошибка 1 (VAL):  1.4441369966619106 Ошибка 1 (VAL_чист):  0.7674733833817231 Ошибка 1 (VAL_чист):  0.6515382783996846\n",
        "      #Ошибка 1:  1.4341247310132184 Ошибка 1 (VAL):  1.470060550523646  Ошибка 1 (VAL_чист):  0.7119020527708861 Ошибка 1 (VAL_чист):  0.5956327249468123\n",
        "      #Ошибка 1:  1.4425109745549276 Ошибка 1 (VAL):  1.4775752439079195 Ошибка 1 (VAL_чист):  0.7288509072605465 Ошибка 1 (VAL_чист):  0.6118551437247776\n",
        "      #Ошибка 1:  1.4794444121249946 Ошибка 1 (VAL):  1.5150122006735316 Ошибка 1 (VAL_чист):  0.756747550880491  Ошибка 1 (VAL_чист):  0.6370399718876337\n",
        "      #Ошибка 1:  1.478101110840682  Ошибка 1 (VAL):  1.511827390230529  Ошибка 1 (VAL_чист):  0.783690921235087  Ошибка 1 (VAL_чист):  0.6632605785239761\n",
        "      #Ошибка 1:  1.4972289288697942 Ошибка 1 (VAL):  1.5308990895435475 Ошибка 1 (VAL_чист):  0.7908108700644174 Ошибка 1 (VAL_чист):  0.6680700428184277\n",
        "      #Ошибка 1:  1.4817989404715222 Ошибка 1 (VAL):  1.5134076940639456 Ошибка 1 (VAL_чист):  0.8309019241778273 Ошибка 1 (VAL_чист):  0.7141481643815152\n",
        "      #Ошибка 1:  2.0022889004617257 Ошибка 1 (VAL):  2.0253074918080394 Ошибка 1 (VAL_чист):  1.2310513863169474 Ошибка 1 (VAL_чист):  0.9879544727674974\n",
        "      #Ошибка 1:  2.6107180409629787 Ошибка 1 (VAL):  2.62604593096904   Ошибка 1 (VAL_чист):  1.9195246386655913 Ошибка 1 (VAL_чист):  1.6554061978310448  \n",
        "\n",
        "    # 2 - 0.001   TST_loss: 0.7344 TST_MAE_: 0.3078 TST_RMSLE: 0.7344 TST_VAL_: 0.8726 TST_mean_squared_error: 58769617031.5805 TST_MAPE_: 0.5561 ///  TRN_loss: 0.8222 TRN_MAE_: 0.3435 TRN_RMSLE: 0.8222 TRN_VAL_: 0.9566 TRN_mean_squared_error: 49363914383.6177 TRN_MAPE_: 0.5457\n",
        "    #Ошибка 2:  1.412089120404965 Ошибка 2 (VAL):  1.4307337011199783 Ошибка 2 (VAL_чист):  0.7681072077180416 Ошибка 2 (VAL_чист):  0.5899942163118871\n",
        "    #Ошибка 2:  1.426513398531468  Ошибка 2 (VAL):  1.4374305117701076 Ошибка 2 (VAL_чист):  0.772188164217135  Ошибка 2 (VAL_чист):  0.5912252674990405\n",
        "    #Ошибка 2:  1.4711884860839508 Ошибка 2 (VAL):  1.4865450169842518 Ошибка 2 (VAL_чист):  0.7729726956881282 Ошибка 2 (VAL_чист):  0.5883201286605256\n",
        "    #Ошибка 2:  1.584895359471045  Ошибка 2 (VAL):  1.595279682390636  Ошибка 2 (VAL_чист):  0.8156651059087789 Ошибка 2 (VAL_чист):  0.6075341541971445\n",
        "      #Ошибка 2:  1.4342707989405115 Ошибка 2 (VAL):  1.445994967988859 Ошибка 2 (VAL_чист):  0.7751574158428917 Ошибка 2 (VAL_чист):  0.5934912395707151\n",
        "      #Ошибка 2:  1.4827505038656164 Ошибка 2 (VAL):  1.485921011505542 Ошибка 2 (VAL_чист):  0.776992332783179  Ошибка 2 (VAL_чист):  0.5982294414393752\n",
        "      #Ошибка 2:  1.5380867615202842 Ошибка 2 (VAL):  1.534869021740785 Ошибка 2 (VAL_чист):  0.8030714183598706 Ошибка 2 (VAL_чист):  0.6100693949499996\n",
        "      #Ошибка 2:  1.544696542956114  Ошибка 2 (VAL):  1.542512084385534 Ошибка 2 (VAL_чист):  0.8014154858977849 Ошибка 2 (VAL_чист):  0.6164432453479144\n",
        "      #Ошибка 2:  1.7437661049074722 Ошибка 2 (VAL):  1.739711067404998 Ошибка 2 (VAL_чист):  0.9019782041199934 Ошибка 2 (VAL_чист):  0.5395988401269427\n",
        "      #Ошибка 2:  1.896885277819035  Ошибка 2 (VAL):  1.886131540810365 Ошибка 2 (VAL_чист):  0.9932058892117468 Ошибка 2 (VAL_чист):  0.5522634244728574\n",
        "      #Ошибка 2:  2.0635301300600255 Ошибка 2 (VAL):  2.053288059566308 Ошибка 2 (VAL_чист):  1.110914319240778  Ошибка 2 (VAL_чист):  0.6531255552895722\n",
        "\n",
        "    #3 - 0.001  TST_loss: 1.0529 TST_MAE_: 0.4362 TST_RMSLE: 1.0238 TST_VAL_: 0.8601 TST_mean_squared_error: 9330985.8708 TST_MAPE_: 0.7937 ///  TRN_loss: 1.1771 TRN_MAE_: 0.4945 TRN_RMSLE: 1.1481 TRN_VAL_: 0.6708 TRN_mean_squared_error: 8529478.6350 TRN_MAPE_: 0.7768\n",
        "    #\n",
        "    #Ошибка 3:  1.377944923928185  Ошибка 3 (VAL):  1.4566577965681673 Ошибка 3 (VAL_чист):  1.0939884892538    Ошибка 3 (VAL_чист):  0.7449018059731893\n",
        "    #Ошибка 3:  1.399828310279418  Ошибка 3 (VAL):  1.4663188962845461 Ошибка 3 (VAL_чист):  1.0923668037824816 Ошибка 3 (VAL_чист):  0.7516940691334648\n",
        "    #Ошибка 3:  1.5811641937262615 Ошибка 3 (VAL):  1.6275882770258792 Ошибка 3 (VAL_чист):  1.1791615642131834 Ошибка 3 (VAL_чист):  0.8287557439810707\n",
        "      #Ошибка 3:  1.4481746307415786 Ошибка 3 (VAL):  1.5064615469019023 Ошибка 3 (VAL_чист):  1.0977130637106953 Ошибка 3 (VAL_чист):  0.7436043184254891\n",
        "      #Ошибка 3:  1.705222807620306 Ошибка 3 (VAL):  1.7366032113308998 Ошибка 3 (VAL_чист):  1.0745064725069604 Ошибка 3 (VAL_чист):  0.7306249462611814\n",
        "      #Ошибка 3:  1.8077285134043073 Ошибка 3 (VAL):  1.8127781024652065 Ошибка 3 (VAL_чист):  1.110416279220095 Ошибка 3 (VAL_чист):  0.7830760480518036\n",
        "      #Ошибка 3:  2.4125767152544086 Ошибка 3 (VAL):  2.4083597850289715 Ошибка 3 (VAL_чист):  1.4406713860219067 Ошибка 3 (VAL_чист):  0.6769461395256884"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKq7llhGn682",
        "colab_type": "code",
        "outputId": "b017d6dc-657b-4732-f34d-a3d002eddc98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#Предсказание из 4х значений = 0:\n",
        "  meter = 1\n",
        "  nn_tmp = keras.models.load_model (DIR_SAVE + str(meter) + 'HANDLY_SAVED3.MODEL')\n",
        "  \n",
        "  gc.collect()\n",
        "  col_name_tmp = 'NN_PRED_'+str(meter) \n",
        "  df['NN_PRED'] = 0.0000\n",
        "  df[col_name_tmp] = nn_tmp.predict(df[In_Columns], batch_size = 400000) \n",
        "  df['NN_PRED'] = np.where(df['meter'] == meter, df[col_name_tmp], df['NN_PRED'])\n",
        "  df.drop(columns = [col_name_tmp], inplace = True) #, 'NN_PRED_1', 'NN_PRED_2', 'NN_PRED_3'\n",
        "  #df.drop(columns = ['Value_x', 'Value_y'])\n",
        "  gc.collect()\n",
        "\n",
        "  df['NN_ERR'] = np.abs(df['NN_PRED']-df['meter_reading'])\n",
        "  df['k_NN_ERR'] = (df['NN_PRED']+0.33)/(df['meter_reading']+0.33)\n",
        "\n",
        "  #print( np.sqrt( np.mean( np.power(np.log(df['meter_reading']+1) - np.log(df['NN_PRED']+1),2.00000)))     )\n",
        "  print('Ошибка ' + str(meter) + ': '  , np.sqrt( np.mean( np.power(np.log(df[df['meter']==meter]['meter_reading']+1) - np.log(df[df['meter']==meter]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка ' + str(meter) + ' (VAL): ', np.sqrt( np.mean( np.power(np.log(df[(df['meter']==meter) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[(df['meter']==meter) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка ' + str(meter) + ' (VAL_чист): ', np.sqrt( np.mean( np.power(np.log(df[ (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==meter) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[ (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==meter) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка ' + str(meter) + ' (VAL_чист): ', np.sqrt( np.mean( np.power(np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==meter) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==meter) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        )\n",
        "  gc.collect()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ошибка 1:  1.3756467607519423 Ошибка 1 (VAL):  1.4121384639175951 Ошибка 1 (VAL_чист):  0.726048282888039 Ошибка 1 (VAL_чист):  0.6114338537265513\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mf8-ceMw8N1q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if 1==1:\n",
        "  reg = 0.00001\n",
        "  meter = 1\n",
        "  epochs = 30\n",
        "  batch_size = 2048\n",
        "  opt = Adam(lr = 0.002)\n",
        "  bias = Constant(value = 1)\n",
        "\n",
        "  earlyStopping = EarlyStopping(monitor='loss', patience=100, verbose=1, mode='min')\n",
        "  reduce_lr_loss = ReduceLROnPlateau(monitor='loss', factor=0.3, patience=9, verbose=1, min_delta=1e-3, mode='min')\n",
        "  model_checkpoint = ModelCheckpoint(monitor='loss', save_best_only=True, filepath = DIR + 'best_nn_' + str(meter) + '.model', save_weights_only = False, verbose=0, mode='min')\n",
        "\n",
        "  nn_1 = Sequential()\n",
        "  nn_1.add(Dense(60, input_shape = df[In_Columns].shape[1:], activation = 'tanh', kernel_regularizer=l2(reg), kernel_initializer = 'normal', bias_initializer=bias))\n",
        "  nn_1.add(Dense(60, activation = 'tanh',  kernel_initializer = 'normal', bias_initializer=bias))\n",
        "  nn_1.add(Dense(60, activation = 'tanh',  kernel_initializer = 'normal', bias_initializer=bias, kernel_regularizer=l1(reg)))\n",
        "  nn_1.add(Dense(60, activation = 'tanh',  kernel_initializer = 'normal', bias_initializer=bias))\n",
        "  nn_1.add(Dense(1, activation = 'relu', kernel_initializer = 'normal', bias_initializer=bias))\n",
        "\n",
        "  nn_1.compile(optimizer = opt, loss = mse, metrics=[ MAE_, RMSLE, VAL_, 'mse', MAPE_ ])\n",
        "  \n",
        "  val = df[ ( df['meter'] == meter ) & ( df['day']%6 == 0 ) & ( df['IS_BAD_PRCNT'] < 0.45 ) ]\n",
        "  tar = df[ ( df['meter'] == meter ) & ( df['day']%6 != 0 ) & ( df['IS_BAD_PRCNT'] < 0.45 ) ]\n",
        "\n",
        "  hist = nn_1.fit( tar[In_Columns], tar[Out_Columns]\n",
        "                  , batch_size = batch_size\n",
        "                  , verbose = 0\n",
        "                  , epochs = epochs, shuffle = True\n",
        "                  , callbacks=[MyCustomCallback(epochs, 1), earlyStopping, reduce_lr_loss,model_checkpoint]\n",
        "                  , validation_data=(val[In_Columns], val[Out_Columns])\n",
        "                  ) \n",
        "  nn_1.save(DIR_SAVE + str(meter) + 'HANDLY_SAVED3.MODEL')\n",
        "  gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7EreUBaUoeP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nn_tmp.save(DIR_SAVE + str(meter) + 'HANDLY_SAVED3best.MODEL')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2H75zE193qOf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Дообучение!\n",
        "  meter = 1\n",
        "  nn_tmp = keras.models.load_model (DIR_SAVE + str(meter) + 'HANDLY_SAVED3best.MODEL')\n",
        "\n",
        "  earlyStopping = EarlyStopping(monitor='loss', patience=100, verbose=1, mode='min')\n",
        "  reduce_lr_loss = ReduceLROnPlateau(monitor='loss', factor=0.3, patience=9, verbose=1, min_delta=2e-4, mode='min')\n",
        "  model_checkpoint = ModelCheckpoint(monitor='loss', save_best_only=True, filepath = DIR + 'best_nn_' + str(meter) + '.model', save_weights_only = False, verbose=0, mode='min')\n",
        "\n",
        "  for lr in [0.0005]:\n",
        "    opt = Adam(lr = lr)\n",
        "    epochs = 30\n",
        "    batch_size = 1024\n",
        "    \n",
        "    val = df[ ( df['meter'] == meter ) & ( df['day']%6 == 0 ) & ( df['IS_BAD_PRCNT'] < 0.75 ) ]\n",
        "    tar = df[ ( df['meter'] == meter ) & ( df['day']%6 != 0 ) & ( df['IS_BAD_PRCNT'] < 0.75 ) ]\n",
        "\n",
        "    print('*'*23, lr, '*'*33, len(tar), len(val))\n",
        "    nn_tmp.compile(optimizer = opt, loss = \n",
        "                   MSLE, metrics=[ MAE_, RMSLE, VAL_, 'mse', MAPE_ ])\n",
        "    hist = nn_tmp.fit( tar[In_Columns], tar[Out_Columns], batch_size = batch_size, verbose = 0\n",
        "                    , epochs = epochs, shuffle = True, callbacks=[ MyCustomCallback(epochs, 1), earlyStopping, reduce_lr_loss]\n",
        "                    , validation_data=(val[In_Columns], val[Out_Columns])\n",
        "                  )\n",
        "    \n",
        "    nn_tmp.save(DIR_SAVE + str(meter) + 'HANDLY_SAVED3.MODEL')\n",
        "    del val, tar\n",
        "    gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHKu4TMG8ROI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if 2==2:\n",
        "  reg = 0.00001\n",
        "  meter = 2\n",
        "  epochs = 15\n",
        "  batch_size = 200\n",
        "  opt = Adam(lr = 0.003)\n",
        "  bias = Constant(value = 1)\n",
        "\n",
        "  earlyStopping = EarlyStopping(monitor='loss', patience=100, verbose=1, mode='min')\n",
        "  reduce_lr_loss = ReduceLROnPlateau(monitor='loss', factor=0.3, patience=9, verbose=1, min_delta=1e-3, mode='min')\n",
        "  model_checkpoint = ModelCheckpoint(monitor='loss', save_best_only=True, filepath = DIR + 'best_nn_' + str(meter) + '.model', save_weights_only = False, verbose=0, mode='min')\n",
        "\n",
        "  nn_1 = Sequential()\n",
        "  nn_1.add(Dense(99, input_shape = df[In_Columns].shape[1:], activation = 'relu', kernel_initializer = 'normal', bias_initializer=bias))\n",
        "  nn_1.add(Dense(99, activation = 'relu',  kernel_initializer = 'normal', bias_initializer=bias))\n",
        "  nn_1.add(Dense(99, activation = 'relu',  kernel_initializer = 'normal', bias_initializer=bias))\n",
        "  nn_1.add(Dense(99, activation = 'relu',  kernel_initializer = 'normal', bias_initializer=bias))\n",
        "  nn_1.add(Dense(1, activation = 'relu', kernel_initializer = 'normal', bias_initializer=bias))\n",
        "\n",
        "  nn_1.compile(optimizer = opt, loss = MALE, metrics=[ MAE_, RMSLE, VAL_, 'mse', MAPE_ ])\n",
        "  \n",
        "  val = df[ ( df['meter'] == meter ) & ( df['day']%6 == 0 ) & ( df['IS_BAD_PRCNT'] < 0.15 ) ]\n",
        "  tar = df[ ( df['meter'] == meter ) & ( df['day']%6 != 0 ) & ( df['IS_BAD_PRCNT'] < 0.15 ) & (df['k_fact_med_hour']<50) ]\n",
        "\n",
        "  hist = nn_1.fit( tar[In_Columns], tar[Out_Columns]\n",
        "                  , batch_size = batch_size\n",
        "                  , verbose = 0\n",
        "                  , epochs = epochs, shuffle = True\n",
        "                  , callbacks=[MyCustomCallback(epochs, 1), earlyStopping, reduce_lr_loss,model_checkpoint]\n",
        "                  , validation_data=(val[In_Columns], val[Out_Columns])\n",
        "                  ) \n",
        "  nn_1.save(DIR_SAVE + str(meter) + 'HANDLY_SAVED3.MODEL')\n",
        "  gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdad7yTx8Uri",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if 3==3:\n",
        "  reg = 0.00001\n",
        "  meter = 3\n",
        "  epochs = 20\n",
        "  batch_size = 200\n",
        "  opt = Adam(lr = 0.003)\n",
        "  bias = Constant(value = 1)\n",
        "\n",
        "  earlyStopping = EarlyStopping(monitor='loss', patience=100, verbose=1, mode='min')\n",
        "  reduce_lr_loss = ReduceLROnPlateau(monitor='loss', factor=0.3, patience=9, verbose=1, min_delta=1e-3, mode='min')\n",
        "  model_checkpoint = ModelCheckpoint(monitor='loss', save_best_only=True, filepath = DIR + 'best_nn_' + str(meter) + '.model', save_weights_only = False, verbose=0, mode='min')\n",
        "\n",
        "  nn_3 = Sequential()\n",
        "  nn_3.add(Dense(99, input_shape = df[In_Columns].shape[1:], activation = 'relu', kernel_regularizer=l2(reg) , kernel_initializer = 'normal', bias_initializer=bias))\n",
        "  nn_3.add(Dense(99, activation = 'relu',  kernel_initializer = 'normal', bias_initializer=bias))\n",
        "  nn_3.add(Dense(99, activation = 'relu',  kernel_initializer = 'normal', bias_initializer=bias, kernel_regularizer=l1(reg)))\n",
        "  nn_3.add(Dense(99, activation = 'relu',  kernel_initializer = 'normal', bias_initializer=bias))\n",
        "  nn_3.add(Dense(1, activation = 'relu', kernel_initializer = 'normal', bias_initializer=bias))\n",
        "\n",
        "  nn_3.compile(optimizer = opt, loss = MALE, metrics=[ MAE_, RMSLE, VAL_, 'mse', MAPE_ ])\n",
        "  \n",
        "  val = df[ ( df['meter'] == meter ) & ( df['day']%6 == 0 ) & ( df['IS_BAD_PRCNT'] < 0.15 ) ]\n",
        "  tar = df[ ( df['meter'] == meter ) & ( df['day']%6 != 0 ) & ( df['IS_BAD_PRCNT'] < 0.15 ) & (df['k_fact_med_hour']<50) ]\n",
        "\n",
        "  hist = nn_3.fit( tar[In_Columns], tar[Out_Columns]\n",
        "                  , batch_size = batch_size\n",
        "                  , verbose = 0\n",
        "                  , epochs = epochs, shuffle = True\n",
        "                  , callbacks=[MyCustomCallback(epochs, 1), earlyStopping, reduce_lr_loss,model_checkpoint]\n",
        "                  , validation_data=(val[In_Columns], val[Out_Columns])\n",
        "                  ) \n",
        "  nn_3.save(DIR_SAVE + str(meter) + 'HANDLY_SAVED3.MODEL')\n",
        "  gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQcBV7uNxXWG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df[(df['meter']==met) & (df['building_id']==building_id)].head(100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3GoK9la567l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#ГРАФИК ПЛАН-ФАКТ\n",
        "  plt.figure(figsize=(20,9))\n",
        "  df['log1p_fact'] = np.log(1+df['meter_reading'])\n",
        "  df['log1p_plan'] = np.log(1+df['NN_PRED'])\n",
        "  met = 3\n",
        "  building_id = 106\n",
        "  plt.plot( df[(df['meter']==met) & (df['building_id']==building_id)]['timestamp']\n",
        "          , df[(df['meter']==met) & (df['building_id']==building_id)]['log1p_fact'] , 'ro', markersize = 1   , color = 'blue' ,label = 'Факт', alpha = 0.3)\n",
        "  plt.plot( df[(df['meter']==met) & (df['building_id']==building_id)]['timestamp']\n",
        "           , df[(df['meter']==met) & (df['building_id']==building_id)]['log1p_plan'] , 'ro', markersize = 1  , color = 'green',label = 'План', alpha = 0.3)\n",
        "  plt.plot( df[(df['meter']==met) & (df['building_id']==building_id)]['timestamp']\n",
        "           , df[(df['meter']==met) & (df['building_id']==building_id)]['is_equal_prev'] , 'ro', markersize = 1  , color = 'black',label = 'Выкинуто', alpha = 0.3)\n",
        "  plt.plot( df[(df['meter']==met) & (df['building_id']==building_id)]['timestamp']\n",
        "           , df[(df['meter']==met) & (df['building_id']==building_id)]['IS_BAD_PRCNT'] , 'ro', markersize = 1  , color = 'brown',label = 'Выкинуто', alpha = 0.3)\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H75KbUGtAdOG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#nn_3.save(DIR + str(meter) + 'HANDLY_SAVED.MODEL')\n",
        "# keras.initializers.RandomUniform(minval=-0.05, maxval=0.05, seed=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYdF9Mh00i4a",
        "colab_type": "text"
      },
      "source": [
        "-- -- -- -- -- -- -- -- -- Предсказание -- -- -- -- -- -- -- -- --"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQ7txJwCTi6Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        },
        "outputId": "88622c8b-82c6-4b98-c4d9-fdff4c8e953d"
      },
      "source": [
        "#Предсказание из 4х значений:\n",
        "  nn_0 = keras.models.load_model (DIR_SAVE + '0HANDLY_SAVED3best.MODEL')\n",
        "  nn_1 = keras.models.load_model (DIR_SAVE + '1HANDLY_SAVED3best.MODEL')\n",
        "  nn_2 = keras.models.load_model (DIR_SAVE + '2HANDLY_SAVED3best.MODEL')\n",
        "  nn_3 = keras.models.load_model (DIR_SAVE + '3HANDLY_SAVED3best.MODEL')\n",
        "\n",
        "  # score = model.evaluate(X, Y, verbose=0)\n",
        "  # print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))\n",
        "  gc.collect()\n",
        "\n",
        "  df['NN_PRED'] = 0\n",
        "  df['NN_PRED_0'] = nn_0.predict(df[In_Columns], batch_size = 10000) \n",
        "  df['NN_PRED_1'] = nn_1.predict(df[In_Columns], batch_size = 10000) \n",
        "  df['NN_PRED_2'] = nn_2.predict(df[In_Columns], batch_size = 10000) \n",
        "  df['NN_PRED_3'] = nn_3.predict(df[In_Columns], batch_size = 10000) \n",
        "  df['NN_PRED'] = np.where(df['meter'] == 0, df['NN_PRED_0'], df['NN_PRED'])\n",
        "  df['NN_PRED'] = np.where(df['meter'] == 1, df['NN_PRED_1'], df['NN_PRED'])\n",
        "  df['NN_PRED'] = np.where(df['meter'] == 2, df['NN_PRED_2'], df['NN_PRED'])\n",
        "  df['NN_PRED'] = np.where(df['meter'] == 3, df['NN_PRED_3'], df['NN_PRED'])\n",
        "  df.drop(columns = ['NN_PRED_0', 'NN_PRED_1', 'NN_PRED_2', 'NN_PRED_3'], inplace = True)\n",
        "  #df.drop(columns = ['Value_x', 'Value_y'])\n",
        "  gc.collect()\n",
        "\n",
        "  df['NN_ERR'] = np.abs(df['NN_PRED']-df['meter_reading'])\n",
        "  df['k_NN_ERR'] = (df['NN_PRED']+0.33)/(df['meter_reading']+0.33)\n",
        "\n",
        "  print( 'Ошибка общая: ', np.sqrt( np.mean( np.power(np.log(df['meter_reading']+1) - np.log(df['NN_PRED']+1),2.00000)))\n",
        "      , 'Ошибка (VAL): ', np.sqrt( np.mean( np.power(np.log(df[(df['day']%6 == 0)]['meter_reading']+1) - np.log(df[(df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка (VAL_чист): ' , np.sqrt( np.mean( np.power(np.log(df[  (df['IS_BAD_PRCNT'] < 0.25) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[(df['IS_BAD_PRCNT'] < 0.25) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка (VAL_чист2): ', np.sqrt( np.mean( np.power(np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "  )\n",
        "  print('Ошибка 0: ', np.sqrt( np.mean( np.power(np.log(df[df['meter']==0]['meter_reading']+1) - np.log(df[df['meter']==0]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка 0 (VAL): ', np.sqrt( np.mean( np.power(np.log(df[(df['meter']==0) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[(df['meter']==0) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка 0 (VAL_чист): ' , np.sqrt( np.mean( np.power(np.log(df[  (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==0) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[ (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==0) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка 0 (VAL_чист2): ', np.sqrt( np.mean( np.power(np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==0) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==0) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "  )\n",
        "  print('Ошибка 1: ', np.sqrt( np.mean( np.power(np.log(df[df['meter']==1]['meter_reading']+1) - np.log(df[df['meter']==1]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка 1 (VAL): ', np.sqrt( np.mean( np.power(np.log(df[(df['meter']==1) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[(df['meter']==1) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка 1 (VAL_чист): ' , np.sqrt( np.mean( np.power(np.log(df[  (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==1) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[ (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==1) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка 1 (VAL_чист2): ', np.sqrt( np.mean( np.power(np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==1) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==1) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "  )\n",
        "  print('Ошибка 2: ', np.sqrt( np.mean( np.power(np.log(df[df['meter']==2]['meter_reading']+1) - np.log(df[df['meter']==2]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка 2 (VAL): ', np.sqrt( np.mean( np.power(np.log(df[(df['meter']==2) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[(df['meter']==2) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка 2 (VAL_чист): ' , np.sqrt( np.mean( np.power(np.log(df[  (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==2) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[ (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==2) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка 2 (VAL_чист2): ', np.sqrt( np.mean( np.power(np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==2) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==2) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "  )\n",
        "  print('Ошибка 3: ', np.sqrt( np.mean( np.power(np.log(df[df['meter']==3]['meter_reading']+1) - np.log(df[df['meter']==3]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка 3 (VAL): ', np.sqrt( np.mean( np.power(np.log(df[(df['meter']==3) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[(df['meter']==3) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка 3 (VAL_чист): ' , np.sqrt( np.mean( np.power(np.log(df[  (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==3) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[ (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==3) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка 3 (VAL_чист2): ', np.sqrt( np.mean( np.power(np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==3) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==3) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "  )\n",
        "  # print('Ошибка 1: ', np.sqrt( np.mean( np.power(np.log(df[df['meter']==1]['meter_reading']+1) - np.log(df[df['meter']==1]['NN_PRED']+1),2.00000)))        )\n",
        "  # print('Ошибка 2: ', np.sqrt( np.mean( np.power(np.log(df[df['meter']==2]['meter_reading']+1) - np.log(df[df['meter']==2]['NN_PRED']+1),2.00000)))        )\n",
        "  # print('Ошибка 3: ', np.sqrt( np.mean( np.power(np.log(df[df['meter']==3]['meter_reading']+1) - np.log(df[df['meter']==3]['NN_PRED']+1),2.00000)))        )\n",
        "\n",
        "  gc.collect()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4409: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1702: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Ошибка общая:  1.2019422970227465 Ошибка (VAL):  1.2157846256813984 Ошибка (VAL_чист):  0.5428777256494879 Ошибка (VAL_чист2):  0.4439034380986012\n",
            "Ошибка 0:  1.0561841191435806 Ошибка 0 (VAL):  1.0494709359899506 Ошибка 0 (VAL_чист):  0.3156408787681845 Ошибка 0 (VAL_чист2):  0.2912135296204619\n",
            "Ошибка 1:  1.3786985710716286 Ошибка 1 (VAL):  1.4146374427353003 Ошибка 1 (VAL_чист):  0.7336364189822585 Ошибка 1 (VAL_чист2):  0.6205787113997202\n",
            "Ошибка 2:  1.412089120404965 Ошибка 2 (VAL):  1.4307337011199783 Ошибка 2 (VAL_чист):  0.7681072077180416 Ошибка 2 (VAL_чист2):  0.5899942163118871\n",
            "Ошибка 3:  1.377944923928185 Ошибка 3 (VAL):  1.4566577965681673 Ошибка 3 (VAL_чист):  1.0939884892538 Ошибка 3 (VAL_чист2):  0.7449018059731893\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ON0qwgtpSld6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Ошибки:\n",
        "  Ошибка  :  1.2019422970227465 Ошибка (VAL):   1.2157846256813984 Ошибка (VAL_чист):   0.5428777256494879 Ошибка (VAL_чист2)  :  0.4439034380986012\n",
        "  Ошибка 0:  1.0561841191435806 Ошибка 0 (VAL): 1.0494709359899506 Ошибка 0 (VAL_чист): 0.3156408787681845 Ошибка 0 (VAL_чист2):  0.2912135296204619\n",
        "  Ошибка 1:  1.3786985710716286 Ошибка 1 (VAL): 1.4146374427353003 Ошибка 1 (VAL_чист): 0.7336364189822585 Ошибка 1 (VAL_чист2):  0.6205787113997202\n",
        "  Ошибка 2:  1.412089120404965 Ошибка 2 (VAL):  1.4307337011199783 Ошибка 2 (VAL_чист): 0.7681072077180416 Ошибка 2 (VAL_чист2):  0.5899942163118871\n",
        "  Ошибка 3:  1.377944923928185 Ошибка 3 (VAL):  1.4566577965681673 Ошибка 3 (VAL_чист): 1.0939884892538    Ошибка 3 (VAL_чист2):  0.7449018059731893\n",
        "  0\n",
        "  Общая:     1.2940425445438188 Ошибка (VAL):   1.3035619563953205 Ошибка (VAL_чист):   0.6154425269032927 Ошибка (VAL_чист2):    0.5166720488706185\n",
        "  Ошибка 0:  1.1108272200417615 Ошибка 0 (VAL): 1.1039979542354519 Ошибка 0 (VAL_чист): 0.4199684887318391 Ошибка 0 (VAL_чист2):  0.40071672645920714\n",
        "  Ошибка 1:  1.4674246744239359 Ошибка 1 (VAL): 1.4998371692364791 Ошибка 1 (VAL_чист): 0.7936248109822508 Ошибка 1 (VAL_чист2):  0.6763456453516548\n",
        "  Ошибка 2:  1.584895359471045 Ошибка 2 (VAL):  1.595279682390636 Ошибка 2 (VAL_чист):  0.8156651059087789 Ошибка 2 (VAL_чист2):  0.6075341541971445\n",
        "  Ошибка 3:  1.5811641937262615 Ошибка 3 (VAL):  1.6275882770258792 Ошибка 3 (VAL_чист):1.1791615642131834 Ошибка 3 (VAL_чист2):  0.8287557439810707\n",
        "  0\n",
        "  Общая  :   1.2383488513622485 Ошибка (VAL):   1.2497646476956246 Ошибка (VAL_чист):    0.5613541671314798 Ошибка (VAL_чист2):    0.4601055341524471\n",
        "  Ошибка 0:  1.089517078219136 Ошибка 0 (VAL):  1.0830665788767133 Ошибка 0 (VAL_чист):  0.32307141312090654 Ошибка 0 (VAL_чист2): 0.2984998363948374\n",
        "  Ошибка 1:  1.4093559595246432 Ошибка 1 (VAL): 1.4441371298998904 Ошибка 1 (VAL_чист):  0.7674735069465627 Ошибка 1 (VAL_чист2):  0.6515384132612695\n",
        "  Ошибка 2:  1.434270799339943 Ошибка 2 (VAL):  1.4459949706379165 Ошибка 2 (VAL_чист):  0.7751574071879366 Ошибка 2 (VAL_чист2):  0.59349123776128\n",
        "  Ошибка 3:  1.4481746111510552 Ошибка 3 (VAL): 1.5064615354375264 Ошибка 3 (VAL_чист):  1.0977130741767314 Ошибка 3 (VAL_чист2):  0.7436043422326556\n",
        "  0\n",
        "  Общая:     1.288451580726024 Ошибка (VAL):     1.2967080663610595 Ошибка (VAL_чист):    0.5559658155345275 Ошибка (VAL_чист2):   0.45027898146764\n",
        "  Ошибка 0:  1.1135345769523262 Ошибка 0 (VAL):  1.1073602983520954 Ошибка 0 (VAL_чист):  0.30211474219652695 Ошибка 0 (VAL_чист2):0.2760929212947043\n",
        "  Ошибка 1:  1.4447116762681158 Ошибка 1 (VAL):  1.4773486254929924 Ошибка 1 (VAL_чист):  0.778543934083951 Ошибка 1 (VAL_чист2):  0.6485716599103746\n",
        "  Ошибка 2:  1.4827505038656164 Ошибка 2 (VAL):  1.4859210115055426 Ошибка 2 (VAL_чист):  0.776992332783179 Ошибка 2 (VAL_чист2):  0.5982294414393752\n",
        "  Ошибка 3:  1.6852442156559078 Ошибка 3 (VAL):  1.7187446259260037 Ошибка 3 (VAL_чист):  1.0748931586686294 Ошибка 3 (VAL_чист2): 0.726536756006331\n",
        "  0\n",
        "  Общая:     1.3473874674637107 Ошибка (VAL):    1.3483415928656848 Ошибка (VAL_чист):    0.5756767405084868 Ошибка (VAL_чист2):   0.4623615327006715\n",
        "  Ошибка 0:  1.097150680567493 Ошибка 0 (VAL):   1.0891511641164369 Ошибка 0 (VAL_чист):  0.33891800740903766 Ошибка 0 (VAL_чист2):0.3149225188104313\n",
        "  Ошибка 1:  1.5319581086991891 Ошибка 1 (VAL):  1.5591904765901698 Ошибка 1 (VAL_чист):  0.7038461305727779 Ошибка 1 (VAL_чист2): 0.5850605730802025\n",
        "  Ошибка 2:  1.6638633608261502 Ошибка 2 (VAL):  1.6575565750506658 Ошибка 2 (VAL_чист):  0.9184081840472923 Ошибка 2 (VAL_чист2): 0.6847327356541326\n",
        "  Ошибка 3:  1.9625404814033556 Ошибка 3 (VAL):  1.955545484766667 Ошибка 3 (VAL_чист):   1.1170540079900018 Ошибка 3 (VAL_чист2): 0.7521327934769413"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxFd8mjwt7KQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#тмп\n",
        "  pd.set_option('display.max_rows', 500)\n",
        "  pd.set_option('display.max_columns', 500)\n",
        "  pd.set_option('display.width', 100)\n",
        "  warnings.filterwarnings('ignore')\n",
        "  np.set_printoptions (precision = 4, suppress  = True)\n",
        "\n",
        "  df['k_NN_ERR'] = (df['NN_PRED']+0.33)/(df['meter_reading']+0.33)\n",
        "  print(len(df), len(df[(df['k_NN_ERR']<50) & (df['k_NN_ERR']>1/50) & (df['IS_BAD_PRCNT']<0.25)]))\n",
        "  print(df[(df['hour']==14) & (df['meter']==0) & (df['building_id']==1) & (df['IS_BAD_PRCNT']<0.25)][['timestamp','hour','weekday','meter_reading','NN_PRED','NN_ERR','k_NN_ERR']].sort_values('timestamp').head(400))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ti8V0jrzZ1C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df[(df['k_NN_ERR']<50) & (df['k_NN_ERR']>1/50)  & (df['IS_BAD_PRCNT']<0.25)].describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Uz_DyKXziWJ",
        "colab_type": "code",
        "outputId": "ef5493d2-c496-4f5e-e570-a09bb29f9aa2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print( np.sqrt( np.mean( np.power(np.log(df['meter_reading']+1) - np.log(df['NN_PRED']+1),2.00000)))     )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.3473874674637107\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBMy61yg06BW",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "**-- -- -- -- -- -- -- -- --РАСЧЁТ НЕЙРОНОК после очистки -- -- -- -- -- -- -- -- --**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Q9aG2Cg_01Ci",
        "colab": {}
      },
      "source": [
        "#0: electricity, 1: chilledwater, 2: steam, 3: hotwater\n",
        "# РАСЧЁТ НЕЙРОНОК:\n",
        "  reg = 0.00001\n",
        "  batch_size = 2048\n",
        "  epochs = 30\n",
        "  meter = 0\n",
        "\n",
        "  earlyStopping = EarlyStopping(monitor='loss', patience=100, verbose=1, mode='min')\n",
        "  reduce_lr_loss = ReduceLROnPlateau(monitor='loss', factor=0.3, patience=5, verbose=1, min_delta=1e-3, mode='min')\n",
        "  model_checkpoint = ModelCheckpoint(monitor='loss', save_best_only=True, filepath = DIR + 'best_nn_' + str(meter) + '.model', save_weights_only = False, verbose=0, mode='min')\n",
        "\n",
        "  init = TruncatedNormal(mean=0.0, stddev=0.05, seed=159)\n",
        "  bias = Constant(value = 0.1)\n",
        "  \n",
        "  if 0==0:\n",
        "    meter = 0\n",
        "    opt = Adam(lr = 0.001)\n",
        "\n",
        "    nn_0 = Sequential()\n",
        "    nn_0.add(Dense(100, input_shape = df[In_Columns].shape[1:], activation = 'tanh', kernel_initializer = 'normal', kernel_regularizer=l2(reg), bias_initializer=bias))\n",
        "    nn_0.add(Dense(100, activation = 'tanh',  kernel_initializer = 'normal', bias_initializer=bias))\n",
        "    nn_0.add(Dense(100, activation = 'tanh',  kernel_initializer = 'normal', bias_initializer=bias, kernel_regularizer=l1(reg)))\n",
        "    nn_0.add(Dense(100, activation = 'tanh',  kernel_initializer = 'normal', bias_initializer=bias))\n",
        "    nn_0.add(Dense(1, activation = 'relu', kernel_initializer = 'normal'))\n",
        "\n",
        "    nn_0.compile(optimizer = opt, loss = MALE, metrics=[ MAE_, RMSLE, VAL_, 'mse', MAPE_ ])\n",
        "    \n",
        "    val = df[(df['meter'] == meter) & (df['day']%6 == 0) ]# & (df['k_NN_ERR'] < 100) & (df['k_NN_ERR'] > 1/100 & (df['IS_BAD_PRCNT'] < 0.25)]\n",
        "    #val_2 = df[(df['meter'] == meter) & (df['day']%6 == 0) & (df['k_NN_ERR'] < 100) & (df['k_NN_ERR'] > 1/100) & (df['IS_BAD_PRCNT'] < 0.25)]\n",
        "    df_cleared = df[(df['day']%6 != 0) & (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['meter'] == meter) & (df['IS_BAD_PRCNT'] < 0.45)][In_Columns + [Out_Columns]]\n",
        "\n",
        "    hist = nn_0.fit( df_cleared[In_Columns], df_cleared[Out_Columns], batch_size = batch_size, verbose = 0\n",
        "                    , epochs = epochs, shuffle = True, callbacks=[MyCustomCallback(epochs, 1), earlyStopping, reduce_lr_loss,model_checkpoint]\n",
        "                    , validation_data=(val[In_Columns], val[Out_Columns])\n",
        "                    ) \n",
        "    nn_0.save(DIR_SAVE + str(meter) + 'HANDLY_SAVED_3.MODEL')\n",
        "    gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "f9h2QsKV01Cn",
        "colab": {}
      },
      "source": [
        "for lr in [0.001]:\n",
        "  opt = Adam(lr = lr)\n",
        "  epochs = 20\n",
        "  batch_size = 2048\n",
        "  meter = 0\n",
        "  nn_0 = keras.models.load_model (DIR + '0HANDLY_SAVED_3best.MODEL')\n",
        "  val = df[(df['meter'] == meter) & (df['day']%6 == 0) & (df['k_NN_ERR'] < 100) & (df['k_NN_ERR'] > 1/100) & (df['IS_BAD_PRCNT'] < 0.25)]\n",
        "  df_cleared = df[(df['k_NN_ERR']<50) & (df['k_NN_ERR']>1/50) & (df['day']%6 != 0) & (df['meter']==meter) & (df['IS_BAD_PRCNT']<0.25)][In_Columns + [Out_Columns]]\n",
        "  print('*'*9, lr, '*'*33)\n",
        "  nn_0.compile(optimizer = opt, loss = RMSLE, metrics=[ MAE_, RMSLE, VAL_, 'mse', MAPE_ ])\n",
        "  hist = nn_0.fit( df_cleared[In_Columns], df_cleared[Out_Columns], batch_size = batch_size, verbose = 0\n",
        "                  , epochs = epochs, shuffle = True, callbacks=[ MyCustomCallback(epochs, 1), earlyStopping, reduce_lr_loss]\n",
        "                  , validation_data=(val[In_Columns], val[Out_Columns])\n",
        "                  ) \n",
        "  nn_0.save(DIR + str(meter) + 'HANDLY_SAVED_3.MODEL')\n",
        "  gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZExPUYLIfQy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#История ошибок:\n",
        "    # 0 - 0.001 |  TST_loss: 0.4634 TST_MAE_: 0.2970 TST_RMSLE: 0.7195 TST_VAL_: 0.9428 TST_mean_squared_error: 95502.1200 TST_MAPE_: 0.5170 ///  TRN_loss: 0.2670 TRN_MAE_: 0.3262 TRN_RMSLE: 0.4111 TRN_VAL_: 0.7641 TRN_mean_squared_error: 60868.2692 TRN_MAPE_: 0.2894\n",
        "    # Ошибка 0:  1.090040142661055  Ошибка 0 (VAL):  1.0821874168451948 Ошибка 0 (VAL_чист):  0.4200194527624282 Ошибка 0 (VAL_чист):  0.3982010565789388\n",
        "    #-Ошибка 0:  1.0561841191435806 Ошибка 0 (VAL):  1.0494709359899506 Ошибка 0 (VAL_чист):  0.3156408787681845 Ошибка 0 (VAL_чист):  0.2912135296204619\n",
        "\n",
        "    # 1 - \n",
        "    #Ошибка 1:  1.4326713621180338 Ошибка 1 (VAL):  1.4735626469840335 Ошибка 1 (VAL_чист):  0.6584706237724794 Ошибка 1 (VAL_чист):  0.521774231818768\n",
        "    #Ошибка 1:  1.434113723728525 Ошибка 1 (VAL):  1.4742295518711512 Ошибка 1 (VAL_чист):  0.665647741234266 Ошибка 1 (VAL_чист):  0.5298978788312768\n",
        "      #Ошибка 1:  1.431368815234858  Ошибка 1 (VAL):  1.4686131222512504 Ошибка 1 (VAL_чист):  0.6759214072760591 Ошибка 1 (VAL_чист):  0.5449250862446658\n",
        "      #Ошибка 1:  1.4691654987946658 Ошибка 1 (VAL):  1.5049969920282047 Ошибка 1 (VAL_чист):  0.6922470701866289 Ошибка 1 (VAL_чист):  0.5644578193999968\n",
        "      #Ошибка 1:  1.485687076453129  Ошибка 1 (VAL):  1.5214040444045644 Ошибка 1 (VAL_чист):  0.6952623800744953 Ошибка 1 (VAL_чист):  0.5632174649208512\n",
        "      #Ошибка 1:  1.4856709523394191 Ошибка 1 (VAL):  1.5205201826214512 Ошибка 1 (VAL_чист):  0.7050914102031174 Ошибка 1 (VAL_чист):  0.5759439648595509\n",
        "      #Ошибка 1:  1.4859038202056085 Ошибка 1 (VAL):  1.519788443345392 Ошибка 1 (VAL_чист):  0.7140834358696859 Ошибка 1 (VAL_чист):  0.5869849079847015\n",
        "    #-Ошибка 1:  1.3667812429174853 Ошибка 1 (VAL):  1.4029945499659757 Ошибка 1 (VAL_чист):  0.7281895570502563 Ошибка 1 (VAL_чист):  0.6149901419154421\n",
        "\n",
        "    # 2 - \n",
        "    #-Ошибка 2:  1.412089120404965 Ошибка 2 (VAL):  1.4307337011199783 Ошибка 2 (VAL_чист):  0.7681072077180416 Ошибка 2 (VAL_чист):  0.5899942163118871\n",
        "\n",
        "\n",
        "    #3 - \n",
        "    #\n",
        "    #-Ошибка 3:  1.377944923928185  Ошибка 3 (VAL):  1.4566577965681673 Ошибка 3 (VAL_чист):  1.0939884892538    Ошибка 3 (VAL_чист):  0.7449018059731893\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SssjG5U44j38",
        "colab_type": "code",
        "outputId": "5f557efc-57b4-4989-8f58-b69dc892cb3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#Предсказание из 4х значений = 0:\n",
        "  meter = 1\n",
        "  nn_tmp = keras.models.load_model (DIR_SAVE + str(meter) + 'HANDLY_SAVED_3.MODEL')\n",
        "  \n",
        "  gc.collect()\n",
        "  col_name_tmp = 'NN_PRED_'+str(meter) \n",
        "  df['NN_PRED'] = 0.0000\n",
        "  df[col_name_tmp] = nn_tmp.predict(df[In_Columns], batch_size = 400000) \n",
        "  df['NN_PRED'] = np.where(df['meter'] == meter, df[col_name_tmp], df['NN_PRED'])\n",
        "  df.drop(columns = [col_name_tmp], inplace = True) #, 'NN_PRED_1', 'NN_PRED_2', 'NN_PRED_3'\n",
        "  #df.drop(columns = ['Value_x', 'Value_y'])\n",
        "  gc.collect()\n",
        "\n",
        "  df['NN_ERR'] = np.abs(df['NN_PRED']-df['meter_reading'])\n",
        "  #df['k_NN_ERR'] = (df['NN_PRED']+0.33)/(df['meter_reading']+0.33)\n",
        "\n",
        "  #print( np.sqrt( np.mean( np.power(np.log(df['meter_reading']+1) - np.log(df['NN_PRED']+1),2.00000)))     )\n",
        "  print('Ошибка ' + str(meter) + ': '  , np.sqrt( np.mean( np.power(np.log(df[df['meter']==meter]['meter_reading']+1) - np.log(df[df['meter']==meter]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка ' + str(meter) + ' (VAL): ', np.sqrt( np.mean( np.power(np.log(df[(df['meter']==meter) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[(df['meter']==meter) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка ' + str(meter) + ' (VAL_чист): ', np.sqrt( np.mean( np.power(np.log(df[ (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==meter) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[ (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==meter) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка ' + str(meter) + ' (VAL_чист): ', np.sqrt( np.mean( np.power(np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==meter) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==meter) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        )\n",
        "  gc.collect()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ошибка 1:  1.4326713621180338 Ошибка 1 (VAL):  1.4735626469840335 Ошибка 1 (VAL_чист):  0.6584706237724794 Ошибка 1 (VAL_чист):  0.521774231818768\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAcxnR-6GGQp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nn_tmp.save(DIR_SAVE + str(meter) + 'HANDLY_SAVED_3best.MODEL')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XhZvGSgQm9T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Дообучение!\n",
        "  meter = 2\n",
        "  nn_tmp = keras.models.load_model (DIR_SAVE + str(meter) + 'HANDLY_SAVED_3.MODEL')\n",
        "  \n",
        "  earlyStopping = EarlyStopping(monitor='loss', patience=100, verbose=1, mode='min')\n",
        "  reduce_lr_loss = ReduceLROnPlateau(monitor='loss', factor=0.5, patience=12, verbose=1, min_delta=1e-4, mode='min')\n",
        "  model_checkpoint = ModelCheckpoint(monitor='loss', save_best_only=True, filepath = DIR + 'best_nn_' + str(meter) + '.model', save_weights_only = False, verbose=0, mode='min')\n",
        "\n",
        "  bad_pcnt = 0.75\n",
        "  k_err = 10\n",
        "\n",
        "  val = df[ ( df['meter'] == meter ) & ( df['day']%6 == 0 ) & ( df['IS_BAD_PRCNT'] < bad_pcnt ) ]\n",
        "  tar = df[ ( df['meter'] == meter ) & ( df['day']%6 != 0 ) & ( df['IS_BAD_PRCNT'] < bad_pcnt ) & (df['k_NN_ERR'] < k_err) & (df['k_NN_ERR'] > 1/k_err) & (df['meter'] == meter) ]\n",
        "\n",
        "  print('Длина трейн ',len(tar), 'длина валидации ',len(val), 'сфильтровано:'\n",
        "  , len(df[ ( df['meter'] == meter ) & ( df['day']%6 != 0 ) & ( df['IS_BAD_PRCNT'] < bad_pcnt ) & (df['k_NN_ERR'] > k_err)  ]) + len(df[ ( df['meter'] == meter ) & ( df['day']%6 != 0 ) & ( df['IS_BAD_PRCNT'] < bad_pcnt ) & (df['k_NN_ERR'] < 1/k_err)  ]))  \n",
        "  \n",
        "  for lr in [0.00004,0.007]:\n",
        "    for los in [MALE,RMSLE,MAE_,mse,MAPE_VAL_RMSLE,RMSLE]:\n",
        "      print(los, lr)\n",
        "      opt = Adam(lr = lr)\n",
        "      epochs = 5\n",
        "      batch_size = 2048\n",
        "      \n",
        "\n",
        "      print('*'*9, lr, '*'*33)\n",
        "      nn_tmp.compile(optimizer = opt, loss = los, metrics=[ MAE_, RMSLE, VAL_, 'mse', MAPE_ ])\n",
        "      hist = nn_tmp.fit( tar[In_Columns], tar[Out_Columns], batch_size = batch_size, verbose = 0\n",
        "                      , epochs = epochs, shuffle = True, callbacks=[ MyCustomCallback(epochs, 1), earlyStopping, reduce_lr_loss]\n",
        "                      , validation_data=(val[In_Columns], val[Out_Columns])\n",
        "                    )\n",
        "      \n",
        "      nn_tmp.save(DIR_SAVE + str(meter) + 'HANDLY_SAVED_3.MODEL')\n",
        "  del val, tar\n",
        "  gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NyBVLwrQvDf",
        "colab_type": "code",
        "outputId": "c6e86fbe-dbce-45ee-8578-8e8e7bb980e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Ошибка 0: ', np.sqrt( np.mean( np.power(np.log(df[df['meter']==0]['meter_reading']+1) - np.log(df[df['meter']==0]['NN_PRED']+1),2.00000)))        \n",
        "  , 'Ошибка 0 (VAL): ', np.sqrt( np.mean( np.power(np.log(df[(df['meter']==0) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[(df['meter']==0) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "  , 'Ошибка 0 (VAL_чист): ', np.sqrt( np.mean( np.power(np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==0) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==0) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        )\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ошибка 0:  1.0967505629134169 Ошибка 0 (VAL):  1.0889958705909204 Ошибка 0 (VAL_чист):  0.29653998158216416\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2V4xV9ON01Co",
        "colab": {}
      },
      "source": [
        "if 1==1:\n",
        "  reg = 0.00001\n",
        "  meter = 1\n",
        "  epochs = 190\n",
        "  batch_size = 1024\n",
        "  opt = Adam(lr = 0.001)\n",
        "  bias = Constant(value = 0.1)\n",
        "\n",
        "  earlyStopping = EarlyStopping(monitor='loss', patience=100, verbose=1, mode='min')\n",
        "  reduce_lr_loss = ReduceLROnPlateau(monitor='loss', factor=0.3, patience=15, verbose=1, min_delta=1e-3, mode='min')\n",
        "  model_checkpoint = ModelCheckpoint(monitor='loss', save_best_only=True, filepath = DIR + 'best_nn_' + str(meter) + '.model', save_weights_only = False, verbose=0, mode='min')\n",
        "\n",
        "  nn_1 = Sequential()\n",
        "  nn_1.add(Dense(100, input_shape = df[In_Columns].shape[1:], activation = 'tanh', kernel_initializer = 'normal', kernel_regularizer=l2(reg), bias_initializer=bias))\n",
        "  nn_1.add(Dense(100, activation = 'tanh',  kernel_initializer = 'normal', bias_initializer=bias))\n",
        "  nn_1.add(Dense(100, activation = 'tanh',  kernel_initializer = 'normal', bias_initializer=bias, kernel_regularizer=l1(reg)))\n",
        "  nn_1.add(Dense(100, activation = 'tanh',  kernel_initializer = 'normal', bias_initializer=bias))\n",
        "  nn_1.add(Dense(1, activation = 'relu', kernel_initializer = 'normal'))\n",
        "\n",
        "  nn_1.compile(optimizer = opt, loss = RMSLE, metrics=[ MAE_, RMSLE, VAL_, 'mse', MAPE_ ])\n",
        "  \n",
        "  \n",
        "  val = df[(df['meter'] == meter) & (df['day']%6 == 0) & (df['k_NN_ERR'] < 100) & (df['k_NN_ERR'] > 1/100) & (df['IS_BAD_PRCNT'] < 0.25)]\n",
        "  df_cleared = df[(df['k_NN_ERR']<50) & (df['k_NN_ERR']>1/50) & (df['day']%6 != 0) & (df['meter']==meter) & (df['IS_BAD_PRCNT']<0.25)][In_Columns + [Out_Columns]]\n",
        "\n",
        "  hist = nn_1.fit( df_cleared[In_Columns], df_cleared[Out_Columns], batch_size = batch_size, verbose = 0\n",
        "                  , epochs = epochs, shuffle = True, callbacks=[MyCustomCallback(epochs, 1), earlyStopping, reduce_lr_loss,model_checkpoint]\n",
        "                  , validation_data=(val[In_Columns], val[Out_Columns])\n",
        "                  ) \n",
        "  nn_1.save(DIR + str(meter) + 'HANDLY_SAVED_3.MODEL')\n",
        "  gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qy1YnwWo01Cq",
        "colab": {}
      },
      "source": [
        "for lr in [0.007]:\n",
        "  opt = Adam(lr = lr)\n",
        "  epochs = 70\n",
        "  meter = 1\n",
        "  batch_size = 720\n",
        "\n",
        "  val = df[(df['meter'] == meter) & (df['day']%6 == 0) & (df['k_NN_ERR'] < 100) & (df['k_NN_ERR'] > 1/100) & (df['IS_BAD_PRCNT'] < 0.45)]\n",
        "  df_cleared = df[(df['k_NN_ERR']<50) & (df['k_NN_ERR']>1/50) & (df['day']%6 != 0) & (df['meter']==meter) & (df['IS_BAD_PRCNT']<0.45)][In_Columns + [Out_Columns]]\n",
        "\n",
        "  print('*'*9, lr, '*'*33)\n",
        "  nn_1.compile(optimizer = opt, loss = RMSLE, metrics=[ MAE_, RMSLE, VAL_, 'mse', MAPE_ ])\n",
        "  hist = nn_1.fit( df_cleared[In_Columns], df_cleared[Out_Columns], batch_size = batch_size, verbose = 0\n",
        "                  , epochs = epochs, shuffle = True, callbacks=[ MyCustomCallback(epochs, 1), earlyStopping, reduce_lr_loss]\n",
        "                  , validation_data=(val[In_Columns], val[Out_Columns])\n",
        "                  ) \n",
        "  nn_1.save(DIR + str(meter) + 'HANDLY_SAVED_3.MODEL')\n",
        "  gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfcTV2-g1JNG",
        "colab_type": "code",
        "outputId": "70c085c9-40ed-4d71-d7b8-530fc0dcad8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "#Предсказание из 4х значений = 0:\n",
        "  #nn_0 = keras.models.load_model (DIR + '0HANDLY_SAVED_3.MODEL')\n",
        "  nn_1 = keras.models.load_model (DIR + '1HANDLY_SAVED_3.MODEL')\n",
        "  #nn_2 = keras.models.load_model (DIR + '2HANDLY_SAVED_3.MODEL')\n",
        "  #nn_3 = keras.models.load_model (DIR + '3HANDLY_SAVED_3.MODEL')\n",
        "\n",
        "  # score = model.evaluate(X, Y, verbose=0)\n",
        "  # print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))\n",
        "  gc.collect()\n",
        "\n",
        "  df['NN_PRED'] = 0\n",
        "  #df['NN_PRED_0'] = nn_0.predict(df[In_Columns], batch_size = 10000) \n",
        "  df['NN_PRED_1'] = nn_1.predict(df[In_Columns], batch_size = 10000) \n",
        "  #df['NN_PRED_2'] = nn_2.predict(df[In_Columns], batch_size = 10000) \n",
        "  #df['NN_PRED_3'] = nn_3.predict(df[In_Columns], batch_size = 10000) \n",
        "  #df['NN_PRED'] = np.where(df['meter'] == 0, df['NN_PRED_0'], df['NN_PRED'])\n",
        "  df['NN_PRED'] = np.where(df['meter'] == 1, df['NN_PRED_1'], df['NN_PRED'])\n",
        "  #df['NN_PRED'] = np.where(df['meter'] == 2, df['NN_PRED_2'], df['NN_PRED'])\n",
        "  #df['NN_PRED'] = np.where(df['meter'] == 3, df['NN_PRED_3'], df['NN_PRED'])\n",
        "  #df.drop(columns = ['NN_PRED_0'], inplace = True) #, 'NN_PRED_1', 'NN_PRED_2', 'NN_PRED_3'\n",
        "  #df.drop(columns = ['Value_x', 'Value_y'])\n",
        "  gc.collect()\n",
        "\n",
        "  df['NN_ERR'] = np.abs(df['NN_PRED']-df['meter_reading'])\n",
        "  print( np.sqrt( np.mean( np.power(np.log(df['meter_reading']+1) - np.log(df['NN_PRED']+1),2.00000)))     )\n",
        "  # print('Ошибка 0: ', np.sqrt( np.mean( np.power(np.log(df[df['meter']==0]['meter_reading']+1) - np.log(df[df['meter']==0]['NN_PRED']+1),2.00000)))        \n",
        "  # , 'Ошибка 0 (VAL): ', np.sqrt( np.mean( np.power(np.log(df[(df['meter']==0) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[(df['meter']==0) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "  # , 'Ошибка 0 (VAL_чист): ', np.sqrt( np.mean( np.power(np.log(df[ (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==0) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[ (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==0) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "  # , 'Ошибка 0 (VAL_чист): ', np.sqrt( np.mean( np.power(np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==0) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==0) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        )\n",
        "  \n",
        "  print('Ошибка 0: ', np.sqrt( np.mean( np.power(np.log(df[df['meter']==1]['meter_reading']+1) - np.log(df[df['meter']==1]['NN_PRED']+1),2.00000)))        \n",
        "  , 'Ошибка 0 (VAL): ', np.sqrt( np.mean( np.power(np.log(df[(df['meter']==1) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[(df['meter']==1) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "  , 'Ошибка 0 (VAL_чист): ', np.sqrt( np.mean( np.power(np.log(df[ (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==1) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[ (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==1) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "  , 'Ошибка 0 (VAL_чист): ', np.sqrt( np.mean( np.power(np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==1) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==1) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        )\n",
        "  \n",
        "  #print('Ошибка 1: ', np.sqrt( np.mean( np.power(np.log(df[df['meter']==1]['meter_reading']+1) - np.log(df[df['meter']==1]['NN_PRED']+1),2.00000)))        )\n",
        "  #print('Ошибка 2: ', np.sqrt( np.mean( np.power(np.log(df[df['meter']==2]['meter_reading']+1) - np.log(df[df['meter']==2]['NN_PRED']+1),2.00000)))        )\n",
        "  #print('Ошибка 3: ', np.sqrt( np.mean( np.power(np.log(df[df['meter']==3]['meter_reading']+1) - np.log(df[df['meter']==3]['NN_PRED']+1),2.00000)))        )\n",
        "  #df['k_NN_ERR'] = (df['NN_PRED']+0.33)/(df['meter_reading']+0.33)\n",
        "  gc.collect()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4.143660029954269\n",
            "Ошибка 0:  1.4462519064009887 Ошибка 0 (VAL):  1.4819992377016542 Ошибка 0 (VAL_чист):  0.628029160200588 Ошибка 0 (VAL_чист):  0.4921451933316616\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RW6m54J1Ixjn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Ошибка 0:  1.4622222874555681 Ошибка 0 (VAL):  1.4974377063554198 Ошибка 0 (VAL_чист):  0.6416758062352609 Ошибка 0 (VAL_чист):  0.5087780382284447\n",
        "Ошибка 0:  1.4513305175601738 Ошибка 0 (VAL):  1.4857607748364132 Ошибка 0 (VAL_чист):  0.6544772099268412 Ошибка 0 (VAL_чист):  0.5241878970208895\n",
        "Ошибка 0:  1.559959814457174 Ошибка 0 (VAL):  1.5880652782130562 Ошибка 0 (VAL_чист):  0.6931055197830647 Ошибка 0 (VAL_чист):  0.5696662087687516\n",
        "Ошибка 1:  1.5319581160458586 Ошибка 1 (VAL):  1.5591904792676097 Ошибка 1 (VAL_чист):  0.7038461338617784 Ошибка 1 (VAL_чист2):  0.5850605758832433"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ur0NQSVo01Cs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        },
        "outputId": "31f9d6fb-d16a-4420-a721-4809b770ebec"
      },
      "source": [
        "if 2==2:\n",
        "  reg = 0.00002\n",
        "  meter = 2\n",
        "  epochs = 30\n",
        "  batch_size = 2400\n",
        "  opt = Adam(lr = 0.003)\n",
        "  bias = Constant(value = 5.7)\n",
        "\n",
        "  earlyStopping = EarlyStopping(monitor='loss', patience=30, verbose=1, mode='min')\n",
        "  reduce_lr_loss = ReduceLROnPlateau(monitor='loss', factor=0.2, patience=12, verbose=1, min_delta=1e-3, mode='min')\n",
        "  model_checkpoint = ModelCheckpoint(monitor='loss', save_best_only=True, filepath = DIR + 'best_nn_' + str(meter) + '.model', save_weights_only = False, verbose=0, mode='min')\n",
        "\n",
        "  nn_2 = Sequential()\n",
        "  nn_2.add(Dense(100, input_shape = df[In_Columns].shape[1:], activation = 'tanh', kernel_initializer = 'uniform', kernel_regularizer=l2(reg), bias_initializer=bias))\n",
        "  nn_2.add(Dense(100, activation = 'tanh',  kernel_initializer = 'uniform', bias_initializer=bias))\n",
        "  nn_2.add(Dense(100, activation = 'tanh',  kernel_initializer = 'uniform', bias_initializer=bias, kernel_regularizer=l1(reg)))\n",
        "  nn_2.add(Dense(100, activation = 'tanh',  kernel_initializer = 'uniform', bias_initializer=bias))\n",
        "  nn_2.add(Dense( 1, activation = 'relu', kernel_initializer = 'normal'))\n",
        "\n",
        "  nn_2.compile(optimizer = opt, loss = MAE_RMSLE, metrics=[ MAE_, RMSLE, VAL_, 'mse', MAPE_ ])\n",
        "  \n",
        "  val = df[(df['meter'] == meter) & (df['day']%6 == 0) & (df['k_NN_ERR'] < 100) & (df['k_NN_ERR'] > 1/100) & (df['IS_BAD_PRCNT'] < 0.75)]\n",
        "  df_cleared = df[(df['k_NN_ERR']<50) & (df['k_NN_ERR']>1/50) & (df['meter']==meter) & (df['IS_BAD_PRCNT']<0.75)][In_Columns + [Out_Columns]]\n",
        "  print (len(df_cleared), len(val))\n",
        "\n",
        "  hist = nn_2.fit( df_cleared[In_Columns], df_cleared[Out_Columns], batch_size = batch_size, verbose = 0\n",
        "                  , epochs = epochs, shuffle = True, callbacks=[MyCustomCallback(epochs, 1), earlyStopping, reduce_lr_loss,model_checkpoint]\n",
        "                  , validation_data=(val[In_Columns], val[Out_Columns])\n",
        "                  ) \n",
        "  nn_2.save(DIR_SAVE + str(meter) + 'HANDLY_SAVED_3.MODEL')\n",
        "  gc.collect()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "2428706 407527\n",
            "# 0001 |  TST_loss: 15.3406 TST_MAE_: 0.8960 TST_RMSLE: 2.5108 TST_VAL_: 0.2237 TST_mean_squared_error: 183042758369.2848 TST_MAPE_: 1.1410 ///  TRN_loss: 20.4609 TRN_MAE_: 0.9966 TRN_RMSLE: 3.0885 TRN_VAL_: 0.0043 TRN_mean_squared_error: 187516955696.7137 TRN_MAPE_: 1.1103\n",
            "# 0002 |  TST_loss: 12.9734 TST_MAE_: 0.9021 TST_RMSLE: 2.2977 TST_VAL_: 0.3566 TST_mean_squared_error: 183041701198.8287 TST_MAPE_: 1.2284 ///  TRN_loss: 13.8853 TRN_MAE_: 0.9934 TRN_RMSLE: 2.5377 TRN_VAL_: 0.0094 TRN_mean_squared_error: 187515735192.6390 TRN_MAPE_: 1.1665\n",
            "# 0003 |  TST_loss: 11.9477 TST_MAE_: 0.9300 TST_RMSLE: 2.1976 TST_VAL_: 0.4768 TST_mean_squared_error: 183040755706.7373 TST_MAPE_: 1.3222 ///  TRN_loss: 12.2817 TRN_MAE_: 0.9917 TRN_RMSLE: 2.3754 TRN_VAL_: 0.0132 TRN_mean_squared_error: 187514758520.8332 TRN_MAPE_: 1.2585\n",
            ".......\n",
            "# 0004 |  TST_loss: 11.4156 TST_MAE_: 0.9722 TST_RMSLE: 2.1408 TST_VAL_: 0.5930 TST_mean_squared_error: 183039829301.5518 TST_MAPE_: 1.4119 ///  TRN_loss: 11.4801 TRN_MAE_: 0.9902 TRN_RMSLE: 2.2898 TRN_VAL_: 0.0172 TRN_mean_squared_error: 187513852801.0903 TRN_MAPE_: 1.3522\n",
            "# 0005 |  TST_loss: 11.1402 TST_MAE_: 1.0228 TST_RMSLE: 2.1074 TST_VAL_: 0.7067 TST_mean_squared_error: 183038960820.9655 TST_MAPE_: 1.4929 ///  TRN_loss: 11.0272 TRN_MAE_: 0.9892 TRN_RMSLE: 2.2399 TRN_VAL_: 0.0207 TRN_mean_squared_error: 187512956774.4699 TRN_MAPE_: 1.4384\n",
            "# 0006 |  TST_loss: 11.0194 TST_MAE_: 1.0775 TST_RMSLE: 2.0886 TST_VAL_: 0.8150 TST_mean_squared_error: 183038127639.0771 TST_MAPE_: 1.5639 ///  TRN_loss: 10.7709 TRN_MAE_: 0.9884 TRN_RMSLE: 2.2113 TRN_VAL_: 0.0242 TRN_mean_squared_error: 187512091144.6892 TRN_MAPE_: 1.5148\n",
            "# 0007 |  TST_loss: 10.9917 TST_MAE_: 1.1308 TST_RMSLE: 2.0793 TST_VAL_: 0.9107 TST_mean_squared_error: 183037375060.5359 TST_MAPE_: 1.6214 ///  TRN_loss: 10.6374 TRN_MAE_: 0.9875 TRN_RMSLE: 2.1962 TRN_VAL_: 0.0283 TRN_mean_squared_error: 187511299851.9386 TRN_MAPE_: 1.5803\n",
            "# 0008 |  TST_loss: 11.0082 TST_MAE_: 1.1751 TST_RMSLE: 2.0756 TST_VAL_: 0.9856 TST_mean_squared_error: 183036790644.5565 TST_MAPE_: 1.6636 ///  TRN_loss: 10.5795 TRN_MAE_: 0.9875 TRN_RMSLE: 2.1896 TRN_VAL_: 0.0303 TRN_mean_squared_error: 187510639699.1010 TRN_MAPE_: 1.6305\n",
            "# 0009 |  TST_loss: 11.0322 TST_MAE_: 1.2039 TST_RMSLE: 2.0745 TST_VAL_: 1.0322 TST_mean_squared_error: 183036425526.3694 TST_MAPE_: 1.6894 ///  TRN_loss: 10.5615 TRN_MAE_: 0.9879 TRN_RMSLE: 2.1875 TRN_VAL_: 0.0305 TRN_mean_squared_error: 187510169358.9363 TRN_MAPE_: 1.6645\n",
            "# 0010 |  TST_loss: 11.0432 TST_MAE_: 1.2146 TST_RMSLE: 2.0743 TST_VAL_: 1.0492 TST_mean_squared_error: 183036314129.8807 TST_MAPE_: 1.6985 ///  TRN_loss: 10.5573 TRN_MAE_: 0.9871 TRN_RMSLE: 2.1871 TRN_VAL_: 0.0336 TRN_mean_squared_error: 187509919178.2257 TRN_MAPE_: 1.6827\n",
            "# 0011 |  TST_loss: 11.0454 TST_MAE_: 1.2167 TST_RMSLE: 2.0743 TST_VAL_: 1.0524 TST_mean_squared_error: 183036297833.8154 TST_MAPE_: 1.7003 ///  TRN_loss: 10.5569 TRN_MAE_: 0.9869 TRN_RMSLE: 2.1871 TRN_VAL_: 0.0344 TRN_mean_squared_error: 187509852521.5152 TRN_MAPE_: 1.6874\n",
            "# 0012 |  TST_loss: 11.0459 TST_MAE_: 1.2170 TST_RMSLE: 2.0743 TST_VAL_: 1.0530 TST_mean_squared_error: 183036269610.1725 TST_MAPE_: 1.7006 ///  TRN_loss: 10.5565 TRN_MAE_: 0.9865 TRN_RMSLE: 2.1871 TRN_VAL_: 0.0356 TRN_mean_squared_error: 187509842738.1522 TRN_MAPE_: 1.6880\n",
            "# 0013 |  TST_loss: 11.0456 TST_MAE_: 1.2168 TST_RMSLE: 2.0743 TST_VAL_: 1.0526 TST_mean_squared_error: 183036297677.4856 TST_MAPE_: 1.7004 ///  TRN_loss: 10.5569 TRN_MAE_: 0.9869 TRN_RMSLE: 2.1871 TRN_VAL_: 0.0346 TRN_mean_squared_error: 187509838370.6119 TRN_MAPE_: 1.6882\n",
            "# 0014 |  TST_loss: 11.0426 TST_MAE_: 1.2141 TST_RMSLE: 2.0743 TST_VAL_: 1.0483 TST_mean_squared_error: 183036314783.0823 TST_MAPE_: 1.6981 ///  TRN_loss: 10.5571 TRN_MAE_: 0.9871 TRN_RMSLE: 2.1871 TRN_VAL_: 0.0339 TRN_mean_squared_error: 187509839821.3832 TRN_MAPE_: 1.6883\n",
            "# 0015 |  TST_loss: 11.0442 TST_MAE_: 1.2155 TST_RMSLE: 2.0743 TST_VAL_: 1.0505 TST_mean_squared_error: 183036313103.9118 TST_MAPE_: 1.6993 ///  TRN_loss: 10.5575 TRN_MAE_: 0.9875 TRN_RMSLE: 2.1871 TRN_VAL_: 0.0328 TRN_mean_squared_error: 187509841213.1090 TRN_MAPE_: 1.6880\n",
            "# 0016 |  TST_loss: 11.0533 TST_MAE_: 1.2236 TST_RMSLE: 2.0742 TST_VAL_: 1.0634 TST_mean_squared_error: 183036194016.2110 TST_MAPE_: 1.7062 ///  TRN_loss: 10.5576 TRN_MAE_: 0.9875 TRN_RMSLE: 2.1871 TRN_VAL_: 0.0327 TRN_mean_squared_error: 187509845840.0714 TRN_MAPE_: 1.6879\n",
            "# 0017 |  TST_loss: 11.0403 TST_MAE_: 1.2119 TST_RMSLE: 2.0743 TST_VAL_: 1.0449 TST_mean_squared_error: 183036346614.2945 TST_MAPE_: 1.6963 ///  TRN_loss: 10.5572 TRN_MAE_: 0.9871 TRN_RMSLE: 2.1871 TRN_VAL_: 0.0339 TRN_mean_squared_error: 187509832886.5001 TRN_MAPE_: 1.6887\n",
            "# 0018 |  TST_loss: 11.0456 TST_MAE_: 1.2169 TST_RMSLE: 2.0743 TST_VAL_: 1.0527 TST_mean_squared_error: 183036297618.6694 TST_MAPE_: 1.7004 ///  TRN_loss: 10.5568 TRN_MAE_: 0.9868 TRN_RMSLE: 2.1871 TRN_VAL_: 0.0347 TRN_mean_squared_error: 187509841562.3210 TRN_MAPE_: 1.6880\n",
            "# 0019 |  TST_loss: 11.0475 TST_MAE_: 1.2186 TST_RMSLE: 2.0743 TST_VAL_: 1.0554 TST_mean_squared_error: 183036255489.7804 TST_MAPE_: 1.7019 ///  TRN_loss: 10.5569 TRN_MAE_: 0.9868 TRN_RMSLE: 2.1871 TRN_VAL_: 0.0347 TRN_mean_squared_error: 187509841084.3501 TRN_MAPE_: 1.6882\n",
            "# 0020 |  TST_loss: 11.0412 TST_MAE_: 1.2127 TST_RMSLE: 2.0743 TST_VAL_: 1.0461 TST_mean_squared_error: 183036330262.1480 TST_MAPE_: 1.6969 ///  TRN_loss: 10.5574 TRN_MAE_: 0.9873 TRN_RMSLE: 2.1871 TRN_VAL_: 0.0333 TRN_mean_squared_error: 187509837819.4357 TRN_MAPE_: 1.6884\n",
            "# 0021 |  TST_loss: 11.0476 TST_MAE_: 1.2186 TST_RMSLE: 2.0743 TST_VAL_: 1.0555 TST_mean_squared_error: 183036255433.1390 TST_MAPE_: 1.7019 ///  TRN_loss: 10.5574 TRN_MAE_: 0.9874 TRN_RMSLE: 2.1871 TRN_VAL_: 0.0332 TRN_mean_squared_error: 187509844120.4846 TRN_MAPE_: 1.6878\n",
            "# 0022 |  TST_loss: 11.0448 TST_MAE_: 1.2161 TST_RMSLE: 2.0743 TST_VAL_: 1.0515 TST_mean_squared_error: 183036298518.5490 TST_MAPE_: 1.6998 ///  TRN_loss: 10.5570 TRN_MAE_: 0.9869 TRN_RMSLE: 2.1871 TRN_VAL_: 0.0343 TRN_mean_squared_error: 187509836824.4796 TRN_MAPE_: 1.6884\n",
            "\n",
            "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.0006000000052154065.\n",
            "# 0023 |  TST_loss: 11.0454 TST_MAE_: 1.2166 TST_RMSLE: 2.0743 TST_VAL_: 1.0523 TST_mean_squared_error: 183036297873.4807 TST_MAPE_: 1.7003 ///  TRN_loss: 10.5573 TRN_MAE_: 0.9873 TRN_RMSLE: 2.1871 TRN_VAL_: 0.0334 TRN_mean_squared_error: 187509841109.4542 TRN_MAPE_: 1.6881\n",
            "# 0024 |  TST_loss: 11.0475 TST_MAE_: 1.2186 TST_RMSLE: 2.0743 TST_VAL_: 1.0555 TST_mean_squared_error: 183036255436.4887 TST_MAPE_: 1.7019 ///  TRN_loss: 10.5578 TRN_MAE_: 0.9878 TRN_RMSLE: 2.1871 TRN_VAL_: 0.0318 TRN_mean_squared_error: 187509846463.3343 TRN_MAPE_: 1.6877\n",
            "# 0025 |  TST_loss: 11.0474 TST_MAE_: 1.2185 TST_RMSLE: 2.0743 TST_VAL_: 1.0553 TST_mean_squared_error: 183036255549.0183 TST_MAPE_: 1.7018 ///  TRN_loss: 10.5572 TRN_MAE_: 0.9872 TRN_RMSLE: 2.1871 TRN_VAL_: 0.0337 TRN_mean_squared_error: 187509836424.3234 TRN_MAPE_: 1.6883\n",
            "# 0026 |  TST_loss: 11.0504 TST_MAE_: 1.2212 TST_RMSLE: 2.0742 TST_VAL_: 1.0595 TST_mean_squared_error: 183036224649.0052 TST_MAPE_: 1.7041 ///  TRN_loss: 10.5572 TRN_MAE_: 0.9873 TRN_RMSLE: 2.1872 TRN_VAL_: 0.0335 TRN_mean_squared_error: 187509847452.8381 TRN_MAPE_: 1.6877\n",
            "# 0027 |  TST_loss: 11.0458 TST_MAE_: 1.2171 TST_RMSLE: 2.0743 TST_VAL_: 1.0530 TST_mean_squared_error: 183036269600.1092 TST_MAPE_: 1.7006 ///  TRN_loss: 10.5570 TRN_MAE_: 0.9871 TRN_RMSLE: 2.1871 TRN_VAL_: 0.0340 TRN_mean_squared_error: 187509831558.6064 TRN_MAPE_: 1.6889\n",
            "# 0028 |  TST_loss: 11.0460 TST_MAE_: 1.2172 TST_RMSLE: 2.0743 TST_VAL_: 1.0533 TST_mean_squared_error: 183036269384.0156 TST_MAPE_: 1.7008 ///  TRN_loss: 10.5565 TRN_MAE_: 0.9865 TRN_RMSLE: 2.1871 TRN_VAL_: 0.0354 TRN_mean_squared_error: 187509838767.0190 TRN_MAPE_: 1.6882\n",
            "# 0029 |  TST_loss: 11.0478 TST_MAE_: 1.2189 TST_RMSLE: 2.0743 TST_VAL_: 1.0559 TST_mean_squared_error: 183036255122.8258 TST_MAPE_: 1.7022 ///  TRN_loss: 10.5572 TRN_MAE_: 0.9873 TRN_RMSLE: 2.1871 TRN_VAL_: 0.0335 TRN_mean_squared_error: 187509842806.6638 TRN_MAPE_: 1.6879\n",
            "# 0030 |  TST_loss: 11.0460 TST_MAE_: 1.2172 TST_RMSLE: 2.0743 TST_VAL_: 1.0532 TST_mean_squared_error: 183036269438.8526 TST_MAPE_: 1.7007 ///  TRN_loss: 10.5570 TRN_MAE_: 0.9870 TRN_RMSLE: 2.1871 TRN_VAL_: 0.0341 TRN_mean_squared_error: 187509833964.3398 TRN_MAPE_: 1.6885\n",
            "# 0030 |  TST_loss: 11.0460 TST_MAE_: 1.2172 TST_RMSLE: 2.0743 TST_VAL_: 1.0532 TST_mean_squared_error: 183036269438.8526 TST_MAPE_: 1.7007 ///  TRN_loss: 10.5570 TRN_MAE_: 0.9870 TRN_RMSLE: 2.1871 TRN_VAL_: 0.0341 TRN_mean_squared_error: 187509833964.3398 TRN_MAPE_: 1.6885\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBMyJFG7Ugac",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for lr in [0.03]:\n",
        "  nn_2 = keras.models.load_model (DIR + '2HANDLY_SAVED_3best.MODEL')\n",
        "  opt = Adam(lr = lr)\n",
        "  epochs = 70\n",
        "  batch_size = 700\n",
        "  meter = 2\n",
        "  bias = Constant(value = 0.1)\n",
        "\n",
        "  earlyStopping = EarlyStopping(monitor='loss', patience=100, verbose=1, mode='min')\n",
        "  reduce_lr_loss = ReduceLROnPlateau(monitor='loss', factor=0.3, patience=15, verbose=1, min_delta=1e-3, mode='min')\n",
        "  model_checkpoint = ModelCheckpoint(monitor='loss', save_best_only=True, filepath = DIR + 'best_nn_' + str(meter) + '.model', save_weights_only = False, verbose=0, mode='min')\n",
        "\n",
        "  val = df[(df['meter'] == meter) & (df['day']%6 == 0) & (df['k_NN_ERR'] < 100) & (df['k_NN_ERR'] > 1/100) & (df['IS_BAD_PRCNT'] < 0.45)]\n",
        "  df_cleared = df[(df['k_NN_ERR']<50) & (df['k_NN_ERR']>1/50) & (df['day']%6 != 0) & (df['meter']==meter) & (df['IS_BAD_PRCNT']<0.45)][In_Columns + [Out_Columns]]\n",
        "  print('*'*9, lr, '*'*33)\n",
        "  nn_0.compile(optimizer = opt, loss = RMSLE, metrics=[ MAE_, RMSLE, VAL_, 'mse', MAPE_ ])\n",
        "  hist = nn_2.fit( df_cleared[In_Columns], df_cleared[Out_Columns], batch_size = batch_size, verbose = 0\n",
        "                  , epochs = epochs, shuffle = True, callbacks=[ MyCustomCallback(epochs, 1), earlyStopping, reduce_lr_loss]\n",
        "                  , validation_data=(val[In_Columns], val[Out_Columns])\n",
        "                  ) \n",
        "  nn_2.save(DIR + str(meter) + 'HANDLY_SAVED_3.MODEL')\n",
        "  gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DQZRFeEH01Cw",
        "colab": {}
      },
      "source": [
        "if 3==3:\n",
        "  meter = 3\n",
        "  epochs = 300\n",
        "  batch_size = 700\n",
        "  opt = Adam(lr = 0.007)\n",
        "\n",
        "  earlyStopping = EarlyStopping(monitor='loss', patience=50, verbose=1, mode='min')\n",
        "  reduce_lr_loss = ReduceLROnPlateau(monitor='loss', factor=0.2, patience=10, verbose=1, min_delta=1e-3, mode='min')\n",
        "  model_checkpoint = ModelCheckpoint(monitor='loss', save_best_only=True, filepath = DIR + 'best_nn_' + str(meter) + '.model', save_weights_only = False, verbose=0, mode='min')\n",
        "\n",
        "  nn_3 = Sequential()\n",
        "  nn_3.add(Dense(100, input_shape = df[In_Columns].shape[1:], activation = 'tanh', kernel_initializer = 'normal', kernel_regularizer=l2(reg), bias_initializer=bias))\n",
        "  nn_3.add(Dense(100, activation = 'tanh',  kernel_initializer = 'normal', bias_initializer=bias))\n",
        "  nn_3.add(Dense(100, activation = 'tanh',  kernel_initializer = 'normal', bias_initializer=bias, kernel_regularizer=l1(reg)))\n",
        "  nn_3.add(Dense(100, activation = 'tanh',  kernel_initializer = 'normal', bias_initializer=bias))\n",
        "  nn_3.add(Dense(1, activation = 'relu', kernel_initializer = 'normal'))\n",
        "\n",
        "  nn_3.compile(optimizer = opt, loss = RMSLE, metrics=[ MAE_, RMSLE, VAL_, 'mse', MAPE_ ])\n",
        "  \n",
        "  val = df[(df['meter'] == meter) & (df['day']%6 == 0) & (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.45)]\n",
        "  df_cleared = df[(df['k_NN_ERR']<50) & (df['k_NN_ERR']>1/50)  & (df['day']%6!=0) & (df['meter']==meter) & (df['IS_BAD_PRCNT']<0.45)][In_Columns + [Out_Columns]]\n",
        "\n",
        "  hist = nn_3.fit( df_cleared[In_Columns], df_cleared[Out_Columns], batch_size = batch_size, verbose = 0\n",
        "                  , epochs = epochs, shuffle = True, callbacks=[MyCustomCallback(epochs, 1), earlyStopping, reduce_lr_loss]\n",
        "                  , validation_data=(val[In_Columns], val[Out_Columns])\n",
        "                  ) \n",
        "  nn_3.save(DIR + str(meter) + 'HANDLY_SAVED0_3.MODEL')\n",
        "  gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_Ihng3E901Cy",
        "colab": {}
      },
      "source": [
        "for lr in [0.007]:\n",
        "  opt = Adam(lr = lr)\n",
        "  epochs = 200\n",
        "  batch_size = 700\n",
        "  meter = 3\n",
        "  nn_3 = keras.models.load_model (DIR + str(meter) + 'HANDLY_SAVED_3best.MODEL')\n",
        "\n",
        "  earlyStopping = EarlyStopping(monitor='loss', patience=50, verbose=1, mode='min')\n",
        "  reduce_lr_loss = ReduceLROnPlateau(monitor='loss', factor=0.2, patience=12, verbose=1, min_delta=1e-3, mode='min')\n",
        "  model_checkpoint = ModelCheckpoint(monitor='loss', save_best_only=True, filepath = DIR + 'best_nn_' + str(meter) + '.model', save_weights_only = False, verbose=0, mode='min')\n",
        "\n",
        "  val = df[(df['meter'] == meter) & (df['day']%6 == 0) & (df['k_NN_ERR'] < 100) & (df['k_NN_ERR'] > 1/100) & (df['IS_BAD_PRCNT'] < 0.45)]\n",
        "  df_cleared = df[(df['k_NN_ERR']<50) & (df['day']%6 != 0) & (df['k_NN_ERR']>1/50) & (df['meter']==meter) & (df['IS_BAD_PRCNT']<0.45)][In_Columns + [Out_Columns]]\n",
        "  print('*'*9, lr, '*'*33)\n",
        "  nn_3.compile(optimizer = opt, loss = RMSLE, metrics=[ MAE_, RMSLE, VAL_, 'mse', MAPE_ ])\n",
        "  hist = nn_3.fit( df_cleared[In_Columns], df_cleared[Out_Columns], batch_size = batch_size, verbose = 0\n",
        "                  , epochs = epochs, shuffle = True, callbacks=[ MyCustomCallback(epochs, 1), earlyStopping, reduce_lr_loss]\n",
        "                  , validation_data=(val[In_Columns], val[Out_Columns])\n",
        "                  ) \n",
        "  nn_3.save(DIR + str(meter) + 'HANDLY_SAVED_3.MODEL')\n",
        "  gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Q-4iZ-RLtI2v",
        "colab": {}
      },
      "source": [
        "#nn_0.save(DIR + '0HANDLY_SAVED_3best.MODEL')\n",
        "  # nn_1.save(DIR + '1HANDLY_SAVED_3best.MODEL')\n",
        "  # nn_2.save(DIR + '2HANDLY_SAVED_3best.MODEL')\n",
        "  # nn_3.save(DIR + '3HANDLY_SAVED_3best.MODEL')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_knQD6Zw0yFy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Предсказание из 4х значений:\n",
        "  nn_0 = keras.models.load_model (DIR_SAVE + '0HANDLY_SAVED_3best.MODEL')\n",
        "  nn_1 = keras.models.load_model (DIR_SAVE + '1HANDLY_SAVED_3best.MODEL')\n",
        "  nn_2 = keras.models.load_model (DIR_SAVE + '2HANDLY_SAVED_3best.MODEL')\n",
        "  nn_3 = keras.models.load_model (DIR_SAVE + '3HANDLY_SAVED_3best.MODEL')\n",
        "\n",
        "  # score = model.evaluate(X, Y, verbose=0)\n",
        "  # print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))\n",
        "  gc.collect()\n",
        "\n",
        "  df['NN_PRED'] = 0\n",
        "  df['NN_PRED_0'] = nn_0.predict(df[In_Columns], batch_size = 10000) \n",
        "  df['NN_PRED_1'] = nn_1.predict(df[In_Columns], batch_size = 10000) \n",
        "  df['NN_PRED_2'] = nn_2.predict(df[In_Columns], batch_size = 10000) \n",
        "  df['NN_PRED_3'] = nn_3.predict(df[In_Columns], batch_size = 10000) \n",
        "  df['NN_PRED'] = np.where(df['meter'] == 0, df['NN_PRED_0'], df['NN_PRED'])\n",
        "  df['NN_PRED'] = np.where(df['meter'] == 1, df['NN_PRED_1'], df['NN_PRED'])\n",
        "  df['NN_PRED'] = np.where(df['meter'] == 2, df['NN_PRED_2'], df['NN_PRED'])\n",
        "  df['NN_PRED'] = np.where(df['meter'] == 3, df['NN_PRED_3'], df['NN_PRED'])\n",
        "  df.drop(columns = ['NN_PRED_0', 'NN_PRED_1', 'NN_PRED_2', 'NN_PRED_3'], inplace = True)\n",
        "  #df.drop(columns = ['Value_x', 'Value_y'])\n",
        "  gc.collect()\n",
        "\n",
        "  df['NN_ERR'] = np.abs(df['NN_PRED']-df['meter_reading'])\n",
        "  df['k_NN_ERR'] = (df['NN_PRED']+0.33)/(df['meter_reading']+0.33)\n",
        "\n",
        "  print( 'Ошибка общая: ', np.sqrt( np.mean( np.power(np.log(df['meter_reading']+1) - np.log(df['NN_PRED']+1),2.00000)))\n",
        "      , 'Ошибка (VAL): ', np.sqrt( np.mean( np.power(np.log(df[(df['day']%6 == 0)]['meter_reading']+1) - np.log(df[(df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка (VAL_чист): ' , np.sqrt( np.mean( np.power(np.log(df[  (df['IS_BAD_PRCNT'] < 0.25) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[(df['IS_BAD_PRCNT'] < 0.25) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка (VAL_чист2): ', np.sqrt( np.mean( np.power(np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "  )\n",
        "  print('Ошибка 0: ', np.sqrt( np.mean( np.power(np.log(df[df['meter']==0]['meter_reading']+1) - np.log(df[df['meter']==0]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка 0 (VAL): ', np.sqrt( np.mean( np.power(np.log(df[(df['meter']==0) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[(df['meter']==0) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка 0 (VAL_чист): ' , np.sqrt( np.mean( np.power(np.log(df[  (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==0) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[ (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==0) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка 0 (VAL_чист2): ', np.sqrt( np.mean( np.power(np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==0) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==0) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "  )\n",
        "  print('Ошибка 1: ', np.sqrt( np.mean( np.power(np.log(df[df['meter']==1]['meter_reading']+1) - np.log(df[df['meter']==1]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка 1 (VAL): ', np.sqrt( np.mean( np.power(np.log(df[(df['meter']==1) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[(df['meter']==1) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка 1 (VAL_чист): ' , np.sqrt( np.mean( np.power(np.log(df[  (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==1) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[ (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==1) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка 1 (VAL_чист2): ', np.sqrt( np.mean( np.power(np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==1) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==1) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "  )\n",
        "  print('Ошибка 2: ', np.sqrt( np.mean( np.power(np.log(df[df['meter']==2]['meter_reading']+1) - np.log(df[df['meter']==2]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка 2 (VAL): ', np.sqrt( np.mean( np.power(np.log(df[(df['meter']==2) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[(df['meter']==2) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка 2 (VAL_чист): ' , np.sqrt( np.mean( np.power(np.log(df[  (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==2) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[ (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==2) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка 2 (VAL_чист2): ', np.sqrt( np.mean( np.power(np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==2) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==2) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "  )\n",
        "  print('Ошибка 3: ', np.sqrt( np.mean( np.power(np.log(df[df['meter']==3]['meter_reading']+1) - np.log(df[df['meter']==3]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка 3 (VAL): ', np.sqrt( np.mean( np.power(np.log(df[(df['meter']==3) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[(df['meter']==3) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка 3 (VAL_чист): ' , np.sqrt( np.mean( np.power(np.log(df[  (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==3) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[ (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==3) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка 3 (VAL_чист2): ', np.sqrt( np.mean( np.power(np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==3) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==3) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "  )\n",
        "  # print('Ошибка 1: ', np.sqrt( np.mean( np.power(np.log(df[df['meter']==1]['meter_reading']+1) - np.log(df[df['meter']==1]['NN_PRED']+1),2.00000)))        )\n",
        "  # print('Ошибка 2: ', np.sqrt( np.mean( np.power(np.log(df[df['meter']==2]['meter_reading']+1) - np.log(df[df['meter']==2]['NN_PRED']+1),2.00000)))        )\n",
        "  # print('Ошибка 3: ', np.sqrt( np.mean( np.power(np.log(df[df['meter']==3]['meter_reading']+1) - np.log(df[df['meter']==3]['NN_PRED']+1),2.00000)))        )\n",
        "\n",
        "  gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWGPRQypQAuh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Ошибки:\n",
        "  Ошибка общая:  1.3332699709812266 Ошибка (VAL):  1.337540194067479 Ошибка (VAL_чист):  0.5418592287241801 Ошибка (VAL_чист2):  0.40073096858305257\n",
        "  Ошибка 0:  1.098206407152078 Ошибка 0 (VAL):  1.0905813857988798 Ошибка 0 (VAL_чист):  0.28240200416498673 Ошибка 0 (VAL_чист2):  0.2562246375809472\n",
        "  Ошибка 1:  1.4462519064009887 Ошибка 1 (VAL):  1.4819992377016542 Ошибка 1 (VAL_чист):  0.628029160200588 Ошибка 1 (VAL_чист2):  0.47946068818401355\n",
        "  Ошибка 2:  1.6966445281141582 Ошибка 2 (VAL):  1.6978240187666451 Ошибка 2 (VAL_чист):  0.926254557141954 Ошибка 2 (VAL_чист2):  0.6472006361307439\n",
        "  Ошибка 3:  1.9577298686058777 Ошибка 3 (VAL):  1.9537862377808086 Ошибка 3 (VAL_чист):  1.1455655044777464 Ошибка 3 (VAL_чист2):  0.6972188121146171\n",
        "\n",
        "  Ошибка общая:  1.3473873510158345 Ошибка (VAL):  1.3483414756663568 Ошибка (VAL_чист):  0.5756767186919248 Ошибка (VAL_чист2):  0.462361504102313\n",
        "  Ошибка 0:  1.0971504229404558 Ошибка 0 (VAL):  1.0891509074774033 Ошибка 0 (VAL_чист):  0.3389179667173395 Ошибка 0 (VAL_чист2):  0.3149224768996143\n",
        "  Ошибка 1:  1.5319581160458586 Ошибка 1 (VAL):  1.5591904792676097 Ошибка 1 (VAL_чист):  0.7038461338617784 Ошибка 1 (VAL_чист2):  0.5850605758832433\n",
        "  Ошибка 2:  1.6638634087676607 Ошибка 2 (VAL):  1.6575566177087862 Ошибка 2 (VAL_чист):  0.918408148629441 Ошибка 2 (VAL_чист2):  0.6847326774214916\n",
        "  Ошибка 3:  1.9625404709477796 Ошибка 3 (VAL):  1.9555454713909437 Ошибка 3 (VAL_чист):  1.117054007408267 Ошибка 3 (VAL_чист2):  0.7521327942946583"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSg8qh29X2xl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Evaluate:\n",
        "  score = nn_0.evaluate(df[df['meter']==0][In_Columns], df[df['meter']==0][Out_Columns], verbose=1, batch_size = 30000)\n",
        "  print(0)\n",
        "  for i in range(len(nn_0.metrics_names)):\n",
        "    print(\"%s: %.2f%%\" % (nn_0.metrics_names[i], score[i]*100))\n",
        "\n",
        "  score = nn_1.evaluate(df[df['meter']==1][In_Columns], df[df['meter']==1][Out_Columns], verbose=1, batch_size = 30000)\n",
        "  print(1)\n",
        "  for i in range(len(nn_1.metrics_names)):\n",
        "    print(\"%s: %.2f%%\" % (nn_1.metrics_names[i], score[i]*100))\n",
        "\n",
        "  score = nn_2.evaluate(df[df['meter']==2][In_Columns], df[df['meter']==2][Out_Columns], verbose=1, batch_size = 30000)\n",
        "  print(2)\n",
        "  for i in range(len(nn_2.metrics_names)):\n",
        "    print(\"%s: %.2f%%\" % (nn_2.metrics_names[i], score[i]*100))\n",
        "\n",
        "  score = nn_3.evaluate(df[df['meter']==3][In_Columns], df[df['meter']==3][Out_Columns], verbose=1, batch_size = 30000)\n",
        "  print(3)\n",
        "  for i in range(len(nn_3.metrics_names)):\n",
        "    print(\"%s: %.2f%%\" % (nn_3.metrics_names[i], score[i]*100))\n",
        "  \n",
        "  gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8qHP3Icaw2D",
        "colab_type": "code",
        "outputId": "43e69f59-8e40-42ea-d66a-644e6e2ad83e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "#Важность показателей 0\n",
        "  from sklearn.utils import shuffle\n",
        "  nn = keras.models.load_model (DIR_SAVE + '0HANDLY_SAVED3best.MODEL')\n",
        "  meter = 0\n",
        "  val = df[(df['meter']==meter) & (df['day']%6==0)  & (df['IS_BAD_PRCNT']<0.45)]\n",
        "  #Подставить нужную нейронку в зависимости от meter\n",
        "  #print(nn.metrics_names)\n",
        "  k = pd.DataFrame( [nn.evaluate(val[In_Columns], val[Out_Columns], batch_size = 800000, verbose = 0)],columns=nn.metrics_names)\n",
        "  k['name'] = '---INITIAL---'\n",
        "  tmp_out=k.copy()\n",
        "  for i in range(len(In_Columns)):\n",
        "      X_val_2 = val[In_Columns].copy()\n",
        "      s = shuffle(X_val_2.iloc[:,i])\n",
        "      s.index = X_val_2.index\n",
        "      X_val_2.iloc[:, i] = s\n",
        "      tmp = pd.DataFrame([nn.evaluate(X_val_2, val[Out_Columns], batch_size = 800000, verbose = 0)], columns = nn.metrics_names)-k[nn.metrics_names] \n",
        "      tmp['name'] = In_Columns[i]\n",
        "      tmp_out = pd.concat([tmp_out, tmp])\n",
        "      X_val_2 = None\n",
        "      gc.collect()\n",
        "  tmp_out.set_index('name', inplace = True)\n",
        "  pd.set_option('display.float_format', lambda x: '%.4f' % x)\n",
        "  print (tmp_out[nn.metrics_names].sort_values('RMSLE', ascending=False))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                 loss    MAE_   RMSLE    VAL_  mean_squared_error   MAPE_\n",
            "name                                                                                     \n",
            "building_meter_weekday_median  2.9106  0.9289  1.3989  0.0326         114978.4964  1.4665\n",
            "square_feet                    0.4069  0.1125  0.3822  0.0089           7386.0101  0.3386\n",
            "---INITIAL---                  0.1303  0.1884  0.3410  0.9108          25827.2513  0.2326\n",
            "site_id                        0.2229  0.0807  0.2424  0.0108           3550.1542  0.2189\n",
            "primary_use_ID                 0.1589  0.0633  0.1832  0.0067           3364.4379  0.1621\n",
            "building_meter_hour_median     0.0844  0.0159  0.1069  0.0043            385.0823  0.1368\n",
            "hour_cos                       0.0713  0.0415  0.0908  0.0012           1410.0715  0.0857\n",
            "week_cos                       0.0378  0.0193  0.0521 -0.0163           1017.2717  0.0297\n",
            "week_sin                       0.0370  0.0178  0.0513 -0.0100            857.0364  0.0294\n",
            "air_temperature                0.0221  0.0150  0.0316 -0.0194            721.6550  0.0197\n",
            "hour_sin                       0.0157  0.0132  0.0218  0.0011            401.7483  0.0230\n",
            "weekday_sin                    0.0143  0.0063  0.0191  0.0007            142.8440  0.0195\n",
            "building_meter_median          0.0125  0.0019  0.0179  0.0011             41.1203  0.0303\n",
            "dew_temperature                0.0042  0.0046  0.0063 -0.0059            178.1515  0.0045\n",
            "weekday_cos                    0.0025  0.0011  0.0035 -0.0002             25.0626  0.0032\n",
            "cloud_coverage                 0.0004  0.0003  0.0006 -0.0002              9.4449  0.0009\n",
            "sea_level_pressure             0.0002  0.0001  0.0003  0.0004             -1.8919  0.0005\n",
            "wind_speed                     0.0001  0.0001  0.0001 -0.0002              1.6454  0.0001\n",
            "wind_direction                -0.0000  0.0000 -0.0000 -0.0001              0.6456 -0.0000\n",
            "is_holiday                    -0.0006 -0.0000 -0.0007  0.0001              0.5574  0.0001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCDCxcqhKHO1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Важность показателей 1\n",
        "  from sklearn.utils import shuffle\n",
        "  nn = keras.models.load_model (DIR_SAVE + '1HANDLY_SAVED3.MODEL')\n",
        "  meter = 1\n",
        "  val = df[(df['meter']==meter) & (df['day']%6==0)  & (df['IS_BAD_PRCNT']<0.25)]\n",
        "  #Подставить нужную нейронку в зависимости от meter\n",
        "  #print(nn.metrics_names)\n",
        "  k = pd.DataFrame( [nn.evaluate(val[In_Columns], val[Out_Columns], batch_size = 800000, verbose = 0)],columns=nn.metrics_names)\n",
        "  k['name'] = '---INITIAL---'\n",
        "  tmp_out=k.copy()\n",
        "  for i in range(len(In_Columns)):\n",
        "      X_val_2 = val[In_Columns].copy()\n",
        "      s = shuffle(X_val_2.iloc[:,i])\n",
        "      s.index = X_val_2.index\n",
        "      X_val_2.iloc[:, i] = s\n",
        "      tmp = pd.DataFrame([nn.evaluate(X_val_2, val[Out_Columns], batch_size = 800000, verbose = 0)], columns = nn.metrics_names)-k[nn.metrics_names] \n",
        "      tmp['name'] = In_Columns[i]\n",
        "      tmp_out = pd.concat([tmp_out, tmp])\n",
        "      X_val_2 = None\n",
        "      gc.collect()\n",
        "  tmp_out.set_index('name', inplace = True)\n",
        "  pd.set_option('display.float_format', lambda x: '%.4f' % x)\n",
        "  print (tmp_out[nn.metrics_names].sort_values('RMSLE', ascending=False))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIfQd2t9KN04",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Важность показателей 2\n",
        "  from sklearn.utils import shuffle\n",
        "  nn = keras.models.load_model (DIR_SAVE + '2HANDLY_SAVED3.MODEL')\n",
        "  meter = 2\n",
        "  val = df[(df['meter']==meter) & (df['day']%6==0)  & (df['IS_BAD_PRCNT']<0.25)]\n",
        "  #Подставить нужную нейронку в зависимости от meter\n",
        "  #print(nn.metrics_names)\n",
        "  k = pd.DataFrame( [nn.evaluate(val[In_Columns], val[Out_Columns], batch_size = 800000, verbose = 0)],columns=nn.metrics_names)\n",
        "  k['name'] = '---INITIAL---'\n",
        "  tmp_out=k.copy()\n",
        "  for i in range(len(In_Columns)):\n",
        "      X_val_2 = val[In_Columns].copy()\n",
        "      s = shuffle(X_val_2.iloc[:,i])\n",
        "      s.index = X_val_2.index\n",
        "      X_val_2.iloc[:, i] = s\n",
        "      tmp = pd.DataFrame([nn.evaluate(X_val_2, val[Out_Columns], batch_size = 800000, verbose = 0)], columns = nn.metrics_names)-k[nn.metrics_names] \n",
        "      tmp['name'] = In_Columns[i]\n",
        "      tmp_out = pd.concat([tmp_out, tmp])\n",
        "      X_val_2 = None\n",
        "      gc.collect()\n",
        "  tmp_out.set_index('name', inplace = True)\n",
        "  pd.set_option('display.float_format', lambda x: '%.4f' % x)\n",
        "  print (tmp_out[nn.metrics_names].sort_values('RMSLE', ascending=False))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wxn_T9DhKRzX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Важность показателей 3\n",
        "  from sklearn.utils import shuffle\n",
        "  nn = keras.models.load_model (DIR_SAVE + '3HANDLY_SAVED03.MODEL')\n",
        "  meter = 3\n",
        "  val = df[(df['meter']==meter) & (df['day']%6==0)  & (df['IS_BAD_PRCNT']<0.25)]\n",
        "  #Подставить нужную нейронку в зависимости от meter\n",
        "  #print(nn.metrics_names)\n",
        "  k = pd.DataFrame( [nn.evaluate(val[In_Columns], val[Out_Columns], batch_size = 800000, verbose = 0)],columns=nn.metrics_names)\n",
        "  k['name'] = '---INITIAL---'\n",
        "  tmp_out=k.copy()\n",
        "  for i in range(len(In_Columns)):\n",
        "      X_val_2 = val[In_Columns].copy()\n",
        "      s = shuffle(X_val_2.iloc[:,i])\n",
        "      s.index = X_val_2.index\n",
        "      X_val_2.iloc[:, i] = s\n",
        "      tmp = pd.DataFrame([nn.evaluate(X_val_2, val[Out_Columns], batch_size = 800000, verbose = 0)], columns = nn.metrics_names)-k[nn.metrics_names] \n",
        "      tmp['name'] = In_Columns[i]\n",
        "      tmp_out = pd.concat([tmp_out, tmp])\n",
        "      X_val_2 = None\n",
        "      gc.collect()\n",
        "  tmp_out.set_index('name', inplace = True)\n",
        "  pd.set_option('display.float_format', lambda x: '%.4f' % x)\n",
        "  print (tmp_out[nn.metrics_names].sort_values('RMSLE', ascending=False))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsiTWGypOAHb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ИДЕИ:\n",
        "  1) Сделать не показатель, а его отклонение от медианы по строению/дню/часу\n",
        "  2) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLLVe_MMYIz-",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6AezgKyEBi6",
        "colab_type": "code",
        "outputId": "26eb9e7a-6504-4dac-b822-27b0e467fb7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#reduce_mem_usage(df_test)\n",
        "gc.collect()\n",
        "#df_test.describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWDYNM3xOBZx",
        "colab_type": "code",
        "outputId": "cd7750df-9ded-4797-bccf-e5aaafc1de46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Подготовка данных тест:\n",
        "  df_test = pd.read_csv(DIR + \"test.csv\", engine = 'python')\n",
        "  print('Забрали с диска')\n",
        "  df_test['timestamp'] = pd.to_datetime(df_test['timestamp'])\n",
        "\n",
        "  df_test['hour_cos'] = np.cos(df_test['timestamp'].dt.hour * 2. * np.pi / 24.)\n",
        "  df_test['hour_sin'] = np.sin(df_test['timestamp'].dt.hour * 2. * np.pi / 24.)\n",
        "\n",
        "  df_test['weekday_cos'] = np.cos(df_test['timestamp'].dt.weekday * 2. * np.pi / 7.)\n",
        "  df_test['weekday_sin'] = np.sin(df_test['timestamp'].dt.weekday * 2. * np.pi / 7.)\n",
        "\n",
        "  df_test['week_cos'] = np.cos(df_test['timestamp'].dt.week * 2. * np.pi / 53.)\n",
        "  df_test['week_sin'] = np.sin(df_test['timestamp'].dt.week * 2. * np.pi / 53.)\n",
        "\n",
        "  #reduce_mem_usage(df_test)\n",
        "  gc.collect()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Забрали с диска\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "91"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "6d9925cb-d229-45fd-97fc-cc15d533037b",
        "id": "z2TmthILE1wp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# Добавление медиан:\n",
        "  # Добавление медианы по метрике постройки\n",
        "    df_median = df.groupby(by=['building_id','meter'])['building_meter_median'].median()\n",
        "    df_test = pd.merge(df_test, df_median, how = 'left', on = ['building_id','meter'])\n",
        "    del df_median \n",
        "    gc.collect()\n",
        "    print('Построены медианы по сооружению')\n",
        "  # Добавление медианы по часу, по неделе, метрике постройки\n",
        "    df_test['hour'] = df_test['timestamp'].dt.hour\n",
        "    df_median = df.groupby(by=['building_id','hour','meter'])['building_meter_hour_median'].median()\n",
        "    df_test = pd.merge(df_test, df_median, how = 'left', on = ['building_id','hour','meter'])\n",
        "    #print(len(df_test))\n",
        "    del df_median #, df_mean, df_median2, df_mean2\n",
        "    gc.collect()\n",
        "    \n",
        "    df_test['weekday'] = df_test['timestamp'].dt.weekday\n",
        "    df_median = df.groupby(by=['building_id','weekday','meter'])['building_meter_weekday_median'].median()\n",
        "    #df_median.name = 'building_meter_weekday_median'\n",
        "    df_test = pd.merge(df_test, df_median, how = 'left', on = ['building_id','weekday','meter'])\n",
        "    del df_median \n",
        "    #print(len(df_test))\n",
        "\n",
        "    print('Построены медианы по сооружению/часу')\n",
        "    holidays = [\"2016-01-01\", \"2016-01-18\", \"2016-02-15\", \"2016-05-30\", \"2016-07-04\",\n",
        "                      \"2016-09-05\", \"2016-10-10\", \"2016-11-11\", \"2016-11-24\", \"2016-12-26\",\n",
        "                      \"2017-01-02\", \"2017-01-16\", \"2017-02-20\", \"2017-05-29\", \"2017-07-04\",\n",
        "                      \"2017-09-04\", \"2017-10-09\", \"2017-11-10\", \"2017-11-23\", \"2017-12-25\",\n",
        "                      \"2018-01-01\", \"2018-01-15\", \"2018-02-19\", \"2018-05-28\", \"2018-07-04\",\n",
        "                      \"2018-09-03\", \"2018-10-08\", \"2018-11-12\", \"2018-11-22\", \"2018-12-25\",\n",
        "                      \"2019-01-01\"]\n",
        "    df_test[\"is_holiday\"] = (df_test.timestamp.isin(holidays)).astype(int)\n",
        "    del holidays\n",
        "    gc.collect()\n",
        "    #print(len(df_test))\n",
        "  # Подстановка параметров сооружения\n",
        "    df_median = df.groupby(by=['building_id'])['primary_use_ID','site_id','square_feet'].median()\n",
        "    df_test = pd.merge(df_test, df_median, how = 'left', on = ['building_id'])\n",
        "    del df_median \n",
        "\n",
        "    print('Подставлены данные по сооружению')\n",
        "    gc.collect()\n",
        "    #print(len(df_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Построены медианы по сооружению\n",
            "Построены медианы по сооружению/часу\n",
            "Подставлены данные по сооружению\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i34pNJGAWNLV",
        "colab_type": "code",
        "outputId": "0ff2362c-681b-4c23-cab5-72fa812270fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "del df\n",
        "gc.collect()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gZDPAWaD0M5n",
        "colab": {}
      },
      "source": [
        "#Вставка данных погоды\n",
        "#Восстановление пустых данных погоды через соседей по линейной инетрполяции\n",
        "  df_weather = pd.read_csv(DIR + \"weather_test.csv\", engine = 'python')\n",
        "  df_weather['timestamp'] = pd.to_datetime(df_weather['timestamp'])\n",
        "  df_weather.drop(columns = ['precip_depth_1_hr'], inplace = True)\n",
        "  gc.collect()\n",
        "\n",
        "  #weather_train.groupby('site_id').apply(lambda group: group.isna().sum())\n",
        "  df_times = df_test.drop_duplicates(['site_id','timestamp'])[['site_id','timestamp']]\n",
        "  df_times = pd.merge(df_times, df_weather, how = 'left', on = ['site_id','timestamp'])\n",
        "  df_times.sort_values(by = ['site_id','timestamp'], inplace = True)\n",
        "  gc.collect()\n",
        "\n",
        "  df_times = df_times.groupby('site_id'  ).apply(lambda group: group.interpolate(limit_direction='both'))\n",
        "  df_times = df_times.groupby('timestamp').apply(lambda group: group.interpolate(limit_direction='both'))\n",
        "  \n",
        "  df_test = pd.merge(df_test, df_times, how = 'left', on = ['site_id','timestamp'])\n",
        "  del df_weather, df_times\n",
        "\n",
        "  #del df_weather"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jblybbA1X8IM",
        "colab_type": "code",
        "outputId": "6ed91f04-db3f-4715-d4a4-5ad69dafcc20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#reduce_mem_usage(df_test)\n",
        "df_test.to_feather(DIR_SAVE + 'DF_TEST_REDUCED3.FTHR')\n",
        "gc.collect()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjgCdq3PZh81",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Загрузка данных:\n",
        "  #df_test = pd.read_feather(DIR_SAVE + 'DF_TEST_REDUCED3.FTHR')\n",
        "  #gc.collect()\n",
        "  import pickle\n",
        "  with open(DIR_SAVE+'scaler31.pickle', 'rb') as handle:\n",
        "      scaler = pickle.load(handle)\n",
        "      In_Columns = pickle.load(handle)\n",
        "      Out_Columns = pickle.load(handle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTDcNmss8mK5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Нормализация\n",
        "  i=0\n",
        "  #print(scaler.data_max_)\n",
        "  for c in In_Columns:\n",
        "    if c in ['building_meter_median','building_meter_hour_median','building_meter_weekday_median','primary_use_ID','site_id','square_feet']:\n",
        "      print(i, c, 'Уже нормализовано:', scaler.scale_[i],scaler.min_[i], '     ',scaler.data_min_[i], scaler.data_max_[i])\n",
        "    else:\n",
        "      print(i, c, scaler.scale_[i],scaler.min_[i], '     ', scaler.data_min_[i], scaler.data_max_[i])\n",
        "      df_test[c] = df_test[c] * scaler.scale_[i] + scaler.min_[i]\n",
        "    i+=1\n",
        "    gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cG1CZk1i-CHl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Выбор нейронок и предсказание:\n",
        "  nn_0 = keras.models.load_model (DIR_SAVE + '0HANDLY_SAVED3best.MODEL')\n",
        "  nn_1 = keras.models.load_model (DIR_SAVE + '1HANDLY_SAVED3best.MODEL')\n",
        "  nn_2 = keras.models.load_model (DIR_SAVE + '2HANDLY_SAVED3best.MODEL')\n",
        "  nn_3 = keras.models.load_model (DIR_SAVE + '3HANDLY_SAVED3best.MODEL')\n",
        "  # score = model.evaluate(X, Y, verbose=0)\n",
        "  # print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))\n",
        "  gc.collect()\n",
        "  #Предсказание из 4х значений:\n",
        "  if 1==1:\n",
        "    df_test['NN_PRED'] = 0 \n",
        "    df_test['NN_PRED']  = df_test['NN_PRED'].astype('float32')\n",
        "    l = len(df_test)\n",
        "    print( len(df_test) )\n",
        "    step = 1600000\n",
        "    for i in range(int(l/step)+1):\n",
        "      print(i*step, (i+1)*step)\n",
        "      tmp = df_test[i*step: (i+1)*step][In_Columns + ['row_id','meter']]\n",
        "      gc.collect() \n",
        "      tmp['NN_PRED'] = 0 \n",
        "      tmp['NN_PRED_0'] = nn_0.predict(tmp[In_Columns], batch_size = 20000) \n",
        "      tmp['NN_PRED_1'] = nn_1.predict(tmp[In_Columns], batch_size = 20000) \n",
        "      tmp['NN_PRED_2'] = nn_2.predict(tmp[In_Columns], batch_size = 20000) \n",
        "      tmp['NN_PRED_3'] = nn_3.predict(tmp[In_Columns], batch_size = 20000) \n",
        "      gc.collect()\n",
        "      tmp['NN_PRED'] = np.where(tmp['meter'] == 0, tmp['NN_PRED_0'], tmp['NN_PRED'])\n",
        "      tmp['NN_PRED'] = np.where(tmp['meter'] == 1, tmp['NN_PRED_1'], tmp['NN_PRED'])\n",
        "      tmp['NN_PRED'] = np.where(tmp['meter'] == 2, tmp['NN_PRED_2'], tmp['NN_PRED'])\n",
        "      tmp['NN_PRED'] = np.where(tmp['meter'] == 3, tmp['NN_PRED_3'], tmp['NN_PRED'])\n",
        "      gc.collect()\n",
        "      #print('спрогнозили')\n",
        "      #df_test[i*step: (i+1)*step]['NN_PRED'] = pd.merge(df_test, tmp[['row_id','NN_PRED']], how = 'left', on = ['row_id'])\n",
        "      #df_test.loc[i*step: (i+1)*step, 'NN_PRED'] = tmp['NN_PRED']\n",
        "      \n",
        "      if i==0:\n",
        "        a = tmp[['row_id','NN_PRED', 'meter']].copy()\n",
        "      else:\n",
        "        a = pd.concat([a, tmp[['row_id','NN_PRED', 'meter']].copy()], sort=False)\n",
        "      #del tmp\n",
        "      #gc.collect() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtxkAc9E00Yn",
        "colab_type": "code",
        "outputId": "b24d653f-2b43-4e9e-f552-1b83bd137906",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(df_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "41697600\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXmjfkrQC61e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a['row_id']         = a['row_id'].astype('Int32')\n",
        "a['meter_reading']  = a['NN_PRED'].astype('float32')\n",
        "a[['row_id', 'meter_reading']].to_csv(DIR_SAVE+'OUT_Ver0.31 no clean_6.csv', index = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pSaG8s-5_yL",
        "colab_type": "code",
        "outputId": "fda74d3e-c62c-4e60-b53b-7bf051fbc54c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "a.head(-1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>row_id</th>\n",
              "      <th>NN_PRED</th>\n",
              "      <th>meter</th>\n",
              "      <th>meter_reading</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>252.3435</td>\n",
              "      <td>0</td>\n",
              "      <td>252.3435</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>138.7939</td>\n",
              "      <td>0</td>\n",
              "      <td>138.7939</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>21.5660</td>\n",
              "      <td>0</td>\n",
              "      <td>21.5660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>346.3572</td>\n",
              "      <td>0</td>\n",
              "      <td>346.3572</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>962.0777</td>\n",
              "      <td>0</td>\n",
              "      <td>962.0777</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41697594</th>\n",
              "      <td>41697594</td>\n",
              "      <td>115.1817</td>\n",
              "      <td>0</td>\n",
              "      <td>115.1817</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41697595</th>\n",
              "      <td>41697595</td>\n",
              "      <td>25.0976</td>\n",
              "      <td>0</td>\n",
              "      <td>25.0976</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41697596</th>\n",
              "      <td>41697596</td>\n",
              "      <td>24.4483</td>\n",
              "      <td>0</td>\n",
              "      <td>24.4483</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41697597</th>\n",
              "      <td>41697597</td>\n",
              "      <td>20.8425</td>\n",
              "      <td>0</td>\n",
              "      <td>20.8425</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41697598</th>\n",
              "      <td>41697598</td>\n",
              "      <td>170.9884</td>\n",
              "      <td>0</td>\n",
              "      <td>170.9884</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>41697599 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            row_id  NN_PRED  meter  meter_reading\n",
              "0                0 252.3435      0       252.3435\n",
              "1                1 138.7939      0       138.7939\n",
              "2                2  21.5660      0        21.5660\n",
              "3                3 346.3572      0       346.3572\n",
              "4                4 962.0777      0       962.0777\n",
              "...            ...      ...    ...            ...\n",
              "41697594  41697594 115.1817      0       115.1817\n",
              "41697595  41697595  25.0976      0        25.0976\n",
              "41697596  41697596  24.4483      0        24.4483\n",
              "41697597  41697597  20.8425      0        20.8425\n",
              "41697598  41697598 170.9884      0       170.9884\n",
              "\n",
              "[41697599 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZW2CAz9u1yg0",
        "colab_type": "code",
        "outputId": "51c0f5a2-3df5-4a2e-a88a-95bc3ebc395a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "a.groupby(['meter'])['NN_PRED'].agg(['mean','median', 'min', 'max'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean</th>\n",
              "      <th>median</th>\n",
              "      <th>min</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>meter</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>159.116</td>\n",
              "      <td>68.534</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1355.983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>352.780</td>\n",
              "      <td>116.053</td>\n",
              "      <td>0.000</td>\n",
              "      <td>2035.047</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>12714.100</td>\n",
              "      <td>237.592</td>\n",
              "      <td>0.000</td>\n",
              "      <td>17835566.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>219.173</td>\n",
              "      <td>32.681</td>\n",
              "      <td>0.000</td>\n",
              "      <td>32506.373</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           mean  median   min          max\n",
              "meter                                     \n",
              "0       159.116  68.534 0.000     1355.983\n",
              "1       352.780 116.053 0.000     2035.047\n",
              "2     12714.100 237.592 0.000 17835566.000\n",
              "3       219.173  32.681 0.000    32506.373"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAlQJtbx36Az",
        "colab_type": "code",
        "outputId": "a90a7cd1-7a6e-440b-aa7f-8688118dc5cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df.groupby(['meter'])['meter_reading'].agg(['mean','median', 'min', 'max'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean</th>\n",
              "      <th>median</th>\n",
              "      <th>min</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>meter</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>162.707</td>\n",
              "      <td>68.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>79769.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>633.801</td>\n",
              "      <td>120.698</td>\n",
              "      <td>0.000</td>\n",
              "      <td>880374.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>14402.644</td>\n",
              "      <td>253.150</td>\n",
              "      <td>0.000</td>\n",
              "      <td>21904700.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>374.154</td>\n",
              "      <td>38.099</td>\n",
              "      <td>0.000</td>\n",
              "      <td>160187.000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           mean  median   min          max\n",
              "meter                                     \n",
              "0       162.707  68.000 0.000    79769.000\n",
              "1       633.801 120.698 0.000   880374.000\n",
              "2     14402.644 253.150 0.000 21904700.000\n",
              "3       374.154  38.099 0.000   160187.000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NFKqWrr7nz7",
        "colab_type": "code",
        "outputId": "24454c2c-8344-4adf-cb1c-47dd0452049c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df.groupby(['meter'])['NN_PRED'].agg(['mean','median', 'min', 'max'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean</th>\n",
              "      <th>median</th>\n",
              "      <th>min</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>meter</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>158.798</td>\n",
              "      <td>74.755</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1289.670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>378.482</td>\n",
              "      <td>138.774</td>\n",
              "      <td>0.000</td>\n",
              "      <td>2033.057</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>11507.809</td>\n",
              "      <td>244.696</td>\n",
              "      <td>0.000</td>\n",
              "      <td>17275218.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>269.547</td>\n",
              "      <td>40.498</td>\n",
              "      <td>0.000</td>\n",
              "      <td>45745.234</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           mean  median   min          max\n",
              "meter                                     \n",
              "0       158.798  74.755 0.000     1289.670\n",
              "1       378.482 138.774 0.000     2033.057\n",
              "2     11507.809 244.696 0.000 17275218.000\n",
              "3       269.547  40.498 0.000    45745.234"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZATVfSA78tqg",
        "colab_type": "code",
        "outputId": "14e02d7f-0af5-4383-a3ae-1a0270317f59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        }
      },
      "source": [
        "df.describe()\n",
        "air_temperature\n",
        "is_holiday\n",
        "cloud_coverage\n",
        "dew_temperature\n",
        "sea_level_pressure\t\n",
        "wind_direction\t\n",
        "wind_speed"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>building_id</th>\n",
              "      <th>meter</th>\n",
              "      <th>meter_reading</th>\n",
              "      <th>hour_cos</th>\n",
              "      <th>hour_sin</th>\n",
              "      <th>weekday_cos</th>\n",
              "      <th>weekday_sin</th>\n",
              "      <th>week_cos</th>\n",
              "      <th>week_sin</th>\n",
              "      <th>meter_reading_prev</th>\n",
              "      <th>is_equal_prev</th>\n",
              "      <th>day</th>\n",
              "      <th>IS_BAD_PRCNT</th>\n",
              "      <th>building_meter_median</th>\n",
              "      <th>building_meter_mean</th>\n",
              "      <th>building_meter_mean_45</th>\n",
              "      <th>hour</th>\n",
              "      <th>building_meter_hour_median</th>\n",
              "      <th>building_meter_hour_mean</th>\n",
              "      <th>k_fact_med_hour</th>\n",
              "      <th>weekday</th>\n",
              "      <th>building_meter_weekday_median</th>\n",
              "      <th>is_holiday</th>\n",
              "      <th>site_id</th>\n",
              "      <th>square_feet</th>\n",
              "      <th>year_built</th>\n",
              "      <th>floor_count</th>\n",
              "      <th>primary_use_ID</th>\n",
              "      <th>air_temperature</th>\n",
              "      <th>cloud_coverage</th>\n",
              "      <th>dew_temperature</th>\n",
              "      <th>precip_depth_1_hr</th>\n",
              "      <th>sea_level_pressure</th>\n",
              "      <th>wind_direction</th>\n",
              "      <th>wind_speed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>18948184.000</td>\n",
              "      <td>18948184.000</td>\n",
              "      <td>18948184.000</td>\n",
              "      <td>18948184.000</td>\n",
              "      <td>18948184.000</td>\n",
              "      <td>18948184.000</td>\n",
              "      <td>18948184.000</td>\n",
              "      <td>18948184.000</td>\n",
              "      <td>18948184.000</td>\n",
              "      <td>18948183.000</td>\n",
              "      <td>18948184.000</td>\n",
              "      <td>18948184.000</td>\n",
              "      <td>18948184.000</td>\n",
              "      <td>18948184.000</td>\n",
              "      <td>18948184.000</td>\n",
              "      <td>18293583.000</td>\n",
              "      <td>18948184.000</td>\n",
              "      <td>18948184.000</td>\n",
              "      <td>18948184.000</td>\n",
              "      <td>18948184.000</td>\n",
              "      <td>18948184.000</td>\n",
              "      <td>18948184.000</td>\n",
              "      <td>18948184.000</td>\n",
              "      <td>18948184.000</td>\n",
              "      <td>18948184.000</td>\n",
              "      <td>6974756.000</td>\n",
              "      <td>2358476.000</td>\n",
              "      <td>18948184.000</td>\n",
              "      <td>18948184.000</td>\n",
              "      <td>18948184.000</td>\n",
              "      <td>18948184.000</td>\n",
              "      <td>18078918.000</td>\n",
              "      <td>18948184.000</td>\n",
              "      <td>18948184.000</td>\n",
              "      <td>18948184.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>801.974</td>\n",
              "      <td>0.676</td>\n",
              "      <td>2232.996</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.472</td>\n",
              "      <td>0.498</td>\n",
              "      <td>0.488</td>\n",
              "      <td>0.493</td>\n",
              "      <td>2232.996</td>\n",
              "      <td>0.161</td>\n",
              "      <td>185.601</td>\n",
              "      <td>0.161</td>\n",
              "      <td>0.001</td>\n",
              "      <td>2232.996</td>\n",
              "      <td>2575.451</td>\n",
              "      <td>11.502</td>\n",
              "      <td>0.001</td>\n",
              "      <td>2232.996</td>\n",
              "      <td>23368.884</td>\n",
              "      <td>3.007</td>\n",
              "      <td>0.009</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.541</td>\n",
              "      <td>0.121</td>\n",
              "      <td>1969.248</td>\n",
              "      <td>4.052</td>\n",
              "      <td>0.220</td>\n",
              "      <td>0.595</td>\n",
              "      <td>0.316</td>\n",
              "      <td>0.685</td>\n",
              "      <td>0.984</td>\n",
              "      <td>0.620</td>\n",
              "      <td>0.470</td>\n",
              "      <td>0.175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>440.083</td>\n",
              "      <td>0.934</td>\n",
              "      <td>158278.578</td>\n",
              "      <td>0.354</td>\n",
              "      <td>0.354</td>\n",
              "      <td>0.372</td>\n",
              "      <td>0.363</td>\n",
              "      <td>0.352</td>\n",
              "      <td>0.355</td>\n",
              "      <td>158278.582</td>\n",
              "      <td>0.367</td>\n",
              "      <td>105.237</td>\n",
              "      <td>0.314</td>\n",
              "      <td>0.022</td>\n",
              "      <td>82117.057</td>\n",
              "      <td>85395.660</td>\n",
              "      <td>6.922</td>\n",
              "      <td>0.024</td>\n",
              "      <td>82265.539</td>\n",
              "      <td>1023290.661</td>\n",
              "      <td>1.997</td>\n",
              "      <td>0.039</td>\n",
              "      <td>0.034</td>\n",
              "      <td>0.348</td>\n",
              "      <td>0.127</td>\n",
              "      <td>31.279</td>\n",
              "      <td>3.071</td>\n",
              "      <td>0.231</td>\n",
              "      <td>0.144</td>\n",
              "      <td>0.306</td>\n",
              "      <td>0.178</td>\n",
              "      <td>7.683</td>\n",
              "      <td>0.091</td>\n",
              "      <td>0.314</td>\n",
              "      <td>0.118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1900.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>357.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>20.707</td>\n",
              "      <td>0.146</td>\n",
              "      <td>0.146</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.099</td>\n",
              "      <td>0.140</td>\n",
              "      <td>0.131</td>\n",
              "      <td>20.707</td>\n",
              "      <td>0.000</td>\n",
              "      <td>97.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>38.634</td>\n",
              "      <td>47.025</td>\n",
              "      <td>6.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>35.973</td>\n",
              "      <td>1.083</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.200</td>\n",
              "      <td>0.038</td>\n",
              "      <td>1951.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.497</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.548</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.563</td>\n",
              "      <td>0.194</td>\n",
              "      <td>0.111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>918.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>83.000</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.357</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.455</td>\n",
              "      <td>0.470</td>\n",
              "      <td>83.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>186.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>109.848</td>\n",
              "      <td>127.470</td>\n",
              "      <td>12.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>107.921</td>\n",
              "      <td>1.274</td>\n",
              "      <td>3.000</td>\n",
              "      <td>0.002</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.600</td>\n",
              "      <td>0.083</td>\n",
              "      <td>1970.000</td>\n",
              "      <td>4.000</td>\n",
              "      <td>0.200</td>\n",
              "      <td>0.606</td>\n",
              "      <td>0.222</td>\n",
              "      <td>0.702</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.620</td>\n",
              "      <td>0.472</td>\n",
              "      <td>0.163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1200.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>272.860</td>\n",
              "      <td>0.854</td>\n",
              "      <td>0.854</td>\n",
              "      <td>0.802</td>\n",
              "      <td>0.901</td>\n",
              "      <td>0.837</td>\n",
              "      <td>0.848</td>\n",
              "      <td>272.860</td>\n",
              "      <td>0.000</td>\n",
              "      <td>277.000</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.001</td>\n",
              "      <td>307.502</td>\n",
              "      <td>358.264</td>\n",
              "      <td>18.000</td>\n",
              "      <td>0.001</td>\n",
              "      <td>305.962</td>\n",
              "      <td>1.978</td>\n",
              "      <td>5.000</td>\n",
              "      <td>0.006</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.867</td>\n",
              "      <td>0.157</td>\n",
              "      <td>1999.000</td>\n",
              "      <td>6.000</td>\n",
              "      <td>0.400</td>\n",
              "      <td>0.700</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.827</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.675</td>\n",
              "      <td>0.750</td>\n",
              "      <td>0.242</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1448.000</td>\n",
              "      <td>3.000</td>\n",
              "      <td>21904700.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>21904700.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>366.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>3813882.148</td>\n",
              "      <td>3866686.396</td>\n",
              "      <td>23.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>4138801.770</td>\n",
              "      <td>57329462.143</td>\n",
              "      <td>6.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>2017.000</td>\n",
              "      <td>16.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>343.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       building_id        meter  meter_reading     hour_cos     hour_sin  weekday_cos  \\\n",
              "count 18948184.000 18948184.000   18948184.000 18948184.000 18948184.000 18948184.000   \n",
              "mean       801.974        0.676       2232.996        0.500        0.500        0.472   \n",
              "std        440.083        0.934     158278.578        0.354        0.354        0.372   \n",
              "min          0.000        0.000          0.000        0.000        0.000        0.000   \n",
              "25%        357.000        0.000         20.707        0.146        0.146        0.000   \n",
              "50%        918.000        0.000         83.000        0.500        0.500        0.357   \n",
              "75%       1200.000        1.000        272.860        0.854        0.854        0.802   \n",
              "max       1448.000        3.000   21904700.000        1.000        1.000        1.000   \n",
              "\n",
              "       weekday_sin     week_cos     week_sin  meter_reading_prev  is_equal_prev          day  \\\n",
              "count 18948184.000 18948184.000 18948184.000        18948183.000   18948184.000 18948184.000   \n",
              "mean         0.498        0.488        0.493            2232.996          0.161      185.601   \n",
              "std          0.363        0.352        0.355          158278.582          0.367      105.237   \n",
              "min          0.000        0.000        0.000               0.000          0.000        1.000   \n",
              "25%          0.099        0.140        0.131              20.707          0.000       97.000   \n",
              "50%          0.500        0.455        0.470              83.000          0.000      186.000   \n",
              "75%          0.901        0.837        0.848             272.860          0.000      277.000   \n",
              "max          1.000        1.000        1.000        21904700.000          1.000      366.000   \n",
              "\n",
              "       IS_BAD_PRCNT  building_meter_median  building_meter_mean  building_meter_mean_45  \\\n",
              "count  18948184.000           18948184.000         18948184.000            18293583.000   \n",
              "mean          0.161                  0.001             2232.996                2575.451   \n",
              "std           0.314                  0.022            82117.057               85395.660   \n",
              "min           0.000                  0.000                0.000                   0.000   \n",
              "25%           0.000                  0.000               38.634                  47.025   \n",
              "50%           0.000                  0.000              109.848                 127.470   \n",
              "75%           0.125                  0.001              307.502                 358.264   \n",
              "max           1.000                  1.000          3813882.148             3866686.396   \n",
              "\n",
              "              hour  building_meter_hour_median  building_meter_hour_mean  k_fact_med_hour  \\\n",
              "count 18948184.000                18948184.000              18948184.000     18948184.000   \n",
              "mean        11.502                       0.001                  2232.996        23368.884   \n",
              "std          6.922                       0.024                 82265.539      1023290.661   \n",
              "min          0.000                       0.000                     0.000            1.000   \n",
              "25%          6.000                       0.000                    35.973            1.083   \n",
              "50%         12.000                       0.000                   107.921            1.274   \n",
              "75%         18.000                       0.001                   305.962            1.978   \n",
              "max         23.000                       1.000               4138801.770     57329462.143   \n",
              "\n",
              "           weekday  building_meter_weekday_median   is_holiday      site_id  square_feet  \\\n",
              "count 18948184.000                   18948184.000 18948184.000 18948184.000 18948184.000   \n",
              "mean         3.007                          0.009        0.001        0.541        0.121   \n",
              "std          1.997                          0.039        0.034        0.348        0.127   \n",
              "min          0.000                          0.000        0.000        0.000        0.000   \n",
              "25%          1.000                          0.001        0.000        0.200        0.038   \n",
              "50%          3.000                          0.002        0.000        0.600        0.083   \n",
              "75%          5.000                          0.006        0.000        0.867        0.157   \n",
              "max          6.000                          1.000        1.000        1.000        1.000   \n",
              "\n",
              "       year_built  floor_count  primary_use_ID  air_temperature  cloud_coverage  dew_temperature  \\\n",
              "count 6974756.000  2358476.000    18948184.000     18948184.000    18948184.000     18948184.000   \n",
              "mean     1969.248        4.052           0.220            0.595           0.316            0.685   \n",
              "std        31.279        3.071           0.231            0.144           0.306            0.178   \n",
              "min      1900.000        1.000           0.000            0.000           0.000            0.000   \n",
              "25%      1951.000        1.000           0.000            0.497           0.000            0.548   \n",
              "50%      1970.000        4.000           0.200            0.606           0.222            0.702   \n",
              "75%      1999.000        6.000           0.400            0.700           0.500            0.827   \n",
              "max      2017.000       16.000           1.000            1.000           1.000            1.000   \n",
              "\n",
              "       precip_depth_1_hr  sea_level_pressure  wind_direction   wind_speed  \n",
              "count       18078918.000        18948184.000    18948184.000 18948184.000  \n",
              "mean               0.984               0.620           0.470        0.175  \n",
              "std                7.683               0.091           0.314        0.118  \n",
              "min               -1.000               0.000           0.000        0.000  \n",
              "25%                0.000               0.563           0.194        0.111  \n",
              "50%                0.000               0.620           0.472        0.163  \n",
              "75%                0.000               0.675           0.750        0.242  \n",
              "max              343.000               1.000           1.000        1.000  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ij-PYo9p8t0g",
        "colab_type": "code",
        "outputId": "c0e63b96-44f5-44a8-ee2a-25f5362b27bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        }
      },
      "source": [
        "df_test.describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>row_id</th>\n",
              "      <th>building_id</th>\n",
              "      <th>meter</th>\n",
              "      <th>hour_cos</th>\n",
              "      <th>hour_sin</th>\n",
              "      <th>weekday_cos</th>\n",
              "      <th>weekday_sin</th>\n",
              "      <th>week_cos</th>\n",
              "      <th>week_sin</th>\n",
              "      <th>building_meter_median</th>\n",
              "      <th>hour</th>\n",
              "      <th>building_meter_hour_median</th>\n",
              "      <th>weekday</th>\n",
              "      <th>building_meter_weekday_median</th>\n",
              "      <th>is_holiday</th>\n",
              "      <th>primary_use_ID</th>\n",
              "      <th>site_id</th>\n",
              "      <th>square_feet</th>\n",
              "      <th>air_temperature</th>\n",
              "      <th>cloud_coverage</th>\n",
              "      <th>dew_temperature</th>\n",
              "      <th>sea_level_pressure</th>\n",
              "      <th>wind_direction</th>\n",
              "      <th>wind_speed</th>\n",
              "      <th>NN_PRED</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>41697600.0000</td>\n",
              "      <td>41697600.0000</td>\n",
              "      <td>41697600.0000</td>\n",
              "      <td>41697600.0000</td>\n",
              "      <td>41697600.0000</td>\n",
              "      <td>41697600.0000</td>\n",
              "      <td>41697600.0000</td>\n",
              "      <td>41697600.0000</td>\n",
              "      <td>41697600.0000</td>\n",
              "      <td>41697600.0000</td>\n",
              "      <td>41697600.0000</td>\n",
              "      <td>41697600.0000</td>\n",
              "      <td>41697600.0000</td>\n",
              "      <td>41697600.0000</td>\n",
              "      <td>41697600.0000</td>\n",
              "      <td>41697600.0000</td>\n",
              "      <td>41697600.0000</td>\n",
              "      <td>41697600.0000</td>\n",
              "      <td>41697600.0000</td>\n",
              "      <td>41697600.0000</td>\n",
              "      <td>41697600.0000</td>\n",
              "      <td>41697600.0000</td>\n",
              "      <td>41697600.0000</td>\n",
              "      <td>41697600.0000</td>\n",
              "      <td>41697600.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>20848799.5000</td>\n",
              "      <td>807.5824</td>\n",
              "      <td>0.6643</td>\n",
              "      <td>0.5000</td>\n",
              "      <td>0.5000</td>\n",
              "      <td>0.4751</td>\n",
              "      <td>0.4995</td>\n",
              "      <td>0.4913</td>\n",
              "      <td>0.5000</td>\n",
              "      <td>0.0013</td>\n",
              "      <td>11.5000</td>\n",
              "      <td>0.0014</td>\n",
              "      <td>3.0000</td>\n",
              "      <td>0.0088</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.2105</td>\n",
              "      <td>0.5391</td>\n",
              "      <td>0.1219</td>\n",
              "      <td>-0.0003</td>\n",
              "      <td>0.1318</td>\n",
              "      <td>12.2029</td>\n",
              "      <td>13.7401</td>\n",
              "      <td>19.5723</td>\n",
              "      <td>0.6340</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>12037060.4366</td>\n",
              "      <td>429.7680</td>\n",
              "      <td>0.9278</td>\n",
              "      <td>0.3536</td>\n",
              "      <td>0.3536</td>\n",
              "      <td>0.3722</td>\n",
              "      <td>0.3625</td>\n",
              "      <td>0.3508</td>\n",
              "      <td>0.3566</td>\n",
              "      <td>0.0215</td>\n",
              "      <td>6.9222</td>\n",
              "      <td>0.0236</td>\n",
              "      <td>2.0034</td>\n",
              "      <td>0.0375</td>\n",
              "      <td>0.0023</td>\n",
              "      <td>0.2301</td>\n",
              "      <td>0.3423</td>\n",
              "      <td>0.1327</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.1338</td>\n",
              "      <td>6.3944</td>\n",
              "      <td>0.0915</td>\n",
              "      <td>9.9943</td>\n",
              "      <td>0.0308</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>-0.0003</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>-10.6000</td>\n",
              "      <td>13.1524</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.5728</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>10424399.7500</td>\n",
              "      <td>404.7500</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.1464</td>\n",
              "      <td>0.1464</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0990</td>\n",
              "      <td>0.1405</td>\n",
              "      <td>0.1516</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>5.7500</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.0005</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2000</td>\n",
              "      <td>0.0365</td>\n",
              "      <td>-0.0003</td>\n",
              "      <td>0.0178</td>\n",
              "      <td>7.6000</td>\n",
              "      <td>13.6999</td>\n",
              "      <td>11.2593</td>\n",
              "      <td>0.6131</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>20848799.5000</td>\n",
              "      <td>900.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.5000</td>\n",
              "      <td>0.5000</td>\n",
              "      <td>0.3569</td>\n",
              "      <td>0.5000</td>\n",
              "      <td>0.5144</td>\n",
              "      <td>0.5000</td>\n",
              "      <td>0.0002</td>\n",
              "      <td>11.5000</td>\n",
              "      <td>0.0002</td>\n",
              "      <td>3.0000</td>\n",
              "      <td>0.0020</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0667</td>\n",
              "      <td>0.6000</td>\n",
              "      <td>0.0823</td>\n",
              "      <td>-0.0003</td>\n",
              "      <td>0.0978</td>\n",
              "      <td>12.4000</td>\n",
              "      <td>13.7472</td>\n",
              "      <td>20.2222</td>\n",
              "      <td>0.6307</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>31273199.2500</td>\n",
              "      <td>1194.2500</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.8536</td>\n",
              "      <td>0.8536</td>\n",
              "      <td>0.8019</td>\n",
              "      <td>0.9010</td>\n",
              "      <td>0.8373</td>\n",
              "      <td>0.8484</td>\n",
              "      <td>0.0006</td>\n",
              "      <td>17.2500</td>\n",
              "      <td>0.0006</td>\n",
              "      <td>5.0000</td>\n",
              "      <td>0.0061</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.8667</td>\n",
              "      <td>0.1579</td>\n",
              "      <td>-0.0003</td>\n",
              "      <td>0.2133</td>\n",
              "      <td>17.0667</td>\n",
              "      <td>13.7922</td>\n",
              "      <td>27.4074</td>\n",
              "      <td>0.6514</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>41697599.0000</td>\n",
              "      <td>1448.0000</td>\n",
              "      <td>3.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.9965</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>23.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>6.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.0667</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>-0.0003</td>\n",
              "      <td>0.6000</td>\n",
              "      <td>26.7000</td>\n",
              "      <td>14.0407</td>\n",
              "      <td>40.0000</td>\n",
              "      <td>0.9689</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             row_id   building_id         meter      hour_cos      hour_sin   weekday_cos  \\\n",
              "count 41697600.0000 41697600.0000 41697600.0000 41697600.0000 41697600.0000 41697600.0000   \n",
              "mean  20848799.5000      807.5824        0.6643        0.5000        0.5000        0.4751   \n",
              "std   12037060.4366      429.7680        0.9278        0.3536        0.3536        0.3722   \n",
              "min          0.0000        0.0000        0.0000        0.0000        0.0000        0.0000   \n",
              "25%   10424399.7500      404.7500        0.0000        0.1464        0.1464        0.0000   \n",
              "50%   20848799.5000      900.0000        0.0000        0.5000        0.5000        0.3569   \n",
              "75%   31273199.2500     1194.2500        1.0000        0.8536        0.8536        0.8019   \n",
              "max   41697599.0000     1448.0000        3.0000        1.0000        1.0000        1.0000   \n",
              "\n",
              "        weekday_sin      week_cos      week_sin  building_meter_median          hour  \\\n",
              "count 41697600.0000 41697600.0000 41697600.0000          41697600.0000 41697600.0000   \n",
              "mean         0.4995        0.4913        0.5000                 0.0013       11.5000   \n",
              "std          0.3625        0.3508        0.3566                 0.0215        6.9222   \n",
              "min          0.0000        0.0000        0.0000                 0.0000        0.0000   \n",
              "25%          0.0990        0.1405        0.1516                 0.0001        5.7500   \n",
              "50%          0.5000        0.5144        0.5000                 0.0002       11.5000   \n",
              "75%          0.9010        0.8373        0.8484                 0.0006       17.2500   \n",
              "max          1.0000        0.9965        1.0000                 1.0000       23.0000   \n",
              "\n",
              "       building_meter_hour_median       weekday  building_meter_weekday_median    is_holiday  \\\n",
              "count               41697600.0000 41697600.0000                  41697600.0000 41697600.0000   \n",
              "mean                       0.0014        3.0000                         0.0088        0.0001   \n",
              "std                        0.0236        2.0034                         0.0375        0.0023   \n",
              "min                        0.0000        0.0000                         0.0000        0.0000   \n",
              "25%                        0.0001        1.0000                         0.0005        0.0000   \n",
              "50%                        0.0002        3.0000                         0.0020        0.0000   \n",
              "75%                        0.0006        5.0000                         0.0061        0.0000   \n",
              "max                        1.0000        6.0000                         1.0000        0.0667   \n",
              "\n",
              "       primary_use_ID       site_id   square_feet  air_temperature  cloud_coverage  \\\n",
              "count   41697600.0000 41697600.0000 41697600.0000    41697600.0000   41697600.0000   \n",
              "mean           0.2105        0.5391        0.1219          -0.0003          0.1318   \n",
              "std            0.2301        0.3423        0.1327           0.0000          0.1338   \n",
              "min            0.0000        0.0000        0.0000          -0.0003          0.0000   \n",
              "25%            0.0000        0.2000        0.0365          -0.0003          0.0178   \n",
              "50%            0.0667        0.6000        0.0823          -0.0003          0.0978   \n",
              "75%            0.4000        0.8667        0.1579          -0.0003          0.2133   \n",
              "max            1.0000        1.0000        1.0000          -0.0003          0.6000   \n",
              "\n",
              "       dew_temperature  sea_level_pressure  wind_direction    wind_speed       NN_PRED  \n",
              "count    41697600.0000       41697600.0000   41697600.0000 41697600.0000 41697600.0000  \n",
              "mean           12.2029             13.7401         19.5723        0.6340        0.0000  \n",
              "std             6.3944              0.0915          9.9943        0.0308        0.0000  \n",
              "min           -10.6000             13.1524          0.0000        0.5728        0.0000  \n",
              "25%             7.6000             13.6999         11.2593        0.6131        0.0000  \n",
              "50%            12.4000             13.7472         20.2222        0.6307        0.0000  \n",
              "75%            17.0667             13.7922         27.4074        0.6514        0.0000  \n",
              "max            26.7000             14.0407         40.0000        0.9689        0.0000  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HcOED4IDv0k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "show_plot(hist) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3y8HyLW1fPvb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvoCZeopmulB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nn = load_model(DIR, 'model_nn')\n",
        "opt = Adam(lr = 0.05)\n",
        "nn.compile(optimizer = opt, loss = mse)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}