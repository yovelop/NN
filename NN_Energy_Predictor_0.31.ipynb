{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of NN Energy Predictor.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yovelop/NN/blob/master/NN_Energy_Predictor_0.31.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zO1azhvf_t9_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "5efb96db-239f-4b7c-e8ba-45ceb42c0db4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "DIR = '/content/drive/My Drive/Colab Notebooks/ENSaver/'\n",
        "DIR_SAVE = '/content/drive/My Drive/Colab Notebooks/ENSaver/31/'\n",
        "#drive.flush_and_unmount()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRgT9oDx_vpi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 969
        },
        "outputId": "9ab9d77c-2d58-4795-de16-4827c17afa85"
      },
      "source": [
        "#Импорты\n",
        "  import numpy as np # linear algebra\n",
        "  import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "  import gc\n",
        "\n",
        "  import matplotlib.pyplot as plt\n",
        "  import matplotlib.style\n",
        "  matplotlib.style.use('ggplot')\n",
        "\n",
        "  from sys import getsizeof\n",
        "\n",
        "  import os\n",
        "  for dirname, _, filenames in os.walk(DIR):\n",
        "      for filename in filenames:\n",
        "          print(os.path.join(dirname, filename))\n",
        "\n",
        "  pd.options.mode.chained_assignment = None  # default='warn'\n",
        "  import warnings\n",
        "  pd.set_option('display.max_rows', 500)\n",
        "  pd.set_option('display.max_columns', 500)\n",
        "  pd.set_option('display.width', 100)\n",
        "  warnings.filterwarnings('ignore')\n",
        "  np.set_printoptions(precision = 3, suppress  = True)\n",
        "  pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
        "\n",
        "  def reduce_mem_usage(df, verbose = False):\n",
        "      start_mem_usg = df.memory_usage().sum() / 1024**2 \n",
        "      print(\"Memory usage of properties dataframe is :\",start_mem_usg,\" MB\")\n",
        "      NAlist = [] # Keeps track of columns that have missing values filled in. \n",
        "      for col in df.columns:\n",
        "          if (df[col].dtype != object) &  (df[col].dtype != 'datetime64[ns]'):  # Exclude strings            \n",
        "              # Print current column type\n",
        "              if verbose:  \n",
        "                print(\"******************************\")\n",
        "                print(\"Column: \",col)\n",
        "                print(\"dtype before: \",df[col].dtype)            \n",
        "              # make variables for Int, max and min\n",
        "              IsInt = False\n",
        "              mx = df[col].max()\n",
        "              mn = df[col].min()\n",
        "              if verbose:\n",
        "                print(\"min for this col: \",mn)\n",
        "                print(\"max for this col: \",mx)\n",
        "              # Integer does not support NA, therefore, NA needs to be filled\n",
        "              if not np.isfinite(df[col]).all(): \n",
        "                  NAlist.append(col)\n",
        "                  df[col].fillna(mn-1,inplace=True)  \n",
        "                    \n",
        "              # test if column can be converted to an integer\n",
        "              asint = df[col].fillna(0).astype(np.int64)\n",
        "              result = abs(df[col] - asint)\n",
        "              result = result.sum()\n",
        "              if result > -0.01 and result < 0.01:\n",
        "                  IsInt = True            \n",
        "              # Make Integer/unsigned Integer datatypes\n",
        "              if IsInt:\n",
        "                  if mn >= 0:\n",
        "                      if mx < 255:\n",
        "                          df[col] = df[col].astype(np.uint8)\n",
        "                      elif mx < 65535:\n",
        "                          df[col] = df[col].astype(np.uint16)\n",
        "                      elif mx < 4294967295:\n",
        "                          df[col] = df[col].astype(np.uint32)\n",
        "                      else:\n",
        "                          df[col] = df[col].astype(np.uint64)\n",
        "                  else:\n",
        "                      if mn > np.iinfo(np.int8).min and mx < np.iinfo(np.int8).max:\n",
        "                          df[col] = df[col].astype(np.int8)\n",
        "                      elif mn > np.iinfo(np.int16).min and mx < np.iinfo(np.int16).max:\n",
        "                          df[col] = df[col].astype(np.int16)\n",
        "                      elif mn > np.iinfo(np.int32).min and mx < np.iinfo(np.int32).max:\n",
        "                          df[col] = df[col].astype(np.int32)\n",
        "                      elif mn > np.iinfo(np.int64).min and mx < np.iinfo(np.int64).max:\n",
        "                          df[col] = df[col].astype(np.int64)    \n",
        "              # Make float datatypes 32 bit\n",
        "              else:\n",
        "                  df[col] = df[col].astype(np.float32)\n",
        "              \n",
        "              # Print new column type\n",
        "              if verbose:\n",
        "                print(\"dtype after: \",df[col].dtype)\n",
        "                print(\"******************************\")\n",
        "      # Print final result\n",
        "      print(\"___MEMORY USAGE AFTER COMPLETION:___\")\n",
        "      mem_usg = df.memory_usage().sum() / 1024**2 \n",
        "      print(\"Memory usage is: \",mem_usg,\" MB\")\n",
        "      print(\"This is \",100*mem_usg/start_mem_usg,\"% of the initial size\")\n",
        "      return df, NAlist\n",
        "\n",
        "  def show_plot(hist):\n",
        "    plt.plot(hist.history['loss'])\n",
        "    plt.plot(hist.history['val_loss'])\n",
        "    plt.title('Model NN')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend(['Train','Val'])\n",
        "    plt.show()\n",
        "    \n",
        "    plt.plot(hist.history['loss'])\n",
        "    plt.plot(hist.history['val_loss'])\n",
        "    plt.title('Model NN')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.ylim([1,2])\n",
        "    plt.legend(['Train','Val'])\n",
        "    plt.show()\n",
        "\n",
        "    plt.plot(hist.history['loss'])\n",
        "    plt.plot(hist.history['val_loss'])\n",
        "    plt.title('Model NN')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.ylim([0,1])\n",
        "    plt.legend(['Train','Val'])\n",
        "    plt.show()\n",
        "\n",
        "  #Импорты Керас:\n",
        "  from keras.models import Sequential, load_model\n",
        "\n",
        "  from keras.layers import Dense\n",
        "  from keras.initializers import TruncatedNormal, Constant\n",
        "  from keras.regularizers import l1,l2,l1_l2\n",
        "  from keras.optimizers import Adam\n",
        "  import keras.backend as K\n",
        "\n",
        "  from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "  #from keras.utils import plot_model\n",
        "  from keras.losses import mean_squared_error as mse #, mean_absolute_percentage_error as mape\n",
        "\n",
        "  def RMSLE(y_true, y_pred):\n",
        "    return K.pow( K.mean( K.pow(K.log(y_true+1) - K.log(y_pred+1),2.00000)),0.5000)\n",
        "\n",
        "  def MSLE(y_true, y_pred):\n",
        "    return K.mean( K.pow(K.log(y_true+1) - K.log(y_pred+1),2.00000))\n",
        "\n",
        "  def MALE(y_true, y_pred):\n",
        "    return K.mean( K.abs(K.log(y_true+1) - K.log(y_pred+1)))\n",
        "\n",
        "  def tweedieloss(y_true, y_pred):\n",
        "      return K.mean(  K.pow(    K.pow(backend.maximum(0.000,K.maximum(0.013000,y_true)),0.5)  -   K.pow(K.maximum(0.013000,y_pred),0.5)   , 2 ) / K.pow(K.maximum(0.013000,y_pred),0.5)\n",
        "                  )\n",
        "\n",
        "  def tweedieloss_bkp(y_true, y_pred):\n",
        "      p=1.5\n",
        "      dev = 2 * (K.pow(K.maximum(0.000,y_true), 2-p)/((1-p) * (2-p)) -\n",
        "                    y_true * K.pow(y_pred, 1-p)/(1-p) +\n",
        "                    K.pow(y_pred, 2-p)/(2-p))\n",
        "      return K.mean(dev)\n",
        "\n",
        "  def VAL_ (y_true, y_pred):\n",
        "      return  K.maximum(0.0330000, K.sum(y_pred))/ K.maximum(0.033000, K.sum(y_true)) \n",
        "      \n",
        "  def VAL_2 (y_true, y_pred):\n",
        "      return  K.minimum( 5.000000, K.exp ( K.abs( K.log( VAL_ (y_true, y_pred))))-1)\n",
        "  \n",
        "  def VAL_3 (y_true, y_pred):\n",
        "      return  K.exp ( K.abs( K.log( VAL_ (y_true, y_pred))))-1\n",
        "\n",
        "  def MAPE_ (y_true, y_pred):\n",
        "      return K.mean( K.minimum( 5.000000,  K.abs(y_true - y_pred)/ K.maximum(0.033000, y_true)) )\n",
        "      \n",
        "  def MAE_(y_true, y_pred):\n",
        "      return K.sum( K.abs(y_true - y_pred))/ K.maximum(0.033000, K.sum(y_true))\n",
        "\n",
        "  def MSE_(y_true, y_pred):\n",
        "      return K.sum( K.pow(y_true - y_pred,2.00000))/ K.maximum(0.033000,  K.sum(K.pow(y_true,2.00000)))\n",
        "\n",
        "  def MAE_MAPE(y_true, y_pred):\n",
        "      return (\n",
        "                        MAE_(y_true, y_pred)\n",
        "          +  0.250000 * MAPE_ (y_true, y_pred)\n",
        "      )\n",
        "              \n",
        "  def MAE_VAL_MAPE(y_true, y_pred):\n",
        "      return (\n",
        "                        MAE_(y_true, y_pred)\n",
        "          + 1.800000 *   VAL_2 (y_true, y_pred)          \n",
        "          + 0.950000 *   MAPE_ (y_true, y_pred)\n",
        "          )\n",
        "\n",
        "  def MAE_VAL(y_true, y_pred):\n",
        "      return (\n",
        "                        MAE_(y_true, y_pred)\n",
        "          + 0.800000 *   VAL_2 (y_true, y_pred)                     \n",
        "              )\n",
        "\n",
        "  def MAPE_VAL(y_true, y_pred):\n",
        "      return (\n",
        "                      MAPE_ (y_true, y_pred)\n",
        "          + 0.4000 *  VAL_2 (y_true, y_pred)             \n",
        "              )\n",
        "\n",
        "  def MSE_VAL_MAPE(y_true, y_pred):\n",
        "      return (\n",
        "            5.000000 *   MSE_(y_true, y_pred)\n",
        "          + 2.200000 *   VAL_2 (y_true, y_pred)          \n",
        "          + 0.750000 *   MAPE_ (y_true, y_pred)\n",
        "          )\n",
        "\n",
        "  def MASPE_VAL(y_true, y_pred):\n",
        "      return (\n",
        "                        MAE_(y_true, y_pred)               \n",
        "          + 0.500000 *   MSE_(y_true, y_pred)\n",
        "          + 1.200000 *   VAL_2 (y_true, y_pred)          \n",
        "          + 0.250000 *   MAPE_ (y_true, y_pred)\n",
        "          )\n",
        "  \n",
        "  def MAE_RMSLE(y_true, y_pred):\n",
        "      return (\n",
        "            1.000000 *   MAE_   (y_true, y_pred)\n",
        "          + 2.000000 *   MSLE  (y_true, y_pred)          \n",
        "          )  \n",
        "\n",
        "  def MAPE_RMSLE(y_true, y_pred):\n",
        "      return (\n",
        "            1.000000 *   MAPE_   (y_true, y_pred)\n",
        "          + 0.100000 *   MSLE  (y_true, y_pred)          \n",
        "          )  \n",
        "  \n",
        "  def MAPE_VAL_RMSLE(y_true, y_pred):\n",
        "      return (\n",
        "            0.500000 *   MAPE_   (y_true, y_pred)\n",
        "          + 1.500000 *   MSLE   (y_true, y_pred)    \n",
        "          + 0.300000 *   VAL_2   (y_true, y_pred)      \n",
        "          )  \n",
        " \n",
        "  import keras.metrics\n",
        "  keras.metrics.MAE_ = MAE_\n",
        "  keras.metrics.VAL_ = VAL_\n",
        "  keras.metrics.VAL_2 = VAL_2\n",
        "  keras.metrics.MAPE_ = MAPE_\n",
        "  keras.metrics.MSE_ = MSE_\n",
        "  keras.metrics.tweedieloss = tweedieloss\n",
        "  keras.metrics.MAE_RMSLE = MAE_RMSLE\n",
        "  keras.metrics.MAPE_RMSLE = MAPE_RMSLE\n",
        "  keras.metrics.MAPE_VAL_RMSLE = MAPE_VAL_RMSLE\n",
        "  keras.metrics.RMSLE = RMSLE\n",
        "  keras.metrics.MSLE = MSLE\n",
        "  keras.metrics.MALE = MALE\n",
        "\n",
        "  import keras.losses\n",
        "  keras.losses.MAE_VAL_MAPE = MAE_VAL_MAPE\n",
        "  keras.losses.MSE_VAL_MAPE = MSE_VAL_MAPE\n",
        "  keras.losses.MAE_ = MAE_\n",
        "  keras.losses.MASPE_VAL = MASPE_VAL\n",
        "  keras.losses.tweedieloss = tweedieloss\n",
        "  keras.losses.MAE_RMSLE = MAE_RMSLE\n",
        "  keras.losses.MAPE_RMSLE = MAPE_RMSLE\n",
        "  keras.losses.MAPE_VAL_RMSLE = MAPE_VAL_RMSLE\n",
        "  keras.losses.RMSLE = RMSLE\n",
        "  keras.losses.MSLE = MSLE\n",
        "  keras.losses.MALE = MALE\n",
        "\n",
        "  class MyCustomCallback(keras.callbacks.Callback):\n",
        "    \n",
        "    def __init__(self, epochs, stats_print_step): \n",
        "        \n",
        "        self.__epochs = epochs\n",
        "        self.__stats_print_step = stats_print_step\n",
        "    \n",
        "    def on_train_begin(self, logs={}):\n",
        "        pass\n",
        "        #print('on_train_begin', logs)\n",
        " \n",
        "    def on_train_end(self, logs={}):\n",
        "        pass\n",
        "        #print('on_train_end', logs)\n",
        " \n",
        "    def on_epoch_begin(self, epoch, logs={}):\n",
        "        pass\n",
        " \n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if ((epoch < 5) or (epoch % self.__stats_print_step == 0)) :\n",
        "            print('# ' + str('{:04d}'.format(epoch + 1)) + ' | ' + self.get_stats_by_epoch(logs))\n",
        "        if epoch == 2:\n",
        "            print('.......')\n",
        "        if epoch == self.__epochs - 1:\n",
        "            print('# ' + str('{:04d}'.format(epoch + 1)) + ' | ' + self.get_stats_by_epoch(logs))\n",
        "        else:\n",
        "            print('# ' + str('{:04d}'.format(epoch + 1)) + ' | ' + self.get_stats_by_epoch(logs), end=\"\\r\")\n",
        " \n",
        "    def on_batch_begin(self, batch, logs={}):\n",
        "        pass\n",
        "        #print('on_batch_begin', batch, logs)\n",
        " \n",
        "    def on_batch_end(self, batch, logs={}):\n",
        "        pass\n",
        "        #print('on_batch_end', batch, logs)\n",
        "\n",
        "    def get_stats_by_epoch(self, logs):\n",
        "        \n",
        "        is_test = True\n",
        "        s = ''\n",
        "        \n",
        "        for key, value in logs.items(): \n",
        "            if is_test:\n",
        "                if 'val_' not in str(key):\n",
        "                    s += ' /// '\n",
        "                    is_test = False\n",
        "            if is_test:\n",
        "                s += ' ' + str(key).replace('val_', 'TST_') + ': ' + \"{0:.4f}\".format(value)\n",
        "            else:\n",
        "                s += ' ' + 'TRN_' + str(key) + ': ' + \"{0:.4f}\".format(value)\n",
        "\n",
        "        return s #'val_loss: ' + \"{0:.4f}\".format(logs['val_loss']) + ' | loss: ' + \"{0:.4f}\".format(logs['loss'])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/ENSaver/building_metadata.csv\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/model_nn.h5\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/model_nn.json\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/test.csv\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/train.csv\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/weather_test.csv\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/weather_train.csv\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/0HANDLY_SAVED.MODEL\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/1HANDLY_SAVED.MODEL\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/2HANDLY_SAVED.MODEL\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/3HANDLY_SAVED.MODEL\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/0HANDLY_SAVED2.MODEL\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/1HANDLY_SAVED2.MODEL\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/3HANDLY_SAVED2.MODEL\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/3HANDLY_SAVED3.MODEL\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/2HANDLY_SAVED2.MODEL\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/scaler.pickle\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/3HANDLY_SAVED03.MODEL\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/2HANDLY_SAVED03.MODEL\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/2HANDLY_SAVED3.MODEL\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/0HANDLY_SAVED3.MODEL\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/1HANDLY_SAVED_3.MODEL\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/3HANDLY_SAVED0_3.MODEL\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/2HANDLY_SAVED_3.MODEL\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/3HANDLY_SAVED_3best.MODEL\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/3HANDLY_SAVED_3.MODEL\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/0HANDLY_SAVED_3.MODEL\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/0HANDLY_SAVED_0best.MODEL\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/0HANDLY_SAVED_3best.MODEL\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/1HANDLY_SAVED_3best.MODEL\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/2HANDLY_SAVED_3best.MODEL\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/DF_TRAIN_REDUCED3.FTHR\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/scaler3.pickle\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/1HANDLY_SAVED3.MODEL\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/best_nn_2.model\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/best_nn_3.model\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/best_nn_0.model\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/best_nn_1.model\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/31/1HANDLY_SAVED3best-.MODEL\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/31/DF_TRAIN_REDUCED3.FTHR\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/31/DF_TEST_REDUCED3.FTHR\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/31/0HANDLY_SAVED3.MODEL\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/31/0HANDLY_SAVED3best.MODEL\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/31/3HANDLY_SAVED3bestMALE.MODEL\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/31/3HANDLY_SAVED3best.MODEL\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/31/3HANDLY_SAVED3.MODEL\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/31/2HANDLY_SAVED3.MODEL\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/31/2HANDLY_SAVED3best.MODEL\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/31/1HANDLY_SAVED3best.MODEL\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/31/1HANDLY_SAVED3.MODEL\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/31/0HANDLY_SAVED_3best.MODEL\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/31/0HANDLY_SAVED_3.MODEL\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/31/scaler31.pickle\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/31/1HANDLY_SAVED_3best.MODEL\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/31/1HANDLY_SAVED_3.MODEL\n",
            "/content/drive/My Drive/Colab Notebooks/ENSaver/31/1HANDLY_SAVED_3bestMSLEVAL.MODEL\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Fv4ErMY_vsQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#0: electricity, 1: chilledwater, 2: steam, 3: hotwater\n",
        "#  Подготовка данных\n",
        "  df = pd.read_csv(DIR + \"train.csv\", engine = 'python')\n",
        "  df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
        "\n",
        "  df['hour_cos'] = np.cos(df['timestamp'].dt.hour * 2 * np.pi / 24)\n",
        "  df['hour_sin'] = np.sin(df['timestamp'].dt.hour * 2 * np.pi / 24)\n",
        "\n",
        "  df['weekday_cos'] = np.cos(df['timestamp'].dt.weekday * 2 * np.pi / 7)\n",
        "  df['weekday_sin'] = np.sin(df['timestamp'].dt.weekday * 2 * np.pi / 7)\n",
        "\n",
        "  df['week_cos'] = np.cos(df['timestamp'].dt.week * 2 * np.pi / 53)\n",
        "  df['week_sin'] = np.sin(df['timestamp'].dt.week * 2 * np.pi / 53)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g52hlFMS2cpu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Очистка от подозрительных нулей\n",
        "  #print(df[df['building_id']==2][['timestamp','meter_reading','meter','ds_zero','de_zero','is_bad_zero']].head(20))\n",
        "  df = df.sort_values(by = ['meter','building_id','timestamp'])\n",
        "  df['meter_reading_prev'] = 0\n",
        "\n",
        "  #for bid in df['building_id'].unique():\n",
        "  #  for met in df['meter'].unique():\n",
        "  df['meter_reading_prev'] = df['meter_reading'].shift()\n",
        "  df['is_equal_prev']= (df['meter_reading_prev'] == df['meter_reading'] )*1\n",
        "\n",
        "  df['day'] = df['timestamp'].dt.dayofyear\n",
        "  df_bad_rows = df.groupby(by=['building_id','day','meter'], as_index = False)['is_equal_prev'].mean()\n",
        "  df_bad_rows.rename({\"is_equal_prev\": \"IS_BAD_PRCNT\"}, axis='columns', inplace=True)\n",
        "\n",
        "  df = pd.merge(df, df_bad_rows, how = 'inner', on = ['building_id','day','meter'])\n",
        "  #print(df_bad_rows[df_bad_rows['building_id']==109].head(365))\n",
        "  del df_bad_rows \n",
        "\n",
        "  #print(df[df['building_id']==2][['timestamp','meter_reading','is_equal_prev','IS_BAD_PRCNT','day']].head(30))\n",
        "# Добавление медиан\n",
        "  # Добавление медианы по метрике постройки\n",
        "  if 1==1:\n",
        "    #df_tmp = df[df['IS_BAD_PRCNT']<0.45]\n",
        "    df_median = df.groupby(by=['building_id','meter']) ['meter_reading'].median()\n",
        "    df_median.name = 'building_meter_median'\n",
        "    df_mean = df.groupby(by=['building_id','meter']) ['meter_reading'].mean()\n",
        "    df_mean.name = 'building_meter_mean'\n",
        "    df_median = pd.merge(df_median, df_mean, how = 'inner', on = ['building_id','meter'])\n",
        "    df_median['building_meter_median'] = ( df_median['building_meter_median'] * 27.000 + df_median['building_meter_mean'])/28.000\n",
        "    \n",
        "    df_median2 = df[df['IS_BAD_PRCNT']<0.45].groupby(by=['building_id','meter']) ['meter_reading'].median()\n",
        "    df_median2.name = 'building_meter_median_45'\n",
        "    df_mean2 = df[df['IS_BAD_PRCNT']<0.45].groupby(by=['building_id','meter']) ['meter_reading'].mean()\n",
        "    df_mean2.name = 'building_meter_mean_45'\n",
        "    df_median2 = pd.merge(df_median2, df_mean2, how = 'inner', on = ['building_id','meter'])\n",
        "    df_median2['building_meter_median_45'] = ( df_median2['building_meter_median_45'] * 27.000 + df_median2['building_meter_mean_45'])/28.000\n",
        "    df_median = pd.merge(df_median, df_median2, how = 'left', on = ['building_id','meter'])\n",
        "\n",
        "    df_median['building_meter_median'] = np.where(df_median['building_meter_median_45'] >= 0, df_median['building_meter_median_45'], df_median['building_meter_median'])\n",
        "    df_median.drop(columns=['building_meter_median_45'], inplace = True)\n",
        "\n",
        "    df = pd.merge(df, df_median, how = 'inner', on = ['building_id','meter'])\n",
        "    del df_median , df_mean, df_median2, df_mean2\n",
        "    gc.collect()\n",
        "    #print(len(df))\n",
        "  # Добавление медианы по часу, по неделе, метрике постройки\n",
        "  if 1==1:\n",
        "    df['hour'] = df['timestamp'].dt.hour\n",
        "    df_median = df.groupby(by=['building_id','hour','meter'])['meter_reading'].median()\n",
        "    df_median.name = 'building_meter_hour_median'\n",
        "    df_mean = df.groupby (by=['building_id','hour','meter']) ['meter_reading'].mean()\n",
        "    df_mean.name = 'building_meter_hour_mean'\n",
        "    df_median = pd.merge(df_median, df_mean, how = 'inner', on = ['building_id','hour','meter'])\n",
        "    df_median['building_meter_hour_median'] = (df_median['building_meter_hour_median'] * 9.000000 + df_median['building_meter_hour_mean'])/10.000000\n",
        "    #print(len(df))\n",
        "\n",
        "    df_median2 = df[df['IS_BAD_PRCNT']<0.75].groupby(by=['building_id','hour','meter'])['meter_reading'].median()\n",
        "    df_median2.name = 'building_meter_hour_median_all'\n",
        "    df_mean2 = df[df['IS_BAD_PRCNT']<0.75].groupby (by=['building_id','hour','meter']) ['meter_reading'].mean()\n",
        "    df_mean2.name = 'building_meter_hour_mean_all'\n",
        "    df_median2 = pd.merge(df_median2, df_mean2, how = 'inner', on = ['building_id','hour','meter'])\n",
        "    df_median2['building_meter_hour_median_all'] = (df_median2['building_meter_hour_median_all'] * 9.000000 + df_median2['building_meter_hour_mean_all'])/10.000000\n",
        "    df_median2.drop(columns=['building_meter_hour_mean_all'], inplace = True)\n",
        "    df_median = pd.merge(df_median, df_median2, how = 'left', on = ['building_id','hour','meter'])\n",
        "    \n",
        "    df_median['building_meter_hour_median'] = np.where(df_median['building_meter_hour_median_all'] >= 0, df_median['building_meter_hour_median_all'], df_median['building_meter_hour_median'])\n",
        "    #print(len(df))\n",
        "\n",
        "    df_median.drop(columns=['building_meter_hour_median_all'], inplace = True)\n",
        "    df_median2 = df[df['IS_BAD_PRCNT']<0.45].groupby(by=['building_id','hour','meter'])['meter_reading'].median()\n",
        "    df_median2.name = 'building_meter_hour_median_45'\n",
        "    df_mean2 = df[df['IS_BAD_PRCNT']<0.45].groupby (by=['building_id','hour','meter']) ['meter_reading'].mean()\n",
        "    df_mean2.name = 'building_meter_hour_mean_45'\n",
        "    df_median2 = pd.merge(df_median2, df_mean2, how = 'inner', on = ['building_id','hour','meter'])\n",
        "    df_median2['building_meter_hour_median_45'] = (df_median2['building_meter_hour_median_45'] * 9.000000 + df_median2['building_meter_hour_mean_45'])/10.000000\n",
        "    df_median2.drop(columns=['building_meter_hour_mean_45'], inplace = True)\n",
        "    df_median = pd.merge(df_median, df_median2, how = 'left', on = ['building_id','hour','meter'])\n",
        "    \n",
        "    df_median['building_meter_hour_median'] = np.where(df_median['building_meter_hour_median_45'] >= 0, df_median['building_meter_hour_median_45'], df_median['building_meter_hour_median'])\n",
        "    df_median.drop(columns=['building_meter_hour_median_45'], inplace = True)\n",
        "\n",
        "    df = pd.merge(df, df_median, how = 'left', on = ['building_id','hour','meter'])\n",
        "    #print(len(df))\n",
        "\n",
        "    del df_median , df_mean, df_median2, df_mean2\n",
        "    gc.collect()\n",
        "    df['k_fact_med_hour']=np.exp( np.abs( np.log( (df['meter_reading']+0.01)/(df['building_meter_hour_median']+0.01)) ) )\n",
        "\n",
        "    df['weekday'] = df['timestamp'].dt.weekday\n",
        "    df_median = df.groupby(by=['building_id','weekday','meter'])['meter_reading'].median()\n",
        "    df_median.name = 'building_meter_weekday_median'\n",
        "    df = pd.merge(df, df_median, how = 'inner', on = ['building_id','weekday','meter'])\n",
        "    del df_median \n",
        "\n",
        "    holidays = [\"2016-01-01\", \"2016-01-18\", \"2016-02-15\", \"2016-05-30\", \"2016-07-04\",\n",
        "                      \"2016-09-05\", \"2016-10-10\", \"2016-11-11\", \"2016-11-24\", \"2016-12-26\",\n",
        "                      \"2017-01-02\", \"2017-01-16\", \"2017-02-20\", \"2017-05-29\", \"2017-07-04\",\n",
        "                      \"2017-09-04\", \"2017-10-09\", \"2017-11-10\", \"2017-11-23\", \"2017-12-25\",\n",
        "                      \"2018-01-01\", \"2018-01-15\", \"2018-02-19\", \"2018-05-28\", \"2018-07-04\",\n",
        "                      \"2018-09-03\", \"2018-10-08\", \"2018-11-12\", \"2018-11-22\", \"2018-12-25\",\n",
        "                      \"2019-01-01\"]\n",
        "    df[\"is_holiday\"] = (df.timestamp.isin(holidays)).astype(int)\n",
        "    del holidays\n",
        "    #print(len(df))\n",
        "  # Подстановка параметров сооружения\n",
        "  if 1==1:\n",
        "    building_df = pd.read_csv(DIR + \"building_metadata.csv\", engine = 'python')\n",
        "    from sklearn.preprocessing import LabelEncoder\n",
        "    le = LabelEncoder()\n",
        "    building_df[\"primary_use_ID\"] = le.fit_transform(building_df[\"primary_use\"])\n",
        "    #building_df['floor_count'].fillna(building_df['floor_count'].mean(), inplace= True)\n",
        "    #building_df['year_built'].fillna(building_df['year_built'].mean, inplace= True)\n",
        "    #building_df['primary_use'] = building_df['primary_use'].astype('category')\n",
        "    #building_df = pd.get_dummies(building_df)\n",
        "\n",
        "    df = df.merge(building_df, left_on = \"building_id\", right_on = \"building_id\", how = \"left\")\n",
        "    df.head(5)\n",
        "    del building_df\n",
        "    gc.collect()\n",
        "\n",
        "    # Деление по магазинам на обучающую и тестовую выборки\n",
        "      # building_df = pd.read_csv(DIR + \"building_metadata.csv\", engine = 'python')\n",
        "      # building_df = building_df.sort_values(by = ['site_id','primary_use'])\n",
        "      # building_df['is_val'] = np.where(building_df['building_id'] % 5 == 0 , 1 , 0)\n",
        "      # print(building_df.groupby(['primary_use','site_id'])['is_val'].agg(['count', 'sum']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIDKj_YCb_bD",
        "colab_type": "code",
        "outputId": "5798e17f-7eea-4992-ff0a-fcaefc886871",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Вставка данных погоды\n",
        "#Восстановление пустых данных погоды через соседей по линейной инетрполяции\n",
        "  df_weather = pd.read_csv(DIR + \"weather_train.csv\", engine = 'python')\n",
        "  df_weather['timestamp'] = pd.to_datetime(df_weather['timestamp'])\n",
        "\n",
        "  #weather_train.groupby('site_id').apply(lambda group: group.isna().sum())\n",
        "  df_times = df.drop_duplicates(['site_id','timestamp'])[['site_id','timestamp']]\n",
        "  df_times = pd.merge(df_times, df_weather, how = 'left', on = ['site_id','timestamp'])\n",
        "  df_times = df_times.sort_values(by = ['site_id','timestamp'])\n",
        "  \n",
        "  df_times = df_times.groupby('site_id').apply(lambda group: group.interpolate(limit_direction='both'))\n",
        "  df_times = df_times.groupby('timestamp').apply(lambda group: group.interpolate(limit_direction='both'))\n",
        "  df = pd.merge(df, df_times, how = 'left', on = ['site_id','timestamp'])\n",
        "  #print(df_times.describe())\n",
        "  del df_weather, df_times\n",
        "  gc.collect()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxPaU99v4PI-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Сохранение выборки\n",
        "  #reduce_mem_usage(df)\n",
        "  df.to_feather(DIR_SAVE + 'DF_TRAIN_REDUCED3.FTHR')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6XbWpxAUnQb",
        "colab_type": "text"
      },
      "source": [
        "  Скорость"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asr3-4DHF_sx",
        "colab_type": "code",
        "outputId": "4a1da19a-8839-4f75-e863-b27c472b0cb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "# Загрузка выборки\n",
        "  df = pd.read_feather(DIR_SAVE + 'DF_TRAIN_REDUCED3.FTHR')\n",
        "  gc.collect()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ArrowInvalid",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mArrowInvalid\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-e8939c6eeff1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_feather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDIR_SAVE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'DF_TRAIN_REDUCED3.FTHR'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/feather_format.py\u001b[0m in \u001b[0;36mread_feather\u001b[0;34m(path, columns, use_threads)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfeather\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_feather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnthreads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint_use_threads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfeather\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_feather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_threads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muse_threads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyarrow/feather.py\u001b[0m in \u001b[0;36mread_feather\u001b[0;34m(source, columns, use_threads)\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \"\"\"\n\u001b[0;32m--> 213\u001b[0;31m     \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFeatherReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_threads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_threads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyarrow/feather.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, source)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0m_check_pandas_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyarrow/feather.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.FeatherReader.open\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyarrow/error.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mArrowInvalid\u001b[0m: File is too small to be a well-formed file"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_Em3Xm6rdeV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Out_Columns = 'meter_reading'\n",
        "In_Columns = [ 'hour_cos','hour_sin', 'weekday_cos', 'weekday_sin', 'week_cos', 'week_sin',\n",
        "       'site_id', 'square_feet',\n",
        "       'primary_use_ID', 'is_holiday',\n",
        "       'air_temperature', 'cloud_coverage',\n",
        "       'dew_temperature', 'sea_level_pressure',\n",
        "       'wind_direction', 'wind_speed',\n",
        "       'building_meter_median','building_meter_hour_median','building_meter_weekday_median',\n",
        "       #КАНДИДАТЫ нА ИСКЛЮЧЕНИЕ:\n",
        "          #'year_built', 'floor_count', 'precip_depth_1_hr',\n",
        "          #  'primary_use_Education', 'primary_use_Entertainment/public assembly', 'primary_use_Food sales and service', 'primary_use_Healthcare',\n",
        "          #  'primary_use_Lodging/residential','primary_use_Manufacturing/industrial', 'primary_use_Office',\n",
        "          #  'primary_use_Other', 'primary_use_Parking', 'primary_use_Public services', 'primary_use_Religious worship',\n",
        "          #  'primary_use_Retail', 'primary_use_Services', 'primary_use_Technology/science', 'primary_use_Utility','primary_use_Warehouse/storage',\n",
        "       ]\n",
        "# Нормализация\n",
        "if 1==1:\n",
        "  df.dropna(subset = In_Columns + [Out_Columns], inplace=True)\n",
        "\n",
        "  #print(df[['air_temperature', 'cloud_coverage','dew_temperature', 'sea_level_pressure','wind_direction', 'wind_speed']].describe())\n",
        "  from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, OneHotEncoder\n",
        "  scaler =  MinMaxScaler (copy=True, feature_range=(0, 1))                                  #quantile_range  = (15.0,85.0)) #Normalizer #(copy=True, feature_range=(-1, 1)) # MinMaxScaler(copy=True, feature_range=(-1, 1)) #StandardScaler() #MinMaxScaler(copy=True, feature_range=(-1, 1)) # RobustScaler()\n",
        "  scaler.fit( df[In_Columns] )\n",
        "  df[In_Columns]     = pd.DataFrame(data = scaler.transform( df[In_Columns]) , columns = df[In_Columns].columns   ) \n",
        "  gc.collect()\n",
        "\n",
        "  #print(df[['air_temperature', 'cloud_coverage','dew_temperature', 'sea_level_pressure','wind_direction', 'wind_speed']].describe())\n",
        "\n",
        "  import pickle\n",
        "  with open(DIR_SAVE+'scaler31.pickle', 'wb') as handle:\n",
        "    pickle.dump(scaler, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "    pickle.dump(In_Columns, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "    pickle.dump(Out_Columns, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "  \n",
        "  #with open('filename.pickle', 'rb') as handle:\n",
        "  #  b = pickle.load(handle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laaKxqJQn2XC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "9f74968c-3fbd-4e26-a54b-d071bcd3e33d"
      },
      "source": [
        "#Всякое инфо:\n",
        "  #df[['building_id','hour','meter','building_meter_hour_mean','building_meter_hour_median','meter_reading','k_fact_med_hour']].head(10)\n",
        "  #Инфо о корявости данных:\n",
        "  if 1== 1:\n",
        "    print('0 Всего:',df[df['meter']==0].shape, 'Откинуть:', df[(df['meter']==0) & (df['IS_BAD_PRCNT']>0.45)].shape)\n",
        "    print('1 Всего:',df[df['meter']==1].shape, 'Откинуть:', df[(df['meter']==1) & (df['IS_BAD_PRCNT']>0.75)].shape)\n",
        "    print('2 Всего:',df[df['meter']==2].shape, 'Откинуть:', df[(df['meter']==2) & (df['IS_BAD_PRCNT']>0.75)].shape)\n",
        "    print('3 Всего:',df[df['meter']==3].shape, 'Откинуть:', df[(df['meter']==3) & (df['IS_BAD_PRCNT']>0.75)].shape)\n",
        "    # #Вывести кол-во пустот по полям. Затем заполнить из средним значением по полю\n",
        "    #   for col in df.columns:\n",
        "    #     print(col)\n",
        "    #     for met in df['meter'].unique():\n",
        "    #       if np.sum(df[col].isnull()) > 0:\n",
        "    #         print(met)\n",
        "    #         print(np.sum(df[col].isnull()))\n",
        "\n",
        "    #         df_col = df.groupby(by=['building_id','meter'], as_index = False)[col].mean()\n",
        "    #         df_col.rename({col: \"tmp\"}, axis='columns', inplace=True)\n",
        "    #         df = df.merge(df_col, left_on = ['building_id','meter'], right_on = ['building_id','meter'], how = \"left\")\n",
        "    #         df[col].fillna( df_col['tmp'], inplace = True)\n",
        "    #         df.drop(columns = ['tmp'],inplace = True)\n",
        "    #         del df_col\n",
        "\n",
        "    #         df_col = df.groupby(by=['meter'], as_index = False)[col].mean()\n",
        "    #         df_col.rename({col: \"tmp\"}, axis='columns', inplace=True)\n",
        "    #         df = df.merge(df_col, left_on = ['meter'], right_on = ['meter'], how = \"left\")\n",
        "    #         df[col].fillna( df_col['tmp'], inplace = True)\n",
        "    #         df.drop(columns = ['tmp'],inplace = True)\n",
        "    #         del df_col\n",
        "\n",
        "    #         df[col].fillna( df[col].mean(), inplace = True)\n",
        "\n",
        "  print(len(df[df['IS_BAD_PRCNT']<0.45]), len(df))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-616cbc0d2c67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'0 Всего:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'meter'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Откинуть:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'meter'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'IS_BAD_PRCNT'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0.45\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'1 Всего:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'meter'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Откинуть:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'meter'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'IS_BAD_PRCNT'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0.75\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'2 Всего:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'meter'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Откинуть:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'meter'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'IS_BAD_PRCNT'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0.75\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'3 Всего:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'meter'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Откинуть:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'meter'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'IS_BAD_PRCNT'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0.75\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WwbRnvu0Vfb",
        "colab_type": "text"
      },
      "source": [
        "**-- -- -- -- -- -- -- -- --РАСЧЁТ НЕЙРОНОК -- -- -- -- -- -- -- -- --**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aup6pDdkDoZZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#0: electricity, 1: chilledwater, 2: steam, 3: hotwater\n",
        "# РАСЧЁТ НЕЙРОНОК:\n",
        "  reg = 0.00001\n",
        "  batch_size = 2048\n",
        "  epochs = 12\n",
        "  meter = 0\n",
        "\n",
        "  earlyStopping = EarlyStopping(monitor='loss', patience=100, verbose=1, mode='min')\n",
        "  reduce_lr_loss = ReduceLROnPlateau(monitor='loss', factor=0.3, patience=7, verbose=1, min_delta=1e-3, mode='min')\n",
        "  model_checkpoint = ModelCheckpoint(monitor='loss', save_best_only=True, filepath = DIR + 'best_nn_' + str(meter) + '.model', save_weights_only = False, verbose=0, mode='min')\n",
        "\n",
        "  init = TruncatedNormal(mean=0.0, stddev=0.05, seed=159)\n",
        "  bias = Constant(value = 1e-3)\n",
        "  \n",
        "  if 0==0:\n",
        "    meter = 0\n",
        "    opt = Adam(lr = 0.0009)\n",
        "    bias = Constant(value = 0.1)\n",
        "\n",
        "    nn_0 = Sequential()\n",
        "    nn_0.add(Dense(60, input_shape = df[In_Columns].shape[1:], activation = 'tanh', kernel_regularizer=l2(reg), kernel_initializer = 'normal'))\n",
        "    nn_0.add(Dense(60, activation = 'tanh',  kernel_initializer = 'normal'))\n",
        "    nn_0.add(Dense(60, activation = 'tanh',  kernel_initializer = 'normal', kernel_regularizer=l1(reg)))\n",
        "    nn_0.add(Dense(60, activation = 'tanh',  kernel_initializer = 'normal'))\n",
        "    nn_0.add(Dense(1, activation = 'relu', kernel_initializer = 'normal'))\n",
        "\n",
        "    nn_0.compile(optimizer = opt, loss = RMSLE, metrics=[ MAE_, RMSLE, VAL_, 'mse', MAPE_ ])\n",
        "    \n",
        "    val = df[(df['meter']==meter) & (df['day']%6==0)]\n",
        "    hist = nn_0.fit( df[(df['meter']==meter) & (df['IS_BAD_PRCNT']<0.45)][In_Columns], df[(df['meter']==meter) & (df['IS_BAD_PRCNT']<0.45)][Out_Columns], batch_size = batch_size, verbose = 0\n",
        "                    , epochs = epochs, shuffle = True, callbacks=[MyCustomCallback(epochs, 1), earlyStopping, reduce_lr_loss,model_checkpoint]\n",
        "                    , validation_data=(val[In_Columns], val[Out_Columns])\n",
        "                    ) \n",
        "    nn_0.save(DIR_SAVE + str(meter) + 'HANDLY_SAVED3.MODEL')\n",
        "    gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3l71K063-sz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Дообучение!\n",
        "  meter = 0\n",
        "  nn_tmp = keras.models.load_model (DIR_SAVE + str(meter) + 'HANDLY_SAVED3best.MODEL')\n",
        "  \n",
        "  earlyStopping = EarlyStopping(monitor='loss', patience=100, verbose=1, mode='min')\n",
        "  reduce_lr_loss = ReduceLROnPlateau(monitor='loss', factor=0.3, patience=7, verbose=1, min_delta=1e-3, mode='min')\n",
        "  model_checkpoint = ModelCheckpoint(monitor='loss', save_best_only=True, filepath = DIR + 'best_nn_' + str(meter) + '.model', save_weights_only = False, verbose=0, mode='min')\n",
        "\n",
        "  for lr in [0.007]:\n",
        "    opt = Adam(lr = lr)\n",
        "    epochs = 20\n",
        "    batch_size = 2048\n",
        "    \n",
        "    val = df[ ( df['meter'] == meter ) & ( df['day']%6 == 0 ) & ( df['IS_BAD_PRCNT'] < 0.25 ) ]\n",
        "    tar = df[ ( df['meter'] == meter ) & ( df['day']%6 != 0 ) & ( df['IS_BAD_PRCNT'] < 0.25 ) ]\n",
        "\n",
        "    print('*'*9, lr, '*'*33)\n",
        "    nn_tmp.compile(optimizer = opt, loss = MSLE, metrics=[ MAE_, RMSLE, VAL_, 'mse', MAPE_ ])\n",
        "    hist = nn_tmp.fit( tar[In_Columns], tar[Out_Columns], batch_size = batch_size, verbose = 0\n",
        "                    , epochs = epochs, shuffle = True, callbacks=[ MyCustomCallback(epochs, 1), earlyStopping, reduce_lr_loss]\n",
        "                    , validation_data=(val[In_Columns], val[Out_Columns])\n",
        "                  )\n",
        "    \n",
        "    nn_tmp.save(DIR_SAVE + str(meter) + 'HANDLY_SAVED3.MODEL')\n",
        "    del val, tar\n",
        "    gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YIKx_MLrPz1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#История ошибок:\n",
        "    # 0 - 0.0009|  TST_loss: 0.3072 TST_MAE_: 0.1830 TST_RMSLE: 0.2885 TST_VAL_: 0.9286 TST_mean_squared_error: 27367.7978 TST_MAPE_: 0.2095 ///  TRN_loss: 0.3087 TRN_MAE_: 0.1822 TRN_RMSLE: 0.2900 TRN_VAL_: 0.9145 TRN_mean_squared_error: 28093.1744 TRN_MAPE_: 0.2099\n",
        "    #Ошибка 0:  1.0561841191435806 Ошибка 0 (VAL):  1.0494709359899506 Ошибка 0 (VAL_чист):  0.3156408787681845 Ошибка 0 (VAL_чист):  0.2912135296204619\n",
        "    #Ошибка 0:  1.089517078219136  Ошибка 0 (VAL):  1.0830665788767133 Ошибка 0 (VAL_чист):  0.32307141312090654 Ошибка 0 (VAL_чист):  0.2984998363948374\n",
        "      #Ошибка 0:  1.1066134245452997 Ошибка 0 (VAL):  1.100076285523506  Ошибка 0 (VAL_чист):  0.3034311145371631  Ошибка 0 (VAL_чист):  0.2775469766783069\n",
        "      #Ошибка 0:  1.1030193587492334 Ошибка 0 (VAL):  1.0966634328629619 Ошибка 0 (VAL_чист):  0.31766628931864216 Ошибка 0 (VAL_чист):  0.2947707690483286\n",
        "      #Ошибка 0:  1.11466815037453   Ошибка 0 (VAL):  1.1077580860952245 Ошибка 0 (VAL_чист):  0.36128705026829394 Ошибка 0 (VAL_чист):  0.3413465001124272\n",
        "      #Ошибка 0:  1.1159494605817608 Ошибка 0 (VAL):  1.108724065391442  Ошибка 0 (VAL_чист):  0.41233170157550914 Ошибка 0 (VAL_чист):  0.39348967701947696\n",
        "      #Ошибка 0:  1.1161679797276878 Ошибка 0 (VAL):  1.1092097596156938 Ошибка 0 (VAL_чист):  0.44160974266951963 Ошибка 0 (VAL_чист):  0.42010303885086286\n",
        "\n",
        "    # 1 - 0.0005|  TST_loss: 0.8377 TST_MAE_: 0.3466 TST_RMSLE: 0.8257 TST_VAL_: 0.8746 TST_mean_squared_error: 73145611.7727 TST_MAPE_: 0.7010 ///  TRN_loss: 0.7481 TRN_MAE_: 0.4902 TRN_RMSLE: 0.8462 TRN_VAL_: 0.6074 TRN_mean_squared_error: 72128872.1765 TRN_MAPE_: 0.6687\n",
        "      # 1 - 0.0001|TST_loss: 0.7542 TST_MAE_: 0.3283 TST_RMSLE: 0.7290 TST_VAL_: 0.8683 TST_mean_squared_error: 76403735.2854 TST_MAPE_: 0.6021 ///  TRN_loss: 0.7802 TRN_MAE_: 0.4676 TRN_RMSLE: 0.7550 TRN_VAL_: 0.6303 TRN_mean_squared_error: 73674603.6638 TRN_MAPE_: 0.5863\n",
        "    #Ошибка 1:  1.3667812429174853 Ошибка 1 (VAL):  1.4029945499659757 Ошибка 1 (VAL_чист):  0.7281895570502563 Ошибка 1 (VAL_чист):  0.6149901419154421\n",
        "    #Ошибка 1:  1.4674246744239359 Ошибка 1 (VAL):  1.4998371692364791 Ошибка 1 (VAL_чист):  0.7936248109822508 Ошибка 1 (VAL_чист):  0.6763456453516548\n",
        "      #Ошибка 1:  1.4093558221005378 Ошибка 1 (VAL):  1.4441369966619106 Ошибка 1 (VAL_чист):  0.7674733833817231 Ошибка 1 (VAL_чист):  0.6515382783996846\n",
        "      #Ошибка 1:  1.4341247310132184 Ошибка 1 (VAL):  1.470060550523646  Ошибка 1 (VAL_чист):  0.7119020527708861 Ошибка 1 (VAL_чист):  0.5956327249468123\n",
        "      #Ошибка 1:  1.4425109745549276 Ошибка 1 (VAL):  1.4775752439079195 Ошибка 1 (VAL_чист):  0.7288509072605465 Ошибка 1 (VAL_чист):  0.6118551437247776\n",
        "      #Ошибка 1:  1.4794444121249946 Ошибка 1 (VAL):  1.5150122006735316 Ошибка 1 (VAL_чист):  0.756747550880491  Ошибка 1 (VAL_чист):  0.6370399718876337\n",
        "      #Ошибка 1:  1.478101110840682  Ошибка 1 (VAL):  1.511827390230529  Ошибка 1 (VAL_чист):  0.783690921235087  Ошибка 1 (VAL_чист):  0.6632605785239761\n",
        "      #Ошибка 1:  1.4972289288697942 Ошибка 1 (VAL):  1.5308990895435475 Ошибка 1 (VAL_чист):  0.7908108700644174 Ошибка 1 (VAL_чист):  0.6680700428184277\n",
        "      #Ошибка 1:  1.4817989404715222 Ошибка 1 (VAL):  1.5134076940639456 Ошибка 1 (VAL_чист):  0.8309019241778273 Ошибка 1 (VAL_чист):  0.7141481643815152\n",
        "      #Ошибка 1:  2.0022889004617257 Ошибка 1 (VAL):  2.0253074918080394 Ошибка 1 (VAL_чист):  1.2310513863169474 Ошибка 1 (VAL_чист):  0.9879544727674974\n",
        "      #Ошибка 1:  2.6107180409629787 Ошибка 1 (VAL):  2.62604593096904   Ошибка 1 (VAL_чист):  1.9195246386655913 Ошибка 1 (VAL_чист):  1.6554061978310448  \n",
        "\n",
        "    # 2 - 0.001   TST_loss: 0.7344 TST_MAE_: 0.3078 TST_RMSLE: 0.7344 TST_VAL_: 0.8726 TST_mean_squared_error: 58769617031.5805 TST_MAPE_: 0.5561 ///  TRN_loss: 0.8222 TRN_MAE_: 0.3435 TRN_RMSLE: 0.8222 TRN_VAL_: 0.9566 TRN_mean_squared_error: 49363914383.6177 TRN_MAPE_: 0.5457\n",
        "    #Ошибка 2:  1.412089120404965 Ошибка 2 (VAL):  1.4307337011199783 Ошибка 2 (VAL_чист):  0.7681072077180416 Ошибка 2 (VAL_чист):  0.5899942163118871\n",
        "    #Ошибка 2:  1.426513398531468  Ошибка 2 (VAL):  1.4374305117701076 Ошибка 2 (VAL_чист):  0.772188164217135  Ошибка 2 (VAL_чист):  0.5912252674990405\n",
        "    #Ошибка 2:  1.4711884860839508 Ошибка 2 (VAL):  1.4865450169842518 Ошибка 2 (VAL_чист):  0.7729726956881282 Ошибка 2 (VAL_чист):  0.5883201286605256\n",
        "    #Ошибка 2:  1.584895359471045  Ошибка 2 (VAL):  1.595279682390636  Ошибка 2 (VAL_чист):  0.8156651059087789 Ошибка 2 (VAL_чист):  0.6075341541971445\n",
        "      #Ошибка 2:  1.4342707989405115 Ошибка 2 (VAL):  1.445994967988859 Ошибка 2 (VAL_чист):  0.7751574158428917 Ошибка 2 (VAL_чист):  0.5934912395707151\n",
        "      #Ошибка 2:  1.4827505038656164 Ошибка 2 (VAL):  1.485921011505542 Ошибка 2 (VAL_чист):  0.776992332783179  Ошибка 2 (VAL_чист):  0.5982294414393752\n",
        "      #Ошибка 2:  1.5380867615202842 Ошибка 2 (VAL):  1.534869021740785 Ошибка 2 (VAL_чист):  0.8030714183598706 Ошибка 2 (VAL_чист):  0.6100693949499996\n",
        "      #Ошибка 2:  1.544696542956114  Ошибка 2 (VAL):  1.542512084385534 Ошибка 2 (VAL_чист):  0.8014154858977849 Ошибка 2 (VAL_чист):  0.6164432453479144\n",
        "      #Ошибка 2:  1.7437661049074722 Ошибка 2 (VAL):  1.739711067404998 Ошибка 2 (VAL_чист):  0.9019782041199934 Ошибка 2 (VAL_чист):  0.5395988401269427\n",
        "      #Ошибка 2:  1.896885277819035  Ошибка 2 (VAL):  1.886131540810365 Ошибка 2 (VAL_чист):  0.9932058892117468 Ошибка 2 (VAL_чист):  0.5522634244728574\n",
        "      #Ошибка 2:  2.0635301300600255 Ошибка 2 (VAL):  2.053288059566308 Ошибка 2 (VAL_чист):  1.110914319240778  Ошибка 2 (VAL_чист):  0.6531255552895722\n",
        "\n",
        "    #3 - 0.001  TST_loss: 1.0529 TST_MAE_: 0.4362 TST_RMSLE: 1.0238 TST_VAL_: 0.8601 TST_mean_squared_error: 9330985.8708 TST_MAPE_: 0.7937 ///  TRN_loss: 1.1771 TRN_MAE_: 0.4945 TRN_RMSLE: 1.1481 TRN_VAL_: 0.6708 TRN_mean_squared_error: 8529478.6350 TRN_MAPE_: 0.7768\n",
        "    #\n",
        "    #Ошибка 3:  1.377944923928185  Ошибка 3 (VAL):  1.4566577965681673 Ошибка 3 (VAL_чист):  1.0939884892538    Ошибка 3 (VAL_чист):  0.7449018059731893\n",
        "    #Ошибка 3:  1.399828310279418  Ошибка 3 (VAL):  1.4663188962845461 Ошибка 3 (VAL_чист):  1.0923668037824816 Ошибка 3 (VAL_чист):  0.7516940691334648\n",
        "    #Ошибка 3:  1.5811641937262615 Ошибка 3 (VAL):  1.6275882770258792 Ошибка 3 (VAL_чист):  1.1791615642131834 Ошибка 3 (VAL_чист):  0.8287557439810707\n",
        "      #Ошибка 3:  1.4481746307415786 Ошибка 3 (VAL):  1.5064615469019023 Ошибка 3 (VAL_чист):  1.0977130637106953 Ошибка 3 (VAL_чист):  0.7436043184254891\n",
        "      #Ошибка 3:  1.705222807620306 Ошибка 3 (VAL):  1.7366032113308998 Ошибка 3 (VAL_чист):  1.0745064725069604 Ошибка 3 (VAL_чист):  0.7306249462611814\n",
        "      #Ошибка 3:  1.8077285134043073 Ошибка 3 (VAL):  1.8127781024652065 Ошибка 3 (VAL_чист):  1.110416279220095 Ошибка 3 (VAL_чист):  0.7830760480518036\n",
        "      #Ошибка 3:  2.4125767152544086 Ошибка 3 (VAL):  2.4083597850289715 Ошибка 3 (VAL_чист):  1.4406713860219067 Ошибка 3 (VAL_чист):  0.6769461395256884"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKq7llhGn682",
        "colab_type": "code",
        "outputId": "b017d6dc-657b-4732-f34d-a3d002eddc98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#Предсказание из 4х значений = 0:\n",
        "  meter = 1\n",
        "  nn_tmp = keras.models.load_model (DIR_SAVE + str(meter) + 'HANDLY_SAVED3.MODEL')\n",
        "  \n",
        "  gc.collect()\n",
        "  col_name_tmp = 'NN_PRED_'+str(meter) \n",
        "  df['NN_PRED'] = 0.0000\n",
        "  df[col_name_tmp] = nn_tmp.predict(df[In_Columns], batch_size = 400000) \n",
        "  df['NN_PRED'] = np.where(df['meter'] == meter, df[col_name_tmp], df['NN_PRED'])\n",
        "  df.drop(columns = [col_name_tmp], inplace = True) #, 'NN_PRED_1', 'NN_PRED_2', 'NN_PRED_3'\n",
        "  #df.drop(columns = ['Value_x', 'Value_y'])\n",
        "  gc.collect()\n",
        "\n",
        "  df['NN_ERR'] = np.abs(df['NN_PRED']-df['meter_reading'])\n",
        "  df['k_NN_ERR'] = (df['NN_PRED']+0.33)/(df['meter_reading']+0.33)\n",
        "\n",
        "  #print( np.sqrt( np.mean( np.power(np.log(df['meter_reading']+1) - np.log(df['NN_PRED']+1),2.00000)))     )\n",
        "  print('Ошибка ' + str(meter) + ': '  , np.sqrt( np.mean( np.power(np.log(df[df['meter']==meter]['meter_reading']+1) - np.log(df[df['meter']==meter]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка ' + str(meter) + ' (VAL): ', np.sqrt( np.mean( np.power(np.log(df[(df['meter']==meter) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[(df['meter']==meter) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка ' + str(meter) + ' (VAL_чист): ', np.sqrt( np.mean( np.power(np.log(df[ (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==meter) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[ (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==meter) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка ' + str(meter) + ' (VAL_чист): ', np.sqrt( np.mean( np.power(np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==meter) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==meter) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        )\n",
        "  gc.collect()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ошибка 1:  1.3756467607519423 Ошибка 1 (VAL):  1.4121384639175951 Ошибка 1 (VAL_чист):  0.726048282888039 Ошибка 1 (VAL_чист):  0.6114338537265513\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mf8-ceMw8N1q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if 1==1:\n",
        "  reg = 0.00001\n",
        "  meter = 1\n",
        "  epochs = 30\n",
        "  batch_size = 2048\n",
        "  opt = Adam(lr = 0.002)\n",
        "  bias = Constant(value = 1)\n",
        "\n",
        "  earlyStopping = EarlyStopping(monitor='loss', patience=100, verbose=1, mode='min')\n",
        "  reduce_lr_loss = ReduceLROnPlateau(monitor='loss', factor=0.3, patience=9, verbose=1, min_delta=1e-3, mode='min')\n",
        "  model_checkpoint = ModelCheckpoint(monitor='loss', save_best_only=True, filepath = DIR + 'best_nn_' + str(meter) + '.model', save_weights_only = False, verbose=0, mode='min')\n",
        "\n",
        "  nn_1 = Sequential()\n",
        "  nn_1.add(Dense(60, input_shape = df[In_Columns].shape[1:], activation = 'tanh', kernel_regularizer=l2(reg), kernel_initializer = 'normal', bias_initializer=bias))\n",
        "  nn_1.add(Dense(60, activation = 'tanh',  kernel_initializer = 'normal', bias_initializer=bias))\n",
        "  nn_1.add(Dense(60, activation = 'tanh',  kernel_initializer = 'normal', bias_initializer=bias, kernel_regularizer=l1(reg)))\n",
        "  nn_1.add(Dense(60, activation = 'tanh',  kernel_initializer = 'normal', bias_initializer=bias))\n",
        "  nn_1.add(Dense(1, activation = 'relu', kernel_initializer = 'normal', bias_initializer=bias))\n",
        "\n",
        "  nn_1.compile(optimizer = opt, loss = mse, metrics=[ MAE_, RMSLE, VAL_, 'mse', MAPE_ ])\n",
        "  \n",
        "  val = df[ ( df['meter'] == meter ) & ( df['day']%6 == 0 ) & ( df['IS_BAD_PRCNT'] < 0.45 ) ]\n",
        "  tar = df[ ( df['meter'] == meter ) & ( df['day']%6 != 0 ) & ( df['IS_BAD_PRCNT'] < 0.45 ) ]\n",
        "\n",
        "  hist = nn_1.fit( tar[In_Columns], tar[Out_Columns]\n",
        "                  , batch_size = batch_size\n",
        "                  , verbose = 0\n",
        "                  , epochs = epochs, shuffle = True\n",
        "                  , callbacks=[MyCustomCallback(epochs, 1), earlyStopping, reduce_lr_loss,model_checkpoint]\n",
        "                  , validation_data=(val[In_Columns], val[Out_Columns])\n",
        "                  ) \n",
        "  nn_1.save(DIR_SAVE + str(meter) + 'HANDLY_SAVED3.MODEL')\n",
        "  gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7EreUBaUoeP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nn_tmp.save(DIR_SAVE + str(meter) + 'HANDLY_SAVED3best.MODEL')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2H75zE193qOf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Дообучение!\n",
        "  meter = 1\n",
        "  nn_tmp = keras.models.load_model (DIR_SAVE + str(meter) + 'HANDLY_SAVED3best.MODEL')\n",
        "\n",
        "  earlyStopping = EarlyStopping(monitor='loss', patience=100, verbose=1, mode='min')\n",
        "  reduce_lr_loss = ReduceLROnPlateau(monitor='loss', factor=0.3, patience=9, verbose=1, min_delta=2e-4, mode='min')\n",
        "  model_checkpoint = ModelCheckpoint(monitor='loss', save_best_only=True, filepath = DIR + 'best_nn_' + str(meter) + '.model', save_weights_only = False, verbose=0, mode='min')\n",
        "\n",
        "  for lr in [0.0005]:\n",
        "    opt = Adam(lr = lr)\n",
        "    epochs = 30\n",
        "    batch_size = 1024\n",
        "    \n",
        "    val = df[ ( df['meter'] == meter ) & ( df['day']%6 == 0 ) & ( df['IS_BAD_PRCNT'] < 0.75 ) ]\n",
        "    tar = df[ ( df['meter'] == meter ) & ( df['day']%6 != 0 ) & ( df['IS_BAD_PRCNT'] < 0.75 ) ]\n",
        "\n",
        "    print('*'*23, lr, '*'*33, len(tar), len(val))\n",
        "    nn_tmp.compile(optimizer = opt, loss = \n",
        "                   MSLE, metrics=[ MAE_, RMSLE, VAL_, 'mse', MAPE_ ])\n",
        "    hist = nn_tmp.fit( tar[In_Columns], tar[Out_Columns], batch_size = batch_size, verbose = 0\n",
        "                    , epochs = epochs, shuffle = True, callbacks=[ MyCustomCallback(epochs, 1), earlyStopping, reduce_lr_loss]\n",
        "                    , validation_data=(val[In_Columns], val[Out_Columns])\n",
        "                  )\n",
        "    \n",
        "    nn_tmp.save(DIR_SAVE + str(meter) + 'HANDLY_SAVED3.MODEL')\n",
        "    del val, tar\n",
        "    gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHKu4TMG8ROI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if 2==2:\n",
        "  reg = 0.00001\n",
        "  meter = 2\n",
        "  epochs = 15\n",
        "  batch_size = 200\n",
        "  opt = Adam(lr = 0.003)\n",
        "  bias = Constant(value = 1)\n",
        "\n",
        "  earlyStopping = EarlyStopping(monitor='loss', patience=100, verbose=1, mode='min')\n",
        "  reduce_lr_loss = ReduceLROnPlateau(monitor='loss', factor=0.3, patience=9, verbose=1, min_delta=1e-3, mode='min')\n",
        "  model_checkpoint = ModelCheckpoint(monitor='loss', save_best_only=True, filepath = DIR + 'best_nn_' + str(meter) + '.model', save_weights_only = False, verbose=0, mode='min')\n",
        "\n",
        "  nn_1 = Sequential()\n",
        "  nn_1.add(Dense(99, input_shape = df[In_Columns].shape[1:], activation = 'relu', kernel_initializer = 'normal', bias_initializer=bias))\n",
        "  nn_1.add(Dense(99, activation = 'relu',  kernel_initializer = 'normal', bias_initializer=bias))\n",
        "  nn_1.add(Dense(99, activation = 'relu',  kernel_initializer = 'normal', bias_initializer=bias))\n",
        "  nn_1.add(Dense(99, activation = 'relu',  kernel_initializer = 'normal', bias_initializer=bias))\n",
        "  nn_1.add(Dense(1, activation = 'relu', kernel_initializer = 'normal', bias_initializer=bias))\n",
        "\n",
        "  nn_1.compile(optimizer = opt, loss = MALE, metrics=[ MAE_, RMSLE, VAL_, 'mse', MAPE_ ])\n",
        "  \n",
        "  val = df[ ( df['meter'] == meter ) & ( df['day']%6 == 0 ) & ( df['IS_BAD_PRCNT'] < 0.15 ) ]\n",
        "  tar = df[ ( df['meter'] == meter ) & ( df['day']%6 != 0 ) & ( df['IS_BAD_PRCNT'] < 0.15 ) & (df['k_fact_med_hour']<50) ]\n",
        "\n",
        "  hist = nn_1.fit( tar[In_Columns], tar[Out_Columns]\n",
        "                  , batch_size = batch_size\n",
        "                  , verbose = 0\n",
        "                  , epochs = epochs, shuffle = True\n",
        "                  , callbacks=[MyCustomCallback(epochs, 1), earlyStopping, reduce_lr_loss,model_checkpoint]\n",
        "                  , validation_data=(val[In_Columns], val[Out_Columns])\n",
        "                  ) \n",
        "  nn_1.save(DIR_SAVE + str(meter) + 'HANDLY_SAVED3.MODEL')\n",
        "  gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdad7yTx8Uri",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if 3==3:\n",
        "  reg = 0.00001\n",
        "  meter = 3\n",
        "  epochs = 20\n",
        "  batch_size = 200\n",
        "  opt = Adam(lr = 0.003)\n",
        "  bias = Constant(value = 1)\n",
        "\n",
        "  earlyStopping = EarlyStopping(monitor='loss', patience=100, verbose=1, mode='min')\n",
        "  reduce_lr_loss = ReduceLROnPlateau(monitor='loss', factor=0.3, patience=9, verbose=1, min_delta=1e-3, mode='min')\n",
        "  model_checkpoint = ModelCheckpoint(monitor='loss', save_best_only=True, filepath = DIR + 'best_nn_' + str(meter) + '.model', save_weights_only = False, verbose=0, mode='min')\n",
        "\n",
        "  nn_3 = Sequential()\n",
        "  nn_3.add(Dense(99, input_shape = df[In_Columns].shape[1:], activation = 'relu', kernel_regularizer=l2(reg) , kernel_initializer = 'normal', bias_initializer=bias))\n",
        "  nn_3.add(Dense(99, activation = 'relu',  kernel_initializer = 'normal', bias_initializer=bias))\n",
        "  nn_3.add(Dense(99, activation = 'relu',  kernel_initializer = 'normal', bias_initializer=bias, kernel_regularizer=l1(reg)))\n",
        "  nn_3.add(Dense(99, activation = 'relu',  kernel_initializer = 'normal', bias_initializer=bias))\n",
        "  nn_3.add(Dense(1, activation = 'relu', kernel_initializer = 'normal', bias_initializer=bias))\n",
        "\n",
        "  nn_3.compile(optimizer = opt, loss = MALE, metrics=[ MAE_, RMSLE, VAL_, 'mse', MAPE_ ])\n",
        "  \n",
        "  val = df[ ( df['meter'] == meter ) & ( df['day']%6 == 0 ) & ( df['IS_BAD_PRCNT'] < 0.15 ) ]\n",
        "  tar = df[ ( df['meter'] == meter ) & ( df['day']%6 != 0 ) & ( df['IS_BAD_PRCNT'] < 0.15 ) & (df['k_fact_med_hour']<50) ]\n",
        "\n",
        "  hist = nn_3.fit( tar[In_Columns], tar[Out_Columns]\n",
        "                  , batch_size = batch_size\n",
        "                  , verbose = 0\n",
        "                  , epochs = epochs, shuffle = True\n",
        "                  , callbacks=[MyCustomCallback(epochs, 1), earlyStopping, reduce_lr_loss,model_checkpoint]\n",
        "                  , validation_data=(val[In_Columns], val[Out_Columns])\n",
        "                  ) \n",
        "  nn_3.save(DIR_SAVE + str(meter) + 'HANDLY_SAVED3.MODEL')\n",
        "  gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQcBV7uNxXWG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df[(df['meter']==met) & (df['building_id']==building_id)].head(100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3GoK9la567l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#ГРАФИК ПЛАН-ФАКТ\n",
        "  plt.figure(figsize=(20,9))\n",
        "  df['log1p_fact'] = np.log(1+df['meter_reading'])\n",
        "  df['log1p_plan'] = np.log(1+df['NN_PRED'])\n",
        "  met = 3\n",
        "  building_id = 106\n",
        "  plt.plot( df[(df['meter']==met) & (df['building_id']==building_id)]['timestamp']\n",
        "          , df[(df['meter']==met) & (df['building_id']==building_id)]['log1p_fact'] , 'ro', markersize = 1   , color = 'blue' ,label = 'Факт', alpha = 0.3)\n",
        "  plt.plot( df[(df['meter']==met) & (df['building_id']==building_id)]['timestamp']\n",
        "           , df[(df['meter']==met) & (df['building_id']==building_id)]['log1p_plan'] , 'ro', markersize = 1  , color = 'green',label = 'План', alpha = 0.3)\n",
        "  plt.plot( df[(df['meter']==met) & (df['building_id']==building_id)]['timestamp']\n",
        "           , df[(df['meter']==met) & (df['building_id']==building_id)]['is_equal_prev'] , 'ro', markersize = 1  , color = 'black',label = 'Выкинуто', alpha = 0.3)\n",
        "  plt.plot( df[(df['meter']==met) & (df['building_id']==building_id)]['timestamp']\n",
        "           , df[(df['meter']==met) & (df['building_id']==building_id)]['IS_BAD_PRCNT'] , 'ro', markersize = 1  , color = 'brown',label = 'Выкинуто', alpha = 0.3)\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H75KbUGtAdOG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#nn_3.save(DIR + str(meter) + 'HANDLY_SAVED.MODEL')\n",
        "# keras.initializers.RandomUniform(minval=-0.05, maxval=0.05, seed=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYdF9Mh00i4a",
        "colab_type": "text"
      },
      "source": [
        "-- -- -- -- -- -- -- -- -- Предсказание -- -- -- -- -- -- -- -- --"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQ7txJwCTi6Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        },
        "outputId": "88622c8b-82c6-4b98-c4d9-fdff4c8e953d"
      },
      "source": [
        "#Предсказание из 4х значений:\n",
        "  nn_0 = keras.models.load_model (DIR_SAVE + '0HANDLY_SAVED3best.MODEL')\n",
        "  nn_1 = keras.models.load_model (DIR_SAVE + '1HANDLY_SAVED3best.MODEL')\n",
        "  nn_2 = keras.models.load_model (DIR_SAVE + '2HANDLY_SAVED3best.MODEL')\n",
        "  nn_3 = keras.models.load_model (DIR_SAVE + '3HANDLY_SAVED3best.MODEL')\n",
        "\n",
        "  # score = model.evaluate(X, Y, verbose=0)\n",
        "  # print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))\n",
        "  gc.collect()\n",
        "\n",
        "  df['NN_PRED'] = 0\n",
        "  df['NN_PRED_0'] = nn_0.predict(df[In_Columns], batch_size = 10000) \n",
        "  df['NN_PRED_1'] = nn_1.predict(df[In_Columns], batch_size = 10000) \n",
        "  df['NN_PRED_2'] = nn_2.predict(df[In_Columns], batch_size = 10000) \n",
        "  df['NN_PRED_3'] = nn_3.predict(df[In_Columns], batch_size = 10000) \n",
        "  df['NN_PRED'] = np.where(df['meter'] == 0, df['NN_PRED_0'], df['NN_PRED'])\n",
        "  df['NN_PRED'] = np.where(df['meter'] == 1, df['NN_PRED_1'], df['NN_PRED'])\n",
        "  df['NN_PRED'] = np.where(df['meter'] == 2, df['NN_PRED_2'], df['NN_PRED'])\n",
        "  df['NN_PRED'] = np.where(df['meter'] == 3, df['NN_PRED_3'], df['NN_PRED'])\n",
        "  df.drop(columns = ['NN_PRED_0', 'NN_PRED_1', 'NN_PRED_2', 'NN_PRED_3'], inplace = True)\n",
        "  #df.drop(columns = ['Value_x', 'Value_y'])\n",
        "  gc.collect()\n",
        "\n",
        "  df['NN_ERR'] = np.abs(df['NN_PRED']-df['meter_reading'])\n",
        "  df['k_NN_ERR'] = (df['NN_PRED']+0.33)/(df['meter_reading']+0.33)\n",
        "\n",
        "  print( 'Ошибка общая: ', np.sqrt( np.mean( np.power(np.log(df['meter_reading']+1) - np.log(df['NN_PRED']+1),2.00000)))\n",
        "      , 'Ошибка (VAL): ', np.sqrt( np.mean( np.power(np.log(df[(df['day']%6 == 0)]['meter_reading']+1) - np.log(df[(df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка (VAL_чист): ' , np.sqrt( np.mean( np.power(np.log(df[  (df['IS_BAD_PRCNT'] < 0.25) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[(df['IS_BAD_PRCNT'] < 0.25) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка (VAL_чист2): ', np.sqrt( np.mean( np.power(np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "  )\n",
        "  print('Ошибка 0: ', np.sqrt( np.mean( np.power(np.log(df[df['meter']==0]['meter_reading']+1) - np.log(df[df['meter']==0]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка 0 (VAL): ', np.sqrt( np.mean( np.power(np.log(df[(df['meter']==0) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[(df['meter']==0) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка 0 (VAL_чист): ' , np.sqrt( np.mean( np.power(np.log(df[  (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==0) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[ (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==0) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка 0 (VAL_чист2): ', np.sqrt( np.mean( np.power(np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==0) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==0) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "  )\n",
        "  print('Ошибка 1: ', np.sqrt( np.mean( np.power(np.log(df[df['meter']==1]['meter_reading']+1) - np.log(df[df['meter']==1]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка 1 (VAL): ', np.sqrt( np.mean( np.power(np.log(df[(df['meter']==1) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[(df['meter']==1) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка 1 (VAL_чист): ' , np.sqrt( np.mean( np.power(np.log(df[  (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==1) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[ (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==1) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка 1 (VAL_чист2): ', np.sqrt( np.mean( np.power(np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==1) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==1) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "  )\n",
        "  print('Ошибка 2: ', np.sqrt( np.mean( np.power(np.log(df[df['meter']==2]['meter_reading']+1) - np.log(df[df['meter']==2]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка 2 (VAL): ', np.sqrt( np.mean( np.power(np.log(df[(df['meter']==2) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[(df['meter']==2) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка 2 (VAL_чист): ' , np.sqrt( np.mean( np.power(np.log(df[  (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==2) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[ (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==2) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка 2 (VAL_чист2): ', np.sqrt( np.mean( np.power(np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==2) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==2) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "  )\n",
        "  print('Ошибка 3: ', np.sqrt( np.mean( np.power(np.log(df[df['meter']==3]['meter_reading']+1) - np.log(df[df['meter']==3]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка 3 (VAL): ', np.sqrt( np.mean( np.power(np.log(df[(df['meter']==3) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[(df['meter']==3) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка 3 (VAL_чист): ' , np.sqrt( np.mean( np.power(np.log(df[  (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==3) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[ (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==3) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка 3 (VAL_чист2): ', np.sqrt( np.mean( np.power(np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==3) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==3) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "  )\n",
        "  # print('Ошибка 1: ', np.sqrt( np.mean( np.power(np.log(df[df['meter']==1]['meter_reading']+1) - np.log(df[df['meter']==1]['NN_PRED']+1),2.00000)))        )\n",
        "  # print('Ошибка 2: ', np.sqrt( np.mean( np.power(np.log(df[df['meter']==2]['meter_reading']+1) - np.log(df[df['meter']==2]['NN_PRED']+1),2.00000)))        )\n",
        "  # print('Ошибка 3: ', np.sqrt( np.mean( np.power(np.log(df[df['meter']==3]['meter_reading']+1) - np.log(df[df['meter']==3]['NN_PRED']+1),2.00000)))        )\n",
        "\n",
        "  gc.collect()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4409: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1702: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Ошибка общая:  1.2019422970227465 Ошибка (VAL):  1.2157846256813984 Ошибка (VAL_чист):  0.5428777256494879 Ошибка (VAL_чист2):  0.4439034380986012\n",
            "Ошибка 0:  1.0561841191435806 Ошибка 0 (VAL):  1.0494709359899506 Ошибка 0 (VAL_чист):  0.3156408787681845 Ошибка 0 (VAL_чист2):  0.2912135296204619\n",
            "Ошибка 1:  1.3786985710716286 Ошибка 1 (VAL):  1.4146374427353003 Ошибка 1 (VAL_чист):  0.7336364189822585 Ошибка 1 (VAL_чист2):  0.6205787113997202\n",
            "Ошибка 2:  1.412089120404965 Ошибка 2 (VAL):  1.4307337011199783 Ошибка 2 (VAL_чист):  0.7681072077180416 Ошибка 2 (VAL_чист2):  0.5899942163118871\n",
            "Ошибка 3:  1.377944923928185 Ошибка 3 (VAL):  1.4566577965681673 Ошибка 3 (VAL_чист):  1.0939884892538 Ошибка 3 (VAL_чист2):  0.7449018059731893\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ON0qwgtpSld6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Ошибки:\n",
        "  Ошибка  :  1.2019422970227465 Ошибка (VAL):   1.2157846256813984 Ошибка (VAL_чист):   0.5428777256494879 Ошибка (VAL_чист2)  :  0.4439034380986012\n",
        "  Ошибка 0:  1.0561841191435806 Ошибка 0 (VAL): 1.0494709359899506 Ошибка 0 (VAL_чист): 0.3156408787681845 Ошибка 0 (VAL_чист2):  0.2912135296204619\n",
        "  Ошибка 1:  1.3786985710716286 Ошибка 1 (VAL): 1.4146374427353003 Ошибка 1 (VAL_чист): 0.7336364189822585 Ошибка 1 (VAL_чист2):  0.6205787113997202\n",
        "  Ошибка 2:  1.412089120404965 Ошибка 2 (VAL):  1.4307337011199783 Ошибка 2 (VAL_чист): 0.7681072077180416 Ошибка 2 (VAL_чист2):  0.5899942163118871\n",
        "  Ошибка 3:  1.377944923928185 Ошибка 3 (VAL):  1.4566577965681673 Ошибка 3 (VAL_чист): 1.0939884892538    Ошибка 3 (VAL_чист2):  0.7449018059731893\n",
        "  0\n",
        "  Общая:     1.2940425445438188 Ошибка (VAL):   1.3035619563953205 Ошибка (VAL_чист):   0.6154425269032927 Ошибка (VAL_чист2):    0.5166720488706185\n",
        "  Ошибка 0:  1.1108272200417615 Ошибка 0 (VAL): 1.1039979542354519 Ошибка 0 (VAL_чист): 0.4199684887318391 Ошибка 0 (VAL_чист2):  0.40071672645920714\n",
        "  Ошибка 1:  1.4674246744239359 Ошибка 1 (VAL): 1.4998371692364791 Ошибка 1 (VAL_чист): 0.7936248109822508 Ошибка 1 (VAL_чист2):  0.6763456453516548\n",
        "  Ошибка 2:  1.584895359471045 Ошибка 2 (VAL):  1.595279682390636 Ошибка 2 (VAL_чист):  0.8156651059087789 Ошибка 2 (VAL_чист2):  0.6075341541971445\n",
        "  Ошибка 3:  1.5811641937262615 Ошибка 3 (VAL):  1.6275882770258792 Ошибка 3 (VAL_чист):1.1791615642131834 Ошибка 3 (VAL_чист2):  0.8287557439810707\n",
        "  0\n",
        "  Общая  :   1.2383488513622485 Ошибка (VAL):   1.2497646476956246 Ошибка (VAL_чист):    0.5613541671314798 Ошибка (VAL_чист2):    0.4601055341524471\n",
        "  Ошибка 0:  1.089517078219136 Ошибка 0 (VAL):  1.0830665788767133 Ошибка 0 (VAL_чист):  0.32307141312090654 Ошибка 0 (VAL_чист2): 0.2984998363948374\n",
        "  Ошибка 1:  1.4093559595246432 Ошибка 1 (VAL): 1.4441371298998904 Ошибка 1 (VAL_чист):  0.7674735069465627 Ошибка 1 (VAL_чист2):  0.6515384132612695\n",
        "  Ошибка 2:  1.434270799339943 Ошибка 2 (VAL):  1.4459949706379165 Ошибка 2 (VAL_чист):  0.7751574071879366 Ошибка 2 (VAL_чист2):  0.59349123776128\n",
        "  Ошибка 3:  1.4481746111510552 Ошибка 3 (VAL): 1.5064615354375264 Ошибка 3 (VAL_чист):  1.0977130741767314 Ошибка 3 (VAL_чист2):  0.7436043422326556\n",
        "  0\n",
        "  Общая:     1.288451580726024 Ошибка (VAL):     1.2967080663610595 Ошибка (VAL_чист):    0.5559658155345275 Ошибка (VAL_чист2):   0.45027898146764\n",
        "  Ошибка 0:  1.1135345769523262 Ошибка 0 (VAL):  1.1073602983520954 Ошибка 0 (VAL_чист):  0.30211474219652695 Ошибка 0 (VAL_чист2):0.2760929212947043\n",
        "  Ошибка 1:  1.4447116762681158 Ошибка 1 (VAL):  1.4773486254929924 Ошибка 1 (VAL_чист):  0.778543934083951 Ошибка 1 (VAL_чист2):  0.6485716599103746\n",
        "  Ошибка 2:  1.4827505038656164 Ошибка 2 (VAL):  1.4859210115055426 Ошибка 2 (VAL_чист):  0.776992332783179 Ошибка 2 (VAL_чист2):  0.5982294414393752\n",
        "  Ошибка 3:  1.6852442156559078 Ошибка 3 (VAL):  1.7187446259260037 Ошибка 3 (VAL_чист):  1.0748931586686294 Ошибка 3 (VAL_чист2): 0.726536756006331\n",
        "  0\n",
        "  Общая:     1.3473874674637107 Ошибка (VAL):    1.3483415928656848 Ошибка (VAL_чист):    0.5756767405084868 Ошибка (VAL_чист2):   0.4623615327006715\n",
        "  Ошибка 0:  1.097150680567493 Ошибка 0 (VAL):   1.0891511641164369 Ошибка 0 (VAL_чист):  0.33891800740903766 Ошибка 0 (VAL_чист2):0.3149225188104313\n",
        "  Ошибка 1:  1.5319581086991891 Ошибка 1 (VAL):  1.5591904765901698 Ошибка 1 (VAL_чист):  0.7038461305727779 Ошибка 1 (VAL_чист2): 0.5850605730802025\n",
        "  Ошибка 2:  1.6638633608261502 Ошибка 2 (VAL):  1.6575565750506658 Ошибка 2 (VAL_чист):  0.9184081840472923 Ошибка 2 (VAL_чист2): 0.6847327356541326\n",
        "  Ошибка 3:  1.9625404814033556 Ошибка 3 (VAL):  1.955545484766667 Ошибка 3 (VAL_чист):   1.1170540079900018 Ошибка 3 (VAL_чист2): 0.7521327934769413"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxFd8mjwt7KQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#тмп\n",
        "  pd.set_option('display.max_rows', 500)\n",
        "  pd.set_option('display.max_columns', 500)\n",
        "  pd.set_option('display.width', 100)\n",
        "  warnings.filterwarnings('ignore')\n",
        "  np.set_printoptions (precision = 4, suppress  = True)\n",
        "\n",
        "  df['k_NN_ERR'] = (df['NN_PRED']+0.33)/(df['meter_reading']+0.33)\n",
        "  print(len(df), len(df[(df['k_NN_ERR']<50) & (df['k_NN_ERR']>1/50) & (df['IS_BAD_PRCNT']<0.25)]))\n",
        "  print(df[(df['hour']==14) & (df['meter']==0) & (df['building_id']==1) & (df['IS_BAD_PRCNT']<0.25)][['timestamp','hour','weekday','meter_reading','NN_PRED','NN_ERR','k_NN_ERR']].sort_values('timestamp').head(400))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ti8V0jrzZ1C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df[(df['k_NN_ERR']<50) & (df['k_NN_ERR']>1/50)  & (df['IS_BAD_PRCNT']<0.25)].describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Uz_DyKXziWJ",
        "colab_type": "code",
        "outputId": "ef5493d2-c496-4f5e-e570-a09bb29f9aa2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print( np.sqrt( np.mean( np.power(np.log(df['meter_reading']+1) - np.log(df['NN_PRED']+1),2.00000)))     )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.3473874674637107\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBMy61yg06BW",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "**-- -- -- -- -- -- -- -- --РАСЧЁТ НЕЙРОНОК после очистки -- -- -- -- -- -- -- -- --**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Q9aG2Cg_01Ci",
        "colab": {}
      },
      "source": [
        "#0: electricity, 1: chilledwater, 2: steam, 3: hotwater\n",
        "# РАСЧЁТ НЕЙРОНОК:\n",
        "  reg = 0.00001\n",
        "  batch_size = 2048\n",
        "  epochs = 30\n",
        "  meter = 0\n",
        "\n",
        "  earlyStopping = EarlyStopping(monitor='loss', patience=100, verbose=1, mode='min')\n",
        "  reduce_lr_loss = ReduceLROnPlateau(monitor='loss', factor=0.3, patience=5, verbose=1, min_delta=1e-3, mode='min')\n",
        "  model_checkpoint = ModelCheckpoint(monitor='loss', save_best_only=True, filepath = DIR + 'best_nn_' + str(meter) + '.model', save_weights_only = False, verbose=0, mode='min')\n",
        "\n",
        "  init = TruncatedNormal(mean=0.0, stddev=0.05, seed=159)\n",
        "  bias = Constant(value = 0.1)\n",
        "  \n",
        "  if 0==0:\n",
        "    meter = 0\n",
        "    opt = Adam(lr = 0.001)\n",
        "\n",
        "    nn_0 = Sequential()\n",
        "    nn_0.add(Dense(100, input_shape = df[In_Columns].shape[1:], activation = 'tanh', kernel_initializer = 'normal', kernel_regularizer=l2(reg), bias_initializer=bias))\n",
        "    nn_0.add(Dense(100, activation = 'tanh',  kernel_initializer = 'normal', bias_initializer=bias))\n",
        "    nn_0.add(Dense(100, activation = 'tanh',  kernel_initializer = 'normal', bias_initializer=bias, kernel_regularizer=l1(reg)))\n",
        "    nn_0.add(Dense(100, activation = 'tanh',  kernel_initializer = 'normal', bias_initializer=bias))\n",
        "    nn_0.add(Dense(1, activation = 'relu', kernel_initializer = 'normal'))\n",
        "\n",
        "    nn_0.compile(optimizer = opt, loss = MALE, metrics=[ MAE_, RMSLE, VAL_, 'mse', MAPE_ ])\n",
        "    \n",
        "    val = df[(df['meter'] == meter) & (df['day']%6 == 0) ]# & (df['k_NN_ERR'] < 100) & (df['k_NN_ERR'] > 1/100 & (df['IS_BAD_PRCNT'] < 0.25)]\n",
        "    #val_2 = df[(df['meter'] == meter) & (df['day']%6 == 0) & (df['k_NN_ERR'] < 100) & (df['k_NN_ERR'] > 1/100) & (df['IS_BAD_PRCNT'] < 0.25)]\n",
        "    df_cleared = df[(df['day']%6 != 0) & (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['meter'] == meter) & (df['IS_BAD_PRCNT'] < 0.45)][In_Columns + [Out_Columns]]\n",
        "\n",
        "    hist = nn_0.fit( df_cleared[In_Columns], df_cleared[Out_Columns], batch_size = batch_size, verbose = 0\n",
        "                    , epochs = epochs, shuffle = True, callbacks=[MyCustomCallback(epochs, 1), earlyStopping, reduce_lr_loss,model_checkpoint]\n",
        "                    , validation_data=(val[In_Columns], val[Out_Columns])\n",
        "                    ) \n",
        "    nn_0.save(DIR_SAVE + str(meter) + 'HANDLY_SAVED_3.MODEL')\n",
        "    gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "f9h2QsKV01Cn",
        "colab": {}
      },
      "source": [
        "for lr in [0.001]:\n",
        "  opt = Adam(lr = lr)\n",
        "  epochs = 20\n",
        "  batch_size = 2048\n",
        "  meter = 0\n",
        "  nn_0 = keras.models.load_model (DIR + '0HANDLY_SAVED_3best.MODEL')\n",
        "  val = df[(df['meter'] == meter) & (df['day']%6 == 0) & (df['k_NN_ERR'] < 100) & (df['k_NN_ERR'] > 1/100) & (df['IS_BAD_PRCNT'] < 0.25)]\n",
        "  df_cleared = df[(df['k_NN_ERR']<50) & (df['k_NN_ERR']>1/50) & (df['day']%6 != 0) & (df['meter']==meter) & (df['IS_BAD_PRCNT']<0.25)][In_Columns + [Out_Columns]]\n",
        "  print('*'*9, lr, '*'*33)\n",
        "  nn_0.compile(optimizer = opt, loss = RMSLE, metrics=[ MAE_, RMSLE, VAL_, 'mse', MAPE_ ])\n",
        "  hist = nn_0.fit( df_cleared[In_Columns], df_cleared[Out_Columns], batch_size = batch_size, verbose = 0\n",
        "                  , epochs = epochs, shuffle = True, callbacks=[ MyCustomCallback(epochs, 1), earlyStopping, reduce_lr_loss]\n",
        "                  , validation_data=(val[In_Columns], val[Out_Columns])\n",
        "                  ) \n",
        "  nn_0.save(DIR + str(meter) + 'HANDLY_SAVED_3.MODEL')\n",
        "  gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZExPUYLIfQy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#История ошибок:\n",
        "    # 0 - 0.001 |  TST_loss: 0.4634 TST_MAE_: 0.2970 TST_RMSLE: 0.7195 TST_VAL_: 0.9428 TST_mean_squared_error: 95502.1200 TST_MAPE_: 0.5170 ///  TRN_loss: 0.2670 TRN_MAE_: 0.3262 TRN_RMSLE: 0.4111 TRN_VAL_: 0.7641 TRN_mean_squared_error: 60868.2692 TRN_MAPE_: 0.2894\n",
        "    # Ошибка 0:  1.090040142661055  Ошибка 0 (VAL):  1.0821874168451948 Ошибка 0 (VAL_чист):  0.4200194527624282 Ошибка 0 (VAL_чист):  0.3982010565789388\n",
        "    #-Ошибка 0:  1.0561841191435806 Ошибка 0 (VAL):  1.0494709359899506 Ошибка 0 (VAL_чист):  0.3156408787681845 Ошибка 0 (VAL_чист):  0.2912135296204619\n",
        "\n",
        "    # 1 - \n",
        "    #Ошибка 1:  1.4326713621180338 Ошибка 1 (VAL):  1.4735626469840335 Ошибка 1 (VAL_чист):  0.6584706237724794 Ошибка 1 (VAL_чист):  0.521774231818768\n",
        "    #Ошибка 1:  1.434113723728525 Ошибка 1 (VAL):  1.4742295518711512 Ошибка 1 (VAL_чист):  0.665647741234266 Ошибка 1 (VAL_чист):  0.5298978788312768\n",
        "      #Ошибка 1:  1.431368815234858  Ошибка 1 (VAL):  1.4686131222512504 Ошибка 1 (VAL_чист):  0.6759214072760591 Ошибка 1 (VAL_чист):  0.5449250862446658\n",
        "      #Ошибка 1:  1.4691654987946658 Ошибка 1 (VAL):  1.5049969920282047 Ошибка 1 (VAL_чист):  0.6922470701866289 Ошибка 1 (VAL_чист):  0.5644578193999968\n",
        "      #Ошибка 1:  1.485687076453129  Ошибка 1 (VAL):  1.5214040444045644 Ошибка 1 (VAL_чист):  0.6952623800744953 Ошибка 1 (VAL_чист):  0.5632174649208512\n",
        "      #Ошибка 1:  1.4856709523394191 Ошибка 1 (VAL):  1.5205201826214512 Ошибка 1 (VAL_чист):  0.7050914102031174 Ошибка 1 (VAL_чист):  0.5759439648595509\n",
        "      #Ошибка 1:  1.4859038202056085 Ошибка 1 (VAL):  1.519788443345392 Ошибка 1 (VAL_чист):  0.7140834358696859 Ошибка 1 (VAL_чист):  0.5869849079847015\n",
        "    #-Ошибка 1:  1.3667812429174853 Ошибка 1 (VAL):  1.4029945499659757 Ошибка 1 (VAL_чист):  0.7281895570502563 Ошибка 1 (VAL_чист):  0.6149901419154421\n",
        "\n",
        "    # 2 - \n",
        "    #-Ошибка 2:  1.412089120404965 Ошибка 2 (VAL):  1.4307337011199783 Ошибка 2 (VAL_чист):  0.7681072077180416 Ошибка 2 (VAL_чист):  0.5899942163118871\n",
        "\n",
        "\n",
        "    #3 - \n",
        "    #\n",
        "    #-Ошибка 3:  1.377944923928185  Ошибка 3 (VAL):  1.4566577965681673 Ошибка 3 (VAL_чист):  1.0939884892538    Ошибка 3 (VAL_чист):  0.7449018059731893\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SssjG5U44j38",
        "colab_type": "code",
        "outputId": "5f557efc-57b4-4989-8f58-b69dc892cb3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#Предсказание из 4х значений = 0:\n",
        "  meter = 1\n",
        "  nn_tmp = keras.models.load_model (DIR_SAVE + str(meter) + 'HANDLY_SAVED_3.MODEL')\n",
        "  \n",
        "  gc.collect()\n",
        "  col_name_tmp = 'NN_PRED_'+str(meter) \n",
        "  df['NN_PRED'] = 0.0000\n",
        "  df[col_name_tmp] = nn_tmp.predict(df[In_Columns], batch_size = 400000) \n",
        "  df['NN_PRED'] = np.where(df['meter'] == meter, df[col_name_tmp], df['NN_PRED'])\n",
        "  df.drop(columns = [col_name_tmp], inplace = True) #, 'NN_PRED_1', 'NN_PRED_2', 'NN_PRED_3'\n",
        "  #df.drop(columns = ['Value_x', 'Value_y'])\n",
        "  gc.collect()\n",
        "\n",
        "  df['NN_ERR'] = np.abs(df['NN_PRED']-df['meter_reading'])\n",
        "  #df['k_NN_ERR'] = (df['NN_PRED']+0.33)/(df['meter_reading']+0.33)\n",
        "\n",
        "  #print( np.sqrt( np.mean( np.power(np.log(df['meter_reading']+1) - np.log(df['NN_PRED']+1),2.00000)))     )\n",
        "  print('Ошибка ' + str(meter) + ': '  , np.sqrt( np.mean( np.power(np.log(df[df['meter']==meter]['meter_reading']+1) - np.log(df[df['meter']==meter]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка ' + str(meter) + ' (VAL): ', np.sqrt( np.mean( np.power(np.log(df[(df['meter']==meter) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[(df['meter']==meter) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка ' + str(meter) + ' (VAL_чист): ', np.sqrt( np.mean( np.power(np.log(df[ (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==meter) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[ (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==meter) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка ' + str(meter) + ' (VAL_чист): ', np.sqrt( np.mean( np.power(np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==meter) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==meter) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        )\n",
        "  gc.collect()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ошибка 1:  1.4326713621180338 Ошибка 1 (VAL):  1.4735626469840335 Ошибка 1 (VAL_чист):  0.6584706237724794 Ошибка 1 (VAL_чист):  0.521774231818768\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAcxnR-6GGQp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nn_tmp.save(DIR_SAVE + str(meter) + 'HANDLY_SAVED_3best.MODEL')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XhZvGSgQm9T",
        "colab_type": "code",
        "outputId": "33985671-7c54-4830-da56-2689ecbf0578",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Дообучение!\n",
        "  meter = 2\n",
        "  nn_tmp = keras.models.load_model (DIR_SAVE + str(meter) + 'HANDLY_SAVED_3.MODEL')\n",
        "  \n",
        "  earlyStopping = EarlyStopping(monitor='loss', patience=100, verbose=1, mode='min')\n",
        "  reduce_lr_loss = ReduceLROnPlateau(monitor='loss', factor=0.5, patience=12, verbose=1, min_delta=1e-4, mode='min')\n",
        "  model_checkpoint = ModelCheckpoint(monitor='loss', save_best_only=True, filepath = DIR + 'best_nn_' + str(meter) + '.model', save_weights_only = False, verbose=0, mode='min')\n",
        "\n",
        "  bad_pcnt = 0.75\n",
        "  k_err = 30\n",
        "\n",
        "  val = df[ ( df['meter'] == meter ) & ( df['day']%6 == 0 ) & ( df['IS_BAD_PRCNT'] < bad_pcnt ) ]\n",
        "  tar = df[ ( df['meter'] == meter ) & ( df['day']%6 != 0 ) & ( df['IS_BAD_PRCNT'] < bad_pcnt ) & (df['k_NN_ERR'] < k_err) & (df['k_NN_ERR'] > 1/k_err) & (df['meter'] == meter) ]\n",
        "\n",
        "  print('Длина трейн ',len(tar), 'длина валидации ',len(val), 'сфильтровано:'\n",
        "  , len(df[ ( df['meter'] == meter ) & ( df['day']%6 != 0 ) & ( df['IS_BAD_PRCNT'] < bad_pcnt ) & (df['k_NN_ERR'] > k_err)  ]) + len(df[ ( df['meter'] == meter ) & ( df['day']%6 != 0 ) & ( df['IS_BAD_PRCNT'] < bad_pcnt ) & (df['k_NN_ERR'] < 1/k_err)  ]))  \n",
        "  \n",
        "  for lr in [0.00004,0.007]:\n",
        "    for los in [MALE,RMSLE,MAE_,mse,MAPE_VAL_RMSLE,RMSLE]:\n",
        "      print(los, lr)\n",
        "      opt = Adam(lr = lr)\n",
        "      epochs = 30\n",
        "      batch_size = 2048\n",
        "      \n",
        "\n",
        "      print('*'*9, lr, '*'*33)\n",
        "      nn_tmp.compile(optimizer = opt, loss = los, metrics=[ MAE_, RMSLE, VAL_, 'mse', MAPE_ ])\n",
        "      hist = nn_tmp.fit( tar[In_Columns], tar[Out_Columns], batch_size = batch_size, verbose = 0\n",
        "                      , epochs = epochs, shuffle = True, callbacks=[ MyCustomCallback(epochs, 1), earlyStopping, reduce_lr_loss]\n",
        "                      , validation_data=(val[In_Columns], val[Out_Columns])\n",
        "                    )\n",
        "      \n",
        "      nn_tmp.save(DIR_SAVE + str(meter) + 'HANDLY_SAVED_3.MODEL')\n",
        "  del val, tar\n",
        "  gc.collect()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Длина трейн  2024342 длина валидации  413377\n",
            "********* 4e-05 *********************************\n",
            "# 0001 |  TST_loss: 1.7395 TST_MAE_: 1.2463 TST_RMSLE: 2.1493 TST_VAL_: 1.1057 TST_mean_squared_error: 185318868818.4252 TST_MAPE_: 1.7483 ///  TRN_loss: 1.6709 TRN_MAE_: 0.9860 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0370 TRN_mean_squared_error: 188361134595.5733 TRN_MAPE_: 1.6936\n",
            "# 0002 |  TST_loss: 1.7390 TST_MAE_: 1.2551 TST_RMSLE: 2.1496 TST_VAL_: 1.1195 TST_mean_squared_error: 185318752702.1679 TST_MAPE_: 1.7553 ///  TRN_loss: 1.6702 TRN_MAE_: 0.9856 TRN_RMSLE: 2.1889 TRN_VAL_: 0.0387 TRN_mean_squared_error: 188361034422.9337 TRN_MAPE_: 1.7008\n",
            "# 0003 |  TST_loss: 1.7385 TST_MAE_: 1.2636 TST_RMSLE: 2.1500 TST_VAL_: 1.1328 TST_mean_squared_error: 185318644763.2158 TST_MAPE_: 1.7620 ///  TRN_loss: 1.6696 TRN_MAE_: 0.9851 TRN_RMSLE: 2.1890 TRN_VAL_: 0.0401 TRN_mean_squared_error: 188360934523.6463 TRN_MAPE_: 1.7077\n",
            ".......\n",
            "# 0004 |  TST_loss: 1.7382 TST_MAE_: 1.2719 TST_RMSLE: 2.1504 TST_VAL_: 1.1456 TST_mean_squared_error: 185318563097.4429 TST_MAPE_: 1.7686 ///  TRN_loss: 1.6690 TRN_MAE_: 0.9854 TRN_RMSLE: 2.1893 TRN_VAL_: 0.0399 TRN_mean_squared_error: 188360835171.3148 TRN_MAPE_: 1.7146\n",
            "# 0005 |  TST_loss: 1.7379 TST_MAE_: 1.2801 TST_RMSLE: 2.1509 TST_VAL_: 1.1582 TST_mean_squared_error: 185318468641.2707 TST_MAPE_: 1.7748 ///  TRN_loss: 1.6685 TRN_MAE_: 0.9859 TRN_RMSLE: 2.1896 TRN_VAL_: 0.0390 TRN_mean_squared_error: 188360741131.7186 TRN_MAPE_: 1.7211\n",
            "# 0006 |  TST_loss: 1.7376 TST_MAE_: 1.2881 TST_RMSLE: 2.1513 TST_VAL_: 1.1705 TST_mean_squared_error: 185318353645.9783 TST_MAPE_: 1.7809 ///  TRN_loss: 1.6681 TRN_MAE_: 0.9856 TRN_RMSLE: 2.1899 TRN_VAL_: 0.0402 TRN_mean_squared_error: 188360649788.9106 TRN_MAPE_: 1.7275\n",
            "# 0007 |  TST_loss: 1.7374 TST_MAE_: 1.2960 TST_RMSLE: 2.1518 TST_VAL_: 1.1825 TST_mean_squared_error: 185318283008.9731 TST_MAPE_: 1.7869 ///  TRN_loss: 1.6677 TRN_MAE_: 0.9856 TRN_RMSLE: 2.1902 TRN_VAL_: 0.0404 TRN_mean_squared_error: 188360560874.9619 TRN_MAPE_: 1.7335\n",
            "# 0008 |  TST_loss: 1.7373 TST_MAE_: 1.3036 TST_RMSLE: 2.1523 TST_VAL_: 1.1940 TST_mean_squared_error: 185318189353.2027 TST_MAPE_: 1.7927 ///  TRN_loss: 1.6674 TRN_MAE_: 0.9852 TRN_RMSLE: 2.1906 TRN_VAL_: 0.0420 TRN_mean_squared_error: 188360472252.8039 TRN_MAPE_: 1.7396\n",
            "# 0009 |  TST_loss: 1.7371 TST_MAE_: 1.3108 TST_RMSLE: 2.1529 TST_VAL_: 1.2050 TST_mean_squared_error: 185318109074.5967 TST_MAPE_: 1.7982 ///  TRN_loss: 1.6672 TRN_MAE_: 0.9853 TRN_RMSLE: 2.1910 TRN_VAL_: 0.0420 TRN_mean_squared_error: 188360387116.2365 TRN_MAPE_: 1.7454\n",
            "# 0010 |  TST_loss: 1.7371 TST_MAE_: 1.3177 TST_RMSLE: 2.1534 TST_VAL_: 1.2153 TST_mean_squared_error: 185318029281.7496 TST_MAPE_: 1.8034 ///  TRN_loss: 1.6669 TRN_MAE_: 0.9853 TRN_RMSLE: 2.1914 TRN_VAL_: 0.0423 TRN_mean_squared_error: 188360310740.0058 TRN_MAPE_: 1.7508\n",
            "# 0011 |  TST_loss: 1.7370 TST_MAE_: 1.3239 TST_RMSLE: 2.1538 TST_VAL_: 1.2247 TST_mean_squared_error: 185317957925.5817 TST_MAPE_: 1.8079 ///  TRN_loss: 1.6668 TRN_MAE_: 0.9852 TRN_RMSLE: 2.1918 TRN_VAL_: 0.0431 TRN_mean_squared_error: 188360237251.5024 TRN_MAPE_: 1.7558\n",
            "# 0012 |  TST_loss: 1.7370 TST_MAE_: 1.3296 TST_RMSLE: 2.1543 TST_VAL_: 1.2331 TST_mean_squared_error: 185317874262.1582 TST_MAPE_: 1.8120 ///  TRN_loss: 1.6666 TRN_MAE_: 0.9853 TRN_RMSLE: 2.1922 TRN_VAL_: 0.0432 TRN_mean_squared_error: 188360169083.7490 TRN_MAPE_: 1.7603\n",
            "# 0013 |  TST_loss: 1.7370 TST_MAE_: 1.3347 TST_RMSLE: 2.1547 TST_VAL_: 1.2408 TST_mean_squared_error: 185317830032.6098 TST_MAPE_: 1.8157 ///  TRN_loss: 1.6665 TRN_MAE_: 0.9850 TRN_RMSLE: 2.1925 TRN_VAL_: 0.0440 TRN_mean_squared_error: 188360111836.7032 TRN_MAPE_: 1.7642\n",
            "# 0014 |  TST_loss: 1.7370 TST_MAE_: 1.3391 TST_RMSLE: 2.1551 TST_VAL_: 1.2473 TST_mean_squared_error: 185317823015.8510 TST_MAPE_: 1.8189 ///  TRN_loss: 1.6665 TRN_MAE_: 0.9858 TRN_RMSLE: 2.1929 TRN_VAL_: 0.0420 TRN_mean_squared_error: 188360060080.8902 TRN_MAPE_: 1.7676\n",
            "# 0015 |  TST_loss: 1.7370 TST_MAE_: 1.3430 TST_RMSLE: 2.1554 TST_VAL_: 1.2530 TST_mean_squared_error: 185317761989.9103 TST_MAPE_: 1.8217 ///  TRN_loss: 1.6664 TRN_MAE_: 0.9858 TRN_RMSLE: 2.1932 TRN_VAL_: 0.0420 TRN_mean_squared_error: 188360012053.3661 TRN_MAPE_: 1.7707\n",
            "# 0016 |  TST_loss: 1.7370 TST_MAE_: 1.3456 TST_RMSLE: 2.1556 TST_VAL_: 1.2569 TST_mean_squared_error: 185317720359.3430 TST_MAPE_: 1.8236 ///  TRN_loss: 1.6664 TRN_MAE_: 0.9859 TRN_RMSLE: 2.1935 TRN_VAL_: 0.0419 TRN_mean_squared_error: 188359980327.7939 TRN_MAPE_: 1.7731\n",
            "# 0017 |  TST_loss: 1.7371 TST_MAE_: 1.3481 TST_RMSLE: 2.1558 TST_VAL_: 1.2605 TST_mean_squared_error: 185317686726.1148 TST_MAPE_: 1.8254 ///  TRN_loss: 1.6664 TRN_MAE_: 0.9852 TRN_RMSLE: 2.1937 TRN_VAL_: 0.0444 TRN_mean_squared_error: 188359949340.3323 TRN_MAPE_: 1.7750\n",
            "# 0018 |  TST_loss: 1.7371 TST_MAE_: 1.3501 TST_RMSLE: 2.1560 TST_VAL_: 1.2634 TST_mean_squared_error: 185317669169.2277 TST_MAPE_: 1.8268 ///  TRN_loss: 1.6663 TRN_MAE_: 0.9854 TRN_RMSLE: 2.1939 TRN_VAL_: 0.0437 TRN_mean_squared_error: 188359929774.8973 TRN_MAPE_: 1.7767\n",
            "# 0019 |  TST_loss: 1.7371 TST_MAE_: 1.3514 TST_RMSLE: 2.1561 TST_VAL_: 1.2654 TST_mean_squared_error: 185317644457.1458 TST_MAPE_: 1.8277 ///  TRN_loss: 1.6663 TRN_MAE_: 0.9848 TRN_RMSLE: 2.1940 TRN_VAL_: 0.0457 TRN_mean_squared_error: 188359904060.1628 TRN_MAPE_: 1.7778\n",
            "# 0020 |  TST_loss: 1.7371 TST_MAE_: 1.3522 TST_RMSLE: 2.1562 TST_VAL_: 1.2666 TST_mean_squared_error: 185317643624.9681 TST_MAPE_: 1.8283 ///  TRN_loss: 1.6663 TRN_MAE_: 0.9850 TRN_RMSLE: 2.1941 TRN_VAL_: 0.0451 TRN_mean_squared_error: 188359890879.1124 TRN_MAPE_: 1.7786\n",
            "# 0021 |  TST_loss: 1.7371 TST_MAE_: 1.3526 TST_RMSLE: 2.1562 TST_VAL_: 1.2672 TST_mean_squared_error: 185317643233.9920 TST_MAPE_: 1.8286 ///  TRN_loss: 1.6663 TRN_MAE_: 0.9851 TRN_RMSLE: 2.1941 TRN_VAL_: 0.0448 TRN_mean_squared_error: 188359887810.1546 TRN_MAPE_: 1.7792\n",
            "# 0022 |  TST_loss: 1.7371 TST_MAE_: 1.3529 TST_RMSLE: 2.1563 TST_VAL_: 1.2676 TST_mean_squared_error: 185317642971.8260 TST_MAPE_: 1.8288 ///  TRN_loss: 1.6663 TRN_MAE_: 0.9855 TRN_RMSLE: 2.1942 TRN_VAL_: 0.0439 TRN_mean_squared_error: 188359888640.9507 TRN_MAPE_: 1.7793\n",
            "# 0023 |  TST_loss: 1.7371 TST_MAE_: 1.3530 TST_RMSLE: 2.1563 TST_VAL_: 1.2677 TST_mean_squared_error: 185317642899.2570 TST_MAPE_: 1.8289 ///  TRN_loss: 1.6663 TRN_MAE_: 0.9857 TRN_RMSLE: 2.1942 TRN_VAL_: 0.0431 TRN_mean_squared_error: 188359887932.1213 TRN_MAPE_: 1.7796\n",
            "# 0024 |  TST_loss: 1.7371 TST_MAE_: 1.3529 TST_RMSLE: 2.1563 TST_VAL_: 1.2677 TST_mean_squared_error: 185317642922.4832 TST_MAPE_: 1.8289 ///  TRN_loss: 1.6663 TRN_MAE_: 0.9856 TRN_RMSLE: 2.1942 TRN_VAL_: 0.0435 TRN_mean_squared_error: 188359888892.4207 TRN_MAPE_: 1.7796\n",
            "# 0025 |  TST_loss: 1.7371 TST_MAE_: 1.3532 TST_RMSLE: 2.1563 TST_VAL_: 1.2680 TST_mean_squared_error: 185317642697.6389 TST_MAPE_: 1.8290 ///  TRN_loss: 1.6663 TRN_MAE_: 0.9856 TRN_RMSLE: 2.1942 TRN_VAL_: 0.0432 TRN_mean_squared_error: 188359888283.3893 TRN_MAPE_: 1.7795\n",
            "# 0026 |  TST_loss: 1.7371 TST_MAE_: 1.3530 TST_RMSLE: 2.1563 TST_VAL_: 1.2678 TST_mean_squared_error: 185317642857.9730 TST_MAPE_: 1.8289 ///  TRN_loss: 1.6663 TRN_MAE_: 0.9848 TRN_RMSLE: 2.1942 TRN_VAL_: 0.0459 TRN_mean_squared_error: 188359888285.9772 TRN_MAPE_: 1.7796\n",
            "# 0027 |  TST_loss: 1.7371 TST_MAE_: 1.3532 TST_RMSLE: 2.1563 TST_VAL_: 1.2680 TST_mean_squared_error: 185317642715.6082 TST_MAPE_: 1.8290 ///  TRN_loss: 1.6663 TRN_MAE_: 0.9853 TRN_RMSLE: 2.1942 TRN_VAL_: 0.0444 TRN_mean_squared_error: 188359888073.0697 TRN_MAPE_: 1.7795\n",
            "# 0028 |  TST_loss: 1.7371 TST_MAE_: 1.3532 TST_RMSLE: 2.1563 TST_VAL_: 1.2680 TST_mean_squared_error: 185317642695.1832 TST_MAPE_: 1.8290 ///  TRN_loss: 1.6663 TRN_MAE_: 0.9854 TRN_RMSLE: 2.1942 TRN_VAL_: 0.0439 TRN_mean_squared_error: 188359888102.1678 TRN_MAPE_: 1.7796\n",
            "# 0029 |  TST_loss: 1.7371 TST_MAE_: 1.3531 TST_RMSLE: 2.1563 TST_VAL_: 1.2679 TST_mean_squared_error: 185317642733.5766 TST_MAPE_: 1.8290 ///  TRN_loss: 1.6663 TRN_MAE_: 0.9857 TRN_RMSLE: 2.1942 TRN_VAL_: 0.0431 TRN_mean_squared_error: 188359887266.9132 TRN_MAPE_: 1.7796\n",
            "# 0030 |  TST_loss: 1.7371 TST_MAE_: 1.3533 TST_RMSLE: 2.1563 TST_VAL_: 1.2681 TST_mean_squared_error: 185317642605.0256 TST_MAPE_: 1.8291 ///  TRN_loss: 1.6663 TRN_MAE_: 0.9856 TRN_RMSLE: 2.1942 TRN_VAL_: 0.0436 TRN_mean_squared_error: 188359887770.5551 TRN_MAPE_: 1.7795\n",
            "# 0030 |  TST_loss: 1.7371 TST_MAE_: 1.3533 TST_RMSLE: 2.1563 TST_VAL_: 1.2681 TST_mean_squared_error: 185317642605.0256 TST_MAPE_: 1.8291 ///  TRN_loss: 1.6663 TRN_MAE_: 0.9856 TRN_RMSLE: 2.1942 TRN_VAL_: 0.0436 TRN_mean_squared_error: 188359887770.5551 TRN_MAPE_: 1.7795\n",
            "\n",
            "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
            "********* 4e-05 *********************************\n",
            "# 0001 |  TST_loss: 2.1554 TST_MAE_: 1.3433 TST_RMSLE: 2.1554 TST_VAL_: 1.2535 TST_mean_squared_error: 185317738286.7080 TST_MAPE_: 1.8219 ///  TRN_loss: 2.1938 TRN_MAE_: 0.9848 TRN_RMSLE: 2.1938 TRN_VAL_: 0.0456 TRN_mean_squared_error: 188359936011.4183 TRN_MAPE_: 1.7760\n",
            "# 0002 |  TST_loss: 2.1546 TST_MAE_: 1.3336 TST_RMSLE: 2.1546 TST_VAL_: 1.2391 TST_mean_squared_error: 185317854552.4607 TST_MAPE_: 1.8149 ///  TRN_loss: 2.1931 TRN_MAE_: 0.9850 TRN_RMSLE: 2.1931 TRN_VAL_: 0.0446 TRN_mean_squared_error: 188360041677.1165 TRN_MAPE_: 1.7688\n",
            "# 0003 |  TST_loss: 2.1539 TST_MAE_: 1.3243 TST_RMSLE: 2.1539 TST_VAL_: 1.2252 TST_mean_squared_error: 185317957549.5692 TST_MAPE_: 1.8082 ///  TRN_loss: 2.1924 TRN_MAE_: 0.9849 TRN_RMSLE: 2.1924 TRN_VAL_: 0.0444 TRN_mean_squared_error: 188360147014.7877 TRN_MAPE_: 1.7618\n",
            ".......\n",
            "# 0004 |  TST_loss: 2.1532 TST_MAE_: 1.3153 TST_RMSLE: 2.1532 TST_VAL_: 1.2117 TST_mean_squared_error: 185318044733.2270 TST_MAPE_: 1.8015 ///  TRN_loss: 2.1918 TRN_MAE_: 0.9856 TRN_RMSLE: 2.1918 TRN_VAL_: 0.0419 TRN_mean_squared_error: 188360250148.4178 TRN_MAPE_: 1.7550\n",
            "# 0005 |  TST_loss: 2.1526 TST_MAE_: 1.3066 TST_RMSLE: 2.1526 TST_VAL_: 1.1985 TST_mean_squared_error: 185318162875.7645 TST_MAPE_: 1.7949 ///  TRN_loss: 2.1912 TRN_MAE_: 0.9848 TRN_RMSLE: 2.1912 TRN_VAL_: 0.0436 TRN_mean_squared_error: 188360346968.4966 TRN_MAPE_: 1.7482\n",
            "# 0006 |  TST_loss: 2.1520 TST_MAE_: 1.2981 TST_RMSLE: 2.1520 TST_VAL_: 1.1858 TST_mean_squared_error: 185318244383.5043 TST_MAPE_: 1.7886 ///  TRN_loss: 2.1907 TRN_MAE_: 0.9846 TRN_RMSLE: 2.1907 TRN_VAL_: 0.0437 TRN_mean_squared_error: 188360443882.6385 TRN_MAPE_: 1.7416\n",
            "# 0007 |  TST_loss: 2.1515 TST_MAE_: 1.2900 TST_RMSLE: 2.1515 TST_VAL_: 1.1734 TST_mean_squared_error: 185318349035.9509 TST_MAPE_: 1.7824 ///  TRN_loss: 2.1903 TRN_MAE_: 0.9856 TRN_RMSLE: 2.1903 TRN_VAL_: 0.0407 TRN_mean_squared_error: 188360538537.7823 TRN_MAPE_: 1.7351\n",
            "# 0008 |  TST_loss: 2.1510 TST_MAE_: 1.2823 TST_RMSLE: 2.1510 TST_VAL_: 1.1616 TST_mean_squared_error: 185318419528.8936 TST_MAPE_: 1.7765 ///  TRN_loss: 2.1900 TRN_MAE_: 0.9850 TRN_RMSLE: 2.1900 TRN_VAL_: 0.0417 TRN_mean_squared_error: 188360625471.8438 TRN_MAPE_: 1.7290\n",
            "# 0009 |  TST_loss: 2.1506 TST_MAE_: 1.2750 TST_RMSLE: 2.1506 TST_VAL_: 1.1504 TST_mean_squared_error: 185318513004.8280 TST_MAPE_: 1.7710 ///  TRN_loss: 2.1897 TRN_MAE_: 0.9857 TRN_RMSLE: 2.1897 TRN_VAL_: 0.0395 TRN_mean_squared_error: 188360715551.7025 TRN_MAPE_: 1.7231\n",
            "# 0010 |  TST_loss: 2.1502 TST_MAE_: 1.2683 TST_RMSLE: 2.1502 TST_VAL_: 1.1400 TST_mean_squared_error: 185318603398.7145 TST_MAPE_: 1.7657 ///  TRN_loss: 2.1894 TRN_MAE_: 0.9847 TRN_RMSLE: 2.1894 TRN_VAL_: 0.0421 TRN_mean_squared_error: 188360791971.7243 TRN_MAPE_: 1.7176\n",
            "# 0011 |  TST_loss: 2.1499 TST_MAE_: 1.2621 TST_RMSLE: 2.1499 TST_VAL_: 1.1304 TST_mean_squared_error: 185318649029.3498 TST_MAPE_: 1.7608 ///  TRN_loss: 2.1892 TRN_MAE_: 0.9857 TRN_RMSLE: 2.1892 TRN_VAL_: 0.0388 TRN_mean_squared_error: 188360865356.8755 TRN_MAPE_: 1.7125\n",
            "# 0012 |  TST_loss: 2.1497 TST_MAE_: 1.2566 TST_RMSLE: 2.1497 TST_VAL_: 1.1219 TST_mean_squared_error: 185318738032.9445 TST_MAPE_: 1.7565 ///  TRN_loss: 2.1891 TRN_MAE_: 0.9850 TRN_RMSLE: 2.1891 TRN_VAL_: 0.0406 TRN_mean_squared_error: 188360934301.1370 TRN_MAPE_: 1.7077\n",
            "# 0013 |  TST_loss: 2.1495 TST_MAE_: 1.2520 TST_RMSLE: 2.1495 TST_VAL_: 1.1146 TST_mean_squared_error: 185318776879.5871 TST_MAPE_: 1.7528 ///  TRN_loss: 2.1889 TRN_MAE_: 0.9849 TRN_RMSLE: 2.1889 TRN_VAL_: 0.0405 TRN_mean_squared_error: 188360992385.5786 TRN_MAPE_: 1.7036\n",
            "# 0014 |  TST_loss: 2.1493 TST_MAE_: 1.2480 TST_RMSLE: 2.1493 TST_VAL_: 1.1085 TST_mean_squared_error: 185318830534.5224 TST_MAPE_: 1.7497 ///  TRN_loss: 2.1889 TRN_MAE_: 0.9859 TRN_RMSLE: 2.1889 TRN_VAL_: 0.0375 TRN_mean_squared_error: 188361042258.5610 TRN_MAPE_: 1.7001\n",
            "# 0015 |  TST_loss: 2.1492 TST_MAE_: 1.2449 TST_RMSLE: 2.1492 TST_VAL_: 1.1036 TST_mean_squared_error: 185318883301.8348 TST_MAPE_: 1.7472 ///  TRN_loss: 2.1889 TRN_MAE_: 0.9857 TRN_RMSLE: 2.1889 TRN_VAL_: 0.0381 TRN_mean_squared_error: 188361085352.8012 TRN_MAPE_: 1.6973\n",
            "# 0016 |  TST_loss: 2.1491 TST_MAE_: 1.2424 TST_RMSLE: 2.1491 TST_VAL_: 1.0997 TST_mean_squared_error: 185318888656.3972 TST_MAPE_: 1.7452 ///  TRN_loss: 2.1888 TRN_MAE_: 0.9858 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0375 TRN_mean_squared_error: 188361112073.8837 TRN_MAPE_: 1.6950\n",
            "# 0017 |  TST_loss: 2.1491 TST_MAE_: 1.2406 TST_RMSLE: 2.1491 TST_VAL_: 1.0967 TST_mean_squared_error: 185318914118.0141 TST_MAPE_: 1.7437 ///  TRN_loss: 2.1888 TRN_MAE_: 0.9856 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0381 TRN_mean_squared_error: 188361142572.5003 TRN_MAPE_: 1.6931\n",
            "# 0018 |  TST_loss: 2.1490 TST_MAE_: 1.2390 TST_RMSLE: 2.1490 TST_VAL_: 1.0943 TST_mean_squared_error: 185318928798.8178 TST_MAPE_: 1.7424 ///  TRN_loss: 2.1888 TRN_MAE_: 0.9861 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0366 TRN_mean_squared_error: 188361162747.2076 TRN_MAPE_: 1.6919\n",
            "# 0019 |  TST_loss: 2.1490 TST_MAE_: 1.2378 TST_RMSLE: 2.1490 TST_VAL_: 1.0924 TST_mean_squared_error: 185318943111.5376 TST_MAPE_: 1.7415 ///  TRN_loss: 2.1888 TRN_MAE_: 0.9855 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0383 TRN_mean_squared_error: 188361169765.4408 TRN_MAPE_: 1.6908\n",
            "# 0020 |  TST_loss: 2.1490 TST_MAE_: 1.2369 TST_RMSLE: 2.1490 TST_VAL_: 1.0910 TST_mean_squared_error: 185318988256.4683 TST_MAPE_: 1.7408 ///  TRN_loss: 2.1888 TRN_MAE_: 0.9852 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0389 TRN_mean_squared_error: 188361186799.9966 TRN_MAPE_: 1.6899\n",
            "# 0021 |  TST_loss: 2.1489 TST_MAE_: 1.2364 TST_RMSLE: 2.1489 TST_VAL_: 1.0901 TST_mean_squared_error: 185318991488.4612 TST_MAPE_: 1.7403 ///  TRN_loss: 2.1888 TRN_MAE_: 0.9841 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0418 TRN_mean_squared_error: 188361204517.6042 TRN_MAPE_: 1.6892\n",
            "# 0022 |  TST_loss: 2.1489 TST_MAE_: 1.2358 TST_RMSLE: 2.1489 TST_VAL_: 1.0892 TST_mean_squared_error: 185318992070.3968 TST_MAPE_: 1.7399 ///  TRN_loss: 2.1888 TRN_MAE_: 0.9852 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0389 TRN_mean_squared_error: 188361206302.4341 TRN_MAPE_: 1.6889\n",
            "# 0023 |  TST_loss: 2.1489 TST_MAE_: 1.2355 TST_RMSLE: 2.1489 TST_VAL_: 1.0887 TST_mean_squared_error: 185318992449.7159 TST_MAPE_: 1.7396 ///  TRN_loss: 2.1888 TRN_MAE_: 0.9862 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0363 TRN_mean_squared_error: 188361217224.7298 TRN_MAPE_: 1.6884\n",
            "# 0024 |  TST_loss: 2.1489 TST_MAE_: 1.2353 TST_RMSLE: 2.1489 TST_VAL_: 1.0884 TST_mean_squared_error: 185318992693.4814 TST_MAPE_: 1.7394 ///  TRN_loss: 2.1888 TRN_MAE_: 0.9852 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0389 TRN_mean_squared_error: 188361219803.4060 TRN_MAPE_: 1.6881\n",
            "# 0025 |  TST_loss: 2.1489 TST_MAE_: 1.2351 TST_RMSLE: 2.1489 TST_VAL_: 1.0881 TST_mean_squared_error: 185318992891.1747 TST_MAPE_: 1.7393 ///  TRN_loss: 2.1888 TRN_MAE_: 0.9850 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0393 TRN_mean_squared_error: 188361220383.3941 TRN_MAPE_: 1.6880\n",
            "# 0026 |  TST_loss: 2.1489 TST_MAE_: 1.2350 TST_RMSLE: 2.1489 TST_VAL_: 1.0878 TST_mean_squared_error: 185318993057.7246 TST_MAPE_: 1.7391 ///  TRN_loss: 2.1888 TRN_MAE_: 0.9855 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0380 TRN_mean_squared_error: 188361220773.7290 TRN_MAPE_: 1.6879\n",
            "# 0027 |  TST_loss: 2.1489 TST_MAE_: 1.2348 TST_RMSLE: 2.1489 TST_VAL_: 1.0876 TST_mean_squared_error: 185318993203.2258 TST_MAPE_: 1.7390 ///  TRN_loss: 2.1888 TRN_MAE_: 0.9856 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0381 TRN_mean_squared_error: 188361221529.8515 TRN_MAPE_: 1.6877\n",
            "# 0028 |  TST_loss: 2.1489 TST_MAE_: 1.2348 TST_RMSLE: 2.1489 TST_VAL_: 1.0876 TST_mean_squared_error: 185318993260.6810 TST_MAPE_: 1.7390 ///  TRN_loss: 2.1888 TRN_MAE_: 0.9867 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0348 TRN_mean_squared_error: 188361221333.8200 TRN_MAPE_: 1.6877\n",
            "\n",
            "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
            "# 0029 |  TST_loss: 2.1489 TST_MAE_: 1.2347 TST_RMSLE: 2.1489 TST_VAL_: 1.0875 TST_mean_squared_error: 185318993303.2511 TST_MAPE_: 1.7390 ///  TRN_loss: 2.1888 TRN_MAE_: 0.9863 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0360 TRN_mean_squared_error: 188361221756.2063 TRN_MAPE_: 1.6877\n",
            "# 0030 |  TST_loss: 2.1489 TST_MAE_: 1.2347 TST_RMSLE: 2.1489 TST_VAL_: 1.0874 TST_mean_squared_error: 185318993348.0283 TST_MAPE_: 1.7389 ///  TRN_loss: 2.1888 TRN_MAE_: 0.9858 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0373 TRN_mean_squared_error: 188361222032.8447 TRN_MAPE_: 1.6877\n",
            "# 0030 |  TST_loss: 2.1489 TST_MAE_: 1.2347 TST_RMSLE: 2.1489 TST_VAL_: 1.0874 TST_mean_squared_error: 185318993348.0283 TST_MAPE_: 1.7389 ///  TRN_loss: 2.1888 TRN_MAE_: 0.9858 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0373 TRN_mean_squared_error: 188361222032.8447 TRN_MAPE_: 1.6877\n",
            "********* 4e-05 *********************************\n",
            "# 0001 |  TST_loss: 1.2407 TST_MAE_: 1.2407 TST_RMSLE: 2.1491 TST_VAL_: 1.0969 TST_mean_squared_error: 185318913957.6395 TST_MAPE_: 1.7438 ///  TRN_loss: 0.9855 TRN_MAE_: 0.9855 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0381 TRN_mean_squared_error: 188361185056.4926 TRN_MAPE_: 1.6902\n",
            "# 0002 |  TST_loss: 1.2464 TST_MAE_: 1.2464 TST_RMSLE: 2.1493 TST_VAL_: 1.1059 TST_mean_squared_error: 185318847950.1503 TST_MAPE_: 1.7483 ///  TRN_loss: 0.9859 TRN_MAE_: 0.9859 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0373 TRN_mean_squared_error: 188361119075.9024 TRN_MAPE_: 1.6949\n",
            "# 0003 |  TST_loss: 1.2525 TST_MAE_: 1.2525 TST_RMSLE: 2.1495 TST_VAL_: 1.1155 TST_mean_squared_error: 185318776286.8263 TST_MAPE_: 1.7532 ///  TRN_loss: 0.9850 TRN_MAE_: 0.9850 TRN_RMSLE: 2.1889 TRN_VAL_: 0.0400 TRN_mean_squared_error: 188361049477.2803 TRN_MAPE_: 1.6997\n",
            ".......\n",
            "# 0004 |  TST_loss: 1.2582 TST_MAE_: 1.2581 TST_RMSLE: 2.1497 TST_VAL_: 1.1243 TST_mean_squared_error: 185318723405.2207 TST_MAPE_: 1.7577 ///  TRN_loss: 0.9856 TRN_MAE_: 0.9856 TRN_RMSLE: 2.1890 TRN_VAL_: 0.0388 TRN_mean_squared_error: 188360978760.9628 TRN_MAPE_: 1.7045\n",
            "# 0005 |  TST_loss: 1.2637 TST_MAE_: 1.2637 TST_RMSLE: 2.1500 TST_VAL_: 1.1329 TST_mean_squared_error: 185318644636.7157 TST_MAPE_: 1.7621 ///  TRN_loss: 0.9861 TRN_MAE_: 0.9861 TRN_RMSLE: 2.1891 TRN_VAL_: 0.0377 TRN_mean_squared_error: 188360915989.6005 TRN_MAPE_: 1.7090\n",
            "# 0006 |  TST_loss: 1.2693 TST_MAE_: 1.2693 TST_RMSLE: 2.1503 TST_VAL_: 1.1415 TST_mean_squared_error: 185318591908.1144 TST_MAPE_: 1.7665 ///  TRN_loss: 0.9856 TRN_MAE_: 0.9856 TRN_RMSLE: 2.1893 TRN_VAL_: 0.0392 TRN_mean_squared_error: 188360853532.1087 TRN_MAPE_: 1.7135\n",
            "# 0007 |  TST_loss: 1.2749 TST_MAE_: 1.2749 TST_RMSLE: 2.1506 TST_VAL_: 1.1502 TST_mean_squared_error: 185318513163.6822 TST_MAPE_: 1.7708 ///  TRN_loss: 0.9852 TRN_MAE_: 0.9852 TRN_RMSLE: 2.1894 TRN_VAL_: 0.0404 TRN_mean_squared_error: 188360784992.6901 TRN_MAPE_: 1.7181\n",
            "# 0008 |  TST_loss: 1.2805 TST_MAE_: 1.2805 TST_RMSLE: 2.1509 TST_VAL_: 1.1588 TST_mean_squared_error: 185318465609.2708 TST_MAPE_: 1.7751 ///  TRN_loss: 0.9854 TRN_MAE_: 0.9854 TRN_RMSLE: 2.1896 TRN_VAL_: 0.0404 TRN_mean_squared_error: 188360725263.1542 TRN_MAPE_: 1.7224\n",
            "# 0009 |  TST_loss: 1.2857 TST_MAE_: 1.2857 TST_RMSLE: 2.1512 TST_VAL_: 1.1668 TST_mean_squared_error: 185318402990.8577 TST_MAPE_: 1.7791 ///  TRN_loss: 0.9859 TRN_MAE_: 0.9859 TRN_RMSLE: 2.1898 TRN_VAL_: 0.0393 TRN_mean_squared_error: 188360659582.8861 TRN_MAPE_: 1.7267\n",
            "# 0010 |  TST_loss: 1.2912 TST_MAE_: 1.2912 TST_RMSLE: 2.1515 TST_VAL_: 1.1752 TST_mean_squared_error: 185318345199.1660 TST_MAPE_: 1.7833 ///  TRN_loss: 0.9852 TRN_MAE_: 0.9852 TRN_RMSLE: 2.1900 TRN_VAL_: 0.0414 TRN_mean_squared_error: 188360602013.8694 TRN_MAPE_: 1.7308\n",
            "# 0011 |  TST_loss: 1.2964 TST_MAE_: 1.2964 TST_RMSLE: 2.1519 TST_VAL_: 1.1831 TST_mean_squared_error: 185318269638.7037 TST_MAPE_: 1.7872 ///  TRN_loss: 0.9856 TRN_MAE_: 0.9856 TRN_RMSLE: 2.1903 TRN_VAL_: 0.0405 TRN_mean_squared_error: 188360540816.3510 TRN_MAPE_: 1.7349\n",
            "# 0012 |  TST_loss: 1.3018 TST_MAE_: 1.3018 TST_RMSLE: 2.1522 TST_VAL_: 1.1913 TST_mean_squared_error: 185318214614.7621 TST_MAPE_: 1.7913 ///  TRN_loss: 0.9855 TRN_MAE_: 0.9855 TRN_RMSLE: 2.1905 TRN_VAL_: 0.0411 TRN_mean_squared_error: 188360480114.6077 TRN_MAPE_: 1.7390\n",
            "# 0013 |  TST_loss: 1.3066 TST_MAE_: 1.3066 TST_RMSLE: 2.1526 TST_VAL_: 1.1986 TST_mean_squared_error: 185318162864.4079 TST_MAPE_: 1.7949 ///  TRN_loss: 0.9852 TRN_MAE_: 0.9852 TRN_RMSLE: 2.1908 TRN_VAL_: 0.0423 TRN_mean_squared_error: 188360422604.4164 TRN_MAPE_: 1.7430\n",
            "# 0014 |  TST_loss: 1.3115 TST_MAE_: 1.3115 TST_RMSLE: 2.1529 TST_VAL_: 1.2061 TST_mean_squared_error: 185318108360.4023 TST_MAPE_: 1.7987 ///  TRN_loss: 0.9857 TRN_MAE_: 0.9857 TRN_RMSLE: 2.1911 TRN_VAL_: 0.0410 TRN_mean_squared_error: 188360367260.6526 TRN_MAPE_: 1.7468\n",
            "# 0015 |  TST_loss: 1.3161 TST_MAE_: 1.3161 TST_RMSLE: 2.1532 TST_VAL_: 1.2129 TST_mean_squared_error: 185318043894.1798 TST_MAPE_: 1.8022 ///  TRN_loss: 0.9849 TRN_MAE_: 0.9849 TRN_RMSLE: 2.1914 TRN_VAL_: 0.0436 TRN_mean_squared_error: 188360315758.1690 TRN_MAPE_: 1.7504\n",
            "# 0016 |  TST_loss: 1.3207 TST_MAE_: 1.3207 TST_RMSLE: 2.1536 TST_VAL_: 1.2198 TST_mean_squared_error: 185317979471.4384 TST_MAPE_: 1.8055 ///  TRN_loss: 0.9850 TRN_MAE_: 0.9850 TRN_RMSLE: 2.1916 TRN_VAL_: 0.0435 TRN_mean_squared_error: 188360263676.0372 TRN_MAPE_: 1.7540\n",
            "# 0017 |  TST_loss: 1.3249 TST_MAE_: 1.3249 TST_RMSLE: 2.1539 TST_VAL_: 1.2262 TST_mean_squared_error: 185317946519.3757 TST_MAPE_: 1.8086 ///  TRN_loss: 0.9852 TRN_MAE_: 0.9852 TRN_RMSLE: 2.1919 TRN_VAL_: 0.0431 TRN_mean_squared_error: 188360218476.8380 TRN_MAPE_: 1.7572\n",
            "# 0018 |  TST_loss: 1.3286 TST_MAE_: 1.3286 TST_RMSLE: 2.1542 TST_VAL_: 1.2317 TST_mean_squared_error: 185317908971.1630 TST_MAPE_: 1.8113 ///  TRN_loss: 0.9853 TRN_MAE_: 0.9853 TRN_RMSLE: 2.1922 TRN_VAL_: 0.0430 TRN_mean_squared_error: 188360173041.1014 TRN_MAPE_: 1.7602\n",
            "# 0019 |  TST_loss: 1.3319 TST_MAE_: 1.3319 TST_RMSLE: 2.1545 TST_VAL_: 1.2366 TST_mean_squared_error: 185317871836.3553 TST_MAPE_: 1.8137 ///  TRN_loss: 0.9854 TRN_MAE_: 0.9854 TRN_RMSLE: 2.1924 TRN_VAL_: 0.0428 TRN_mean_squared_error: 188360130755.5408 TRN_MAPE_: 1.7628\n",
            "# 0020 |  TST_loss: 1.3351 TST_MAE_: 1.3351 TST_RMSLE: 2.1547 TST_VAL_: 1.2414 TST_mean_squared_error: 185317829622.2450 TST_MAPE_: 1.8160 ///  TRN_loss: 0.9849 TRN_MAE_: 0.9849 TRN_RMSLE: 2.1927 TRN_VAL_: 0.0446 TRN_mean_squared_error: 188360098791.4130 TRN_MAPE_: 1.7652\n",
            "# 0021 |  TST_loss: 1.3378 TST_MAE_: 1.3378 TST_RMSLE: 2.1550 TST_VAL_: 1.2454 TST_mean_squared_error: 185317824297.0012 TST_MAPE_: 1.8180 ///  TRN_loss: 0.9847 TRN_MAE_: 0.9847 TRN_RMSLE: 2.1929 TRN_VAL_: 0.0452 TRN_mean_squared_error: 188360064438.5268 TRN_MAPE_: 1.7673\n",
            "# 0022 |  TST_loss: 1.3404 TST_MAE_: 1.3404 TST_RMSLE: 2.1552 TST_VAL_: 1.2492 TST_mean_squared_error: 185317764540.0400 TST_MAPE_: 1.8198 ///  TRN_loss: 0.9857 TRN_MAE_: 0.9857 TRN_RMSLE: 2.1930 TRN_VAL_: 0.0425 TRN_mean_squared_error: 188360038933.9096 TRN_MAPE_: 1.7692\n",
            "# 0023 |  TST_loss: 1.3428 TST_MAE_: 1.3428 TST_RMSLE: 2.1554 TST_VAL_: 1.2528 TST_mean_squared_error: 185317762148.5443 TST_MAPE_: 1.8216 ///  TRN_loss: 0.9849 TRN_MAE_: 0.9849 TRN_RMSLE: 2.1933 TRN_VAL_: 0.0449 TRN_mean_squared_error: 188360004345.1931 TRN_MAPE_: 1.7713\n",
            "# 0024 |  TST_loss: 1.3446 TST_MAE_: 1.3446 TST_RMSLE: 2.1555 TST_VAL_: 1.2554 TST_mean_squared_error: 185317736969.5395 TST_MAPE_: 1.8228 ///  TRN_loss: 0.9858 TRN_MAE_: 0.9858 TRN_RMSLE: 2.1934 TRN_VAL_: 0.0422 TRN_mean_squared_error: 188359992318.6231 TRN_MAPE_: 1.7725\n",
            "# 0025 |  TST_loss: 1.3462 TST_MAE_: 1.3462 TST_RMSLE: 2.1557 TST_VAL_: 1.2577 TST_mean_squared_error: 185317709424.5682 TST_MAPE_: 1.8240 ///  TRN_loss: 0.9855 TRN_MAE_: 0.9855 TRN_RMSLE: 2.1935 TRN_VAL_: 0.0433 TRN_mean_squared_error: 188359960377.7539 TRN_MAPE_: 1.7740\n",
            "# 0026 |  TST_loss: 1.3474 TST_MAE_: 1.3474 TST_RMSLE: 2.1558 TST_VAL_: 1.2595 TST_mean_squared_error: 185317708222.1253 TST_MAPE_: 1.8248 ///  TRN_loss: 0.9851 TRN_MAE_: 0.9851 TRN_RMSLE: 2.1936 TRN_VAL_: 0.0446 TRN_mean_squared_error: 188359948038.1004 TRN_MAPE_: 1.7748\n",
            "# 0027 |  TST_loss: 1.3484 TST_MAE_: 1.3484 TST_RMSLE: 2.1559 TST_VAL_: 1.2610 TST_mean_squared_error: 185317686414.2589 TST_MAPE_: 1.8256 ///  TRN_loss: 0.9854 TRN_MAE_: 0.9854 TRN_RMSLE: 2.1938 TRN_VAL_: 0.0440 TRN_mean_squared_error: 188359944236.8926 TRN_MAPE_: 1.7758\n",
            "# 0028 |  TST_loss: 1.3494 TST_MAE_: 1.3494 TST_RMSLE: 2.1560 TST_VAL_: 1.2625 TST_mean_squared_error: 185317682811.5174 TST_MAPE_: 1.8263 ///  TRN_loss: 0.9857 TRN_MAE_: 0.9857 TRN_RMSLE: 2.1938 TRN_VAL_: 0.0431 TRN_mean_squared_error: 188359931855.1277 TRN_MAPE_: 1.7765\n",
            "# 0029 |  TST_loss: 1.3505 TST_MAE_: 1.3505 TST_RMSLE: 2.1561 TST_VAL_: 1.2641 TST_mean_squared_error: 185317668708.1075 TST_MAPE_: 1.8271 ///  TRN_loss: 0.9860 TRN_MAE_: 0.9860 TRN_RMSLE: 2.1939 TRN_VAL_: 0.0420 TRN_mean_squared_error: 188359914408.4254 TRN_MAPE_: 1.7773\n",
            "# 0030 |  TST_loss: 1.3514 TST_MAE_: 1.3514 TST_RMSLE: 2.1561 TST_VAL_: 1.2654 TST_mean_squared_error: 185317644479.2327 TST_MAPE_: 1.8277 ///  TRN_loss: 0.9852 TRN_MAE_: 0.9852 TRN_RMSLE: 2.1940 TRN_VAL_: 0.0444 TRN_mean_squared_error: 188359903363.9000 TRN_MAPE_: 1.7780\n",
            "# 0030 |  TST_loss: 1.3514 TST_MAE_: 1.3514 TST_RMSLE: 2.1561 TST_VAL_: 1.2654 TST_mean_squared_error: 185317644479.2327 TST_MAPE_: 1.8277 ///  TRN_loss: 0.9852 TRN_MAE_: 0.9852 TRN_RMSLE: 2.1940 TRN_VAL_: 0.0444 TRN_mean_squared_error: 188359903363.9000 TRN_MAPE_: 1.7780\n",
            "********* 4e-05 *********************************\n",
            "# 0001 |  TST_loss: 185317573380.5058 TST_MAE_: 1.3602 TST_RMSLE: 2.1569 TST_VAL_: 1.2783 TST_mean_squared_error: 185317573380.5058 TST_MAPE_: 1.8341 ///  TRN_loss: 188359855069.1966 TRN_MAE_: 0.9851 TRN_RMSLE: 2.1944 TRN_VAL_: 0.0451 TRN_mean_squared_error: 188359855069.1966 TRN_MAPE_: 1.7815\n",
            "# 0002 |  TST_loss: 185317465784.4117 TST_MAE_: 1.3693 TST_RMSLE: 2.1578 TST_VAL_: 1.2914 TST_mean_squared_error: 185317465784.4117 TST_MAPE_: 1.8405 ///  TRN_loss: 188359756207.7596 TRN_MAE_: 0.9858 TRN_RMSLE: 2.1951 TRN_VAL_: 0.0433 TRN_mean_squared_error: 188359756207.7596 TRN_MAPE_: 1.7881\n",
            "# 0003 |  TST_loss: 185317342738.8416 TST_MAE_: 1.3782 TST_RMSLE: 2.1586 TST_VAL_: 1.3044 TST_mean_squared_error: 185317342738.8416 TST_MAPE_: 1.8466 ///  TRN_loss: 188359660920.9928 TRN_MAE_: 0.9857 TRN_RMSLE: 2.1959 TRN_VAL_: 0.0444 TRN_mean_squared_error: 188359660920.9928 TRN_MAPE_: 1.7944\n",
            ".......\n",
            "# 0004 |  TST_loss: 185317281969.3559 TST_MAE_: 1.3873 TST_RMSLE: 2.1595 TST_VAL_: 1.3175 TST_mean_squared_error: 185317281969.3559 TST_MAPE_: 1.8528 ///  TRN_loss: 188359564155.6542 TRN_MAE_: 0.9856 TRN_RMSLE: 2.1968 TRN_VAL_: 0.0451 TRN_mean_squared_error: 188359564155.6542 TRN_MAPE_: 1.8007\n",
            "# 0005 |  TST_loss: 185317174462.5866 TST_MAE_: 1.3965 TST_RMSLE: 2.1604 TST_VAL_: 1.3306 TST_mean_squared_error: 185317174462.5866 TST_MAPE_: 1.8589 ///  TRN_loss: 188359466428.5905 TRN_MAE_: 0.9860 TRN_RMSLE: 2.1976 TRN_VAL_: 0.0443 TRN_mean_squared_error: 188359466428.5905 TRN_MAPE_: 1.8070\n",
            "# 0006 |  TST_loss: 185317059245.2737 TST_MAE_: 1.4056 TST_RMSLE: 2.1614 TST_VAL_: 1.3436 TST_mean_squared_error: 185317059245.2737 TST_MAPE_: 1.8651 ///  TRN_loss: 188359371350.7850 TRN_MAE_: 0.9850 TRN_RMSLE: 2.1985 TRN_VAL_: 0.0480 TRN_mean_squared_error: 188359371350.7850 TRN_MAPE_: 1.8133\n",
            "# 0007 |  TST_loss: 185316985631.9766 TST_MAE_: 1.4147 TST_RMSLE: 2.1623 TST_VAL_: 1.3566 TST_mean_squared_error: 185316985631.9766 TST_MAPE_: 1.8712 ///  TRN_loss: 188359275779.7435 TRN_MAE_: 0.9857 TRN_RMSLE: 2.1994 TRN_VAL_: 0.0462 TRN_mean_squared_error: 188359275779.7435 TRN_MAPE_: 1.8196\n",
            "# 0008 |  TST_loss: 185316883428.5287 TST_MAE_: 1.4239 TST_RMSLE: 2.1633 TST_VAL_: 1.3697 TST_mean_squared_error: 185316883428.5287 TST_MAPE_: 1.8772 ///  TRN_loss: 188359177977.3499 TRN_MAE_: 0.9848 TRN_RMSLE: 2.2004 TRN_VAL_: 0.0496 TRN_mean_squared_error: 188359177977.3499 TRN_MAPE_: 1.8257\n",
            "# 0009 |  TST_loss: 185316776095.5623 TST_MAE_: 1.4331 TST_RMSLE: 2.1644 TST_VAL_: 1.3827 TST_mean_squared_error: 185316776095.5623 TST_MAPE_: 1.8830 ///  TRN_loss: 188359082886.7908 TRN_MAE_: 0.9849 TRN_RMSLE: 2.2014 TRN_VAL_: 0.0496 TRN_mean_squared_error: 188359082886.7908 TRN_MAPE_: 1.8317\n",
            "# 0010 |  TST_loss: 185316694778.9531 TST_MAE_: 1.4424 TST_RMSLE: 2.1654 TST_VAL_: 1.3956 TST_mean_squared_error: 185316694778.9531 TST_MAPE_: 1.8888 ///  TRN_loss: 188358986451.7243 TRN_MAE_: 0.9852 TRN_RMSLE: 2.2024 TRN_VAL_: 0.0493 TRN_mean_squared_error: 188358986451.7243 TRN_MAPE_: 1.8377\n",
            "# 0011 |  TST_loss: 185316587494.3528 TST_MAE_: 1.4516 TST_RMSLE: 2.1665 TST_VAL_: 1.4086 TST_mean_squared_error: 185316587494.3528 TST_MAPE_: 1.8946 ///  TRN_loss: 188358889850.1223 TRN_MAE_: 0.9851 TRN_RMSLE: 2.2034 TRN_VAL_: 0.0498 TRN_mean_squared_error: 188358889850.1223 TRN_MAPE_: 1.8437\n",
            "# 0012 |  TST_loss: 185316485446.1560 TST_MAE_: 1.4609 TST_RMSLE: 2.1675 TST_VAL_: 1.4215 TST_mean_squared_error: 185316485446.1560 TST_MAPE_: 1.9005 ///  TRN_loss: 188358795893.1200 TRN_MAE_: 0.9850 TRN_RMSLE: 2.2045 TRN_VAL_: 0.0507 TRN_mean_squared_error: 188358795893.1200 TRN_MAPE_: 1.8496\n",
            "# 0013 |  TST_loss: 185316401549.8198 TST_MAE_: 1.4703 TST_RMSLE: 2.1686 TST_VAL_: 1.4346 TST_mean_squared_error: 185316401549.8198 TST_MAPE_: 1.9063 ///  TRN_loss: 188358699976.6692 TRN_MAE_: 0.9857 TRN_RMSLE: 2.2056 TRN_VAL_: 0.0490 TRN_mean_squared_error: 188358699976.6692 TRN_MAPE_: 1.8556\n",
            "# 0014 |  TST_loss: 185316296910.4345 TST_MAE_: 1.4796 TST_RMSLE: 2.1698 TST_VAL_: 1.4476 TST_mean_squared_error: 185316296910.4345 TST_MAPE_: 1.9119 ///  TRN_loss: 188358602532.6117 TRN_MAE_: 0.9856 TRN_RMSLE: 2.2068 TRN_VAL_: 0.0495 TRN_mean_squared_error: 188358602532.6117 TRN_MAPE_: 1.8614\n",
            "# 0015 |  TST_loss: 185316192240.2984 TST_MAE_: 1.4891 TST_RMSLE: 2.1709 TST_VAL_: 1.4607 TST_mean_squared_error: 185316192240.2984 TST_MAPE_: 1.9175 ///  TRN_loss: 188358508531.6412 TRN_MAE_: 0.9856 TRN_RMSLE: 2.2080 TRN_VAL_: 0.0507 TRN_mean_squared_error: 188358508531.6412 TRN_MAPE_: 1.8671\n",
            "# 0016 |  TST_loss: 185316111046.4109 TST_MAE_: 1.4985 TST_RMSLE: 2.1721 TST_VAL_: 1.4736 TST_mean_squared_error: 185316111046.4109 TST_MAPE_: 1.9231 ///  TRN_loss: 188358412007.4916 TRN_MAE_: 0.9856 TRN_RMSLE: 2.2091 TRN_VAL_: 0.0512 TRN_mean_squared_error: 188358412007.4916 TRN_MAPE_: 1.8729\n",
            "# 0017 |  TST_loss: 185316003923.5375 TST_MAE_: 1.5079 TST_RMSLE: 2.1733 TST_VAL_: 1.4865 TST_mean_squared_error: 185316003923.5375 TST_MAPE_: 1.9287 ///  TRN_loss: 188358314964.3846 TRN_MAE_: 0.9858 TRN_RMSLE: 2.2103 TRN_VAL_: 0.0509 TRN_mean_squared_error: 188358314964.3846 TRN_MAPE_: 1.8786\n",
            "# 0018 |  TST_loss: 185315920115.1221 TST_MAE_: 1.5174 TST_RMSLE: 2.1745 TST_VAL_: 1.4996 TST_mean_squared_error: 185315920115.1221 TST_MAPE_: 1.9343 ///  TRN_loss: 188358220864.3609 TRN_MAE_: 0.9860 TRN_RMSLE: 2.2115 TRN_VAL_: 0.0505 TRN_mean_squared_error: 188358220864.3609 TRN_MAPE_: 1.8843\n",
            "# 0019 |  TST_loss: 185315807726.7244 TST_MAE_: 1.5270 TST_RMSLE: 2.1757 TST_VAL_: 1.5127 TST_mean_squared_error: 185315807726.7244 TST_MAPE_: 1.9398 ///  TRN_loss: 188358124074.9770 TRN_MAE_: 0.9855 TRN_RMSLE: 2.2128 TRN_VAL_: 0.0529 TRN_mean_squared_error: 188358124074.9770 TRN_MAPE_: 1.8901\n",
            "# 0020 |  TST_loss: 185315713519.3368 TST_MAE_: 1.5366 TST_RMSLE: 2.1769 TST_VAL_: 1.5259 TST_mean_squared_error: 185315713519.3368 TST_MAPE_: 1.9453 ///  TRN_loss: 188358024607.9135 TRN_MAE_: 0.9854 TRN_RMSLE: 2.2141 TRN_VAL_: 0.0541 TRN_mean_squared_error: 188358024607.9135 TRN_MAPE_: 1.8956\n",
            "# 0021 |  TST_loss: 185315616776.6972 TST_MAE_: 1.5463 TST_RMSLE: 2.1782 TST_VAL_: 1.5389 TST_mean_squared_error: 185315616776.6972 TST_MAPE_: 1.9507 ///  TRN_loss: 188357930719.1219 TRN_MAE_: 0.9858 TRN_RMSLE: 2.2154 TRN_VAL_: 0.0529 TRN_mean_squared_error: 188357930719.1219 TRN_MAPE_: 1.9012\n",
            "# 0022 |  TST_loss: 185315525321.5620 TST_MAE_: 1.5558 TST_RMSLE: 2.1795 TST_VAL_: 1.5519 TST_mean_squared_error: 185315525321.5620 TST_MAPE_: 1.9561 ///  TRN_loss: 188357835149.1395 TRN_MAE_: 0.9859 TRN_RMSLE: 2.2167 TRN_VAL_: 0.0537 TRN_mean_squared_error: 188357835149.1395 TRN_MAPE_: 1.9068\n",
            "# 0023 |  TST_loss: 185315420923.2100 TST_MAE_: 1.5654 TST_RMSLE: 2.1807 TST_VAL_: 1.5648 TST_mean_squared_error: 185315420923.2100 TST_MAPE_: 1.9615 ///  TRN_loss: 188357737773.9187 TRN_MAE_: 0.9861 TRN_RMSLE: 2.2181 TRN_VAL_: 0.0530 TRN_mean_squared_error: 188357737773.9187 TRN_MAPE_: 1.9123\n",
            "# 0024 |  TST_loss: 185315324236.9302 TST_MAE_: 1.5751 TST_RMSLE: 2.1820 TST_VAL_: 1.5779 TST_mean_squared_error: 185315324236.9302 TST_MAPE_: 1.9669 ///  TRN_loss: 188357642976.5970 TRN_MAE_: 0.9854 TRN_RMSLE: 2.2194 TRN_VAL_: 0.0563 TRN_mean_squared_error: 188357642976.5970 TRN_MAPE_: 1.9178\n",
            "# 0025 |  TST_loss: 185315222530.6080 TST_MAE_: 1.5847 TST_RMSLE: 2.1833 TST_VAL_: 1.5908 TST_mean_squared_error: 185315222530.6080 TST_MAPE_: 1.9720 ///  TRN_loss: 188357547315.5335 TRN_MAE_: 0.9858 TRN_RMSLE: 2.2208 TRN_VAL_: 0.0556 TRN_mean_squared_error: 188357547315.5335 TRN_MAPE_: 1.9232\n",
            "# 0026 |  TST_loss: 185315149398.7797 TST_MAE_: 1.5943 TST_RMSLE: 2.1847 TST_VAL_: 1.6037 TST_mean_squared_error: 185315149398.7797 TST_MAPE_: 1.9772 ///  TRN_loss: 188357451733.2927 TRN_MAE_: 0.9861 TRN_RMSLE: 2.2222 TRN_VAL_: 0.0551 TRN_mean_squared_error: 188357451733.2927 TRN_MAPE_: 1.9286\n",
            "# 0027 |  TST_loss: 185315034559.4097 TST_MAE_: 1.6041 TST_RMSLE: 2.1860 TST_VAL_: 1.6168 TST_mean_squared_error: 185315034559.4097 TST_MAPE_: 1.9825 ///  TRN_loss: 188357356446.0313 TRN_MAE_: 0.9861 TRN_RMSLE: 2.2236 TRN_VAL_: 0.0556 TRN_mean_squared_error: 188357356446.0313 TRN_MAPE_: 1.9338\n",
            "# 0028 |  TST_loss: 185314940548.5565 TST_MAE_: 1.6139 TST_RMSLE: 2.1874 TST_VAL_: 1.6299 TST_mean_squared_error: 185314940548.5565 TST_MAPE_: 1.9878 ///  TRN_loss: 188357261026.7711 TRN_MAE_: 0.9858 TRN_RMSLE: 2.2250 TRN_VAL_: 0.0570 TRN_mean_squared_error: 188357261026.7711 TRN_MAPE_: 1.9392\n",
            "# 0029 |  TST_loss: 185314836229.0486 TST_MAE_: 1.6237 TST_RMSLE: 2.1887 TST_VAL_: 1.6430 TST_mean_squared_error: 185314836229.0486 TST_MAPE_: 1.9930 ///  TRN_loss: 188357164085.6730 TRN_MAE_: 0.9867 TRN_RMSLE: 2.2265 TRN_VAL_: 0.0544 TRN_mean_squared_error: 188357164085.6730 TRN_MAPE_: 1.9447\n",
            "# 0030 |  TST_loss: 185314742295.6953 TST_MAE_: 1.6335 TST_RMSLE: 2.1901 TST_VAL_: 1.6560 TST_mean_squared_error: 185314742295.6953 TST_MAPE_: 1.9982 ///  TRN_loss: 188357069699.2398 TRN_MAE_: 0.9860 TRN_RMSLE: 2.2280 TRN_VAL_: 0.0579 TRN_mean_squared_error: 188357069699.2398 TRN_MAPE_: 1.9500\n",
            "# 0030 |  TST_loss: 185314742295.6953 TST_MAE_: 1.6335 TST_RMSLE: 2.1901 TST_VAL_: 1.6560 TST_mean_squared_error: 185314742295.6953 TST_MAPE_: 1.9982 ///  TRN_loss: 188357069699.2398 TRN_MAE_: 0.9860 TRN_RMSLE: 2.2280 TRN_VAL_: 0.0579 TRN_mean_squared_error: 188357069699.2398 TRN_MAPE_: 1.9500\n",
            "********* 4e-05 *********************************\n",
            "# 0001 |  TST_loss: 9.9311 TST_MAE_: 1.6222 TST_RMSLE: 2.1885 TST_VAL_: 1.6410 TST_mean_squared_error: 185314840053.1053 TST_MAPE_: 1.9923 ///  TRN_loss: 9.8661 TRN_MAE_: 0.9859 TRN_RMSLE: 2.2278 TRN_VAL_: 0.0582 TRN_mean_squared_error: 188357076090.2674 TRN_MAPE_: 1.9496\n",
            "# 0002 |  TST_loss: 9.9152 TST_MAE_: 1.6109 TST_RMSLE: 2.1869 TST_VAL_: 1.6259 TST_mean_squared_error: 185314976872.9030 TST_MAPE_: 1.9862 ///  TRN_loss: 9.8602 TRN_MAE_: 0.9863 TRN_RMSLE: 2.2261 TRN_VAL_: 0.0561 TRN_mean_squared_error: 188357187936.6467 TRN_MAPE_: 1.9434\n",
            "# 0003 |  TST_loss: 9.8997 TST_MAE_: 1.5998 TST_RMSLE: 2.1854 TST_VAL_: 1.6110 TST_mean_squared_error: 185315064223.7053 TST_MAPE_: 1.9802 ///  TRN_loss: 9.8401 TRN_MAE_: 0.9857 TRN_RMSLE: 2.2245 TRN_VAL_: 0.0577 TRN_mean_squared_error: 188357296639.6848 TRN_MAPE_: 1.9372\n",
            ".......\n",
            "# 0004 |  TST_loss: 9.8845 TST_MAE_: 1.5887 TST_RMSLE: 2.1839 TST_VAL_: 1.5962 TST_mean_squared_error: 185315182725.3887 TST_MAPE_: 1.9742 ///  TRN_loss: 9.8292 TRN_MAE_: 0.9856 TRN_RMSLE: 2.2229 TRN_VAL_: 0.0571 TRN_mean_squared_error: 188357405963.8856 TRN_MAPE_: 1.9311\n",
            "# 0005 |  TST_loss: 9.8695 TST_MAE_: 1.5777 TST_RMSLE: 2.1824 TST_VAL_: 1.5814 TST_mean_squared_error: 185315311640.5875 TST_MAPE_: 1.9683 ///  TRN_loss: 9.8182 TRN_MAE_: 0.9859 TRN_RMSLE: 2.2213 TRN_VAL_: 0.0555 TRN_mean_squared_error: 188357515885.3204 TRN_MAPE_: 1.9250\n",
            "# 0006 |  TST_loss: 9.8548 TST_MAE_: 1.5668 TST_RMSLE: 2.1809 TST_VAL_: 1.5668 TST_mean_squared_error: 185315417087.1255 TST_MAPE_: 1.9623 ///  TRN_loss: 9.7968 TRN_MAE_: 0.9853 TRN_RMSLE: 2.2197 TRN_VAL_: 0.0569 TRN_mean_squared_error: 188357622362.5930 TRN_MAPE_: 1.9190\n",
            "# 0007 |  TST_loss: 9.8400 TST_MAE_: 1.5559 TST_RMSLE: 2.1795 TST_VAL_: 1.5519 TST_mean_squared_error: 185315525306.1317 TST_MAPE_: 1.9561 ///  TRN_loss: 9.7933 TRN_MAE_: 0.9858 TRN_RMSLE: 2.2182 TRN_VAL_: 0.0543 TRN_mean_squared_error: 188357730611.1339 TRN_MAPE_: 1.9127\n",
            "# 0008 |  TST_loss: 9.8255 TST_MAE_: 1.5449 TST_RMSLE: 2.1780 TST_VAL_: 1.5371 TST_mean_squared_error: 185315620553.5287 TST_MAPE_: 1.9499 ///  TRN_loss: 9.7832 TRN_MAE_: 0.9860 TRN_RMSLE: 2.2166 TRN_VAL_: 0.0529 TRN_mean_squared_error: 188357838943.9379 TRN_MAPE_: 1.9063\n",
            "# 0009 |  TST_loss: 9.8113 TST_MAE_: 1.5341 TST_RMSLE: 2.1766 TST_VAL_: 1.5224 TST_mean_squared_error: 185315739105.7671 TST_MAPE_: 1.9439 ///  TRN_loss: 9.7722 TRN_MAE_: 0.9857 TRN_RMSLE: 2.2151 TRN_VAL_: 0.0535 TRN_mean_squared_error: 188357950328.8913 TRN_MAPE_: 1.9001\n",
            "# 0010 |  TST_loss: 9.7975 TST_MAE_: 1.5236 TST_RMSLE: 2.1752 TST_VAL_: 1.5080 TST_mean_squared_error: 185315834142.4903 TST_MAPE_: 1.9379 ///  TRN_loss: 9.7539 TRN_MAE_: 0.9853 TRN_RMSLE: 2.2137 TRN_VAL_: 0.0542 TRN_mean_squared_error: 188358057971.3763 TRN_MAPE_: 1.8939\n",
            "# 0011 |  TST_loss: 9.7835 TST_MAE_: 1.5128 TST_RMSLE: 2.1739 TST_VAL_: 1.4933 TST_mean_squared_error: 185315950177.4593 TST_MAPE_: 1.9316 ///  TRN_loss: 9.7507 TRN_MAE_: 0.9858 TRN_RMSLE: 2.2123 TRN_VAL_: 0.0517 TRN_mean_squared_error: 188358162638.8070 TRN_MAPE_: 1.8877\n",
            "# 0012 |  TST_loss: 9.7695 TST_MAE_: 1.5020 TST_RMSLE: 2.1725 TST_VAL_: 1.4785 TST_mean_squared_error: 185316068909.2439 TST_MAPE_: 1.9252 ///  TRN_loss: 9.7468 TRN_MAE_: 0.9868 TRN_RMSLE: 2.2109 TRN_VAL_: 0.0476 TRN_mean_squared_error: 188358273915.0461 TRN_MAPE_: 1.8812\n",
            "# 0013 |  TST_loss: 9.7564 TST_MAE_: 1.4917 TST_RMSLE: 2.1712 TST_VAL_: 1.4643 TST_mean_squared_error: 185316187244.3581 TST_MAPE_: 1.9191 ///  TRN_loss: 9.7228 TRN_MAE_: 0.9851 TRN_RMSLE: 2.2095 TRN_VAL_: 0.0531 TRN_mean_squared_error: 188358378690.1720 TRN_MAPE_: 1.8748\n",
            "# 0014 |  TST_loss: 9.7432 TST_MAE_: 1.4812 TST_RMSLE: 2.1700 TST_VAL_: 1.4498 TST_mean_squared_error: 185316292845.3516 TST_MAPE_: 1.9129 ///  TRN_loss: 9.7159 TRN_MAE_: 0.9859 TRN_RMSLE: 2.2082 TRN_VAL_: 0.0497 TRN_mean_squared_error: 188358484166.0478 TRN_MAPE_: 1.8684\n",
            "# 0015 |  TST_loss: 9.7304 TST_MAE_: 1.4709 TST_RMSLE: 2.1687 TST_VAL_: 1.4355 TST_mean_squared_error: 185316398337.0917 TST_MAPE_: 1.9067 ///  TRN_loss: 9.7058 TRN_MAE_: 0.9859 TRN_RMSLE: 2.2069 TRN_VAL_: 0.0490 TRN_mean_squared_error: 188358591182.3613 TRN_MAPE_: 1.8621\n",
            "# 0016 |  TST_loss: 9.7178 TST_MAE_: 1.4607 TST_RMSLE: 2.1675 TST_VAL_: 1.4212 TST_mean_squared_error: 185316485657.9663 TST_MAPE_: 1.9003 ///  TRN_loss: 9.6935 TRN_MAE_: 0.9858 TRN_RMSLE: 2.2057 TRN_VAL_: 0.0486 TRN_mean_squared_error: 188358697025.9458 TRN_MAPE_: 1.8557\n",
            "# 0017 |  TST_loss: 9.7054 TST_MAE_: 1.4504 TST_RMSLE: 2.1663 TST_VAL_: 1.4070 TST_mean_squared_error: 185316588574.7764 TST_MAPE_: 1.8939 ///  TRN_loss: 9.6850 TRN_MAE_: 0.9859 TRN_RMSLE: 2.2044 TRN_VAL_: 0.0479 TRN_mean_squared_error: 188358803266.6102 TRN_MAPE_: 1.8491\n",
            "# 0018 |  TST_loss: 9.6931 TST_MAE_: 1.4402 TST_RMSLE: 2.1652 TST_VAL_: 1.3926 TST_mean_squared_error: 185316717534.1901 TST_MAPE_: 1.8875 ///  TRN_loss: 9.6793 TRN_MAE_: 0.9859 TRN_RMSLE: 2.2033 TRN_VAL_: 0.0474 TRN_mean_squared_error: 188358907659.2770 TRN_MAPE_: 1.8425\n",
            "# 0019 |  TST_loss: 9.6814 TST_MAE_: 1.4304 TST_RMSLE: 2.1641 TST_VAL_: 1.3788 TST_mean_squared_error: 185316815036.7829 TST_MAPE_: 1.8812 ///  TRN_loss: 9.6642 TRN_MAE_: 0.9853 TRN_RMSLE: 2.2021 TRN_VAL_: 0.0487 TRN_mean_squared_error: 188359010812.2250 TRN_MAPE_: 1.8362\n",
            "# 0020 |  TST_loss: 9.6701 TST_MAE_: 1.4206 TST_RMSLE: 2.1630 TST_VAL_: 1.3649 TST_mean_squared_error: 185316907374.9867 TST_MAPE_: 1.8750 ///  TRN_loss: 9.6571 TRN_MAE_: 0.9857 TRN_RMSLE: 2.2011 TRN_VAL_: 0.0470 TRN_mean_squared_error: 188359114471.6674 TRN_MAPE_: 1.8298\n",
            "# 0021 |  TST_loss: 9.6590 TST_MAE_: 1.4109 TST_RMSLE: 2.1619 TST_VAL_: 1.3512 TST_mean_squared_error: 185317004854.5338 TST_MAPE_: 1.8686 ///  TRN_loss: 9.6450 TRN_MAE_: 0.9852 TRN_RMSLE: 2.2000 TRN_VAL_: 0.0479 TRN_mean_squared_error: 188359217413.7638 TRN_MAPE_: 1.8234\n",
            "# 0022 |  TST_loss: 9.6483 TST_MAE_: 1.4015 TST_RMSLE: 2.1610 TST_VAL_: 1.3378 TST_mean_squared_error: 185317120320.5314 TST_MAPE_: 1.8623 ///  TRN_loss: 9.6345 TRN_MAE_: 0.9849 TRN_RMSLE: 2.1990 TRN_VAL_: 0.0486 TRN_mean_squared_error: 188359317102.2167 TRN_MAPE_: 1.8168\n",
            "# 0023 |  TST_loss: 9.6378 TST_MAE_: 1.3919 TST_RMSLE: 2.1600 TST_VAL_: 1.3241 TST_mean_squared_error: 185317215187.7007 TST_MAPE_: 1.8559 ///  TRN_loss: 9.6292 TRN_MAE_: 0.9853 TRN_RMSLE: 2.1981 TRN_VAL_: 0.0465 TRN_mean_squared_error: 188359416578.0241 TRN_MAPE_: 1.8103\n",
            "# 0024 |  TST_loss: 9.6279 TST_MAE_: 1.3827 TST_RMSLE: 2.1591 TST_VAL_: 1.3109 TST_mean_squared_error: 185317322778.4261 TST_MAPE_: 1.8497 ///  TRN_loss: 9.6215 TRN_MAE_: 0.9854 TRN_RMSLE: 2.1972 TRN_VAL_: 0.0459 TRN_mean_squared_error: 188359515716.7375 TRN_MAPE_: 1.8038\n",
            "# 0025 |  TST_loss: 9.6182 TST_MAE_: 1.3736 TST_RMSLE: 2.1582 TST_VAL_: 1.2977 TST_mean_squared_error: 185317414800.7734 TST_MAPE_: 1.8435 ///  TRN_loss: 9.6170 TRN_MAE_: 0.9856 TRN_RMSLE: 2.1963 TRN_VAL_: 0.0447 TRN_mean_squared_error: 188359614341.4139 TRN_MAPE_: 1.7974\n",
            "# 0026 |  TST_loss: 9.6089 TST_MAE_: 1.3647 TST_RMSLE: 2.1573 TST_VAL_: 1.2848 TST_mean_squared_error: 185317511821.2933 TST_MAPE_: 1.8373 ///  TRN_loss: 9.6075 TRN_MAE_: 0.9856 TRN_RMSLE: 2.1955 TRN_VAL_: 0.0444 TRN_mean_squared_error: 188359708933.2242 TRN_MAPE_: 1.7912\n",
            "# 0027 |  TST_loss: 9.6000 TST_MAE_: 1.3560 TST_RMSLE: 2.1565 TST_VAL_: 1.2721 TST_mean_squared_error: 185317603553.4057 TST_MAPE_: 1.8310 ///  TRN_loss: 9.5996 TRN_MAE_: 0.9855 TRN_RMSLE: 2.1947 TRN_VAL_: 0.0441 TRN_mean_squared_error: 188359804587.7833 TRN_MAPE_: 1.7849\n",
            "# 0028 |  TST_loss: 9.5914 TST_MAE_: 1.3474 TST_RMSLE: 2.1558 TST_VAL_: 1.2596 TST_mean_squared_error: 185317708163.9530 TST_MAPE_: 1.8249 ///  TRN_loss: 9.5923 TRN_MAE_: 0.9853 TRN_RMSLE: 2.1941 TRN_VAL_: 0.0444 TRN_mean_squared_error: 188359900001.8773 TRN_MAPE_: 1.7785\n",
            "# 0029 |  TST_loss: 9.5833 TST_MAE_: 1.3392 TST_RMSLE: 2.1551 TST_VAL_: 1.2474 TST_mean_squared_error: 185317822927.1532 TST_MAPE_: 1.8190 ///  TRN_loss: 9.5862 TRN_MAE_: 0.9853 TRN_RMSLE: 2.1934 TRN_VAL_: 0.0439 TRN_mean_squared_error: 188359988312.9981 TRN_MAPE_: 1.7723\n",
            "# 0030 |  TST_loss: 9.5756 TST_MAE_: 1.3311 TST_RMSLE: 2.1544 TST_VAL_: 1.2354 TST_mean_squared_error: 185317872656.6929 TST_MAPE_: 1.8131 ///  TRN_loss: 9.5812 TRN_MAE_: 0.9854 TRN_RMSLE: 2.1928 TRN_VAL_: 0.0432 TRN_mean_squared_error: 188360081099.8198 TRN_MAPE_: 1.7664\n",
            "# 0030 |  TST_loss: 9.5756 TST_MAE_: 1.3311 TST_RMSLE: 2.1544 TST_VAL_: 1.2354 TST_mean_squared_error: 185317872656.6929 TST_MAPE_: 1.8131 ///  TRN_loss: 9.5812 TRN_MAE_: 0.9854 TRN_RMSLE: 2.1928 TRN_VAL_: 0.0432 TRN_mean_squared_error: 188360081099.8198 TRN_MAPE_: 1.7664\n",
            "********* 4e-05 *********************************\n",
            "# 0001 |  TST_loss: 2.1537 TST_MAE_: 1.3216 TST_RMSLE: 2.1537 TST_VAL_: 1.2212 TST_mean_squared_error: 185317978482.1750 TST_MAPE_: 1.8062 ///  TRN_loss: 2.1922 TRN_MAE_: 0.9860 TRN_RMSLE: 2.1922 TRN_VAL_: 0.0410 TRN_mean_squared_error: 188360174962.6452 TRN_MAPE_: 1.7599\n",
            "# 0002 |  TST_loss: 2.1530 TST_MAE_: 1.3124 TST_RMSLE: 2.1530 TST_VAL_: 1.2074 TST_mean_squared_error: 185318104848.0736 TST_MAPE_: 1.7994 ///  TRN_loss: 2.1916 TRN_MAE_: 0.9862 TRN_RMSLE: 2.1916 TRN_VAL_: 0.0400 TRN_mean_squared_error: 188360279442.9093 TRN_MAPE_: 1.7529\n",
            "# 0003 |  TST_loss: 2.1524 TST_MAE_: 1.3037 TST_RMSLE: 2.1524 TST_VAL_: 1.1942 TST_mean_squared_error: 185318189228.5265 TST_MAPE_: 1.7928 ///  TRN_loss: 2.1910 TRN_MAE_: 0.9859 TRN_RMSLE: 2.1910 TRN_VAL_: 0.0404 TRN_mean_squared_error: 188360380129.6689 TRN_MAPE_: 1.7460\n",
            ".......\n",
            "# 0004 |  TST_loss: 2.1518 TST_MAE_: 1.2953 TST_RMSLE: 2.1518 TST_VAL_: 1.1815 TST_mean_squared_error: 185318283713.7151 TST_MAPE_: 1.7864 ///  TRN_loss: 2.1906 TRN_MAE_: 0.9854 TRN_RMSLE: 2.1906 TRN_VAL_: 0.0412 TRN_mean_squared_error: 188360476116.9431 TRN_MAPE_: 1.7394\n",
            "# 0005 |  TST_loss: 2.1513 TST_MAE_: 1.2873 TST_RMSLE: 2.1513 TST_VAL_: 1.1693 TST_mean_squared_error: 185318375249.9070 TST_MAPE_: 1.7803 ///  TRN_loss: 2.1902 TRN_MAE_: 0.9861 TRN_RMSLE: 2.1902 TRN_VAL_: 0.0391 TRN_mean_squared_error: 188360565804.5368 TRN_MAPE_: 1.7330\n",
            "# 0006 |  TST_loss: 2.1508 TST_MAE_: 1.2798 TST_RMSLE: 2.1508 TST_VAL_: 1.1577 TST_mean_squared_error: 185318468990.2084 TST_MAPE_: 1.7746 ///  TRN_loss: 2.1899 TRN_MAE_: 0.9863 TRN_RMSLE: 2.1899 TRN_VAL_: 0.0381 TRN_mean_squared_error: 188360659234.5848 TRN_MAPE_: 1.7269\n",
            "# 0007 |  TST_loss: 2.1505 TST_MAE_: 1.2727 TST_RMSLE: 2.1505 TST_VAL_: 1.1468 TST_mean_squared_error: 185318538867.8713 TST_MAPE_: 1.7692 ///  TRN_loss: 2.1896 TRN_MAE_: 0.9855 TRN_RMSLE: 2.1896 TRN_VAL_: 0.0400 TRN_mean_squared_error: 188360739024.5131 TRN_MAPE_: 1.7213\n",
            "# 0008 |  TST_loss: 2.1501 TST_MAE_: 1.2662 TST_RMSLE: 2.1501 TST_VAL_: 1.1368 TST_mean_squared_error: 185318628966.4379 TST_MAPE_: 1.7641 ///  TRN_loss: 2.1893 TRN_MAE_: 0.9857 TRN_RMSLE: 2.1893 TRN_VAL_: 0.0392 TRN_mean_squared_error: 188360817105.3529 TRN_MAPE_: 1.7159\n",
            "# 0009 |  TST_loss: 2.1498 TST_MAE_: 1.2603 TST_RMSLE: 2.1498 TST_VAL_: 1.1276 TST_mean_squared_error: 185318695088.8064 TST_MAPE_: 1.7594 ///  TRN_loss: 2.1892 TRN_MAE_: 0.9853 TRN_RMSLE: 2.1892 TRN_VAL_: 0.0399 TRN_mean_squared_error: 188360892169.2658 TRN_MAPE_: 1.7108\n",
            "# 0010 |  TST_loss: 2.1496 TST_MAE_: 1.2551 TST_RMSLE: 2.1496 TST_VAL_: 1.1196 TST_mean_squared_error: 185318752645.1433 TST_MAPE_: 1.7553 ///  TRN_loss: 2.1890 TRN_MAE_: 0.9845 TRN_RMSLE: 2.1890 TRN_VAL_: 0.0415 TRN_mean_squared_error: 188360954769.1187 TRN_MAPE_: 1.7063\n",
            "# 0011 |  TST_loss: 2.1494 TST_MAE_: 1.2507 TST_RMSLE: 2.1494 TST_VAL_: 1.1126 TST_mean_squared_error: 185318814651.3775 TST_MAPE_: 1.7518 ///  TRN_loss: 2.1890 TRN_MAE_: 0.9855 TRN_RMSLE: 2.1890 TRN_VAL_: 0.0390 TRN_mean_squared_error: 188361008428.4629 TRN_MAPE_: 1.7025\n",
            "# 0012 |  TST_loss: 2.1493 TST_MAE_: 1.2471 TST_RMSLE: 2.1493 TST_VAL_: 1.1070 TST_mean_squared_error: 185318834209.1908 TST_MAPE_: 1.7489 ///  TRN_loss: 2.1889 TRN_MAE_: 0.9853 TRN_RMSLE: 2.1889 TRN_VAL_: 0.0391 TRN_mean_squared_error: 188361053448.3235 TRN_MAPE_: 1.6992\n",
            "# 0013 |  TST_loss: 2.1492 TST_MAE_: 1.2442 TST_RMSLE: 2.1492 TST_VAL_: 1.1024 TST_mean_squared_error: 185318884167.8042 TST_MAPE_: 1.7466 ///  TRN_loss: 2.1889 TRN_MAE_: 0.9854 TRN_RMSLE: 2.1889 TRN_VAL_: 0.0390 TRN_mean_squared_error: 188361097910.0212 TRN_MAPE_: 1.6965\n",
            "# 0014 |  TST_loss: 2.1491 TST_MAE_: 1.2418 TST_RMSLE: 2.1491 TST_VAL_: 1.0987 TST_mean_squared_error: 185318912721.7546 TST_MAPE_: 1.7447 ///  TRN_loss: 2.1888 TRN_MAE_: 0.9856 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0382 TRN_mean_squared_error: 188361121078.7245 TRN_MAPE_: 1.6944\n",
            "# 0015 |  TST_loss: 2.1490 TST_MAE_: 1.2400 TST_RMSLE: 2.1490 TST_VAL_: 1.0958 TST_mean_squared_error: 185318927757.4212 TST_MAPE_: 1.7432 ///  TRN_loss: 2.1889 TRN_MAE_: 0.9854 TRN_RMSLE: 2.1889 TRN_VAL_: 0.0387 TRN_mean_squared_error: 188361153207.0834 TRN_MAPE_: 1.6927\n",
            "# 0016 |  TST_loss: 2.1490 TST_MAE_: 1.2386 TST_RMSLE: 2.1490 TST_VAL_: 1.0936 TST_mean_squared_error: 185318929310.4227 TST_MAPE_: 1.7421 ///  TRN_loss: 2.1888 TRN_MAE_: 0.9847 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0403 TRN_mean_squared_error: 188361163874.3034 TRN_MAPE_: 1.6914\n",
            "# 0017 |  TST_loss: 2.1490 TST_MAE_: 1.2375 TST_RMSLE: 2.1490 TST_VAL_: 1.0919 TST_mean_squared_error: 185318943472.8615 TST_MAPE_: 1.7412 ///  TRN_loss: 2.1888 TRN_MAE_: 0.9852 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0390 TRN_mean_squared_error: 188361175130.0588 TRN_MAPE_: 1.6904\n",
            "# 0018 |  TST_loss: 2.1489 TST_MAE_: 1.2368 TST_RMSLE: 2.1489 TST_VAL_: 1.0907 TST_mean_squared_error: 185318988457.7434 TST_MAPE_: 1.7406 ///  TRN_loss: 2.1888 TRN_MAE_: 0.9859 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0371 TRN_mean_squared_error: 188361189289.0658 TRN_MAPE_: 1.6896\n",
            "# 0019 |  TST_loss: 2.1489 TST_MAE_: 1.2361 TST_RMSLE: 2.1489 TST_VAL_: 1.0897 TST_mean_squared_error: 185318991741.5565 TST_MAPE_: 1.7401 ///  TRN_loss: 2.1888 TRN_MAE_: 0.9856 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0379 TRN_mean_squared_error: 188361205545.0901 TRN_MAPE_: 1.6891\n",
            "# 0020 |  TST_loss: 2.1489 TST_MAE_: 1.2358 TST_RMSLE: 2.1489 TST_VAL_: 1.0891 TST_mean_squared_error: 185318992155.6612 TST_MAPE_: 1.7398 ///  TRN_loss: 2.1888 TRN_MAE_: 0.9852 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0389 TRN_mean_squared_error: 188361210821.6003 TRN_MAPE_: 1.6886\n",
            "# 0021 |  TST_loss: 2.1489 TST_MAE_: 1.2354 TST_RMSLE: 2.1489 TST_VAL_: 1.0886 TST_mean_squared_error: 185318992542.0291 TST_MAPE_: 1.7395 ///  TRN_loss: 2.1889 TRN_MAE_: 0.9855 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0382 TRN_mean_squared_error: 188361217918.9576 TRN_MAPE_: 1.6883\n",
            "# 0022 |  TST_loss: 2.1489 TST_MAE_: 1.2352 TST_RMSLE: 2.1489 TST_VAL_: 1.0883 TST_mean_squared_error: 185318992754.4429 TST_MAPE_: 1.7394 ///  TRN_loss: 2.1888 TRN_MAE_: 0.9851 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0393 TRN_mean_squared_error: 188361219723.1910 TRN_MAPE_: 1.6880\n",
            "# 0023 |  TST_loss: 2.1489 TST_MAE_: 1.2350 TST_RMSLE: 2.1489 TST_VAL_: 1.0879 TST_mean_squared_error: 185318992999.1233 TST_MAPE_: 1.7392 ///  TRN_loss: 2.1888 TRN_MAE_: 0.9860 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0367 TRN_mean_squared_error: 188361218699.6760 TRN_MAPE_: 1.6881\n",
            "# 0024 |  TST_loss: 2.1489 TST_MAE_: 1.2348 TST_RMSLE: 2.1489 TST_VAL_: 1.0876 TST_mean_squared_error: 185318993210.6848 TST_MAPE_: 1.7390 ///  TRN_loss: 2.1888 TRN_MAE_: 0.9852 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0390 TRN_mean_squared_error: 188361221749.9996 TRN_MAPE_: 1.6879\n",
            "# 0025 |  TST_loss: 2.1489 TST_MAE_: 1.2348 TST_RMSLE: 2.1489 TST_VAL_: 1.0876 TST_mean_squared_error: 185318993234.3972 TST_MAPE_: 1.7390 ///  TRN_loss: 2.1888 TRN_MAE_: 0.9861 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0366 TRN_mean_squared_error: 188361220704.9565 TRN_MAPE_: 1.6876\n",
            "# 0026 |  TST_loss: 2.1489 TST_MAE_: 1.2347 TST_RMSLE: 2.1489 TST_VAL_: 1.0875 TST_mean_squared_error: 185318993308.6978 TST_MAPE_: 1.7390 ///  TRN_loss: 2.1888 TRN_MAE_: 0.9859 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0371 TRN_mean_squared_error: 188361221553.4380 TRN_MAPE_: 1.6877\n",
            "# 0027 |  TST_loss: 2.1489 TST_MAE_: 1.2347 TST_RMSLE: 2.1489 TST_VAL_: 1.0874 TST_mean_squared_error: 185318993347.3348 TST_MAPE_: 1.7389 ///  TRN_loss: 2.1888 TRN_MAE_: 0.9859 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0370 TRN_mean_squared_error: 188361221950.0070 TRN_MAPE_: 1.6876\n",
            "# 0028 |  TST_loss: 2.1489 TST_MAE_: 1.2347 TST_RMSLE: 2.1489 TST_VAL_: 1.0874 TST_mean_squared_error: 185318993362.5837 TST_MAPE_: 1.7389 ///  TRN_loss: 2.1888 TRN_MAE_: 0.9854 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0381 TRN_mean_squared_error: 188361222966.1647 TRN_MAPE_: 1.6874\n",
            "# 0029 |  TST_loss: 2.1489 TST_MAE_: 1.2346 TST_RMSLE: 2.1489 TST_VAL_: 1.0874 TST_mean_squared_error: 185318993396.7772 TST_MAPE_: 1.7389 ///  TRN_loss: 2.1888 TRN_MAE_: 0.9856 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0376 TRN_mean_squared_error: 188361221218.6263 TRN_MAPE_: 1.6875\n",
            "# 0030 |  TST_loss: 2.1489 TST_MAE_: 1.2347 TST_RMSLE: 2.1489 TST_VAL_: 1.0874 TST_mean_squared_error: 185318993367.9318 TST_MAPE_: 1.7389 ///  TRN_loss: 2.1888 TRN_MAE_: 0.9859 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0368 TRN_mean_squared_error: 188361222086.6151 TRN_MAPE_: 1.6876\n",
            "# 0030 |  TST_loss: 2.1489 TST_MAE_: 1.2347 TST_RMSLE: 2.1489 TST_VAL_: 1.0874 TST_mean_squared_error: 185318993367.9318 TST_MAPE_: 1.7389 ///  TRN_loss: 2.1888 TRN_MAE_: 0.9859 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0368 TRN_mean_squared_error: 188361222086.6151 TRN_MAPE_: 1.6876\n",
            "\n",
            "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
            "********* 0.007 *********************************\n",
            "# 0001 |  TST_loss: 1.7373 TST_MAE_: 1.3514 TST_RMSLE: 2.1561 TST_VAL_: 1.2654 TST_mean_squared_error: 185317644450.0932 TST_MAPE_: 1.8278 ///  TRN_loss: 1.6666 TRN_MAE_: 0.9851 TRN_RMSLE: 2.1939 TRN_VAL_: 0.0448 TRN_mean_squared_error: 188359940019.9532 TRN_MAPE_: 1.7758\n",
            "# 0002 |  TST_loss: 1.7373 TST_MAE_: 1.3553 TST_RMSLE: 2.1565 TST_VAL_: 1.2711 TST_mean_squared_error: 185317604197.1501 TST_MAPE_: 1.8306 ///  TRN_loss: 1.6665 TRN_MAE_: 0.9851 TRN_RMSLE: 2.1942 TRN_VAL_: 0.0452 TRN_mean_squared_error: 188359877919.2047 TRN_MAPE_: 1.7799\n",
            "# 0003 |  TST_loss: 1.7374 TST_MAE_: 1.3632 TST_RMSLE: 2.1572 TST_VAL_: 1.2826 TST_mean_squared_error: 185317523699.6770 TST_MAPE_: 1.8362 ///  TRN_loss: 1.6665 TRN_MAE_: 0.9850 TRN_RMSLE: 2.1942 TRN_VAL_: 0.0454 TRN_mean_squared_error: 188359883074.7243 TRN_MAPE_: 1.7796\n",
            ".......\n",
            "# 0004 |  TST_loss: 1.7373 TST_MAE_: 1.3565 TST_RMSLE: 2.1566 TST_VAL_: 1.2729 TST_mean_squared_error: 185317602989.8546 TST_MAPE_: 1.8315 ///  TRN_loss: 1.6665 TRN_MAE_: 0.9856 TRN_RMSLE: 2.1942 TRN_VAL_: 0.0436 TRN_mean_squared_error: 188359876466.1028 TRN_MAPE_: 1.7800\n",
            "# 0005 |  TST_loss: 1.7373 TST_MAE_: 1.3575 TST_RMSLE: 2.1567 TST_VAL_: 1.2743 TST_mean_squared_error: 185317599462.7719 TST_MAPE_: 1.8321 ///  TRN_loss: 1.6665 TRN_MAE_: 0.9857 TRN_RMSLE: 2.1942 TRN_VAL_: 0.0429 TRN_mean_squared_error: 188359879408.3044 TRN_MAPE_: 1.7797\n",
            "# 0006 |  TST_loss: 1.7373 TST_MAE_: 1.3547 TST_RMSLE: 2.1564 TST_VAL_: 1.2702 TST_mean_squared_error: 185317615193.4640 TST_MAPE_: 1.8301 ///  TRN_loss: 1.6665 TRN_MAE_: 0.9853 TRN_RMSLE: 2.1942 TRN_VAL_: 0.0446 TRN_mean_squared_error: 188359876548.0300 TRN_MAPE_: 1.7800\n",
            "# 0007 |  TST_loss: 1.7373 TST_MAE_: 1.3547 TST_RMSLE: 2.1564 TST_VAL_: 1.2702 TST_mean_squared_error: 185317615214.6538 TST_MAPE_: 1.8301 ///  TRN_loss: 1.6665 TRN_MAE_: 0.9855 TRN_RMSLE: 2.1942 TRN_VAL_: 0.0438 TRN_mean_squared_error: 188359873321.9807 TRN_MAPE_: 1.7800\n",
            "# 0008 |  TST_loss: 1.7372 TST_MAE_: 1.3536 TST_RMSLE: 2.1563 TST_VAL_: 1.2686 TST_mean_squared_error: 185317642258.6984 TST_MAPE_: 1.8293 ///  TRN_loss: 1.6665 TRN_MAE_: 0.9856 TRN_RMSLE: 2.1942 TRN_VAL_: 0.0434 TRN_mean_squared_error: 188359879517.1081 TRN_MAPE_: 1.7799\n",
            "# 0009 |  TST_loss: 1.7373 TST_MAE_: 1.3527 TST_RMSLE: 2.1563 TST_VAL_: 1.2673 TST_mean_squared_error: 185317643163.7831 TST_MAPE_: 1.8287 ///  TRN_loss: 1.6665 TRN_MAE_: 0.9849 TRN_RMSLE: 2.1942 TRN_VAL_: 0.0454 TRN_mean_squared_error: 188359877352.1199 TRN_MAPE_: 1.7798\n",
            "# 0010 |  TST_loss: 1.7374 TST_MAE_: 1.3586 TST_RMSLE: 2.1568 TST_VAL_: 1.2759 TST_mean_squared_error: 185317598358.3856 TST_MAPE_: 1.8329 ///  TRN_loss: 1.6665 TRN_MAE_: 0.9855 TRN_RMSLE: 2.1942 TRN_VAL_: 0.0436 TRN_mean_squared_error: 188359881265.0916 TRN_MAPE_: 1.7798\n",
            "# 0011 |  TST_loss: 1.7372 TST_MAE_: 1.3521 TST_RMSLE: 2.1562 TST_VAL_: 1.2664 TST_mean_squared_error: 185317643777.5977 TST_MAPE_: 1.8282 ///  TRN_loss: 1.6665 TRN_MAE_: 0.9858 TRN_RMSLE: 2.1942 TRN_VAL_: 0.0427 TRN_mean_squared_error: 188359877475.9984 TRN_MAPE_: 1.7799\n",
            "# 0012 |  TST_loss: 1.7375 TST_MAE_: 1.3539 TST_RMSLE: 2.1564 TST_VAL_: 1.2691 TST_mean_squared_error: 185317641969.9184 TST_MAPE_: 1.8295 ///  TRN_loss: 1.6665 TRN_MAE_: 0.9854 TRN_RMSLE: 2.1942 TRN_VAL_: 0.0441 TRN_mean_squared_error: 188359882718.1227 TRN_MAPE_: 1.7795\n",
            "# 0013 |  TST_loss: 1.7373 TST_MAE_: 1.3485 TST_RMSLE: 2.1559 TST_VAL_: 1.2611 TST_mean_squared_error: 185317686345.1642 TST_MAPE_: 1.8256 ///  TRN_loss: 1.6665 TRN_MAE_: 0.9853 TRN_RMSLE: 2.1942 TRN_VAL_: 0.0443 TRN_mean_squared_error: 188359875976.5749 TRN_MAPE_: 1.7801\n",
            "# 0014 |  TST_loss: 1.7372 TST_MAE_: 1.3541 TST_RMSLE: 2.1564 TST_VAL_: 1.2694 TST_mean_squared_error: 185317628778.1224 TST_MAPE_: 1.8297 ///  TRN_loss: 1.6665 TRN_MAE_: 0.9855 TRN_RMSLE: 2.1942 TRN_VAL_: 0.0435 TRN_mean_squared_error: 188359875057.7620 TRN_MAPE_: 1.7800\n",
            "\n",
            "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0035000001080334187.\n",
            "# 0015 |  TST_loss: 1.7372 TST_MAE_: 1.3523 TST_RMSLE: 2.1562 TST_VAL_: 1.2667 TST_mean_squared_error: 185317643605.3824 TST_MAPE_: 1.8284 ///  TRN_loss: 1.6664 TRN_MAE_: 0.9851 TRN_RMSLE: 2.1942 TRN_VAL_: 0.0450 TRN_mean_squared_error: 188359880857.0881 TRN_MAPE_: 1.7798\n",
            "# 0016 |  TST_loss: 1.7373 TST_MAE_: 1.3560 TST_RMSLE: 2.1565 TST_VAL_: 1.2721 TST_mean_squared_error: 185317603548.8824 TST_MAPE_: 1.8310 ///  TRN_loss: 1.6664 TRN_MAE_: 0.9848 TRN_RMSLE: 2.1942 TRN_VAL_: 0.0459 TRN_mean_squared_error: 188359878738.9340 TRN_MAPE_: 1.7797\n",
            "# 0017 |  TST_loss: 1.7373 TST_MAE_: 1.3577 TST_RMSLE: 2.1567 TST_VAL_: 1.2747 TST_mean_squared_error: 185317599214.9496 TST_MAPE_: 1.8323 ///  TRN_loss: 1.6664 TRN_MAE_: 0.9846 TRN_RMSLE: 2.1942 TRN_VAL_: 0.0465 TRN_mean_squared_error: 188359880809.6444 TRN_MAPE_: 1.7797\n",
            "# 0018 |  TST_loss: 1.7373 TST_MAE_: 1.3563 TST_RMSLE: 2.1566 TST_VAL_: 1.2726 TST_mean_squared_error: 185317603195.0597 TST_MAPE_: 1.8313 ///  TRN_loss: 1.6664 TRN_MAE_: 0.9855 TRN_RMSLE: 2.1942 TRN_VAL_: 0.0439 TRN_mean_squared_error: 188359879776.0607 TRN_MAPE_: 1.7797\n",
            "# 0019 |  TST_loss: 1.7372 TST_MAE_: 1.3549 TST_RMSLE: 2.1564 TST_VAL_: 1.2705 TST_mean_squared_error: 185317614998.5595 TST_MAPE_: 1.8303 ///  TRN_loss: 1.6664 TRN_MAE_: 0.9853 TRN_RMSLE: 2.1942 TRN_VAL_: 0.0445 TRN_mean_squared_error: 188359881977.8654 TRN_MAPE_: 1.7797\n",
            "# 0020 |  TST_loss: 1.7371 TST_MAE_: 1.3448 TST_RMSLE: 2.1556 TST_VAL_: 1.2556 TST_mean_squared_error: 185317723832.7921 TST_MAPE_: 1.8230 ///  TRN_loss: 1.6664 TRN_MAE_: 0.9856 TRN_RMSLE: 2.1942 TRN_VAL_: 0.0435 TRN_mean_squared_error: 188359874746.1015 TRN_MAPE_: 1.7801\n",
            "# 0021 |  TST_loss: 1.7372 TST_MAE_: 1.3526 TST_RMSLE: 2.1562 TST_VAL_: 1.2671 TST_mean_squared_error: 185317643282.1728 TST_MAPE_: 1.8286 ///  TRN_loss: 1.6664 TRN_MAE_: 0.9857 TRN_RMSLE: 2.1942 TRN_VAL_: 0.0430 TRN_mean_squared_error: 188359882438.4398 TRN_MAPE_: 1.7795\n",
            "# 0022 |  TST_loss: 1.7371 TST_MAE_: 1.3507 TST_RMSLE: 2.1561 TST_VAL_: 1.2644 TST_mean_squared_error: 185317665883.0976 TST_MAPE_: 1.8273 ///  TRN_loss: 1.6664 TRN_MAE_: 0.9859 TRN_RMSLE: 2.1942 TRN_VAL_: 0.0426 TRN_mean_squared_error: 188359882853.0428 TRN_MAPE_: 1.7796\n",
            "# 0023 |  TST_loss: 1.7372 TST_MAE_: 1.3550 TST_RMSLE: 2.1565 TST_VAL_: 1.2707 TST_mean_squared_error: 185317614872.4532 TST_MAPE_: 1.8304 ///  TRN_loss: 1.6664 TRN_MAE_: 0.9848 TRN_RMSLE: 2.1942 TRN_VAL_: 0.0458 TRN_mean_squared_error: 188359881953.7488 TRN_MAPE_: 1.7797\n",
            "# 0024 |  TST_loss: 1.7372 TST_MAE_: 1.3505 TST_RMSLE: 2.1561 TST_VAL_: 1.2641 TST_mean_squared_error: 185317668712.8306 TST_MAPE_: 1.8271 ///  TRN_loss: 1.6664 TRN_MAE_: 0.9848 TRN_RMSLE: 2.1942 TRN_VAL_: 0.0457 TRN_mean_squared_error: 188359879649.1102 TRN_MAPE_: 1.7798\n",
            "# 0025 |  TST_loss: 1.7372 TST_MAE_: 1.3549 TST_RMSLE: 2.1564 TST_VAL_: 1.2705 TST_mean_squared_error: 185317615015.9061 TST_MAPE_: 1.8303 ///  TRN_loss: 1.6664 TRN_MAE_: 0.9853 TRN_RMSLE: 2.1942 TRN_VAL_: 0.0443 TRN_mean_squared_error: 188359883202.7328 TRN_MAPE_: 1.7796\n",
            "# 0026 |  TST_loss: 1.7372 TST_MAE_: 1.3534 TST_RMSLE: 2.1563 TST_VAL_: 1.2683 TST_mean_squared_error: 185317642515.8502 TST_MAPE_: 1.8292 ///  TRN_loss: 1.6664 TRN_MAE_: 0.9848 TRN_RMSLE: 2.1942 TRN_VAL_: 0.0461 TRN_mean_squared_error: 188359878710.7606 TRN_MAPE_: 1.7799\n",
            "# 0026 |  TST_loss: 1.7372 TST_MAE_: 1.3534 TST_RMSLE: 2.1563 TST_VAL_: 1.2683 TST_mean_squared_error: 185317642515.8502 TST_MAPE_: 1.8292 ///  TRN_loss: 1.6664 TRN_MAE_: 0.9848 TRN_RMSLE: 2.1942 TRN_VAL_: 0.0461 TRN_mean_squared_error: 188359878710.7606 TRN_MAPE_: 1.7799\n",
            "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.0017500000540167093.\n",
            "# 0027 |  TST_loss: 1.7372 TST_MAE_: 1.3552 TST_RMSLE: 2.1565 TST_VAL_: 1.2709 TST_mean_squared_error: 185317614736.7249 TST_MAPE_: 1.8305 ///  TRN_loss: 1.6664 TRN_MAE_: 0.9855 TRN_RMSLE: 2.1942 TRN_VAL_: 0.0438 TRN_mean_squared_error: 188359880589.3273 TRN_MAPE_: 1.7796\n",
            "# 0028 |  TST_loss: 1.7372 TST_MAE_: 1.3555 TST_RMSLE: 2.1565 TST_VAL_: 1.2714 TST_mean_squared_error: 185317604031.7392 TST_MAPE_: 1.8307 ///  TRN_loss: 1.6664 TRN_MAE_: 0.9853 TRN_RMSLE: 2.1942 TRN_VAL_: 0.0444 TRN_mean_squared_error: 188359883358.3990 TRN_MAPE_: 1.7795\n",
            "# 0029 |  TST_loss: 1.7372 TST_MAE_: 1.3533 TST_RMSLE: 2.1563 TST_VAL_: 1.2682 TST_mean_squared_error: 185317642529.9499 TST_MAPE_: 1.8291 ///  TRN_loss: 1.6664 TRN_MAE_: 0.9857 TRN_RMSLE: 2.1942 TRN_VAL_: 0.0433 TRN_mean_squared_error: 188359881490.1785 TRN_MAPE_: 1.7797\n",
            "# 0030 |  TST_loss: 1.7372 TST_MAE_: 1.3543 TST_RMSLE: 2.1564 TST_VAL_: 1.2696 TST_mean_squared_error: 185317628603.4549 TST_MAPE_: 1.8298 ///  TRN_loss: 1.6664 TRN_MAE_: 0.9856 TRN_RMSLE: 2.1942 TRN_VAL_: 0.0436 TRN_mean_squared_error: 188359880285.4632 TRN_MAPE_: 1.7797\n",
            "# 0030 |  TST_loss: 1.7372 TST_MAE_: 1.3543 TST_RMSLE: 2.1564 TST_VAL_: 1.2696 TST_mean_squared_error: 185317628603.4549 TST_MAPE_: 1.8298 ///  TRN_loss: 1.6664 TRN_MAE_: 0.9856 TRN_RMSLE: 2.1942 TRN_VAL_: 0.0436 TRN_mean_squared_error: 188359880285.4632 TRN_MAPE_: 1.7797\n",
            "********* 0.007 *********************************\n",
            "# 0001 |  TST_loss: 2.1490 TST_MAE_: 1.2342 TST_RMSLE: 2.1489 TST_VAL_: 1.0866 TST_mean_squared_error: 185318993908.9514 TST_MAPE_: 1.7385 ///  TRN_loss: 2.1891 TRN_MAE_: 0.9857 TRN_RMSLE: 2.1890 TRN_VAL_: 0.0379 TRN_mean_squared_error: 188361158130.0536 TRN_MAPE_: 1.6921\n",
            "# 0002 |  TST_loss: 2.1491 TST_MAE_: 1.2362 TST_RMSLE: 2.1489 TST_VAL_: 1.0898 TST_mean_squared_error: 185318991673.3680 TST_MAPE_: 1.7402 ///  TRN_loss: 2.1890 TRN_MAE_: 0.9857 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0373 TRN_mean_squared_error: 188361220259.2263 TRN_MAPE_: 1.6875\n",
            "# 0003 |  TST_loss: 2.1491 TST_MAE_: 1.2383 TST_RMSLE: 2.1490 TST_VAL_: 1.0931 TST_mean_squared_error: 185318942620.6865 TST_MAPE_: 1.7418 ///  TRN_loss: 2.1889 TRN_MAE_: 0.9857 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0376 TRN_mean_squared_error: 188361223396.7494 TRN_MAPE_: 1.6874\n",
            ".......\n",
            "# 0004 |  TST_loss: 2.1490 TST_MAE_: 1.2344 TST_RMSLE: 2.1489 TST_VAL_: 1.0869 TST_mean_squared_error: 185318993699.5089 TST_MAPE_: 1.7387 ///  TRN_loss: 2.1890 TRN_MAE_: 0.9859 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0370 TRN_mean_squared_error: 188361219524.5771 TRN_MAPE_: 1.6876\n",
            "# 0005 |  TST_loss: 2.1491 TST_MAE_: 1.2370 TST_RMSLE: 2.1490 TST_VAL_: 1.0910 TST_mean_squared_error: 185318988234.4022 TST_MAPE_: 1.7408 ///  TRN_loss: 2.1890 TRN_MAE_: 0.9852 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0389 TRN_mean_squared_error: 188361221144.7644 TRN_MAPE_: 1.6875\n",
            "# 0006 |  TST_loss: 2.1491 TST_MAE_: 1.2388 TST_RMSLE: 2.1490 TST_VAL_: 1.0939 TST_mean_squared_error: 185318929097.4897 TST_MAPE_: 1.7422 ///  TRN_loss: 2.1889 TRN_MAE_: 0.9852 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0389 TRN_mean_squared_error: 188361221218.2840 TRN_MAPE_: 1.6876\n",
            "# 0007 |  TST_loss: 2.1489 TST_MAE_: 1.2300 TST_RMSLE: 2.1488 TST_VAL_: 1.0801 TST_mean_squared_error: 185319058270.6765 TST_MAPE_: 1.7352 ///  TRN_loss: 2.1889 TRN_MAE_: 0.9852 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0390 TRN_mean_squared_error: 188361222850.4669 TRN_MAPE_: 1.6875\n",
            "# 0008 |  TST_loss: 2.1491 TST_MAE_: 1.2356 TST_RMSLE: 2.1489 TST_VAL_: 1.0889 TST_mean_squared_error: 185318992318.8364 TST_MAPE_: 1.7397 ///  TRN_loss: 2.1890 TRN_MAE_: 0.9854 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0385 TRN_mean_squared_error: 188361221987.5706 TRN_MAPE_: 1.6875\n",
            "# 0009 |  TST_loss: 2.1487 TST_MAE_: 1.2239 TST_RMSLE: 2.1486 TST_VAL_: 1.0702 TST_mean_squared_error: 185319114522.8165 TST_MAPE_: 1.7301 ///  TRN_loss: 2.1889 TRN_MAE_: 0.9861 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0366 TRN_mean_squared_error: 188361220227.1530 TRN_MAPE_: 1.6877\n",
            "# 0010 |  TST_loss: 2.1489 TST_MAE_: 1.2250 TST_RMSLE: 2.1486 TST_VAL_: 1.0721 TST_mean_squared_error: 185319113239.3367 TST_MAPE_: 1.7311 ///  TRN_loss: 2.1889 TRN_MAE_: 0.9858 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0371 TRN_mean_squared_error: 188361222737.4696 TRN_MAPE_: 1.6873\n",
            "# 0011 |  TST_loss: 2.1491 TST_MAE_: 1.2360 TST_RMSLE: 2.1489 TST_VAL_: 1.0895 TST_mean_squared_error: 185318991882.9823 TST_MAPE_: 1.7400 ///  TRN_loss: 2.1889 TRN_MAE_: 0.9847 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0401 TRN_mean_squared_error: 188361223418.2215 TRN_MAPE_: 1.6875\n",
            "# 0012 |  TST_loss: 2.1488 TST_MAE_: 1.2298 TST_RMSLE: 2.1488 TST_VAL_: 1.0796 TST_mean_squared_error: 185319058579.5332 TST_MAPE_: 1.7350 ///  TRN_loss: 2.1889 TRN_MAE_: 0.9858 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0373 TRN_mean_squared_error: 188361225341.9884 TRN_MAPE_: 1.6875\n",
            "# 0013 |  TST_loss: 2.1490 TST_MAE_: 1.2322 TST_RMSLE: 2.1488 TST_VAL_: 1.0835 TST_mean_squared_error: 185318996128.4913 TST_MAPE_: 1.7369 ///  TRN_loss: 2.1889 TRN_MAE_: 0.9860 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0367 TRN_mean_squared_error: 188361219527.8832 TRN_MAPE_: 1.6875\n",
            "# 0014 |  TST_loss: 2.1489 TST_MAE_: 1.2331 TST_RMSLE: 2.1488 TST_VAL_: 1.0849 TST_mean_squared_error: 185318995098.8194 TST_MAPE_: 1.7377 ///  TRN_loss: 2.1890 TRN_MAE_: 0.9857 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0374 TRN_mean_squared_error: 188361223597.4378 TRN_MAPE_: 1.6875\n",
            "\n",
            "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0035000001080334187.\n",
            "# 0015 |  TST_loss: 2.1489 TST_MAE_: 1.2330 TST_RMSLE: 2.1488 TST_VAL_: 1.0848 TST_mean_squared_error: 185318995176.5699 TST_MAPE_: 1.7376 ///  TRN_loss: 2.1888 TRN_MAE_: 0.9858 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0372 TRN_mean_squared_error: 188361223254.8401 TRN_MAPE_: 1.6875\n",
            "# 0016 |  TST_loss: 2.1489 TST_MAE_: 1.2319 TST_RMSLE: 2.1488 TST_VAL_: 1.0831 TST_mean_squared_error: 185319032784.2648 TST_MAPE_: 1.7367 ///  TRN_loss: 2.1889 TRN_MAE_: 0.9859 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0370 TRN_mean_squared_error: 188361221360.5518 TRN_MAPE_: 1.6875\n",
            "# 0017 |  TST_loss: 2.1489 TST_MAE_: 1.2340 TST_RMSLE: 2.1489 TST_VAL_: 1.0863 TST_mean_squared_error: 185318994123.4301 TST_MAPE_: 1.7384 ///  TRN_loss: 2.1889 TRN_MAE_: 0.9857 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0376 TRN_mean_squared_error: 188361223595.2990 TRN_MAPE_: 1.6875\n",
            "# 0018 |  TST_loss: 2.1488 TST_MAE_: 1.2289 TST_RMSLE: 2.1487 TST_VAL_: 1.0782 TST_mean_squared_error: 185319059594.1274 TST_MAPE_: 1.7342 ///  TRN_loss: 2.1888 TRN_MAE_: 0.9849 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0398 TRN_mean_squared_error: 188361217814.4015 TRN_MAPE_: 1.6879\n",
            "# 0019 |  TST_loss: 2.1490 TST_MAE_: 1.2356 TST_RMSLE: 2.1489 TST_VAL_: 1.0888 TST_mean_squared_error: 185318992364.3587 TST_MAPE_: 1.7397 ///  TRN_loss: 2.1889 TRN_MAE_: 0.9861 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0365 TRN_mean_squared_error: 188361228694.2755 TRN_MAPE_: 1.6871\n",
            "# 0020 |  TST_loss: 2.1489 TST_MAE_: 1.2335 TST_RMSLE: 2.1489 TST_VAL_: 1.0855 TST_mean_squared_error: 185318994668.7136 TST_MAPE_: 1.7380 ///  TRN_loss: 2.1889 TRN_MAE_: 0.9852 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0389 TRN_mean_squared_error: 188361221700.9460 TRN_MAPE_: 1.6876\n",
            "# 0021 |  TST_loss: 2.1490 TST_MAE_: 1.2371 TST_RMSLE: 2.1490 TST_VAL_: 1.0912 TST_mean_squared_error: 185318943962.2889 TST_MAPE_: 1.7408 ///  TRN_loss: 2.1889 TRN_MAE_: 0.9859 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0370 TRN_mean_squared_error: 188361224017.0854 TRN_MAPE_: 1.6874\n",
            "# 0022 |  TST_loss: 2.1488 TST_MAE_: 1.2293 TST_RMSLE: 2.1487 TST_VAL_: 1.0788 TST_mean_squared_error: 185319059122.1407 TST_MAPE_: 1.7346 ///  TRN_loss: 2.1889 TRN_MAE_: 0.9852 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0388 TRN_mean_squared_error: 188361221257.4872 TRN_MAPE_: 1.6877\n",
            "# 0023 |  TST_loss: 2.1488 TST_MAE_: 1.2290 TST_RMSLE: 2.1487 TST_VAL_: 1.0784 TST_mean_squared_error: 185319059439.3803 TST_MAPE_: 1.7343 ///  TRN_loss: 2.1889 TRN_MAE_: 0.9859 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0371 TRN_mean_squared_error: 188361219082.3222 TRN_MAPE_: 1.6876\n",
            "# 0024 |  TST_loss: 2.1488 TST_MAE_: 1.2293 TST_RMSLE: 2.1487 TST_VAL_: 1.0789 TST_mean_squared_error: 185319059116.7628 TST_MAPE_: 1.7346 ///  TRN_loss: 2.1889 TRN_MAE_: 0.9855 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0380 TRN_mean_squared_error: 188361221213.7296 TRN_MAPE_: 1.6875\n",
            "# 0025 |  TST_loss: 2.1489 TST_MAE_: 1.2337 TST_RMSLE: 2.1489 TST_VAL_: 1.0858 TST_mean_squared_error: 185318994487.6113 TST_MAPE_: 1.7381 ///  TRN_loss: 2.1889 TRN_MAE_: 0.9854 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0383 TRN_mean_squared_error: 188361226849.1710 TRN_MAPE_: 1.6872\n",
            "# 0026 |  TST_loss: 2.1490 TST_MAE_: 1.2394 TST_RMSLE: 2.1490 TST_VAL_: 1.0949 TST_mean_squared_error: 185318928333.0420 TST_MAPE_: 1.7428 ///  TRN_loss: 2.1889 TRN_MAE_: 0.9864 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0358 TRN_mean_squared_error: 188361224163.5959 TRN_MAPE_: 1.6874\n",
            "# 0027 |  TST_loss: 2.1489 TST_MAE_: 1.2323 TST_RMSLE: 2.1488 TST_VAL_: 1.0837 TST_mean_squared_error: 185318995987.8708 TST_MAPE_: 1.7370 ///  TRN_loss: 2.1888 TRN_MAE_: 0.9857 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0374 TRN_mean_squared_error: 188361220746.1897 TRN_MAPE_: 1.6876\n",
            "# 0027 |  TST_loss: 2.1489 TST_MAE_: 1.2323 TST_RMSLE: 2.1488 TST_VAL_: 1.0837 TST_mean_squared_error: 185318995987.8708 TST_MAPE_: 1.7370 ///  TRN_loss: 2.1888 TRN_MAE_: 0.9857 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0374 TRN_mean_squared_error: 188361220746.1897 TRN_MAPE_: 1.6876\n",
            "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.0017500000540167093.\n",
            "# 0028 |  TST_loss: 2.1488 TST_MAE_: 1.2299 TST_RMSLE: 2.1488 TST_VAL_: 1.0798 TST_mean_squared_error: 185319058441.5957 TST_MAPE_: 1.7350 ///  TRN_loss: 2.1888 TRN_MAE_: 0.9859 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0370 TRN_mean_squared_error: 188361222955.4547 TRN_MAPE_: 1.6876\n",
            "# 0029 |  TST_loss: 2.1489 TST_MAE_: 1.2342 TST_RMSLE: 2.1489 TST_VAL_: 1.0866 TST_mean_squared_error: 185318993897.0134 TST_MAPE_: 1.7385 ///  TRN_loss: 2.1889 TRN_MAE_: 0.9856 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0378 TRN_mean_squared_error: 188361225740.3449 TRN_MAPE_: 1.6872\n",
            "# 0030 |  TST_loss: 2.1489 TST_MAE_: 1.2345 TST_RMSLE: 2.1489 TST_VAL_: 1.0871 TST_mean_squared_error: 185318993611.5401 TST_MAPE_: 1.7387 ///  TRN_loss: 2.1888 TRN_MAE_: 0.9846 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0403 TRN_mean_squared_error: 188361222683.2159 TRN_MAPE_: 1.6875\n",
            "# 0030 |  TST_loss: 2.1489 TST_MAE_: 1.2345 TST_RMSLE: 2.1489 TST_VAL_: 1.0871 TST_mean_squared_error: 185318993611.5401 TST_MAPE_: 1.7387 ///  TRN_loss: 2.1888 TRN_MAE_: 0.9846 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0403 TRN_mean_squared_error: 188361222683.2159 TRN_MAPE_: 1.6875\n",
            "********* 0.007 *********************************\n",
            "# 0001 |  TST_loss: 1.3513 TST_MAE_: 1.3512 TST_RMSLE: 2.1561 TST_VAL_: 1.2651 TST_mean_squared_error: 185317665417.3055 TST_MAPE_: 1.8276 ///  TRN_loss: 0.9852 TRN_MAE_: 0.9851 TRN_RMSLE: 2.1937 TRN_VAL_: 0.0445 TRN_mean_squared_error: 188359967494.6140 TRN_MAPE_: 1.7740\n",
            "# 0002 |  TST_loss: 1.3477 TST_MAE_: 1.3474 TST_RMSLE: 2.1558 TST_VAL_: 1.2596 TST_mean_squared_error: 185317708146.0832 TST_MAPE_: 1.8249 ///  TRN_loss: 0.9854 TRN_MAE_: 0.9852 TRN_RMSLE: 2.1940 TRN_VAL_: 0.0445 TRN_mean_squared_error: 188359895779.7150 TRN_MAPE_: 1.7787\n",
            "# 0003 |  TST_loss: 1.3499 TST_MAE_: 1.3497 TST_RMSLE: 2.1560 TST_VAL_: 1.2629 TST_mean_squared_error: 185317682523.4998 TST_MAPE_: 1.8265 ///  TRN_loss: 0.9846 TRN_MAE_: 0.9844 TRN_RMSLE: 2.1942 TRN_VAL_: 0.0470 TRN_mean_squared_error: 188359882004.1460 TRN_MAPE_: 1.7796\n",
            ".......\n",
            "# 0004 |  TST_loss: 1.3473 TST_MAE_: 1.3472 TST_RMSLE: 2.1558 TST_VAL_: 1.2593 TST_mean_squared_error: 185317708363.3746 TST_MAPE_: 1.8247 ///  TRN_loss: 0.9859 TRN_MAE_: 0.9858 TRN_RMSLE: 2.1942 TRN_VAL_: 0.0428 TRN_mean_squared_error: 188359885552.9256 TRN_MAPE_: 1.7793\n",
            "# 0005 |  TST_loss: 1.3366 TST_MAE_: 1.3366 TST_RMSLE: 2.1549 TST_VAL_: 1.2436 TST_mean_squared_error: 185317828156.2226 TST_MAPE_: 1.8171 ///  TRN_loss: 0.9858 TRN_MAE_: 0.9857 TRN_RMSLE: 2.1941 TRN_VAL_: 0.0432 TRN_mean_squared_error: 188359888725.5679 TRN_MAPE_: 1.7792\n",
            "# 0006 |  TST_loss: 1.3628 TST_MAE_: 1.3627 TST_RMSLE: 2.1572 TST_VAL_: 1.2818 TST_mean_squared_error: 185317524228.6736 TST_MAPE_: 1.8359 ///  TRN_loss: 0.9856 TRN_MAE_: 0.9855 TRN_RMSLE: 2.1940 TRN_VAL_: 0.0436 TRN_mean_squared_error: 188359904103.3867 TRN_MAPE_: 1.7781\n",
            "# 0007 |  TST_loss: 1.3535 TST_MAE_: 1.3535 TST_RMSLE: 2.1563 TST_VAL_: 1.2684 TST_mean_squared_error: 185317642403.3236 TST_MAPE_: 1.8292 ///  TRN_loss: 0.9853 TRN_MAE_: 0.9851 TRN_RMSLE: 2.1941 TRN_VAL_: 0.0449 TRN_mean_squared_error: 188359892263.5916 TRN_MAPE_: 1.7788\n",
            "# 0008 |  TST_loss: 1.3589 TST_MAE_: 1.3587 TST_RMSLE: 2.1568 TST_VAL_: 1.2761 TST_mean_squared_error: 185317598243.1619 TST_MAPE_: 1.8330 ///  TRN_loss: 0.9854 TRN_MAE_: 0.9853 TRN_RMSLE: 2.1942 TRN_VAL_: 0.0444 TRN_mean_squared_error: 188359875561.1065 TRN_MAPE_: 1.7802\n",
            "# 0009 |  TST_loss: 1.3442 TST_MAE_: 1.3440 TST_RMSLE: 2.1555 TST_VAL_: 1.2545 TST_mean_squared_error: 185317737590.6833 TST_MAPE_: 1.8224 ///  TRN_loss: 0.9860 TRN_MAE_: 0.9859 TRN_RMSLE: 2.1942 TRN_VAL_: 0.0426 TRN_mean_squared_error: 188359885065.1147 TRN_MAPE_: 1.7794\n",
            "# 0010 |  TST_loss: 1.3415 TST_MAE_: 1.3413 TST_RMSLE: 2.1553 TST_VAL_: 1.2506 TST_mean_squared_error: 185317763639.9442 TST_MAPE_: 1.8205 ///  TRN_loss: 0.9859 TRN_MAE_: 0.9858 TRN_RMSLE: 2.1942 TRN_VAL_: 0.0428 TRN_mean_squared_error: 188359879898.4242 TRN_MAPE_: 1.7798\n",
            "# 0011 |  TST_loss: 1.3475 TST_MAE_: 1.3474 TST_RMSLE: 2.1558 TST_VAL_: 1.2595 TST_mean_squared_error: 185317708239.3041 TST_MAPE_: 1.8248 ///  TRN_loss: 0.9847 TRN_MAE_: 0.9845 TRN_RMSLE: 2.1939 TRN_VAL_: 0.0466 TRN_mean_squared_error: 188359923014.9543 TRN_MAPE_: 1.7770\n",
            "# 0012 |  TST_loss: 1.3456 TST_MAE_: 1.3453 TST_RMSLE: 2.1556 TST_VAL_: 1.2564 TST_mean_squared_error: 185317720692.2095 TST_MAPE_: 1.8233 ///  TRN_loss: 0.9860 TRN_MAE_: 0.9858 TRN_RMSLE: 2.1943 TRN_VAL_: 0.0428 TRN_mean_squared_error: 188359857187.0996 TRN_MAPE_: 1.7813\n",
            "# 0013 |  TST_loss: 1.3648 TST_MAE_: 1.3647 TST_RMSLE: 2.1573 TST_VAL_: 1.2848 TST_mean_squared_error: 185317511816.0134 TST_MAPE_: 1.8373 ///  TRN_loss: 0.9853 TRN_MAE_: 0.9852 TRN_RMSLE: 2.1940 TRN_VAL_: 0.0446 TRN_mean_squared_error: 188359911669.0467 TRN_MAPE_: 1.7777\n",
            "# 0014 |  TST_loss: 1.3520 TST_MAE_: 1.3520 TST_RMSLE: 2.1562 TST_VAL_: 1.2663 TST_mean_squared_error: 185317643868.6078 TST_MAPE_: 1.8282 ///  TRN_loss: 0.9852 TRN_MAE_: 0.9851 TRN_RMSLE: 2.1941 TRN_VAL_: 0.0450 TRN_mean_squared_error: 188359894622.2128 TRN_MAPE_: 1.7788\n",
            "# 0015 |  TST_loss: 1.3516 TST_MAE_: 1.3513 TST_RMSLE: 2.1561 TST_VAL_: 1.2653 TST_mean_squared_error: 185317644554.8685 TST_MAPE_: 1.8277 ///  TRN_loss: 0.9855 TRN_MAE_: 0.9854 TRN_RMSLE: 2.1942 TRN_VAL_: 0.0440 TRN_mean_squared_error: 188359879223.1658 TRN_MAPE_: 1.7798\n",
            "\n",
            "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0035000001080334187.\n",
            "# 0016 |  TST_loss: 1.3508 TST_MAE_: 1.3508 TST_RMSLE: 2.1561 TST_VAL_: 1.2645 TST_mean_squared_error: 185317665869.7698 TST_MAPE_: 1.8273 ///  TRN_loss: 0.9852 TRN_MAE_: 0.9851 TRN_RMSLE: 2.1943 TRN_VAL_: 0.0448 TRN_mean_squared_error: 188359874245.9198 TRN_MAPE_: 1.7802\n",
            "# 0017 |  TST_loss: 1.3504 TST_MAE_: 1.3503 TST_RMSLE: 2.1560 TST_VAL_: 1.2638 TST_mean_squared_error: 185317668911.4984 TST_MAPE_: 1.8270 ///  TRN_loss: 0.9850 TRN_MAE_: 0.9850 TRN_RMSLE: 2.1942 TRN_VAL_: 0.0454 TRN_mean_squared_error: 188359876645.4002 TRN_MAPE_: 1.7799\n",
            "# 0018 |  TST_loss: 1.3491 TST_MAE_: 1.3490 TST_RMSLE: 2.1559 TST_VAL_: 1.2619 TST_mean_squared_error: 185317683179.9390 TST_MAPE_: 1.8260 ///  TRN_loss: 0.9856 TRN_MAE_: 0.9855 TRN_RMSLE: 2.1941 TRN_VAL_: 0.0436 TRN_mean_squared_error: 188359896337.2404 TRN_MAPE_: 1.7788\n",
            "# 0019 |  TST_loss: 1.3602 TST_MAE_: 1.3601 TST_RMSLE: 2.1569 TST_VAL_: 1.2781 TST_mean_squared_error: 185317573516.0026 TST_MAPE_: 1.8340 ///  TRN_loss: 0.9855 TRN_MAE_: 0.9855 TRN_RMSLE: 2.1940 TRN_VAL_: 0.0438 TRN_mean_squared_error: 188359904677.1136 TRN_MAPE_: 1.7781\n",
            "# 0020 |  TST_loss: 1.3479 TST_MAE_: 1.3479 TST_RMSLE: 2.1558 TST_VAL_: 1.2602 TST_mean_squared_error: 185317686961.9830 TST_MAPE_: 1.8252 ///  TRN_loss: 0.9857 TRN_MAE_: 0.9856 TRN_RMSLE: 2.1941 TRN_VAL_: 0.0435 TRN_mean_squared_error: 188359893491.4813 TRN_MAPE_: 1.7788\n",
            "# 0021 |  TST_loss: 1.3525 TST_MAE_: 1.3524 TST_RMSLE: 2.1562 TST_VAL_: 1.2669 TST_mean_squared_error: 185317643412.6971 TST_MAPE_: 1.8285 ///  TRN_loss: 0.9857 TRN_MAE_: 0.9857 TRN_RMSLE: 2.1942 TRN_VAL_: 0.0432 TRN_mean_squared_error: 188359873493.8865 TRN_MAPE_: 1.7800\n",
            "# 0022 |  TST_loss: 1.3499 TST_MAE_: 1.3499 TST_RMSLE: 2.1560 TST_VAL_: 1.2632 TST_mean_squared_error: 185317682307.1146 TST_MAPE_: 1.8267 ///  TRN_loss: 0.9852 TRN_MAE_: 0.9852 TRN_RMSLE: 2.1941 TRN_VAL_: 0.0447 TRN_mean_squared_error: 188359901202.2346 TRN_MAPE_: 1.7783\n",
            "# 0023 |  TST_loss: 1.3494 TST_MAE_: 1.3493 TST_RMSLE: 2.1560 TST_VAL_: 1.2624 TST_mean_squared_error: 185317682889.8449 TST_MAPE_: 1.8263 ///  TRN_loss: 0.9853 TRN_MAE_: 0.9853 TRN_RMSLE: 2.1941 TRN_VAL_: 0.0443 TRN_mean_squared_error: 188359894152.4674 TRN_MAPE_: 1.7789\n",
            "# 0024 |  TST_loss: 1.3511 TST_MAE_: 1.3511 TST_RMSLE: 2.1561 TST_VAL_: 1.2650 TST_mean_squared_error: 185317665532.9297 TST_MAPE_: 1.8275 ///  TRN_loss: 0.9862 TRN_MAE_: 0.9861 TRN_RMSLE: 2.1941 TRN_VAL_: 0.0417 TRN_mean_squared_error: 188359897847.1616 TRN_MAPE_: 1.7786\n",
            "# 0025 |  TST_loss: 1.3511 TST_MAE_: 1.3510 TST_RMSLE: 2.1561 TST_VAL_: 1.2649 TST_mean_squared_error: 185317665595.3277 TST_MAPE_: 1.8275 ///  TRN_loss: 0.9850 TRN_MAE_: 0.9850 TRN_RMSLE: 2.1942 TRN_VAL_: 0.0453 TRN_mean_squared_error: 188359879584.8822 TRN_MAPE_: 1.7799\n",
            "# 0026 |  TST_loss: 1.3403 TST_MAE_: 1.3403 TST_RMSLE: 2.1552 TST_VAL_: 1.2490 TST_mean_squared_error: 185317764699.7452 TST_MAPE_: 1.8197 ///  TRN_loss: 0.9857 TRN_MAE_: 0.9856 TRN_RMSLE: 2.1942 TRN_VAL_: 0.0433 TRN_mean_squared_error: 188359876462.8138 TRN_MAPE_: 1.7801\n",
            "# 0027 |  TST_loss: 1.3482 TST_MAE_: 1.3481 TST_RMSLE: 2.1558 TST_VAL_: 1.2605 TST_mean_squared_error: 185317686733.7729 TST_MAPE_: 1.8254 ///  TRN_loss: 0.9851 TRN_MAE_: 0.9850 TRN_RMSLE: 2.1941 TRN_VAL_: 0.0451 TRN_mean_squared_error: 188359889474.8851 TRN_MAPE_: 1.7791\n",
            "# 0027 |  TST_loss: 1.3482 TST_MAE_: 1.3481 TST_RMSLE: 2.1558 TST_VAL_: 1.2605 TST_mean_squared_error: 185317686733.7729 TST_MAPE_: 1.8254 ///  TRN_loss: 0.9851 TRN_MAE_: 0.9850 TRN_RMSLE: 2.1941 TRN_VAL_: 0.0451 TRN_mean_squared_error: 188359889474.8851 TRN_MAPE_: 1.7791\n",
            "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.0017500000540167093.\n",
            "# 0028 |  TST_loss: 1.3509 TST_MAE_: 1.3508 TST_RMSLE: 2.1561 TST_VAL_: 1.2645 TST_mean_squared_error: 185317665822.1384 TST_MAPE_: 1.8273 ///  TRN_loss: 0.9856 TRN_MAE_: 0.9855 TRN_RMSLE: 2.1940 TRN_VAL_: 0.0436 TRN_mean_squared_error: 188359905284.1924 TRN_MAPE_: 1.7781\n",
            "# 0029 |  TST_loss: 1.3516 TST_MAE_: 1.3515 TST_RMSLE: 2.1561 TST_VAL_: 1.2656 TST_mean_squared_error: 185317644332.6604 TST_MAPE_: 1.8278 ///  TRN_loss: 0.9858 TRN_MAE_: 0.9857 TRN_RMSLE: 2.1940 TRN_VAL_: 0.0430 TRN_mean_squared_error: 188359899011.4958 TRN_MAPE_: 1.7785\n",
            "# 0030 |  TST_loss: 1.3511 TST_MAE_: 1.3511 TST_RMSLE: 2.1561 TST_VAL_: 1.2649 TST_mean_squared_error: 185317665567.0238 TST_MAPE_: 1.8275 ///  TRN_loss: 0.9850 TRN_MAE_: 0.9850 TRN_RMSLE: 2.1940 TRN_VAL_: 0.0453 TRN_mean_squared_error: 188359897757.7832 TRN_MAPE_: 1.7784\n",
            "# 0030 |  TST_loss: 1.3511 TST_MAE_: 1.3511 TST_RMSLE: 2.1561 TST_VAL_: 1.2649 TST_mean_squared_error: 185317665567.0238 TST_MAPE_: 1.8275 ///  TRN_loss: 0.9850 TRN_MAE_: 0.9850 TRN_RMSLE: 2.1940 TRN_VAL_: 0.0453 TRN_mean_squared_error: 188359897757.7832 TRN_MAPE_: 1.7784\n",
            "********* 0.007 *********************************\n",
            "# 0001 |  TST_loss: 185301152617.1270 TST_MAE_: 3.1883 TST_RMSLE: 2.4238 TST_VAL_: 3.5168 TST_mean_squared_error: 185301152617.1270 TST_MAPE_: 2.5656 ///  TRN_loss: 188351694148.6311 TRN_MAE_: 0.9919 TRN_RMSLE: 2.3282 TRN_VAL_: 0.0846 TRN_mean_squared_error: 188351694148.6311 TRN_MAPE_: 2.1993\n",
            "# 0002 |  TST_loss: 185285754694.2780 TST_MAE_: 5.1948 TST_RMSLE: 2.6705 TST_VAL_: 5.7035 TST_mean_squared_error: 185285754694.2780 TST_MAPE_: 2.9754 ///  TRN_loss: 188335905558.8436 TRN_MAE_: 1.0212 TRN_RMSLE: 2.6188 TRN_VAL_: 0.1611 TRN_mean_squared_error: 188335905558.8436 TRN_MAPE_: 2.7560\n",
            "# 0003 |  TST_loss: 185271328133.1058 TST_MAE_: 7.2266 TST_RMSLE: 2.8671 TST_VAL_: 7.8404 TST_mean_squared_error: 185271328133.1058 TST_MAPE_: 3.2470 ///  TRN_loss: 188321137507.6630 TRN_MAE_: 1.0676 TRN_RMSLE: 2.8510 TRN_VAL_: 0.2498 TRN_mean_squared_error: 188321137507.6630 TRN_MAPE_: 3.0998\n",
            ".......\n",
            "# 0004 |  TST_loss: 185257588061.3971 TST_MAE_: 9.2732 TST_RMSLE: 3.0299 TST_VAL_: 9.9582 TST_mean_squared_error: 185257588061.3971 TST_MAPE_: 3.4465 ///  TRN_loss: 188307249105.8435 TRN_MAE_: 1.1074 TRN_RMSLE: 3.0319 TRN_VAL_: 0.2949 TRN_mean_squared_error: 188307249105.8435 TRN_MAPE_: 3.3344\n",
            "# 0005 |  TST_loss: 185244657889.6455 TST_MAE_: 11.3047 TST_RMSLE: 3.1671 TST_VAL_: 12.0407 TST_mean_squared_error: 185244657889.6455 TST_MAPE_: 3.6038 ///  TRN_loss: 188294077472.4046 TRN_MAE_: 1.1656 TRN_RMSLE: 3.1827 TRN_VAL_: 0.3825 TRN_mean_squared_error: 188294077472.4046 TRN_MAPE_: 3.5148\n",
            "# 0006 |  TST_loss: 185232514523.7714 TST_MAE_: 13.3156 TST_RMSLE: 3.2851 TST_VAL_: 14.0883 TST_mean_squared_error: 185232514523.7714 TST_MAPE_: 3.7317 ///  TRN_loss: 188281692936.0014 TRN_MAE_: 1.2230 TRN_RMSLE: 3.3097 TRN_VAL_: 0.4565 TRN_mean_squared_error: 188281692936.0014 TRN_MAPE_: 3.6592\n",
            "# 0007 |  TST_loss: 185221050262.8603 TST_MAE_: 15.3101 TST_RMSLE: 3.3888 TST_VAL_: 16.1097 TST_mean_squared_error: 185221050262.8603 TST_MAPE_: 3.8374 ///  TRN_loss: 188270057226.6902 TRN_MAE_: 1.2739 TRN_RMSLE: 3.4183 TRN_VAL_: 0.5156 TRN_mean_squared_error: 188270057226.6902 TRN_MAPE_: 3.7765\n",
            "# 0008 |  TST_loss: 185210714993.2966 TST_MAE_: 17.1996 TST_RMSLE: 3.4772 TST_VAL_: 18.0183 TST_mean_squared_error: 185210714993.2966 TST_MAPE_: 3.9235 ///  TRN_loss: 188259343821.5211 TRN_MAE_: 1.3487 TRN_RMSLE: 3.5158 TRN_VAL_: 0.6127 TRN_mean_squared_error: 188259343821.5211 TRN_MAPE_: 3.8764\n",
            "# 0009 |  TST_loss: 185200886053.8310 TST_MAE_: 19.0924 TST_RMSLE: 3.5581 TST_VAL_: 19.9260 TST_mean_squared_error: 185200886053.8310 TST_MAPE_: 3.9987 ///  TRN_loss: 188249397543.2061 TRN_MAE_: 1.3736 TRN_RMSLE: 3.5988 TRN_VAL_: 0.6258 TRN_mean_squared_error: 188249397543.2061 TRN_MAPE_: 3.9576\n",
            "# 0010 |  TST_loss: 185191587459.4350 TST_MAE_: 20.9686 TST_RMSLE: 3.6317 TST_VAL_: 21.8138 TST_mean_squared_error: 185191587459.4350 TST_MAPE_: 4.0647 ///  TRN_loss: 188239959728.0573 TRN_MAE_: 1.4518 TRN_RMSLE: 3.6734 TRN_VAL_: 0.7247 TRN_mean_squared_error: 188239959728.0573 TRN_MAPE_: 4.0277\n",
            "# 0011 |  TST_loss: 185183135257.2414 TST_MAE_: 22.7689 TST_RMSLE: 3.6973 TST_VAL_: 23.6234 TST_mean_squared_error: 185183135257.2414 TST_MAPE_: 4.1212 ///  TRN_loss: 188231226333.7210 TRN_MAE_: 1.5128 TRN_RMSLE: 3.7429 TRN_VAL_: 0.7952 TRN_mean_squared_error: 188231226333.7210 TRN_MAPE_: 4.0904\n",
            "# 0012 |  TST_loss: 185175341895.0396 TST_MAE_: 24.5171 TST_RMSLE: 3.7569 TST_VAL_: 25.3794 TST_mean_squared_error: 185175341895.0396 TST_MAPE_: 4.1704 ///  TRN_loss: 188223248436.6215 TRN_MAE_: 1.5761 TRN_RMSLE: 3.8052 TRN_VAL_: 0.8676 TRN_mean_squared_error: 188223248436.6215 TRN_MAPE_: 4.1442\n",
            "# 0013 |  TST_loss: 185168064068.4019 TST_MAE_: 26.2378 TST_RMSLE: 3.8120 TST_VAL_: 27.1069 TST_mean_squared_error: 185168064068.4019 TST_MAPE_: 4.2140 ///  TRN_loss: 188215844674.3856 TRN_MAE_: 1.6248 TRN_RMSLE: 3.8604 TRN_VAL_: 0.9188 TRN_mean_squared_error: 188215844674.3856 TRN_MAPE_: 4.1901\n",
            "# 0014 |  TST_loss: 185161418175.4918 TST_MAE_: 27.8987 TST_RMSLE: 3.8623 TST_VAL_: 28.7737 TST_mean_squared_error: 185161418175.4918 TST_MAPE_: 4.2524 ///  TRN_loss: 188208995106.5286 TRN_MAE_: 1.6950 TRN_RMSLE: 3.9121 TRN_VAL_: 1.0023 TRN_mean_squared_error: 188208995106.5286 TRN_MAPE_: 4.2314\n",
            "# 0015 |  TST_loss: 185155303919.0504 TST_MAE_: 29.5092 TST_RMSLE: 3.9086 TST_VAL_: 30.3895 TST_mean_squared_error: 185155303919.0504 TST_MAPE_: 4.2868 ///  TRN_loss: 188202783008.3105 TRN_MAE_: 1.7401 TRN_RMSLE: 3.9592 TRN_VAL_: 1.0484 TRN_mean_squared_error: 188202783008.3105 TRN_MAPE_: 4.2679\n",
            "# 0016 |  TST_loss: 185149876123.9332 TST_MAE_: 31.0267 TST_RMSLE: 3.9502 TST_VAL_: 31.9116 TST_mean_squared_error: 185149876123.9332 TST_MAPE_: 4.3166 ///  TRN_loss: 188197141426.8640 TRN_MAE_: 1.8093 TRN_RMSLE: 4.0038 TRN_VAL_: 1.1265 TRN_mean_squared_error: 188197141426.8640 TRN_MAPE_: 4.3014\n",
            "# 0017 |  TST_loss: 185144893364.8455 TST_MAE_: 32.5014 TST_RMSLE: 3.9890 TST_VAL_: 33.3904 TST_mean_squared_error: 185144893364.8455 TST_MAPE_: 4.3436 ///  TRN_loss: 188192038064.9471 TRN_MAE_: 1.7964 TRN_RMSLE: 4.0435 TRN_VAL_: 1.0958 TRN_mean_squared_error: 188192038064.9471 TRN_MAPE_: 4.3301\n",
            "# 0018 |  TST_loss: 185140375757.7827 TST_MAE_: 33.9170 TST_RMSLE: 4.0248 TST_VAL_: 34.8097 TST_mean_squared_error: 185140375757.7827 TST_MAPE_: 4.3678 ///  TRN_loss: 188187392577.1288 TRN_MAE_: 1.8880 TRN_RMSLE: 4.0797 TRN_VAL_: 1.2071 TRN_mean_squared_error: 188187392577.1288 TRN_MAPE_: 4.3554\n",
            "# 0019 |  TST_loss: 185136302633.8743 TST_MAE_: 35.2665 TST_RMSLE: 4.0576 TST_VAL_: 36.1626 TST_mean_squared_error: 185136302633.8743 TST_MAPE_: 4.3894 ///  TRN_loss: 188183210731.5576 TRN_MAE_: 1.9467 TRN_RMSLE: 4.1129 TRN_VAL_: 1.2737 TRN_mean_squared_error: 188183210731.5576 TRN_MAPE_: 4.3780\n",
            "# 0020 |  TST_loss: 185132661196.2768 TST_MAE_: 36.5555 TST_RMSLE: 4.0880 TST_VAL_: 37.4545 TST_mean_squared_error: 185132661196.2768 TST_MAPE_: 4.4089 ///  TRN_loss: 188179471927.3242 TRN_MAE_: 1.9732 TRN_RMSLE: 4.1445 TRN_VAL_: 1.2964 TRN_mean_squared_error: 188179471927.3242 TRN_MAPE_: 4.3990\n",
            "# 0021 |  TST_loss: 185129347040.0012 TST_MAE_: 37.7917 TST_RMSLE: 4.1162 TST_VAL_: 38.6934 TST_mean_squared_error: 185129347040.0012 TST_MAPE_: 4.4266 ///  TRN_loss: 188176092156.5391 TRN_MAE_: 1.9679 TRN_RMSLE: 4.1731 TRN_VAL_: 1.2805 TRN_mean_squared_error: 188176092156.5391 TRN_MAPE_: 4.4175\n",
            "# 0022 |  TST_loss: 185126361386.1422 TST_MAE_: 38.9789 TST_RMSLE: 4.1425 TST_VAL_: 39.8831 TST_mean_squared_error: 185126361386.1422 TST_MAPE_: 4.4428 ///  TRN_loss: 188173039596.0151 TRN_MAE_: 2.0206 TRN_RMSLE: 4.2002 TRN_VAL_: 1.3407 TRN_mean_squared_error: 188173039596.0151 TRN_MAPE_: 4.4347\n",
            "# 0023 |  TST_loss: 185123666670.3597 TST_MAE_: 40.1195 TST_RMSLE: 4.1672 TST_VAL_: 41.0259 TST_mean_squared_error: 185123666670.3597 TST_MAPE_: 4.4576 ///  TRN_loss: 188170295612.1663 TRN_MAE_: 2.0414 TRN_RMSLE: 4.2246 TRN_VAL_: 1.3575 TRN_mean_squared_error: 188170295612.1663 TRN_MAPE_: 4.4499\n",
            "# 0024 |  TST_loss: 185121320292.9339 TST_MAE_: 41.1842 TST_RMSLE: 4.1896 TST_VAL_: 42.0927 TST_mean_squared_error: 185121320292.9339 TST_MAPE_: 4.4708 ///  TRN_loss: 188167862172.7110 TRN_MAE_: 2.1219 TRN_RMSLE: 4.2483 TRN_VAL_: 1.4533 TRN_mean_squared_error: 188167862172.7110 TRN_MAPE_: 4.4643\n",
            "# 0025 |  TST_loss: 185119171583.6386 TST_MAE_: 42.2203 TST_RMSLE: 4.2109 TST_VAL_: 43.1307 TST_mean_squared_error: 185119171583.6386 TST_MAPE_: 4.4831 ///  TRN_loss: 188165679791.5120 TRN_MAE_: 2.1486 TRN_RMSLE: 4.2683 TRN_VAL_: 1.4807 TRN_mean_squared_error: 188165679791.5120 TRN_MAPE_: 4.4762\n",
            "# 0026 |  TST_loss: 185117303386.3545 TST_MAE_: 43.1699 TST_RMSLE: 4.2300 TST_VAL_: 44.0820 TST_mean_squared_error: 185117303386.3545 TST_MAPE_: 4.4940 ///  TRN_loss: 188163766841.3632 TRN_MAE_: 2.1919 TRN_RMSLE: 4.2890 TRN_VAL_: 1.5279 TRN_mean_squared_error: 188163766841.3632 TRN_MAPE_: 4.4884\n",
            "# 0027 |  TST_loss: 185115673740.2169 TST_MAE_: 44.0731 TST_RMSLE: 4.2479 TST_VAL_: 44.9866 TST_mean_squared_error: 185115673740.2169 TST_MAPE_: 4.5040 ///  TRN_loss: 188162100345.4176 TRN_MAE_: 2.2297 TRN_RMSLE: 4.3063 TRN_VAL_: 1.5701 TRN_mean_squared_error: 188162100345.4176 TRN_MAPE_: 4.4984\n",
            "# 0028 |  TST_loss: 185114231752.1976 TST_MAE_: 44.9139 TST_RMSLE: 4.2642 TST_VAL_: 45.8289 TST_mean_squared_error: 185114231752.1976 TST_MAPE_: 4.5130 ///  TRN_loss: 188160619696.2449 TRN_MAE_: 2.3142 TRN_RMSLE: 4.3239 TRN_VAL_: 1.6716 TRN_mean_squared_error: 188160619696.2449 TRN_MAPE_: 4.5084\n",
            "# 0029 |  TST_loss: 185112992652.2280 TST_MAE_: 45.6978 TST_RMSLE: 4.2791 TST_VAL_: 46.6140 TST_mean_squared_error: 185112992652.2280 TST_MAPE_: 4.5212 ///  TRN_loss: 188159339531.9288 TRN_MAE_: 2.2522 TRN_RMSLE: 4.3391 TRN_VAL_: 1.5867 TRN_mean_squared_error: 188159339531.9288 TRN_MAPE_: 4.5169\n",
            "# 0030 |  TST_loss: 185111818854.2077 TST_MAE_: 46.4638 TST_RMSLE: 4.2935 TST_VAL_: 47.3811 TST_mean_squared_error: 185111818854.2077 TST_MAPE_: 4.5289 ///  TRN_loss: 188158201697.3051 TRN_MAE_: 2.2898 TRN_RMSLE: 4.3539 TRN_VAL_: 1.6306 TRN_mean_squared_error: 188158201697.3051 TRN_MAPE_: 4.5251\n",
            "# 0030 |  TST_loss: 185111818854.2077 TST_MAE_: 46.4638 TST_RMSLE: 4.2935 TST_VAL_: 47.3811 TST_mean_squared_error: 185111818854.2077 TST_MAPE_: 4.5289 ///  TRN_loss: 188158201697.3051 TRN_MAE_: 2.2898 TRN_RMSLE: 4.3539 TRN_VAL_: 1.6306 TRN_mean_squared_error: 188158201697.3051 TRN_MAPE_: 4.5251\n",
            "********* 0.007 *********************************\n",
            "# 0001 |  TST_loss: 33.0381 TST_MAE_: 43.7186 TST_RMSLE: 4.2409 TST_VAL_: 44.6316 TST_mean_squared_error: 185116308104.6914 TST_MAPE_: 4.5001 ///  TRN_loss: 30.8091 TRN_MAE_: 2.2640 TRN_RMSLE: 4.3350 TRN_VAL_: 1.6033 TRN_mean_squared_error: 188159846576.5616 TRN_MAPE_: 4.5146\n",
            "# 0002 |  TST_loss: 32.2812 TST_MAE_: 40.9290 TST_RMSLE: 4.1843 TST_VAL_: 41.8371 TST_mean_squared_error: 185121863577.5847 TST_MAPE_: 4.4677 ///  TRN_loss: 30.1109 TRN_MAE_: 2.1896 TRN_RMSLE: 4.2815 TRN_VAL_: 1.5271 TRN_mean_squared_error: 188164620571.8955 TRN_MAPE_: 4.4839\n",
            "# 0003 |  TST_loss: 31.4748 TST_MAE_: 38.1031 TST_RMSLE: 4.1232 TST_VAL_: 39.0055 TST_mean_squared_error: 185128549557.8126 TST_MAPE_: 4.4309 ///  TRN_loss: 29.3604 TRN_MAE_: 2.0669 TRN_RMSLE: 4.2238 TRN_VAL_: 1.3926 TRN_mean_squared_error: 188170361403.0911 TRN_MAPE_: 4.4493\n",
            ".......\n",
            "# 0004 |  TST_loss: 30.6166 TST_MAE_: 35.2594 TST_RMSLE: 4.0575 TST_VAL_: 36.1554 TST_mean_squared_error: 185136334915.5038 TST_MAPE_: 4.3893 ///  TRN_loss: 28.5672 TRN_MAE_: 1.9736 TRN_RMSLE: 4.1616 TRN_VAL_: 1.2921 TRN_mean_squared_error: 188177366435.8045 TRN_MAPE_: 4.4101\n",
            "# 0005 |  TST_loss: 29.6996 TST_MAE_: 32.4056 TST_RMSLE: 3.9865 TST_VAL_: 33.2944 TST_mean_squared_error: 185145209294.7607 TST_MAPE_: 4.3419 ///  TRN_loss: 27.7313 TRN_MAE_: 1.8837 TRN_RMSLE: 4.0945 TRN_VAL_: 1.1947 TRN_mean_squared_error: 188185482598.5029 TRN_MAPE_: 4.3655\n",
            "# 0006 |  TST_loss: 28.7168 TST_MAE_: 29.5403 TST_RMSLE: 3.9095 TST_VAL_: 30.4207 TST_mean_squared_error: 185155205467.3668 TST_MAPE_: 4.2874 ///  TRN_loss: 26.8459 TRN_MAE_: 1.7979 TRN_RMSLE: 4.0219 TRN_VAL_: 1.1052 TRN_mean_squared_error: 188194731213.2844 TRN_MAPE_: 4.3145\n",
            "# 0007 |  TST_loss: 27.6568 TST_MAE_: 26.6639 TST_RMSLE: 3.8251 TST_VAL_: 27.5346 TST_mean_squared_error: 185166348603.7358 TST_MAPE_: 4.2242 ///  TRN_loss: 25.9163 TRN_MAE_: 1.7322 TRN_RMSLE: 3.9428 TRN_VAL_: 1.0436 TRN_mean_squared_error: 188204995503.5088 TRN_MAPE_: 4.2552\n",
            "# 0008 |  TST_loss: 26.5062 TST_MAE_: 23.7847 TST_RMSLE: 3.7324 TST_VAL_: 24.6439 TST_mean_squared_error: 185178559477.7788 TST_MAPE_: 4.1504 ///  TRN_loss: 24.8893 TRN_MAE_: 1.5986 TRN_RMSLE: 3.8560 TRN_VAL_: 0.8832 TRN_mean_squared_error: 188216290717.0626 TRN_MAPE_: 4.1863\n",
            "# 0009 |  TST_loss: 25.2419 TST_MAE_: 20.8848 TST_RMSLE: 3.6286 TST_VAL_: 21.7296 TST_mean_squared_error: 185192002872.8709 TST_MAPE_: 4.0619 ///  TRN_loss: 23.8110 TRN_MAE_: 1.5297 TRN_RMSLE: 3.7593 TRN_VAL_: 0.8145 TRN_mean_squared_error: 188228887512.8568 TRN_MAPE_: 4.1046\n",
            "# 0010 |  TST_loss: 23.8439 TST_MAE_: 17.9759 TST_RMSLE: 3.5112 TST_VAL_: 18.8012 TST_mean_squared_error: 185206614403.4674 TST_MAPE_: 3.9555 ///  TRN_loss: 22.6243 TRN_MAE_: 1.4357 TRN_RMSLE: 3.6504 TRN_VAL_: 0.7073 TRN_mean_squared_error: 188243024786.2006 TRN_MAPE_: 4.0063\n",
            "# 0011 |  TST_loss: 22.2554 TST_MAE_: 15.0306 TST_RMSLE: 3.3750 TST_VAL_: 15.8270 TST_mean_squared_error: 185222620988.3325 TST_MAPE_: 3.8237 ///  TRN_loss: 21.3144 TRN_MAE_: 1.3515 TRN_RMSLE: 3.5257 TRN_VAL_: 0.6152 TRN_mean_squared_error: 188257841603.9933 TRN_MAPE_: 3.8860\n",
            "# 0012 |  TST_loss: 20.4229 TST_MAE_: 12.0629 TST_RMSLE: 3.2134 TST_VAL_: 12.8141 TST_mean_squared_error: 185240013859.3632 TST_MAPE_: 3.6549 ///  TRN_loss: 19.8372 TRN_MAE_: 1.2584 TRN_RMSLE: 3.3786 TRN_VAL_: 0.4982 TRN_mean_squared_error: 188274763079.6459 TRN_MAPE_: 3.7341\n",
            "# 0013 |  TST_loss: 18.2221 TST_MAE_: 9.0445 TST_RMSLE: 3.0131 TST_VAL_: 9.7226 TST_mean_squared_error: 185259096924.1156 TST_MAPE_: 3.4267 ///  TRN_loss: 18.1064 TRN_MAE_: 1.1740 TRN_RMSLE: 3.1996 TRN_VAL_: 0.3926 TRN_mean_squared_error: 188292517245.8237 TRN_MAPE_: 3.5341\n",
            "# 0014 |  TST_loss: 15.4848 TST_MAE_: 5.9902 TST_RMSLE: 2.7526 TST_VAL_: 6.5459 TST_mean_squared_error: 185279985271.6872 TST_MAPE_: 3.0937 ///  TRN_loss: 15.9930 TRN_MAE_: 1.0949 TRN_RMSLE: 2.9694 TRN_VAL_: 0.2834 TRN_mean_squared_error: 188312128685.7501 TRN_MAPE_: 3.2547\n",
            "# 0015 |  TST_loss: 11.8534 TST_MAE_: 2.9317 TST_RMSLE: 2.3872 TST_VAL_: 3.2260 TST_mean_squared_error: 185303250045.6978 TST_MAPE_: 2.4969 ///  TRN_loss: 13.2162 TRN_MAE_: 1.0280 TRN_RMSLE: 2.6483 TRN_VAL_: 0.1744 TRN_mean_squared_error: 188333915584.4089 TRN_MAPE_: 2.7991\n",
            "# 0016 |  TST_loss: 9.4941 TST_MAE_: 1.1983 TST_RMSLE: 2.1484 TST_VAL_: 1.0289 TST_mean_squared_error: 185319411299.7722 TST_MAPE_: 1.7083 ///  TRN_loss: 10.1368 TRN_MAE_: 0.9884 TRN_RMSLE: 2.2646 TRN_VAL_: 0.0665 TRN_mean_squared_error: 188355778182.1714 TRN_MAPE_: 1.9958\n",
            "# 0017 |  TST_loss: 9.4922 TST_MAE_: 1.1890 TST_RMSLE: 2.1484 TST_VAL_: 1.0135 TST_mean_squared_error: 185319541688.9713 TST_MAPE_: 1.7003 ///  TRN_loss: 9.5195 TRN_MAE_: 0.9858 TRN_RMSLE: 2.1905 TRN_VAL_: 0.0347 TRN_mean_squared_error: 188361888436.5016 TRN_MAPE_: 1.6394\n",
            "# 0018 |  TST_loss: 9.4910 TST_MAE_: 1.1797 TST_RMSLE: 2.1486 TST_VAL_: 0.9980 TST_mean_squared_error: 185319651454.9443 TST_MAPE_: 1.6922 ///  TRN_loss: 9.5191 TRN_MAE_: 0.9859 TRN_RMSLE: 2.1905 TRN_VAL_: 0.0345 TRN_mean_squared_error: 188361890242.4702 TRN_MAPE_: 1.6392\n",
            "# 0019 |  TST_loss: 9.4915 TST_MAE_: 1.1840 TST_RMSLE: 2.1485 TST_VAL_: 1.0052 TST_mean_squared_error: 185319607369.4386 TST_MAPE_: 1.6960 ///  TRN_loss: 9.5193 TRN_MAE_: 0.9862 TRN_RMSLE: 2.1906 TRN_VAL_: 0.0338 TRN_mean_squared_error: 188361900926.4029 TRN_MAPE_: 1.6386\n",
            "# 0020 |  TST_loss: 9.4918 TST_MAE_: 1.1854 TST_RMSLE: 2.1485 TST_VAL_: 1.0075 TST_mean_squared_error: 185319582346.3767 TST_MAPE_: 1.6972 ///  TRN_loss: 9.5188 TRN_MAE_: 0.9857 TRN_RMSLE: 2.1906 TRN_VAL_: 0.0350 TRN_mean_squared_error: 188361902448.5959 TRN_MAPE_: 1.6382\n",
            "# 0021 |  TST_loss: 9.4910 TST_MAE_: 1.1796 TST_RMSLE: 2.1486 TST_VAL_: 0.9979 TST_mean_squared_error: 185319651533.3120 TST_MAPE_: 1.6921 ///  TRN_loss: 9.5197 TRN_MAE_: 0.9857 TRN_RMSLE: 2.1906 TRN_VAL_: 0.0351 TRN_mean_squared_error: 188361909797.2033 TRN_MAPE_: 1.6379\n",
            "# 0022 |  TST_loss: 9.4917 TST_MAE_: 1.1862 TST_RMSLE: 2.1485 TST_VAL_: 1.0089 TST_mean_squared_error: 185319560587.6637 TST_MAPE_: 1.6979 ///  TRN_loss: 9.5196 TRN_MAE_: 0.9858 TRN_RMSLE: 2.1907 TRN_VAL_: 0.0346 TRN_mean_squared_error: 188361923682.5757 TRN_MAPE_: 1.6366\n",
            "# 0023 |  TST_loss: 9.4908 TST_MAE_: 1.1729 TST_RMSLE: 2.1488 TST_VAL_: 0.9866 TST_mean_squared_error: 185319745292.5434 TST_MAPE_: 1.6860 ///  TRN_loss: 9.5195 TRN_MAE_: 0.9861 TRN_RMSLE: 2.1906 TRN_VAL_: 0.0339 TRN_mean_squared_error: 188361902694.2790 TRN_MAPE_: 1.6383\n",
            "# 0024 |  TST_loss: 9.4906 TST_MAE_: 1.1752 TST_RMSLE: 2.1487 TST_VAL_: 0.9904 TST_mean_squared_error: 185319727013.3887 TST_MAPE_: 1.6880 ///  TRN_loss: 9.5193 TRN_MAE_: 0.9856 TRN_RMSLE: 2.1907 TRN_VAL_: 0.0353 TRN_mean_squared_error: 188361907010.0649 TRN_MAPE_: 1.6379\n",
            "# 0025 |  TST_loss: 9.4905 TST_MAE_: 1.1713 TST_RMSLE: 2.1488 TST_VAL_: 0.9840 TST_mean_squared_error: 185319747197.2359 TST_MAPE_: 1.6845 ///  TRN_loss: 9.5195 TRN_MAE_: 0.9858 TRN_RMSLE: 2.1906 TRN_VAL_: 0.0347 TRN_mean_squared_error: 188361890264.3522 TRN_MAPE_: 1.6390\n",
            "# 0026 |  TST_loss: 9.4909 TST_MAE_: 1.1769 TST_RMSLE: 2.1487 TST_VAL_: 0.9933 TST_mean_squared_error: 185319701561.0396 TST_MAPE_: 1.6896 ///  TRN_loss: 9.5195 TRN_MAE_: 0.9855 TRN_RMSLE: 2.1906 TRN_VAL_: 0.0356 TRN_mean_squared_error: 188361911900.8812 TRN_MAPE_: 1.6377\n",
            "# 0027 |  TST_loss: 9.4906 TST_MAE_: 1.1686 TST_RMSLE: 2.1489 TST_VAL_: 0.9794 TST_mean_squared_error: 185319820588.0280 TST_MAPE_: 1.6821 ///  TRN_loss: 9.5197 TRN_MAE_: 0.9862 TRN_RMSLE: 2.1907 TRN_VAL_: 0.0337 TRN_mean_squared_error: 188361919026.3318 TRN_MAPE_: 1.6369\n",
            "# 0028 |  TST_loss: 9.4907 TST_MAE_: 1.1759 TST_RMSLE: 2.1487 TST_VAL_: 0.9917 TST_mean_squared_error: 185319702744.8954 TST_MAPE_: 1.6887 ///  TRN_loss: 9.5195 TRN_MAE_: 0.9851 TRN_RMSLE: 2.1906 TRN_VAL_: 0.0364 TRN_mean_squared_error: 188361903957.3203 TRN_MAPE_: 1.6382\n",
            "# 0029 |  TST_loss: 9.4906 TST_MAE_: 1.1729 TST_RMSLE: 2.1488 TST_VAL_: 0.9866 TST_mean_squared_error: 185319745339.0351 TST_MAPE_: 1.6860 ///  TRN_loss: 9.5194 TRN_MAE_: 0.9856 TRN_RMSLE: 2.1905 TRN_VAL_: 0.0353 TRN_mean_squared_error: 188361879657.3065 TRN_MAPE_: 1.6397\n",
            "# 0030 |  TST_loss: 9.4914 TST_MAE_: 1.1845 TST_RMSLE: 2.1485 TST_VAL_: 1.0061 TST_mean_squared_error: 185319606744.9516 TST_MAPE_: 1.6965 ///  TRN_loss: 9.5196 TRN_MAE_: 0.9866 TRN_RMSLE: 2.1908 TRN_VAL_: 0.0327 TRN_mean_squared_error: 188361928435.2434 TRN_MAPE_: 1.6363\n",
            "# 0030 |  TST_loss: 9.4914 TST_MAE_: 1.1845 TST_RMSLE: 2.1485 TST_VAL_: 1.0061 TST_mean_squared_error: 185319606744.9516 TST_MAPE_: 1.6965 ///  TRN_loss: 9.5196 TRN_MAE_: 0.9866 TRN_RMSLE: 2.1908 TRN_VAL_: 0.0327 TRN_mean_squared_error: 188361928435.2434 TRN_MAPE_: 1.6363\n",
            "********* 0.007 *********************************\n",
            "# 0001 |  TST_loss: 2.1490 TST_MAE_: 1.2342 TST_RMSLE: 2.1489 TST_VAL_: 1.0866 TST_mean_squared_error: 185318993934.4825 TST_MAPE_: 1.7385 ///  TRN_loss: 2.1890 TRN_MAE_: 0.9863 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0358 TRN_mean_squared_error: 188361241433.2265 TRN_MAPE_: 1.6864\n",
            "# 0002 |  TST_loss: 2.1492 TST_MAE_: 1.2368 TST_RMSLE: 2.1489 TST_VAL_: 1.0908 TST_mean_squared_error: 185318988361.9599 TST_MAPE_: 1.7407 ///  TRN_loss: 2.1890 TRN_MAE_: 0.9853 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0387 TRN_mean_squared_error: 188361223942.6339 TRN_MAPE_: 1.6875\n",
            "# 0003 |  TST_loss: 2.1488 TST_MAE_: 1.2254 TST_RMSLE: 2.1487 TST_VAL_: 1.0727 TST_mean_squared_error: 185319112774.6975 TST_MAPE_: 1.7314 ///  TRN_loss: 2.1889 TRN_MAE_: 0.9851 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0392 TRN_mean_squared_error: 188361220950.5172 TRN_MAPE_: 1.6876\n",
            ".......\n",
            "# 0004 |  TST_loss: 2.1490 TST_MAE_: 1.2359 TST_RMSLE: 2.1489 TST_VAL_: 1.0894 TST_mean_squared_error: 185318991969.6850 TST_MAPE_: 1.7399 ///  TRN_loss: 2.1889 TRN_MAE_: 0.9855 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0381 TRN_mean_squared_error: 188361222968.3691 TRN_MAPE_: 1.6875\n",
            "# 0005 |  TST_loss: 2.1487 TST_MAE_: 1.2265 TST_RMSLE: 2.1487 TST_VAL_: 1.0743 TST_mean_squared_error: 185319098652.7236 TST_MAPE_: 1.7323 ///  TRN_loss: 2.1890 TRN_MAE_: 0.9858 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0373 TRN_mean_squared_error: 188361220871.9820 TRN_MAPE_: 1.6877\n",
            "# 0006 |  TST_loss: 2.1489 TST_MAE_: 1.2310 TST_RMSLE: 2.1488 TST_VAL_: 1.0816 TST_mean_squared_error: 185319033829.6494 TST_MAPE_: 1.7359 ///  TRN_loss: 2.1889 TRN_MAE_: 0.9853 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0385 TRN_mean_squared_error: 188361224101.8102 TRN_MAPE_: 1.6875\n",
            "# 0007 |  TST_loss: 2.1489 TST_MAE_: 1.2322 TST_RMSLE: 2.1488 TST_VAL_: 1.0835 TST_mean_squared_error: 185318996086.6432 TST_MAPE_: 1.7369 ///  TRN_loss: 2.1890 TRN_MAE_: 0.9857 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0374 TRN_mean_squared_error: 188361222461.6877 TRN_MAPE_: 1.6875\n",
            "# 0008 |  TST_loss: 2.1491 TST_MAE_: 1.2369 TST_RMSLE: 2.1490 TST_VAL_: 1.0909 TST_mean_squared_error: 185318988288.7597 TST_MAPE_: 1.7407 ///  TRN_loss: 2.1890 TRN_MAE_: 0.9861 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0363 TRN_mean_squared_error: 188361223487.2056 TRN_MAPE_: 1.6874\n",
            "# 0009 |  TST_loss: 2.1491 TST_MAE_: 1.2372 TST_RMSLE: 2.1490 TST_VAL_: 1.0914 TST_mean_squared_error: 185318943787.6845 TST_MAPE_: 1.7410 ///  TRN_loss: 2.1889 TRN_MAE_: 0.9855 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0381 TRN_mean_squared_error: 188361223968.5164 TRN_MAPE_: 1.6874\n",
            "# 0010 |  TST_loss: 2.1487 TST_MAE_: 1.2224 TST_RMSLE: 2.1486 TST_VAL_: 1.0679 TST_mean_squared_error: 185319126567.1345 TST_MAPE_: 1.7289 ///  TRN_loss: 2.1889 TRN_MAE_: 0.9856 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0379 TRN_mean_squared_error: 188361219413.4676 TRN_MAPE_: 1.6878\n",
            "# 0011 |  TST_loss: 2.1490 TST_MAE_: 1.2326 TST_RMSLE: 2.1488 TST_VAL_: 1.0841 TST_mean_squared_error: 185318995700.7204 TST_MAPE_: 1.7372 ///  TRN_loss: 2.1890 TRN_MAE_: 0.9852 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0388 TRN_mean_squared_error: 188361229738.5322 TRN_MAPE_: 1.6872\n",
            "# 0012 |  TST_loss: 2.1489 TST_MAE_: 1.2223 TST_RMSLE: 2.1486 TST_VAL_: 1.0676 TST_mean_squared_error: 185319150127.8621 TST_MAPE_: 1.7287 ///  TRN_loss: 2.1890 TRN_MAE_: 0.9862 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0362 TRN_mean_squared_error: 188361214368.0906 TRN_MAPE_: 1.6880\n",
            "# 0013 |  TST_loss: 2.1490 TST_MAE_: 1.2358 TST_RMSLE: 2.1489 TST_VAL_: 1.0891 TST_mean_squared_error: 185318992144.2373 TST_MAPE_: 1.7398 ///  TRN_loss: 2.1889 TRN_MAE_: 0.9859 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0369 TRN_mean_squared_error: 188361228271.6032 TRN_MAPE_: 1.6873\n",
            "\n",
            "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0035000001080334187.\n",
            "# 0014 |  TST_loss: 2.1490 TST_MAE_: 1.2341 TST_RMSLE: 2.1489 TST_VAL_: 1.0865 TST_mean_squared_error: 185318993993.2591 TST_MAPE_: 1.7385 ///  TRN_loss: 2.1889 TRN_MAE_: 0.9855 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0379 TRN_mean_squared_error: 188361222343.2011 TRN_MAPE_: 1.6874\n",
            "# 0015 |  TST_loss: 2.1492 TST_MAE_: 1.2425 TST_RMSLE: 2.1491 TST_VAL_: 1.0997 TST_mean_squared_error: 185318888616.5383 TST_MAPE_: 1.7452 ///  TRN_loss: 2.1889 TRN_MAE_: 0.9856 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0378 TRN_mean_squared_error: 188361226357.2363 TRN_MAPE_: 1.6872\n",
            "# 0016 |  TST_loss: 2.1491 TST_MAE_: 1.2384 TST_RMSLE: 2.1490 TST_VAL_: 1.0933 TST_mean_squared_error: 185318929515.9095 TST_MAPE_: 1.7419 ///  TRN_loss: 2.1889 TRN_MAE_: 0.9855 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0382 TRN_mean_squared_error: 188361217313.4062 TRN_MAPE_: 1.6878\n",
            "# 0017 |  TST_loss: 2.1489 TST_MAE_: 1.2322 TST_RMSLE: 2.1488 TST_VAL_: 1.0835 TST_mean_squared_error: 185318996134.9898 TST_MAPE_: 1.7369 ///  TRN_loss: 2.1889 TRN_MAE_: 0.9861 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0364 TRN_mean_squared_error: 188361217362.5660 TRN_MAPE_: 1.6877\n",
            "# 0018 |  TST_loss: 2.1489 TST_MAE_: 1.2310 TST_RMSLE: 2.1488 TST_VAL_: 1.0816 TST_mean_squared_error: 185319033839.2220 TST_MAPE_: 1.7359 ///  TRN_loss: 2.1889 TRN_MAE_: 0.9850 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0392 TRN_mean_squared_error: 188361221926.7261 TRN_MAPE_: 1.6876\n",
            "# 0019 |  TST_loss: 2.1488 TST_MAE_: 1.2279 TST_RMSLE: 2.1487 TST_VAL_: 1.0767 TST_mean_squared_error: 185319071041.6830 TST_MAPE_: 1.7335 ///  TRN_loss: 2.1889 TRN_MAE_: 0.9850 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0395 TRN_mean_squared_error: 188361220976.8834 TRN_MAPE_: 1.6876\n",
            "# 0020 |  TST_loss: 2.1491 TST_MAE_: 1.2383 TST_RMSLE: 2.1490 TST_VAL_: 1.0931 TST_mean_squared_error: 185318929594.6908 TST_MAPE_: 1.7419 ///  TRN_loss: 2.1889 TRN_MAE_: 0.9857 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0375 TRN_mean_squared_error: 188361228140.5959 TRN_MAPE_: 1.6871\n",
            "# 0021 |  TST_loss: 2.1490 TST_MAE_: 1.2350 TST_RMSLE: 2.1489 TST_VAL_: 1.0880 TST_mean_squared_error: 185318992960.7451 TST_MAPE_: 1.7392 ///  TRN_loss: 2.1889 TRN_MAE_: 0.9851 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0393 TRN_mean_squared_error: 188361221126.8623 TRN_MAPE_: 1.6877\n",
            "# 0022 |  TST_loss: 2.1489 TST_MAE_: 1.2339 TST_RMSLE: 2.1489 TST_VAL_: 1.0862 TST_mean_squared_error: 185318994179.5663 TST_MAPE_: 1.7383 ///  TRN_loss: 2.1889 TRN_MAE_: 0.9857 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0374 TRN_mean_squared_error: 188361224658.7113 TRN_MAPE_: 1.6874\n",
            "# 0023 |  TST_loss: 2.1491 TST_MAE_: 1.2385 TST_RMSLE: 2.1490 TST_VAL_: 1.0935 TST_mean_squared_error: 185318929329.1723 TST_MAPE_: 1.7420 ///  TRN_loss: 2.1889 TRN_MAE_: 0.9860 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0368 TRN_mean_squared_error: 188361225589.4166 TRN_MAPE_: 1.6873\n",
            "# 0024 |  TST_loss: 2.1488 TST_MAE_: 1.2315 TST_RMSLE: 2.1488 TST_VAL_: 1.0823 TST_mean_squared_error: 185319033280.8435 TST_MAPE_: 1.7363 ///  TRN_loss: 2.1889 TRN_MAE_: 0.9860 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0367 TRN_mean_squared_error: 188361218566.4146 TRN_MAPE_: 1.6877\n",
            "# 0025 |  TST_loss: 2.1492 TST_MAE_: 1.2379 TST_RMSLE: 2.1490 TST_VAL_: 1.0925 TST_mean_squared_error: 185318943036.3592 TST_MAPE_: 1.7415 ///  TRN_loss: 2.1889 TRN_MAE_: 0.9853 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0386 TRN_mean_squared_error: 188361227836.0969 TRN_MAPE_: 1.6872\n",
            "# 0025 |  TST_loss: 2.1492 TST_MAE_: 1.2379 TST_RMSLE: 2.1490 TST_VAL_: 1.0925 TST_mean_squared_error: 185318943036.3592 TST_MAPE_: 1.7415 ///  TRN_loss: 2.1889 TRN_MAE_: 0.9853 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0386 TRN_mean_squared_error: 188361227836.0969 TRN_MAPE_: 1.6872\n",
            "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.0017500000540167093.\n",
            "# 0026 |  TST_loss: 2.1490 TST_MAE_: 1.2362 TST_RMSLE: 2.1489 TST_VAL_: 1.0899 TST_mean_squared_error: 185318991636.0201 TST_MAPE_: 1.7402 ///  TRN_loss: 2.1888 TRN_MAE_: 0.9857 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0375 TRN_mean_squared_error: 188361219042.2436 TRN_MAPE_: 1.6876\n",
            "# 0027 |  TST_loss: 2.1490 TST_MAE_: 1.2365 TST_RMSLE: 2.1489 TST_VAL_: 1.0903 TST_mean_squared_error: 185318988762.7521 TST_MAPE_: 1.7404 ///  TRN_loss: 2.1888 TRN_MAE_: 0.9855 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0381 TRN_mean_squared_error: 188361220889.5701 TRN_MAPE_: 1.6875\n",
            "# 0028 |  TST_loss: 2.1490 TST_MAE_: 1.2358 TST_RMSLE: 2.1489 TST_VAL_: 1.0891 TST_mean_squared_error: 185318992159.1060 TST_MAPE_: 1.7398 ///  TRN_loss: 2.1889 TRN_MAE_: 0.9852 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0389 TRN_mean_squared_error: 188361222607.6378 TRN_MAPE_: 1.6875\n",
            "# 0029 |  TST_loss: 2.1489 TST_MAE_: 1.2354 TST_RMSLE: 2.1489 TST_VAL_: 1.0885 TST_mean_squared_error: 185318992599.8952 TST_MAPE_: 1.7395 ///  TRN_loss: 2.1889 TRN_MAE_: 0.9858 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0371 TRN_mean_squared_error: 188361221509.8707 TRN_MAPE_: 1.6876\n",
            "# 0030 |  TST_loss: 2.1488 TST_MAE_: 1.2308 TST_RMSLE: 2.1488 TST_VAL_: 1.0812 TST_mean_squared_error: 185319034057.0473 TST_MAPE_: 1.7358 ///  TRN_loss: 2.1888 TRN_MAE_: 0.9860 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0367 TRN_mean_squared_error: 188361219722.1433 TRN_MAPE_: 1.6878\n",
            "# 0030 |  TST_loss: 2.1488 TST_MAE_: 1.2308 TST_RMSLE: 2.1488 TST_VAL_: 1.0812 TST_mean_squared_error: 185319034057.0473 TST_MAPE_: 1.7358 ///  TRN_loss: 2.1888 TRN_MAE_: 0.9860 TRN_RMSLE: 2.1888 TRN_VAL_: 0.0367 TRN_mean_squared_error: 188361219722.1433 TRN_MAPE_: 1.6878\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1150"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NyBVLwrQvDf",
        "colab_type": "code",
        "outputId": "c6e86fbe-dbce-45ee-8578-8e8e7bb980e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Ошибка 0: ', np.sqrt( np.mean( np.power(np.log(df[df['meter']==0]['meter_reading']+1) - np.log(df[df['meter']==0]['NN_PRED']+1),2.00000)))        \n",
        "  , 'Ошибка 0 (VAL): ', np.sqrt( np.mean( np.power(np.log(df[(df['meter']==0) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[(df['meter']==0) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "  , 'Ошибка 0 (VAL_чист): ', np.sqrt( np.mean( np.power(np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==0) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==0) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        )\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ошибка 0:  1.0967505629134169 Ошибка 0 (VAL):  1.0889958705909204 Ошибка 0 (VAL_чист):  0.29653998158216416\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2V4xV9ON01Co",
        "colab": {}
      },
      "source": [
        "if 1==1:\n",
        "  reg = 0.00001\n",
        "  meter = 1\n",
        "  epochs = 190\n",
        "  batch_size = 1024\n",
        "  opt = Adam(lr = 0.001)\n",
        "  bias = Constant(value = 0.1)\n",
        "\n",
        "  earlyStopping = EarlyStopping(monitor='loss', patience=100, verbose=1, mode='min')\n",
        "  reduce_lr_loss = ReduceLROnPlateau(monitor='loss', factor=0.3, patience=15, verbose=1, min_delta=1e-3, mode='min')\n",
        "  model_checkpoint = ModelCheckpoint(monitor='loss', save_best_only=True, filepath = DIR + 'best_nn_' + str(meter) + '.model', save_weights_only = False, verbose=0, mode='min')\n",
        "\n",
        "  nn_1 = Sequential()\n",
        "  nn_1.add(Dense(100, input_shape = df[In_Columns].shape[1:], activation = 'tanh', kernel_initializer = 'normal', kernel_regularizer=l2(reg), bias_initializer=bias))\n",
        "  nn_1.add(Dense(100, activation = 'tanh',  kernel_initializer = 'normal', bias_initializer=bias))\n",
        "  nn_1.add(Dense(100, activation = 'tanh',  kernel_initializer = 'normal', bias_initializer=bias, kernel_regularizer=l1(reg)))\n",
        "  nn_1.add(Dense(100, activation = 'tanh',  kernel_initializer = 'normal', bias_initializer=bias))\n",
        "  nn_1.add(Dense(1, activation = 'relu', kernel_initializer = 'normal'))\n",
        "\n",
        "  nn_1.compile(optimizer = opt, loss = RMSLE, metrics=[ MAE_, RMSLE, VAL_, 'mse', MAPE_ ])\n",
        "  \n",
        "  \n",
        "  val = df[(df['meter'] == meter) & (df['day']%6 == 0) & (df['k_NN_ERR'] < 100) & (df['k_NN_ERR'] > 1/100) & (df['IS_BAD_PRCNT'] < 0.25)]\n",
        "  df_cleared = df[(df['k_NN_ERR']<50) & (df['k_NN_ERR']>1/50) & (df['day']%6 != 0) & (df['meter']==meter) & (df['IS_BAD_PRCNT']<0.25)][In_Columns + [Out_Columns]]\n",
        "\n",
        "  hist = nn_1.fit( df_cleared[In_Columns], df_cleared[Out_Columns], batch_size = batch_size, verbose = 0\n",
        "                  , epochs = epochs, shuffle = True, callbacks=[MyCustomCallback(epochs, 1), earlyStopping, reduce_lr_loss,model_checkpoint]\n",
        "                  , validation_data=(val[In_Columns], val[Out_Columns])\n",
        "                  ) \n",
        "  nn_1.save(DIR + str(meter) + 'HANDLY_SAVED_3.MODEL')\n",
        "  gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qy1YnwWo01Cq",
        "colab": {}
      },
      "source": [
        "for lr in [0.007]:\n",
        "  opt = Adam(lr = lr)\n",
        "  epochs = 70\n",
        "  meter = 1\n",
        "  batch_size = 720\n",
        "\n",
        "  val = df[(df['meter'] == meter) & (df['day']%6 == 0) & (df['k_NN_ERR'] < 100) & (df['k_NN_ERR'] > 1/100) & (df['IS_BAD_PRCNT'] < 0.45)]\n",
        "  df_cleared = df[(df['k_NN_ERR']<50) & (df['k_NN_ERR']>1/50) & (df['day']%6 != 0) & (df['meter']==meter) & (df['IS_BAD_PRCNT']<0.45)][In_Columns + [Out_Columns]]\n",
        "\n",
        "  print('*'*9, lr, '*'*33)\n",
        "  nn_1.compile(optimizer = opt, loss = RMSLE, metrics=[ MAE_, RMSLE, VAL_, 'mse', MAPE_ ])\n",
        "  hist = nn_1.fit( df_cleared[In_Columns], df_cleared[Out_Columns], batch_size = batch_size, verbose = 0\n",
        "                  , epochs = epochs, shuffle = True, callbacks=[ MyCustomCallback(epochs, 1), earlyStopping, reduce_lr_loss]\n",
        "                  , validation_data=(val[In_Columns], val[Out_Columns])\n",
        "                  ) \n",
        "  nn_1.save(DIR + str(meter) + 'HANDLY_SAVED_3.MODEL')\n",
        "  gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfcTV2-g1JNG",
        "colab_type": "code",
        "outputId": "70c085c9-40ed-4d71-d7b8-530fc0dcad8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "#Предсказание из 4х значений = 0:\n",
        "  #nn_0 = keras.models.load_model (DIR + '0HANDLY_SAVED_3.MODEL')\n",
        "  nn_1 = keras.models.load_model (DIR + '1HANDLY_SAVED_3.MODEL')\n",
        "  #nn_2 = keras.models.load_model (DIR + '2HANDLY_SAVED_3.MODEL')\n",
        "  #nn_3 = keras.models.load_model (DIR + '3HANDLY_SAVED_3.MODEL')\n",
        "\n",
        "  # score = model.evaluate(X, Y, verbose=0)\n",
        "  # print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))\n",
        "  gc.collect()\n",
        "\n",
        "  df['NN_PRED'] = 0\n",
        "  #df['NN_PRED_0'] = nn_0.predict(df[In_Columns], batch_size = 10000) \n",
        "  df['NN_PRED_1'] = nn_1.predict(df[In_Columns], batch_size = 10000) \n",
        "  #df['NN_PRED_2'] = nn_2.predict(df[In_Columns], batch_size = 10000) \n",
        "  #df['NN_PRED_3'] = nn_3.predict(df[In_Columns], batch_size = 10000) \n",
        "  #df['NN_PRED'] = np.where(df['meter'] == 0, df['NN_PRED_0'], df['NN_PRED'])\n",
        "  df['NN_PRED'] = np.where(df['meter'] == 1, df['NN_PRED_1'], df['NN_PRED'])\n",
        "  #df['NN_PRED'] = np.where(df['meter'] == 2, df['NN_PRED_2'], df['NN_PRED'])\n",
        "  #df['NN_PRED'] = np.where(df['meter'] == 3, df['NN_PRED_3'], df['NN_PRED'])\n",
        "  #df.drop(columns = ['NN_PRED_0'], inplace = True) #, 'NN_PRED_1', 'NN_PRED_2', 'NN_PRED_3'\n",
        "  #df.drop(columns = ['Value_x', 'Value_y'])\n",
        "  gc.collect()\n",
        "\n",
        "  df['NN_ERR'] = np.abs(df['NN_PRED']-df['meter_reading'])\n",
        "  print( np.sqrt( np.mean( np.power(np.log(df['meter_reading']+1) - np.log(df['NN_PRED']+1),2.00000)))     )\n",
        "  # print('Ошибка 0: ', np.sqrt( np.mean( np.power(np.log(df[df['meter']==0]['meter_reading']+1) - np.log(df[df['meter']==0]['NN_PRED']+1),2.00000)))        \n",
        "  # , 'Ошибка 0 (VAL): ', np.sqrt( np.mean( np.power(np.log(df[(df['meter']==0) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[(df['meter']==0) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "  # , 'Ошибка 0 (VAL_чист): ', np.sqrt( np.mean( np.power(np.log(df[ (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==0) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[ (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==0) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "  # , 'Ошибка 0 (VAL_чист): ', np.sqrt( np.mean( np.power(np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==0) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==0) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        )\n",
        "  \n",
        "  print('Ошибка 0: ', np.sqrt( np.mean( np.power(np.log(df[df['meter']==1]['meter_reading']+1) - np.log(df[df['meter']==1]['NN_PRED']+1),2.00000)))        \n",
        "  , 'Ошибка 0 (VAL): ', np.sqrt( np.mean( np.power(np.log(df[(df['meter']==1) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[(df['meter']==1) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "  , 'Ошибка 0 (VAL_чист): ', np.sqrt( np.mean( np.power(np.log(df[ (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==1) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[ (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==1) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "  , 'Ошибка 0 (VAL_чист): ', np.sqrt( np.mean( np.power(np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==1) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==1) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        )\n",
        "  \n",
        "  #print('Ошибка 1: ', np.sqrt( np.mean( np.power(np.log(df[df['meter']==1]['meter_reading']+1) - np.log(df[df['meter']==1]['NN_PRED']+1),2.00000)))        )\n",
        "  #print('Ошибка 2: ', np.sqrt( np.mean( np.power(np.log(df[df['meter']==2]['meter_reading']+1) - np.log(df[df['meter']==2]['NN_PRED']+1),2.00000)))        )\n",
        "  #print('Ошибка 3: ', np.sqrt( np.mean( np.power(np.log(df[df['meter']==3]['meter_reading']+1) - np.log(df[df['meter']==3]['NN_PRED']+1),2.00000)))        )\n",
        "  #df['k_NN_ERR'] = (df['NN_PRED']+0.33)/(df['meter_reading']+0.33)\n",
        "  gc.collect()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4.143660029954269\n",
            "Ошибка 0:  1.4462519064009887 Ошибка 0 (VAL):  1.4819992377016542 Ошибка 0 (VAL_чист):  0.628029160200588 Ошибка 0 (VAL_чист):  0.4921451933316616\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RW6m54J1Ixjn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Ошибка 0:  1.4622222874555681 Ошибка 0 (VAL):  1.4974377063554198 Ошибка 0 (VAL_чист):  0.6416758062352609 Ошибка 0 (VAL_чист):  0.5087780382284447\n",
        "Ошибка 0:  1.4513305175601738 Ошибка 0 (VAL):  1.4857607748364132 Ошибка 0 (VAL_чист):  0.6544772099268412 Ошибка 0 (VAL_чист):  0.5241878970208895\n",
        "Ошибка 0:  1.559959814457174 Ошибка 0 (VAL):  1.5880652782130562 Ошибка 0 (VAL_чист):  0.6931055197830647 Ошибка 0 (VAL_чист):  0.5696662087687516\n",
        "Ошибка 1:  1.5319581160458586 Ошибка 1 (VAL):  1.5591904792676097 Ошибка 1 (VAL_чист):  0.7038461338617784 Ошибка 1 (VAL_чист2):  0.5850605758832433"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ur0NQSVo01Cs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        },
        "outputId": "31f9d6fb-d16a-4420-a721-4809b770ebec"
      },
      "source": [
        "if 2==2:\n",
        "  reg = 0.00002\n",
        "  meter = 2\n",
        "  epochs = 30\n",
        "  batch_size = 2400\n",
        "  opt = Adam(lr = 0.003)\n",
        "  bias = Constant(value = 5.7)\n",
        "\n",
        "  earlyStopping = EarlyStopping(monitor='loss', patience=30, verbose=1, mode='min')\n",
        "  reduce_lr_loss = ReduceLROnPlateau(monitor='loss', factor=0.2, patience=12, verbose=1, min_delta=1e-3, mode='min')\n",
        "  model_checkpoint = ModelCheckpoint(monitor='loss', save_best_only=True, filepath = DIR + 'best_nn_' + str(meter) + '.model', save_weights_only = False, verbose=0, mode='min')\n",
        "\n",
        "  nn_2 = Sequential()\n",
        "  nn_2.add(Dense(100, input_shape = df[In_Columns].shape[1:], activation = 'tanh', kernel_initializer = 'uniform', kernel_regularizer=l2(reg), bias_initializer=bias))\n",
        "  nn_2.add(Dense(100, activation = 'tanh',  kernel_initializer = 'uniform', bias_initializer=bias))\n",
        "  nn_2.add(Dense(100, activation = 'tanh',  kernel_initializer = 'uniform', bias_initializer=bias, kernel_regularizer=l1(reg)))\n",
        "  nn_2.add(Dense(100, activation = 'tanh',  kernel_initializer = 'uniform', bias_initializer=bias))\n",
        "  nn_2.add(Dense( 1, activation = 'relu', kernel_initializer = 'normal'))\n",
        "\n",
        "  nn_2.compile(optimizer = opt, loss = MAE_RMSLE, metrics=[ MAE_, RMSLE, VAL_, 'mse', MAPE_ ])\n",
        "  \n",
        "  val = df[(df['meter'] == meter) & (df['day']%6 == 0) & (df['k_NN_ERR'] < 100) & (df['k_NN_ERR'] > 1/100) & (df['IS_BAD_PRCNT'] < 0.75)]\n",
        "  df_cleared = df[(df['k_NN_ERR']<50) & (df['k_NN_ERR']>1/50) & (df['meter']==meter) & (df['IS_BAD_PRCNT']<0.75)][In_Columns + [Out_Columns]]\n",
        "  print (len(df_cleared), len(val))\n",
        "\n",
        "  hist = nn_2.fit( df_cleared[In_Columns], df_cleared[Out_Columns], batch_size = batch_size, verbose = 0\n",
        "                  , epochs = epochs, shuffle = True, callbacks=[MyCustomCallback(epochs, 1), earlyStopping, reduce_lr_loss,model_checkpoint]\n",
        "                  , validation_data=(val[In_Columns], val[Out_Columns])\n",
        "                  ) \n",
        "  nn_2.save(DIR_SAVE + str(meter) + 'HANDLY_SAVED_3.MODEL')\n",
        "  gc.collect()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "2428706 407527\n",
            "# 0001 |  TST_loss: 15.3406 TST_MAE_: 0.8960 TST_RMSLE: 2.5108 TST_VAL_: 0.2237 TST_mean_squared_error: 183042758369.2848 TST_MAPE_: 1.1410 ///  TRN_loss: 20.4609 TRN_MAE_: 0.9966 TRN_RMSLE: 3.0885 TRN_VAL_: 0.0043 TRN_mean_squared_error: 187516955696.7137 TRN_MAPE_: 1.1103\n",
            "# 0002 |  TST_loss: 12.9734 TST_MAE_: 0.9021 TST_RMSLE: 2.2977 TST_VAL_: 0.3566 TST_mean_squared_error: 183041701198.8287 TST_MAPE_: 1.2284 ///  TRN_loss: 13.8853 TRN_MAE_: 0.9934 TRN_RMSLE: 2.5377 TRN_VAL_: 0.0094 TRN_mean_squared_error: 187515735192.6390 TRN_MAPE_: 1.1665\n",
            "# 0003 |  TST_loss: 11.9477 TST_MAE_: 0.9300 TST_RMSLE: 2.1976 TST_VAL_: 0.4768 TST_mean_squared_error: 183040755706.7373 TST_MAPE_: 1.3222 ///  TRN_loss: 12.2817 TRN_MAE_: 0.9917 TRN_RMSLE: 2.3754 TRN_VAL_: 0.0132 TRN_mean_squared_error: 187514758520.8332 TRN_MAPE_: 1.2585\n",
            ".......\n",
            "# 0004 |  TST_loss: 11.4156 TST_MAE_: 0.9722 TST_RMSLE: 2.1408 TST_VAL_: 0.5930 TST_mean_squared_error: 183039829301.5518 TST_MAPE_: 1.4119 ///  TRN_loss: 11.4801 TRN_MAE_: 0.9902 TRN_RMSLE: 2.2898 TRN_VAL_: 0.0172 TRN_mean_squared_error: 187513852801.0903 TRN_MAPE_: 1.3522\n",
            "# 0005 |  TST_loss: 11.1402 TST_MAE_: 1.0228 TST_RMSLE: 2.1074 TST_VAL_: 0.7067 TST_mean_squared_error: 183038960820.9655 TST_MAPE_: 1.4929 ///  TRN_loss: 11.0272 TRN_MAE_: 0.9892 TRN_RMSLE: 2.2399 TRN_VAL_: 0.0207 TRN_mean_squared_error: 187512956774.4699 TRN_MAPE_: 1.4384\n",
            "# 0006 |  TST_loss: 11.0194 TST_MAE_: 1.0775 TST_RMSLE: 2.0886 TST_VAL_: 0.8150 TST_mean_squared_error: 183038127639.0771 TST_MAPE_: 1.5639 ///  TRN_loss: 10.7709 TRN_MAE_: 0.9884 TRN_RMSLE: 2.2113 TRN_VAL_: 0.0242 TRN_mean_squared_error: 187512091144.6892 TRN_MAPE_: 1.5148\n",
            "# 0007 |  TST_loss: 10.9917 TST_MAE_: 1.1308 TST_RMSLE: 2.0793 TST_VAL_: 0.9107 TST_mean_squared_error: 183037375060.5359 TST_MAPE_: 1.6214 ///  TRN_loss: 10.6374 TRN_MAE_: 0.9875 TRN_RMSLE: 2.1962 TRN_VAL_: 0.0283 TRN_mean_squared_error: 187511299851.9386 TRN_MAPE_: 1.5803\n",
            "# 0008 |  TST_loss: 11.0082 TST_MAE_: 1.1751 TST_RMSLE: 2.0756 TST_VAL_: 0.9856 TST_mean_squared_error: 183036790644.5565 TST_MAPE_: 1.6636 ///  TRN_loss: 10.5795 TRN_MAE_: 0.9875 TRN_RMSLE: 2.1896 TRN_VAL_: 0.0303 TRN_mean_squared_error: 187510639699.1010 TRN_MAPE_: 1.6305\n",
            "# 0009 |  TST_loss: 11.0322 TST_MAE_: 1.2039 TST_RMSLE: 2.0745 TST_VAL_: 1.0322 TST_mean_squared_error: 183036425526.3694 TST_MAPE_: 1.6894 ///  TRN_loss: 10.5615 TRN_MAE_: 0.9879 TRN_RMSLE: 2.1875 TRN_VAL_: 0.0305 TRN_mean_squared_error: 187510169358.9363 TRN_MAPE_: 1.6645\n",
            "# 0010 |  TST_loss: 11.0432 TST_MAE_: 1.2146 TST_RMSLE: 2.0743 TST_VAL_: 1.0492 TST_mean_squared_error: 183036314129.8807 TST_MAPE_: 1.6985 ///  TRN_loss: 10.5573 TRN_MAE_: 0.9871 TRN_RMSLE: 2.1871 TRN_VAL_: 0.0336 TRN_mean_squared_error: 187509919178.2257 TRN_MAPE_: 1.6827\n",
            "# 0011 |  TST_loss: 11.0454 TST_MAE_: 1.2167 TST_RMSLE: 2.0743 TST_VAL_: 1.0524 TST_mean_squared_error: 183036297833.8154 TST_MAPE_: 1.7003 ///  TRN_loss: 10.5569 TRN_MAE_: 0.9869 TRN_RMSLE: 2.1871 TRN_VAL_: 0.0344 TRN_mean_squared_error: 187509852521.5152 TRN_MAPE_: 1.6874\n",
            "# 0012 |  TST_loss: 11.0459 TST_MAE_: 1.2170 TST_RMSLE: 2.0743 TST_VAL_: 1.0530 TST_mean_squared_error: 183036269610.1725 TST_MAPE_: 1.7006 ///  TRN_loss: 10.5565 TRN_MAE_: 0.9865 TRN_RMSLE: 2.1871 TRN_VAL_: 0.0356 TRN_mean_squared_error: 187509842738.1522 TRN_MAPE_: 1.6880\n",
            "# 0013 |  TST_loss: 11.0456 TST_MAE_: 1.2168 TST_RMSLE: 2.0743 TST_VAL_: 1.0526 TST_mean_squared_error: 183036297677.4856 TST_MAPE_: 1.7004 ///  TRN_loss: 10.5569 TRN_MAE_: 0.9869 TRN_RMSLE: 2.1871 TRN_VAL_: 0.0346 TRN_mean_squared_error: 187509838370.6119 TRN_MAPE_: 1.6882\n",
            "# 0014 |  TST_loss: 11.0426 TST_MAE_: 1.2141 TST_RMSLE: 2.0743 TST_VAL_: 1.0483 TST_mean_squared_error: 183036314783.0823 TST_MAPE_: 1.6981 ///  TRN_loss: 10.5571 TRN_MAE_: 0.9871 TRN_RMSLE: 2.1871 TRN_VAL_: 0.0339 TRN_mean_squared_error: 187509839821.3832 TRN_MAPE_: 1.6883\n",
            "# 0015 |  TST_loss: 11.0442 TST_MAE_: 1.2155 TST_RMSLE: 2.0743 TST_VAL_: 1.0505 TST_mean_squared_error: 183036313103.9118 TST_MAPE_: 1.6993 ///  TRN_loss: 10.5575 TRN_MAE_: 0.9875 TRN_RMSLE: 2.1871 TRN_VAL_: 0.0328 TRN_mean_squared_error: 187509841213.1090 TRN_MAPE_: 1.6880\n",
            "# 0016 |  TST_loss: 11.0533 TST_MAE_: 1.2236 TST_RMSLE: 2.0742 TST_VAL_: 1.0634 TST_mean_squared_error: 183036194016.2110 TST_MAPE_: 1.7062 ///  TRN_loss: 10.5576 TRN_MAE_: 0.9875 TRN_RMSLE: 2.1871 TRN_VAL_: 0.0327 TRN_mean_squared_error: 187509845840.0714 TRN_MAPE_: 1.6879\n",
            "# 0017 |  TST_loss: 11.0403 TST_MAE_: 1.2119 TST_RMSLE: 2.0743 TST_VAL_: 1.0449 TST_mean_squared_error: 183036346614.2945 TST_MAPE_: 1.6963 ///  TRN_loss: 10.5572 TRN_MAE_: 0.9871 TRN_RMSLE: 2.1871 TRN_VAL_: 0.0339 TRN_mean_squared_error: 187509832886.5001 TRN_MAPE_: 1.6887\n",
            "# 0018 |  TST_loss: 11.0456 TST_MAE_: 1.2169 TST_RMSLE: 2.0743 TST_VAL_: 1.0527 TST_mean_squared_error: 183036297618.6694 TST_MAPE_: 1.7004 ///  TRN_loss: 10.5568 TRN_MAE_: 0.9868 TRN_RMSLE: 2.1871 TRN_VAL_: 0.0347 TRN_mean_squared_error: 187509841562.3210 TRN_MAPE_: 1.6880\n",
            "# 0019 |  TST_loss: 11.0475 TST_MAE_: 1.2186 TST_RMSLE: 2.0743 TST_VAL_: 1.0554 TST_mean_squared_error: 183036255489.7804 TST_MAPE_: 1.7019 ///  TRN_loss: 10.5569 TRN_MAE_: 0.9868 TRN_RMSLE: 2.1871 TRN_VAL_: 0.0347 TRN_mean_squared_error: 187509841084.3501 TRN_MAPE_: 1.6882\n",
            "# 0020 |  TST_loss: 11.0412 TST_MAE_: 1.2127 TST_RMSLE: 2.0743 TST_VAL_: 1.0461 TST_mean_squared_error: 183036330262.1480 TST_MAPE_: 1.6969 ///  TRN_loss: 10.5574 TRN_MAE_: 0.9873 TRN_RMSLE: 2.1871 TRN_VAL_: 0.0333 TRN_mean_squared_error: 187509837819.4357 TRN_MAPE_: 1.6884\n",
            "# 0021 |  TST_loss: 11.0476 TST_MAE_: 1.2186 TST_RMSLE: 2.0743 TST_VAL_: 1.0555 TST_mean_squared_error: 183036255433.1390 TST_MAPE_: 1.7019 ///  TRN_loss: 10.5574 TRN_MAE_: 0.9874 TRN_RMSLE: 2.1871 TRN_VAL_: 0.0332 TRN_mean_squared_error: 187509844120.4846 TRN_MAPE_: 1.6878\n",
            "# 0022 |  TST_loss: 11.0448 TST_MAE_: 1.2161 TST_RMSLE: 2.0743 TST_VAL_: 1.0515 TST_mean_squared_error: 183036298518.5490 TST_MAPE_: 1.6998 ///  TRN_loss: 10.5570 TRN_MAE_: 0.9869 TRN_RMSLE: 2.1871 TRN_VAL_: 0.0343 TRN_mean_squared_error: 187509836824.4796 TRN_MAPE_: 1.6884\n",
            "\n",
            "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.0006000000052154065.\n",
            "# 0023 |  TST_loss: 11.0454 TST_MAE_: 1.2166 TST_RMSLE: 2.0743 TST_VAL_: 1.0523 TST_mean_squared_error: 183036297873.4807 TST_MAPE_: 1.7003 ///  TRN_loss: 10.5573 TRN_MAE_: 0.9873 TRN_RMSLE: 2.1871 TRN_VAL_: 0.0334 TRN_mean_squared_error: 187509841109.4542 TRN_MAPE_: 1.6881\n",
            "# 0024 |  TST_loss: 11.0475 TST_MAE_: 1.2186 TST_RMSLE: 2.0743 TST_VAL_: 1.0555 TST_mean_squared_error: 183036255436.4887 TST_MAPE_: 1.7019 ///  TRN_loss: 10.5578 TRN_MAE_: 0.9878 TRN_RMSLE: 2.1871 TRN_VAL_: 0.0318 TRN_mean_squared_error: 187509846463.3343 TRN_MAPE_: 1.6877\n",
            "# 0025 |  TST_loss: 11.0474 TST_MAE_: 1.2185 TST_RMSLE: 2.0743 TST_VAL_: 1.0553 TST_mean_squared_error: 183036255549.0183 TST_MAPE_: 1.7018 ///  TRN_loss: 10.5572 TRN_MAE_: 0.9872 TRN_RMSLE: 2.1871 TRN_VAL_: 0.0337 TRN_mean_squared_error: 187509836424.3234 TRN_MAPE_: 1.6883\n",
            "# 0026 |  TST_loss: 11.0504 TST_MAE_: 1.2212 TST_RMSLE: 2.0742 TST_VAL_: 1.0595 TST_mean_squared_error: 183036224649.0052 TST_MAPE_: 1.7041 ///  TRN_loss: 10.5572 TRN_MAE_: 0.9873 TRN_RMSLE: 2.1872 TRN_VAL_: 0.0335 TRN_mean_squared_error: 187509847452.8381 TRN_MAPE_: 1.6877\n",
            "# 0027 |  TST_loss: 11.0458 TST_MAE_: 1.2171 TST_RMSLE: 2.0743 TST_VAL_: 1.0530 TST_mean_squared_error: 183036269600.1092 TST_MAPE_: 1.7006 ///  TRN_loss: 10.5570 TRN_MAE_: 0.9871 TRN_RMSLE: 2.1871 TRN_VAL_: 0.0340 TRN_mean_squared_error: 187509831558.6064 TRN_MAPE_: 1.6889\n",
            "# 0028 |  TST_loss: 11.0460 TST_MAE_: 1.2172 TST_RMSLE: 2.0743 TST_VAL_: 1.0533 TST_mean_squared_error: 183036269384.0156 TST_MAPE_: 1.7008 ///  TRN_loss: 10.5565 TRN_MAE_: 0.9865 TRN_RMSLE: 2.1871 TRN_VAL_: 0.0354 TRN_mean_squared_error: 187509838767.0190 TRN_MAPE_: 1.6882\n",
            "# 0029 |  TST_loss: 11.0478 TST_MAE_: 1.2189 TST_RMSLE: 2.0743 TST_VAL_: 1.0559 TST_mean_squared_error: 183036255122.8258 TST_MAPE_: 1.7022 ///  TRN_loss: 10.5572 TRN_MAE_: 0.9873 TRN_RMSLE: 2.1871 TRN_VAL_: 0.0335 TRN_mean_squared_error: 187509842806.6638 TRN_MAPE_: 1.6879\n",
            "# 0030 |  TST_loss: 11.0460 TST_MAE_: 1.2172 TST_RMSLE: 2.0743 TST_VAL_: 1.0532 TST_mean_squared_error: 183036269438.8526 TST_MAPE_: 1.7007 ///  TRN_loss: 10.5570 TRN_MAE_: 0.9870 TRN_RMSLE: 2.1871 TRN_VAL_: 0.0341 TRN_mean_squared_error: 187509833964.3398 TRN_MAPE_: 1.6885\n",
            "# 0030 |  TST_loss: 11.0460 TST_MAE_: 1.2172 TST_RMSLE: 2.0743 TST_VAL_: 1.0532 TST_mean_squared_error: 183036269438.8526 TST_MAPE_: 1.7007 ///  TRN_loss: 10.5570 TRN_MAE_: 0.9870 TRN_RMSLE: 2.1871 TRN_VAL_: 0.0341 TRN_mean_squared_error: 187509833964.3398 TRN_MAPE_: 1.6885\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBMyJFG7Ugac",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for lr in [0.03]:\n",
        "  nn_2 = keras.models.load_model (DIR + '2HANDLY_SAVED_3best.MODEL')\n",
        "  opt = Adam(lr = lr)\n",
        "  epochs = 70\n",
        "  batch_size = 700\n",
        "  meter = 2\n",
        "  bias = Constant(value = 0.1)\n",
        "\n",
        "  earlyStopping = EarlyStopping(monitor='loss', patience=100, verbose=1, mode='min')\n",
        "  reduce_lr_loss = ReduceLROnPlateau(monitor='loss', factor=0.3, patience=15, verbose=1, min_delta=1e-3, mode='min')\n",
        "  model_checkpoint = ModelCheckpoint(monitor='loss', save_best_only=True, filepath = DIR + 'best_nn_' + str(meter) + '.model', save_weights_only = False, verbose=0, mode='min')\n",
        "\n",
        "  val = df[(df['meter'] == meter) & (df['day']%6 == 0) & (df['k_NN_ERR'] < 100) & (df['k_NN_ERR'] > 1/100) & (df['IS_BAD_PRCNT'] < 0.45)]\n",
        "  df_cleared = df[(df['k_NN_ERR']<50) & (df['k_NN_ERR']>1/50) & (df['day']%6 != 0) & (df['meter']==meter) & (df['IS_BAD_PRCNT']<0.45)][In_Columns + [Out_Columns]]\n",
        "  print('*'*9, lr, '*'*33)\n",
        "  nn_0.compile(optimizer = opt, loss = RMSLE, metrics=[ MAE_, RMSLE, VAL_, 'mse', MAPE_ ])\n",
        "  hist = nn_2.fit( df_cleared[In_Columns], df_cleared[Out_Columns], batch_size = batch_size, verbose = 0\n",
        "                  , epochs = epochs, shuffle = True, callbacks=[ MyCustomCallback(epochs, 1), earlyStopping, reduce_lr_loss]\n",
        "                  , validation_data=(val[In_Columns], val[Out_Columns])\n",
        "                  ) \n",
        "  nn_2.save(DIR + str(meter) + 'HANDLY_SAVED_3.MODEL')\n",
        "  gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DQZRFeEH01Cw",
        "colab": {}
      },
      "source": [
        "if 3==3:\n",
        "  meter = 3\n",
        "  epochs = 300\n",
        "  batch_size = 700\n",
        "  opt = Adam(lr = 0.007)\n",
        "\n",
        "  earlyStopping = EarlyStopping(monitor='loss', patience=50, verbose=1, mode='min')\n",
        "  reduce_lr_loss = ReduceLROnPlateau(monitor='loss', factor=0.2, patience=10, verbose=1, min_delta=1e-3, mode='min')\n",
        "  model_checkpoint = ModelCheckpoint(monitor='loss', save_best_only=True, filepath = DIR + 'best_nn_' + str(meter) + '.model', save_weights_only = False, verbose=0, mode='min')\n",
        "\n",
        "  nn_3 = Sequential()\n",
        "  nn_3.add(Dense(100, input_shape = df[In_Columns].shape[1:], activation = 'tanh', kernel_initializer = 'normal', kernel_regularizer=l2(reg), bias_initializer=bias))\n",
        "  nn_3.add(Dense(100, activation = 'tanh',  kernel_initializer = 'normal', bias_initializer=bias))\n",
        "  nn_3.add(Dense(100, activation = 'tanh',  kernel_initializer = 'normal', bias_initializer=bias, kernel_regularizer=l1(reg)))\n",
        "  nn_3.add(Dense(100, activation = 'tanh',  kernel_initializer = 'normal', bias_initializer=bias))\n",
        "  nn_3.add(Dense(1, activation = 'relu', kernel_initializer = 'normal'))\n",
        "\n",
        "  nn_3.compile(optimizer = opt, loss = RMSLE, metrics=[ MAE_, RMSLE, VAL_, 'mse', MAPE_ ])\n",
        "  \n",
        "  val = df[(df['meter'] == meter) & (df['day']%6 == 0) & (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.45)]\n",
        "  df_cleared = df[(df['k_NN_ERR']<50) & (df['k_NN_ERR']>1/50)  & (df['day']%6!=0) & (df['meter']==meter) & (df['IS_BAD_PRCNT']<0.45)][In_Columns + [Out_Columns]]\n",
        "\n",
        "  hist = nn_3.fit( df_cleared[In_Columns], df_cleared[Out_Columns], batch_size = batch_size, verbose = 0\n",
        "                  , epochs = epochs, shuffle = True, callbacks=[MyCustomCallback(epochs, 1), earlyStopping, reduce_lr_loss]\n",
        "                  , validation_data=(val[In_Columns], val[Out_Columns])\n",
        "                  ) \n",
        "  nn_3.save(DIR + str(meter) + 'HANDLY_SAVED0_3.MODEL')\n",
        "  gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_Ihng3E901Cy",
        "colab": {}
      },
      "source": [
        "for lr in [0.007]:\n",
        "  opt = Adam(lr = lr)\n",
        "  epochs = 200\n",
        "  batch_size = 700\n",
        "  meter = 3\n",
        "  nn_3 = keras.models.load_model (DIR + str(meter) + 'HANDLY_SAVED_3best.MODEL')\n",
        "\n",
        "  earlyStopping = EarlyStopping(monitor='loss', patience=50, verbose=1, mode='min')\n",
        "  reduce_lr_loss = ReduceLROnPlateau(monitor='loss', factor=0.2, patience=12, verbose=1, min_delta=1e-3, mode='min')\n",
        "  model_checkpoint = ModelCheckpoint(monitor='loss', save_best_only=True, filepath = DIR + 'best_nn_' + str(meter) + '.model', save_weights_only = False, verbose=0, mode='min')\n",
        "\n",
        "  val = df[(df['meter'] == meter) & (df['day']%6 == 0) & (df['k_NN_ERR'] < 100) & (df['k_NN_ERR'] > 1/100) & (df['IS_BAD_PRCNT'] < 0.45)]\n",
        "  df_cleared = df[(df['k_NN_ERR']<50) & (df['day']%6 != 0) & (df['k_NN_ERR']>1/50) & (df['meter']==meter) & (df['IS_BAD_PRCNT']<0.45)][In_Columns + [Out_Columns]]\n",
        "  print('*'*9, lr, '*'*33)\n",
        "  nn_3.compile(optimizer = opt, loss = RMSLE, metrics=[ MAE_, RMSLE, VAL_, 'mse', MAPE_ ])\n",
        "  hist = nn_3.fit( df_cleared[In_Columns], df_cleared[Out_Columns], batch_size = batch_size, verbose = 0\n",
        "                  , epochs = epochs, shuffle = True, callbacks=[ MyCustomCallback(epochs, 1), earlyStopping, reduce_lr_loss]\n",
        "                  , validation_data=(val[In_Columns], val[Out_Columns])\n",
        "                  ) \n",
        "  nn_3.save(DIR + str(meter) + 'HANDLY_SAVED_3.MODEL')\n",
        "  gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Q-4iZ-RLtI2v",
        "colab": {}
      },
      "source": [
        "#nn_0.save(DIR + '0HANDLY_SAVED_3best.MODEL')\n",
        "  # nn_1.save(DIR + '1HANDLY_SAVED_3best.MODEL')\n",
        "  # nn_2.save(DIR + '2HANDLY_SAVED_3best.MODEL')\n",
        "  # nn_3.save(DIR + '3HANDLY_SAVED_3best.MODEL')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_knQD6Zw0yFy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Предсказание из 4х значений:\n",
        "  nn_0 = keras.models.load_model (DIR_SAVE + '0HANDLY_SAVED_3best.MODEL')\n",
        "  nn_1 = keras.models.load_model (DIR_SAVE + '1HANDLY_SAVED_3best.MODEL')\n",
        "  nn_2 = keras.models.load_model (DIR_SAVE + '2HANDLY_SAVED_3best.MODEL')\n",
        "  nn_3 = keras.models.load_model (DIR_SAVE + '3HANDLY_SAVED_3best.MODEL')\n",
        "\n",
        "  # score = model.evaluate(X, Y, verbose=0)\n",
        "  # print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))\n",
        "  gc.collect()\n",
        "\n",
        "  df['NN_PRED'] = 0\n",
        "  df['NN_PRED_0'] = nn_0.predict(df[In_Columns], batch_size = 10000) \n",
        "  df['NN_PRED_1'] = nn_1.predict(df[In_Columns], batch_size = 10000) \n",
        "  df['NN_PRED_2'] = nn_2.predict(df[In_Columns], batch_size = 10000) \n",
        "  df['NN_PRED_3'] = nn_3.predict(df[In_Columns], batch_size = 10000) \n",
        "  df['NN_PRED'] = np.where(df['meter'] == 0, df['NN_PRED_0'], df['NN_PRED'])\n",
        "  df['NN_PRED'] = np.where(df['meter'] == 1, df['NN_PRED_1'], df['NN_PRED'])\n",
        "  df['NN_PRED'] = np.where(df['meter'] == 2, df['NN_PRED_2'], df['NN_PRED'])\n",
        "  df['NN_PRED'] = np.where(df['meter'] == 3, df['NN_PRED_3'], df['NN_PRED'])\n",
        "  df.drop(columns = ['NN_PRED_0', 'NN_PRED_1', 'NN_PRED_2', 'NN_PRED_3'], inplace = True)\n",
        "  #df.drop(columns = ['Value_x', 'Value_y'])\n",
        "  gc.collect()\n",
        "\n",
        "  df['NN_ERR'] = np.abs(df['NN_PRED']-df['meter_reading'])\n",
        "  df['k_NN_ERR'] = (df['NN_PRED']+0.33)/(df['meter_reading']+0.33)\n",
        "\n",
        "  print( 'Ошибка общая: ', np.sqrt( np.mean( np.power(np.log(df['meter_reading']+1) - np.log(df['NN_PRED']+1),2.00000)))\n",
        "      , 'Ошибка (VAL): ', np.sqrt( np.mean( np.power(np.log(df[(df['day']%6 == 0)]['meter_reading']+1) - np.log(df[(df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка (VAL_чист): ' , np.sqrt( np.mean( np.power(np.log(df[  (df['IS_BAD_PRCNT'] < 0.25) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[(df['IS_BAD_PRCNT'] < 0.25) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка (VAL_чист2): ', np.sqrt( np.mean( np.power(np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "  )\n",
        "  print('Ошибка 0: ', np.sqrt( np.mean( np.power(np.log(df[df['meter']==0]['meter_reading']+1) - np.log(df[df['meter']==0]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка 0 (VAL): ', np.sqrt( np.mean( np.power(np.log(df[(df['meter']==0) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[(df['meter']==0) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка 0 (VAL_чист): ' , np.sqrt( np.mean( np.power(np.log(df[  (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==0) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[ (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==0) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка 0 (VAL_чист2): ', np.sqrt( np.mean( np.power(np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==0) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==0) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "  )\n",
        "  print('Ошибка 1: ', np.sqrt( np.mean( np.power(np.log(df[df['meter']==1]['meter_reading']+1) - np.log(df[df['meter']==1]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка 1 (VAL): ', np.sqrt( np.mean( np.power(np.log(df[(df['meter']==1) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[(df['meter']==1) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка 1 (VAL_чист): ' , np.sqrt( np.mean( np.power(np.log(df[  (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==1) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[ (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==1) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка 1 (VAL_чист2): ', np.sqrt( np.mean( np.power(np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==1) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==1) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "  )\n",
        "  print('Ошибка 2: ', np.sqrt( np.mean( np.power(np.log(df[df['meter']==2]['meter_reading']+1) - np.log(df[df['meter']==2]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка 2 (VAL): ', np.sqrt( np.mean( np.power(np.log(df[(df['meter']==2) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[(df['meter']==2) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка 2 (VAL_чист): ' , np.sqrt( np.mean( np.power(np.log(df[  (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==2) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[ (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==2) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка 2 (VAL_чист2): ', np.sqrt( np.mean( np.power(np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==2) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==2) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "  )\n",
        "  print('Ошибка 3: ', np.sqrt( np.mean( np.power(np.log(df[df['meter']==3]['meter_reading']+1) - np.log(df[df['meter']==3]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка 3 (VAL): ', np.sqrt( np.mean( np.power(np.log(df[(df['meter']==3) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[(df['meter']==3) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка 3 (VAL_чист): ' , np.sqrt( np.mean( np.power(np.log(df[  (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==3) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[ (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==3) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка 3 (VAL_чист2): ', np.sqrt( np.mean( np.power(np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==3) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==3) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "  )\n",
        "  # print('Ошибка 1: ', np.sqrt( np.mean( np.power(np.log(df[df['meter']==1]['meter_reading']+1) - np.log(df[df['meter']==1]['NN_PRED']+1),2.00000)))        )\n",
        "  # print('Ошибка 2: ', np.sqrt( np.mean( np.power(np.log(df[df['meter']==2]['meter_reading']+1) - np.log(df[df['meter']==2]['NN_PRED']+1),2.00000)))        )\n",
        "  # print('Ошибка 3: ', np.sqrt( np.mean( np.power(np.log(df[df['meter']==3]['meter_reading']+1) - np.log(df[df['meter']==3]['NN_PRED']+1),2.00000)))        )\n",
        "\n",
        "  gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWGPRQypQAuh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Ошибки:\n",
        "  Ошибка общая:  1.3332699709812266 Ошибка (VAL):  1.337540194067479 Ошибка (VAL_чист):  0.5418592287241801 Ошибка (VAL_чист2):  0.40073096858305257\n",
        "  Ошибка 0:  1.098206407152078 Ошибка 0 (VAL):  1.0905813857988798 Ошибка 0 (VAL_чист):  0.28240200416498673 Ошибка 0 (VAL_чист2):  0.2562246375809472\n",
        "  Ошибка 1:  1.4462519064009887 Ошибка 1 (VAL):  1.4819992377016542 Ошибка 1 (VAL_чист):  0.628029160200588 Ошибка 1 (VAL_чист2):  0.47946068818401355\n",
        "  Ошибка 2:  1.6966445281141582 Ошибка 2 (VAL):  1.6978240187666451 Ошибка 2 (VAL_чист):  0.926254557141954 Ошибка 2 (VAL_чист2):  0.6472006361307439\n",
        "  Ошибка 3:  1.9577298686058777 Ошибка 3 (VAL):  1.9537862377808086 Ошибка 3 (VAL_чист):  1.1455655044777464 Ошибка 3 (VAL_чист2):  0.6972188121146171\n",
        "\n",
        "  Ошибка общая:  1.3473873510158345 Ошибка (VAL):  1.3483414756663568 Ошибка (VAL_чист):  0.5756767186919248 Ошибка (VAL_чист2):  0.462361504102313\n",
        "  Ошибка 0:  1.0971504229404558 Ошибка 0 (VAL):  1.0891509074774033 Ошибка 0 (VAL_чист):  0.3389179667173395 Ошибка 0 (VAL_чист2):  0.3149224768996143\n",
        "  Ошибка 1:  1.5319581160458586 Ошибка 1 (VAL):  1.5591904792676097 Ошибка 1 (VAL_чист):  0.7038461338617784 Ошибка 1 (VAL_чист2):  0.5850605758832433\n",
        "  Ошибка 2:  1.6638634087676607 Ошибка 2 (VAL):  1.6575566177087862 Ошибка 2 (VAL_чист):  0.918408148629441 Ошибка 2 (VAL_чист2):  0.6847326774214916\n",
        "  Ошибка 3:  1.9625404709477796 Ошибка 3 (VAL):  1.9555454713909437 Ошибка 3 (VAL_чист):  1.117054007408267 Ошибка 3 (VAL_чист2):  0.7521327942946583"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSg8qh29X2xl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Evaluate:\n",
        "  score = nn_0.evaluate(df[df['meter']==0][In_Columns], df[df['meter']==0][Out_Columns], verbose=1, batch_size = 30000)\n",
        "  print(0)\n",
        "  for i in range(len(nn_0.metrics_names)):\n",
        "    print(\"%s: %.2f%%\" % (nn_0.metrics_names[i], score[i]*100))\n",
        "\n",
        "  score = nn_1.evaluate(df[df['meter']==1][In_Columns], df[df['meter']==1][Out_Columns], verbose=1, batch_size = 30000)\n",
        "  print(1)\n",
        "  for i in range(len(nn_1.metrics_names)):\n",
        "    print(\"%s: %.2f%%\" % (nn_1.metrics_names[i], score[i]*100))\n",
        "\n",
        "  score = nn_2.evaluate(df[df['meter']==2][In_Columns], df[df['meter']==2][Out_Columns], verbose=1, batch_size = 30000)\n",
        "  print(2)\n",
        "  for i in range(len(nn_2.metrics_names)):\n",
        "    print(\"%s: %.2f%%\" % (nn_2.metrics_names[i], score[i]*100))\n",
        "\n",
        "  score = nn_3.evaluate(df[df['meter']==3][In_Columns], df[df['meter']==3][Out_Columns], verbose=1, batch_size = 30000)\n",
        "  print(3)\n",
        "  for i in range(len(nn_3.metrics_names)):\n",
        "    print(\"%s: %.2f%%\" % (nn_3.metrics_names[i], score[i]*100))\n",
        "  \n",
        "  gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8qHP3Icaw2D",
        "colab_type": "code",
        "outputId": "43e69f59-8e40-42ea-d66a-644e6e2ad83e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "#Важность показателей 0\n",
        "  from sklearn.utils import shuffle\n",
        "  nn = keras.models.load_model (DIR_SAVE + '0HANDLY_SAVED3best.MODEL')\n",
        "  meter = 0\n",
        "  val = df[(df['meter']==meter) & (df['day']%6==0)  & (df['IS_BAD_PRCNT']<0.45)]\n",
        "  #Подставить нужную нейронку в зависимости от meter\n",
        "  #print(nn.metrics_names)\n",
        "  k = pd.DataFrame( [nn.evaluate(val[In_Columns], val[Out_Columns], batch_size = 800000, verbose = 0)],columns=nn.metrics_names)\n",
        "  k['name'] = '---INITIAL---'\n",
        "  tmp_out=k.copy()\n",
        "  for i in range(len(In_Columns)):\n",
        "      X_val_2 = val[In_Columns].copy()\n",
        "      s = shuffle(X_val_2.iloc[:,i])\n",
        "      s.index = X_val_2.index\n",
        "      X_val_2.iloc[:, i] = s\n",
        "      tmp = pd.DataFrame([nn.evaluate(X_val_2, val[Out_Columns], batch_size = 800000, verbose = 0)], columns = nn.metrics_names)-k[nn.metrics_names] \n",
        "      tmp['name'] = In_Columns[i]\n",
        "      tmp_out = pd.concat([tmp_out, tmp])\n",
        "      X_val_2 = None\n",
        "      gc.collect()\n",
        "  tmp_out.set_index('name', inplace = True)\n",
        "  pd.set_option('display.float_format', lambda x: '%.4f' % x)\n",
        "  print (tmp_out[nn.metrics_names].sort_values('RMSLE', ascending=False))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                 loss    MAE_   RMSLE    VAL_  mean_squared_error   MAPE_\n",
            "name                                                                                     \n",
            "building_meter_weekday_median  2.9106  0.9289  1.3989  0.0326         114978.4964  1.4665\n",
            "square_feet                    0.4069  0.1125  0.3822  0.0089           7386.0101  0.3386\n",
            "---INITIAL---                  0.1303  0.1884  0.3410  0.9108          25827.2513  0.2326\n",
            "site_id                        0.2229  0.0807  0.2424  0.0108           3550.1542  0.2189\n",
            "primary_use_ID                 0.1589  0.0633  0.1832  0.0067           3364.4379  0.1621\n",
            "building_meter_hour_median     0.0844  0.0159  0.1069  0.0043            385.0823  0.1368\n",
            "hour_cos                       0.0713  0.0415  0.0908  0.0012           1410.0715  0.0857\n",
            "week_cos                       0.0378  0.0193  0.0521 -0.0163           1017.2717  0.0297\n",
            "week_sin                       0.0370  0.0178  0.0513 -0.0100            857.0364  0.0294\n",
            "air_temperature                0.0221  0.0150  0.0316 -0.0194            721.6550  0.0197\n",
            "hour_sin                       0.0157  0.0132  0.0218  0.0011            401.7483  0.0230\n",
            "weekday_sin                    0.0143  0.0063  0.0191  0.0007            142.8440  0.0195\n",
            "building_meter_median          0.0125  0.0019  0.0179  0.0011             41.1203  0.0303\n",
            "dew_temperature                0.0042  0.0046  0.0063 -0.0059            178.1515  0.0045\n",
            "weekday_cos                    0.0025  0.0011  0.0035 -0.0002             25.0626  0.0032\n",
            "cloud_coverage                 0.0004  0.0003  0.0006 -0.0002              9.4449  0.0009\n",
            "sea_level_pressure             0.0002  0.0001  0.0003  0.0004             -1.8919  0.0005\n",
            "wind_speed                     0.0001  0.0001  0.0001 -0.0002              1.6454  0.0001\n",
            "wind_direction                -0.0000  0.0000 -0.0000 -0.0001              0.6456 -0.0000\n",
            "is_holiday                    -0.0006 -0.0000 -0.0007  0.0001              0.5574  0.0001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCDCxcqhKHO1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Важность показателей 1\n",
        "  from sklearn.utils import shuffle\n",
        "  nn = keras.models.load_model (DIR_SAVE + '1HANDLY_SAVED3.MODEL')\n",
        "  meter = 1\n",
        "  val = df[(df['meter']==meter) & (df['day']%6==0)  & (df['IS_BAD_PRCNT']<0.25)]\n",
        "  #Подставить нужную нейронку в зависимости от meter\n",
        "  #print(nn.metrics_names)\n",
        "  k = pd.DataFrame( [nn.evaluate(val[In_Columns], val[Out_Columns], batch_size = 800000, verbose = 0)],columns=nn.metrics_names)\n",
        "  k['name'] = '---INITIAL---'\n",
        "  tmp_out=k.copy()\n",
        "  for i in range(len(In_Columns)):\n",
        "      X_val_2 = val[In_Columns].copy()\n",
        "      s = shuffle(X_val_2.iloc[:,i])\n",
        "      s.index = X_val_2.index\n",
        "      X_val_2.iloc[:, i] = s\n",
        "      tmp = pd.DataFrame([nn.evaluate(X_val_2, val[Out_Columns], batch_size = 800000, verbose = 0)], columns = nn.metrics_names)-k[nn.metrics_names] \n",
        "      tmp['name'] = In_Columns[i]\n",
        "      tmp_out = pd.concat([tmp_out, tmp])\n",
        "      X_val_2 = None\n",
        "      gc.collect()\n",
        "  tmp_out.set_index('name', inplace = True)\n",
        "  pd.set_option('display.float_format', lambda x: '%.4f' % x)\n",
        "  print (tmp_out[nn.metrics_names].sort_values('RMSLE', ascending=False))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIfQd2t9KN04",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Важность показателей 2\n",
        "  from sklearn.utils import shuffle\n",
        "  nn = keras.models.load_model (DIR_SAVE + '2HANDLY_SAVED3.MODEL')\n",
        "  meter = 2\n",
        "  val = df[(df['meter']==meter) & (df['day']%6==0)  & (df['IS_BAD_PRCNT']<0.25)]\n",
        "  #Подставить нужную нейронку в зависимости от meter\n",
        "  #print(nn.metrics_names)\n",
        "  k = pd.DataFrame( [nn.evaluate(val[In_Columns], val[Out_Columns], batch_size = 800000, verbose = 0)],columns=nn.metrics_names)\n",
        "  k['name'] = '---INITIAL---'\n",
        "  tmp_out=k.copy()\n",
        "  for i in range(len(In_Columns)):\n",
        "      X_val_2 = val[In_Columns].copy()\n",
        "      s = shuffle(X_val_2.iloc[:,i])\n",
        "      s.index = X_val_2.index\n",
        "      X_val_2.iloc[:, i] = s\n",
        "      tmp = pd.DataFrame([nn.evaluate(X_val_2, val[Out_Columns], batch_size = 800000, verbose = 0)], columns = nn.metrics_names)-k[nn.metrics_names] \n",
        "      tmp['name'] = In_Columns[i]\n",
        "      tmp_out = pd.concat([tmp_out, tmp])\n",
        "      X_val_2 = None\n",
        "      gc.collect()\n",
        "  tmp_out.set_index('name', inplace = True)\n",
        "  pd.set_option('display.float_format', lambda x: '%.4f' % x)\n",
        "  print (tmp_out[nn.metrics_names].sort_values('RMSLE', ascending=False))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wxn_T9DhKRzX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Важность показателей 3\n",
        "  from sklearn.utils import shuffle\n",
        "  nn = keras.models.load_model (DIR_SAVE + '3HANDLY_SAVED03.MODEL')\n",
        "  meter = 3\n",
        "  val = df[(df['meter']==meter) & (df['day']%6==0)  & (df['IS_BAD_PRCNT']<0.25)]\n",
        "  #Подставить нужную нейронку в зависимости от meter\n",
        "  #print(nn.metrics_names)\n",
        "  k = pd.DataFrame( [nn.evaluate(val[In_Columns], val[Out_Columns], batch_size = 800000, verbose = 0)],columns=nn.metrics_names)\n",
        "  k['name'] = '---INITIAL---'\n",
        "  tmp_out=k.copy()\n",
        "  for i in range(len(In_Columns)):\n",
        "      X_val_2 = val[In_Columns].copy()\n",
        "      s = shuffle(X_val_2.iloc[:,i])\n",
        "      s.index = X_val_2.index\n",
        "      X_val_2.iloc[:, i] = s\n",
        "      tmp = pd.DataFrame([nn.evaluate(X_val_2, val[Out_Columns], batch_size = 800000, verbose = 0)], columns = nn.metrics_names)-k[nn.metrics_names] \n",
        "      tmp['name'] = In_Columns[i]\n",
        "      tmp_out = pd.concat([tmp_out, tmp])\n",
        "      X_val_2 = None\n",
        "      gc.collect()\n",
        "  tmp_out.set_index('name', inplace = True)\n",
        "  pd.set_option('display.float_format', lambda x: '%.4f' % x)\n",
        "  print (tmp_out[nn.metrics_names].sort_values('RMSLE', ascending=False))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsiTWGypOAHb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ИДЕИ:\n",
        "  1) Сделать не показатель, а его отклонение от медианы по строению/дню/часу\n",
        "  2) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLLVe_MMYIz-",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6AezgKyEBi6",
        "colab_type": "code",
        "outputId": "26eb9e7a-6504-4dac-b822-27b0e467fb7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#reduce_mem_usage(df_test)\n",
        "gc.collect()\n",
        "#df_test.describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWDYNM3xOBZx",
        "colab_type": "code",
        "outputId": "cd7750df-9ded-4797-bccf-e5aaafc1de46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Подготовка данных тест:\n",
        "  df_test = pd.read_csv(DIR + \"test.csv\", engine = 'python')\n",
        "  print('Забрали с диска')\n",
        "  df_test['timestamp'] = pd.to_datetime(df_test['timestamp'])\n",
        "\n",
        "  df_test['hour_cos'] = np.cos(df_test['timestamp'].dt.hour * 2. * np.pi / 24.)\n",
        "  df_test['hour_sin'] = np.sin(df_test['timestamp'].dt.hour * 2. * np.pi / 24.)\n",
        "\n",
        "  df_test['weekday_cos'] = np.cos(df_test['timestamp'].dt.weekday * 2. * np.pi / 7.)\n",
        "  df_test['weekday_sin'] = np.sin(df_test['timestamp'].dt.weekday * 2. * np.pi / 7.)\n",
        "\n",
        "  df_test['week_cos'] = np.cos(df_test['timestamp'].dt.week * 2. * np.pi / 53.)\n",
        "  df_test['week_sin'] = np.sin(df_test['timestamp'].dt.week * 2. * np.pi / 53.)\n",
        "\n",
        "  #reduce_mem_usage(df_test)\n",
        "  gc.collect()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Забрали с диска\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "91"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "6d9925cb-d229-45fd-97fc-cc15d533037b",
        "id": "z2TmthILE1wp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# Добавление медиан:\n",
        "  # Добавление медианы по метрике постройки\n",
        "    df_median = df.groupby(by=['building_id','meter'])['building_meter_median'].median()\n",
        "    df_test = pd.merge(df_test, df_median, how = 'left', on = ['building_id','meter'])\n",
        "    del df_median \n",
        "    gc.collect()\n",
        "    print('Построены медианы по сооружению')\n",
        "  # Добавление медианы по часу, по неделе, метрике постройки\n",
        "    df_test['hour'] = df_test['timestamp'].dt.hour\n",
        "    df_median = df.groupby(by=['building_id','hour','meter'])['building_meter_hour_median'].median()\n",
        "    df_test = pd.merge(df_test, df_median, how = 'left', on = ['building_id','hour','meter'])\n",
        "    #print(len(df_test))\n",
        "    del df_median #, df_mean, df_median2, df_mean2\n",
        "    gc.collect()\n",
        "    \n",
        "    df_test['weekday'] = df_test['timestamp'].dt.weekday\n",
        "    df_median = df.groupby(by=['building_id','weekday','meter'])['building_meter_weekday_median'].median()\n",
        "    #df_median.name = 'building_meter_weekday_median'\n",
        "    df_test = pd.merge(df_test, df_median, how = 'left', on = ['building_id','weekday','meter'])\n",
        "    del df_median \n",
        "    #print(len(df_test))\n",
        "\n",
        "    print('Построены медианы по сооружению/часу')\n",
        "    holidays = [\"2016-01-01\", \"2016-01-18\", \"2016-02-15\", \"2016-05-30\", \"2016-07-04\",\n",
        "                      \"2016-09-05\", \"2016-10-10\", \"2016-11-11\", \"2016-11-24\", \"2016-12-26\",\n",
        "                      \"2017-01-02\", \"2017-01-16\", \"2017-02-20\", \"2017-05-29\", \"2017-07-04\",\n",
        "                      \"2017-09-04\", \"2017-10-09\", \"2017-11-10\", \"2017-11-23\", \"2017-12-25\",\n",
        "                      \"2018-01-01\", \"2018-01-15\", \"2018-02-19\", \"2018-05-28\", \"2018-07-04\",\n",
        "                      \"2018-09-03\", \"2018-10-08\", \"2018-11-12\", \"2018-11-22\", \"2018-12-25\",\n",
        "                      \"2019-01-01\"]\n",
        "    df_test[\"is_holiday\"] = (df_test.timestamp.isin(holidays)).astype(int)\n",
        "    del holidays\n",
        "    gc.collect()\n",
        "    #print(len(df_test))\n",
        "  # Подстановка параметров сооружения\n",
        "    df_median = df.groupby(by=['building_id'])['primary_use_ID','site_id','square_feet'].median()\n",
        "    df_test = pd.merge(df_test, df_median, how = 'left', on = ['building_id'])\n",
        "    del df_median \n",
        "\n",
        "    print('Подставлены данные по сооружению')\n",
        "    gc.collect()\n",
        "    #print(len(df_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Построены медианы по сооружению\n",
            "Построены медианы по сооружению/часу\n",
            "Подставлены данные по сооружению\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i34pNJGAWNLV",
        "colab_type": "code",
        "outputId": "0ff2362c-681b-4c23-cab5-72fa812270fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "del df\n",
        "gc.collect()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gZDPAWaD0M5n",
        "colab": {}
      },
      "source": [
        "#Вставка данных погоды\n",
        "#Восстановление пустых данных погоды через соседей по линейной инетрполяции\n",
        "  df_weather = pd.read_csv(DIR + \"weather_test.csv\", engine = 'python')\n",
        "  df_weather['timestamp'] = pd.to_datetime(df_weather['timestamp'])\n",
        "  df_weather.drop(columns = ['precip_depth_1_hr'], inplace = True)\n",
        "  gc.collect()\n",
        "\n",
        "  #weather_train.groupby('site_id').apply(lambda group: group.isna().sum())\n",
        "  df_times = df_test.drop_duplicates(['site_id','timestamp'])[['site_id','timestamp']]\n",
        "  df_times = pd.merge(df_times, df_weather, how = 'left', on = ['site_id','timestamp'])\n",
        "  df_times.sort_values(by = ['site_id','timestamp'], inplace = True)\n",
        "  gc.collect()\n",
        "\n",
        "  df_times = df_times.groupby('site_id'  ).apply(lambda group: group.interpolate(limit_direction='both'))\n",
        "  df_times = df_times.groupby('timestamp').apply(lambda group: group.interpolate(limit_direction='both'))\n",
        "  \n",
        "  df_test = pd.merge(df_test, df_times, how = 'left', on = ['site_id','timestamp'])\n",
        "  del df_weather, df_times\n",
        "\n",
        "  #del df_weather"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jblybbA1X8IM",
        "colab_type": "code",
        "outputId": "6ed91f04-db3f-4715-d4a4-5ad69dafcc20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#reduce_mem_usage(df_test)\n",
        "df_test.to_feather(DIR_SAVE + 'DF_TEST_REDUCED3.FTHR')\n",
        "gc.collect()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjgCdq3PZh81",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Загрузка данных:\n",
        "  #df_test = pd.read_feather(DIR_SAVE + 'DF_TEST_REDUCED3.FTHR')\n",
        "  #gc.collect()\n",
        "  import pickle\n",
        "  with open(DIR_SAVE+'scaler31.pickle', 'rb') as handle:\n",
        "      scaler = pickle.load(handle)\n",
        "      In_Columns = pickle.load(handle)\n",
        "      Out_Columns = pickle.load(handle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTDcNmss8mK5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Нормализация\n",
        "  i=0\n",
        "  #print(scaler.data_max_)\n",
        "  for c in In_Columns:\n",
        "    if c in ['building_meter_median','building_meter_hour_median','building_meter_weekday_median','primary_use_ID','site_id','square_feet']:\n",
        "      print(i, c, 'Уже нормализовано:', scaler.scale_[i],scaler.min_[i], '     ',scaler.data_min_[i], scaler.data_max_[i])\n",
        "    else:\n",
        "      print(i, c, scaler.scale_[i],scaler.min_[i], '     ', scaler.data_min_[i], scaler.data_max_[i])\n",
        "      df_test[c] = df_test[c] * scaler.scale_[i] + scaler.min_[i]\n",
        "    i+=1\n",
        "    gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cG1CZk1i-CHl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Выбор нейронок и предсказание:\n",
        "  nn_0 = keras.models.load_model (DIR_SAVE + '0HANDLY_SAVED3best.MODEL')\n",
        "  nn_1 = keras.models.load_model (DIR_SAVE + '1HANDLY_SAVED3best.MODEL')\n",
        "  nn_2 = keras.models.load_model (DIR_SAVE + '2HANDLY_SAVED3best.MODEL')\n",
        "  nn_3 = keras.models.load_model (DIR_SAVE + '3HANDLY_SAVED3best.MODEL')\n",
        "  # score = model.evaluate(X, Y, verbose=0)\n",
        "  # print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))\n",
        "  gc.collect()\n",
        "  #Предсказание из 4х значений:\n",
        "  if 1==1:\n",
        "    df_test['NN_PRED'] = 0 \n",
        "    df_test['NN_PRED']  = df_test['NN_PRED'].astype('float32')\n",
        "    l = len(df_test)\n",
        "    print( len(df_test) )\n",
        "    step = 1600000\n",
        "    for i in range(int(l/step)+1):\n",
        "      print(i*step, (i+1)*step)\n",
        "      tmp = df_test[i*step: (i+1)*step][In_Columns + ['row_id','meter']]\n",
        "      gc.collect() \n",
        "      tmp['NN_PRED'] = 0 \n",
        "      tmp['NN_PRED_0'] = nn_0.predict(tmp[In_Columns], batch_size = 20000) \n",
        "      tmp['NN_PRED_1'] = nn_1.predict(tmp[In_Columns], batch_size = 20000) \n",
        "      tmp['NN_PRED_2'] = nn_2.predict(tmp[In_Columns], batch_size = 20000) \n",
        "      tmp['NN_PRED_3'] = nn_3.predict(tmp[In_Columns], batch_size = 20000) \n",
        "      gc.collect()\n",
        "      tmp['NN_PRED'] = np.where(tmp['meter'] == 0, tmp['NN_PRED_0'], tmp['NN_PRED'])\n",
        "      tmp['NN_PRED'] = np.where(tmp['meter'] == 1, tmp['NN_PRED_1'], tmp['NN_PRED'])\n",
        "      tmp['NN_PRED'] = np.where(tmp['meter'] == 2, tmp['NN_PRED_2'], tmp['NN_PRED'])\n",
        "      tmp['NN_PRED'] = np.where(tmp['meter'] == 3, tmp['NN_PRED_3'], tmp['NN_PRED'])\n",
        "      gc.collect()\n",
        "      #print('спрогнозили')\n",
        "      #df_test[i*step: (i+1)*step]['NN_PRED'] = pd.merge(df_test, tmp[['row_id','NN_PRED']], how = 'left', on = ['row_id'])\n",
        "      #df_test.loc[i*step: (i+1)*step, 'NN_PRED'] = tmp['NN_PRED']\n",
        "      \n",
        "      if i==0:\n",
        "        a = tmp[['row_id','NN_PRED', 'meter']].copy()\n",
        "      else:\n",
        "        a = pd.concat([a, tmp[['row_id','NN_PRED', 'meter']].copy()], sort=False)\n",
        "      #del tmp\n",
        "      #gc.collect() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtxkAc9E00Yn",
        "colab_type": "code",
        "outputId": "b24d653f-2b43-4e9e-f552-1b83bd137906",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(df_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "41697600\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXmjfkrQC61e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a['row_id']         = a['row_id'].astype('Int32')\n",
        "a['meter_reading']  = a['NN_PRED'].astype('float32')\n",
        "a[['row_id', 'meter_reading']].to_csv(DIR_SAVE+'OUT_Ver0.31 no clean_6.csv', index = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pSaG8s-5_yL",
        "colab_type": "code",
        "outputId": "fda74d3e-c62c-4e60-b53b-7bf051fbc54c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "a.head(-1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>row_id</th>\n",
              "      <th>NN_PRED</th>\n",
              "      <th>meter</th>\n",
              "      <th>meter_reading</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>252.3435</td>\n",
              "      <td>0</td>\n",
              "      <td>252.3435</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>138.7939</td>\n",
              "      <td>0</td>\n",
              "      <td>138.7939</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>21.5660</td>\n",
              "      <td>0</td>\n",
              "      <td>21.5660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>346.3572</td>\n",
              "      <td>0</td>\n",
              "      <td>346.3572</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>962.0777</td>\n",
              "      <td>0</td>\n",
              "      <td>962.0777</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41697594</th>\n",
              "      <td>41697594</td>\n",
              "      <td>115.1817</td>\n",
              "      <td>0</td>\n",
              "      <td>115.1817</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41697595</th>\n",
              "      <td>41697595</td>\n",
              "      <td>25.0976</td>\n",
              "      <td>0</td>\n",
              "      <td>25.0976</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41697596</th>\n",
              "      <td>41697596</td>\n",
              "      <td>24.4483</td>\n",
              "      <td>0</td>\n",
              "      <td>24.4483</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41697597</th>\n",
              "      <td>41697597</td>\n",
              "      <td>20.8425</td>\n",
              "      <td>0</td>\n",
              "      <td>20.8425</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41697598</th>\n",
              "      <td>41697598</td>\n",
              "      <td>170.9884</td>\n",
              "      <td>0</td>\n",
              "      <td>170.9884</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>41697599 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            row_id  NN_PRED  meter  meter_reading\n",
              "0                0 252.3435      0       252.3435\n",
              "1                1 138.7939      0       138.7939\n",
              "2                2  21.5660      0        21.5660\n",
              "3                3 346.3572      0       346.3572\n",
              "4                4 962.0777      0       962.0777\n",
              "...            ...      ...    ...            ...\n",
              "41697594  41697594 115.1817      0       115.1817\n",
              "41697595  41697595  25.0976      0        25.0976\n",
              "41697596  41697596  24.4483      0        24.4483\n",
              "41697597  41697597  20.8425      0        20.8425\n",
              "41697598  41697598 170.9884      0       170.9884\n",
              "\n",
              "[41697599 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZW2CAz9u1yg0",
        "colab_type": "code",
        "outputId": "51c0f5a2-3df5-4a2e-a88a-95bc3ebc395a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "a.groupby(['meter'])['NN_PRED'].agg(['mean','median', 'min', 'max'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean</th>\n",
              "      <th>median</th>\n",
              "      <th>min</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>meter</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>159.116</td>\n",
              "      <td>68.534</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1355.983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>352.780</td>\n",
              "      <td>116.053</td>\n",
              "      <td>0.000</td>\n",
              "      <td>2035.047</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>12714.100</td>\n",
              "      <td>237.592</td>\n",
              "      <td>0.000</td>\n",
              "      <td>17835566.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>219.173</td>\n",
              "      <td>32.681</td>\n",
              "      <td>0.000</td>\n",
              "      <td>32506.373</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           mean  median   min          max\n",
              "meter                                     \n",
              "0       159.116  68.534 0.000     1355.983\n",
              "1       352.780 116.053 0.000     2035.047\n",
              "2     12714.100 237.592 0.000 17835566.000\n",
              "3       219.173  32.681 0.000    32506.373"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAlQJtbx36Az",
        "colab_type": "code",
        "outputId": "a90a7cd1-7a6e-440b-aa7f-8688118dc5cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df.groupby(['meter'])['meter_reading'].agg(['mean','median', 'min', 'max'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean</th>\n",
              "      <th>median</th>\n",
              "      <th>min</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>meter</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>162.707</td>\n",
              "      <td>68.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>79769.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>633.801</td>\n",
              "      <td>120.698</td>\n",
              "      <td>0.000</td>\n",
              "      <td>880374.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>14402.644</td>\n",
              "      <td>253.150</td>\n",
              "      <td>0.000</td>\n",
              "      <td>21904700.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>374.154</td>\n",
              "      <td>38.099</td>\n",
              "      <td>0.000</td>\n",
              "      <td>160187.000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           mean  median   min          max\n",
              "meter                                     \n",
              "0       162.707  68.000 0.000    79769.000\n",
              "1       633.801 120.698 0.000   880374.000\n",
              "2     14402.644 253.150 0.000 21904700.000\n",
              "3       374.154  38.099 0.000   160187.000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NFKqWrr7nz7",
        "colab_type": "code",
        "outputId": "24454c2c-8344-4adf-cb1c-47dd0452049c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df.groupby(['meter'])['NN_PRED'].agg(['mean','median', 'min', 'max'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean</th>\n",
              "      <th>median</th>\n",
              "      <th>min</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>meter</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>158.798</td>\n",
              "      <td>74.755</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1289.670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>378.482</td>\n",
              "      <td>138.774</td>\n",
              "      <td>0.000</td>\n",
              "      <td>2033.057</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>11507.809</td>\n",
              "      <td>244.696</td>\n",
              "      <td>0.000</td>\n",
              "      <td>17275218.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>269.547</td>\n",
              "      <td>40.498</td>\n",
              "      <td>0.000</td>\n",
              "      <td>45745.234</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           mean  median   min          max\n",
              "meter                                     \n",
              "0       158.798  74.755 0.000     1289.670\n",
              "1       378.482 138.774 0.000     2033.057\n",
              "2     11507.809 244.696 0.000 17275218.000\n",
              "3       269.547  40.498 0.000    45745.234"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZATVfSA78tqg",
        "colab_type": "code",
        "outputId": "14e02d7f-0af5-4383-a3ae-1a0270317f59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        }
      },
      "source": [
        "df.describe()\n",
        "air_temperature\n",
        "is_holiday\n",
        "cloud_coverage\n",
        "dew_temperature\n",
        "sea_level_pressure\t\n",
        "wind_direction\t\n",
        "wind_speed"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>building_id</th>\n",
              "      <th>meter</th>\n",
              "      <th>meter_reading</th>\n",
              "      <th>hour_cos</th>\n",
              "      <th>hour_sin</th>\n",
              "      <th>weekday_cos</th>\n",
              "      <th>weekday_sin</th>\n",
              "      <th>week_cos</th>\n",
              "      <th>week_sin</th>\n",
              "      <th>meter_reading_prev</th>\n",
              "      <th>is_equal_prev</th>\n",
              "      <th>day</th>\n",
              "      <th>IS_BAD_PRCNT</th>\n",
              "      <th>building_meter_median</th>\n",
              "      <th>building_meter_mean</th>\n",
              "      <th>building_meter_mean_45</th>\n",
              "      <th>hour</th>\n",
              "      <th>building_meter_hour_median</th>\n",
              "      <th>building_meter_hour_mean</th>\n",
              "      <th>k_fact_med_hour</th>\n",
              "      <th>weekday</th>\n",
              "      <th>building_meter_weekday_median</th>\n",
              "      <th>is_holiday</th>\n",
              "      <th>site_id</th>\n",
              "      <th>square_feet</th>\n",
              "      <th>year_built</th>\n",
              "      <th>floor_count</th>\n",
              "      <th>primary_use_ID</th>\n",
              "      <th>air_temperature</th>\n",
              "      <th>cloud_coverage</th>\n",
              "      <th>dew_temperature</th>\n",
              "      <th>precip_depth_1_hr</th>\n",
              "      <th>sea_level_pressure</th>\n",
              "      <th>wind_direction</th>\n",
              "      <th>wind_speed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>18948184.000</td>\n",
              "      <td>18948184.000</td>\n",
              "      <td>18948184.000</td>\n",
              "      <td>18948184.000</td>\n",
              "      <td>18948184.000</td>\n",
              "      <td>18948184.000</td>\n",
              "      <td>18948184.000</td>\n",
              "      <td>18948184.000</td>\n",
              "      <td>18948184.000</td>\n",
              "      <td>18948183.000</td>\n",
              "      <td>18948184.000</td>\n",
              "      <td>18948184.000</td>\n",
              "      <td>18948184.000</td>\n",
              "      <td>18948184.000</td>\n",
              "      <td>18948184.000</td>\n",
              "      <td>18293583.000</td>\n",
              "      <td>18948184.000</td>\n",
              "      <td>18948184.000</td>\n",
              "      <td>18948184.000</td>\n",
              "      <td>18948184.000</td>\n",
              "      <td>18948184.000</td>\n",
              "      <td>18948184.000</td>\n",
              "      <td>18948184.000</td>\n",
              "      <td>18948184.000</td>\n",
              "      <td>18948184.000</td>\n",
              "      <td>6974756.000</td>\n",
              "      <td>2358476.000</td>\n",
              "      <td>18948184.000</td>\n",
              "      <td>18948184.000</td>\n",
              "      <td>18948184.000</td>\n",
              "      <td>18948184.000</td>\n",
              "      <td>18078918.000</td>\n",
              "      <td>18948184.000</td>\n",
              "      <td>18948184.000</td>\n",
              "      <td>18948184.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>801.974</td>\n",
              "      <td>0.676</td>\n",
              "      <td>2232.996</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.472</td>\n",
              "      <td>0.498</td>\n",
              "      <td>0.488</td>\n",
              "      <td>0.493</td>\n",
              "      <td>2232.996</td>\n",
              "      <td>0.161</td>\n",
              "      <td>185.601</td>\n",
              "      <td>0.161</td>\n",
              "      <td>0.001</td>\n",
              "      <td>2232.996</td>\n",
              "      <td>2575.451</td>\n",
              "      <td>11.502</td>\n",
              "      <td>0.001</td>\n",
              "      <td>2232.996</td>\n",
              "      <td>23368.884</td>\n",
              "      <td>3.007</td>\n",
              "      <td>0.009</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.541</td>\n",
              "      <td>0.121</td>\n",
              "      <td>1969.248</td>\n",
              "      <td>4.052</td>\n",
              "      <td>0.220</td>\n",
              "      <td>0.595</td>\n",
              "      <td>0.316</td>\n",
              "      <td>0.685</td>\n",
              "      <td>0.984</td>\n",
              "      <td>0.620</td>\n",
              "      <td>0.470</td>\n",
              "      <td>0.175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>440.083</td>\n",
              "      <td>0.934</td>\n",
              "      <td>158278.578</td>\n",
              "      <td>0.354</td>\n",
              "      <td>0.354</td>\n",
              "      <td>0.372</td>\n",
              "      <td>0.363</td>\n",
              "      <td>0.352</td>\n",
              "      <td>0.355</td>\n",
              "      <td>158278.582</td>\n",
              "      <td>0.367</td>\n",
              "      <td>105.237</td>\n",
              "      <td>0.314</td>\n",
              "      <td>0.022</td>\n",
              "      <td>82117.057</td>\n",
              "      <td>85395.660</td>\n",
              "      <td>6.922</td>\n",
              "      <td>0.024</td>\n",
              "      <td>82265.539</td>\n",
              "      <td>1023290.661</td>\n",
              "      <td>1.997</td>\n",
              "      <td>0.039</td>\n",
              "      <td>0.034</td>\n",
              "      <td>0.348</td>\n",
              "      <td>0.127</td>\n",
              "      <td>31.279</td>\n",
              "      <td>3.071</td>\n",
              "      <td>0.231</td>\n",
              "      <td>0.144</td>\n",
              "      <td>0.306</td>\n",
              "      <td>0.178</td>\n",
              "      <td>7.683</td>\n",
              "      <td>0.091</td>\n",
              "      <td>0.314</td>\n",
              "      <td>0.118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1900.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>357.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>20.707</td>\n",
              "      <td>0.146</td>\n",
              "      <td>0.146</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.099</td>\n",
              "      <td>0.140</td>\n",
              "      <td>0.131</td>\n",
              "      <td>20.707</td>\n",
              "      <td>0.000</td>\n",
              "      <td>97.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>38.634</td>\n",
              "      <td>47.025</td>\n",
              "      <td>6.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>35.973</td>\n",
              "      <td>1.083</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.200</td>\n",
              "      <td>0.038</td>\n",
              "      <td>1951.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.497</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.548</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.563</td>\n",
              "      <td>0.194</td>\n",
              "      <td>0.111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>918.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>83.000</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.357</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.455</td>\n",
              "      <td>0.470</td>\n",
              "      <td>83.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>186.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>109.848</td>\n",
              "      <td>127.470</td>\n",
              "      <td>12.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>107.921</td>\n",
              "      <td>1.274</td>\n",
              "      <td>3.000</td>\n",
              "      <td>0.002</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.600</td>\n",
              "      <td>0.083</td>\n",
              "      <td>1970.000</td>\n",
              "      <td>4.000</td>\n",
              "      <td>0.200</td>\n",
              "      <td>0.606</td>\n",
              "      <td>0.222</td>\n",
              "      <td>0.702</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.620</td>\n",
              "      <td>0.472</td>\n",
              "      <td>0.163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1200.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>272.860</td>\n",
              "      <td>0.854</td>\n",
              "      <td>0.854</td>\n",
              "      <td>0.802</td>\n",
              "      <td>0.901</td>\n",
              "      <td>0.837</td>\n",
              "      <td>0.848</td>\n",
              "      <td>272.860</td>\n",
              "      <td>0.000</td>\n",
              "      <td>277.000</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.001</td>\n",
              "      <td>307.502</td>\n",
              "      <td>358.264</td>\n",
              "      <td>18.000</td>\n",
              "      <td>0.001</td>\n",
              "      <td>305.962</td>\n",
              "      <td>1.978</td>\n",
              "      <td>5.000</td>\n",
              "      <td>0.006</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.867</td>\n",
              "      <td>0.157</td>\n",
              "      <td>1999.000</td>\n",
              "      <td>6.000</td>\n",
              "      <td>0.400</td>\n",
              "      <td>0.700</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.827</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.675</td>\n",
              "      <td>0.750</td>\n",
              "      <td>0.242</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1448.000</td>\n",
              "      <td>3.000</td>\n",
              "      <td>21904700.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>21904700.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>366.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>3813882.148</td>\n",
              "      <td>3866686.396</td>\n",
              "      <td>23.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>4138801.770</td>\n",
              "      <td>57329462.143</td>\n",
              "      <td>6.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>2017.000</td>\n",
              "      <td>16.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>343.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       building_id        meter  meter_reading     hour_cos     hour_sin  weekday_cos  \\\n",
              "count 18948184.000 18948184.000   18948184.000 18948184.000 18948184.000 18948184.000   \n",
              "mean       801.974        0.676       2232.996        0.500        0.500        0.472   \n",
              "std        440.083        0.934     158278.578        0.354        0.354        0.372   \n",
              "min          0.000        0.000          0.000        0.000        0.000        0.000   \n",
              "25%        357.000        0.000         20.707        0.146        0.146        0.000   \n",
              "50%        918.000        0.000         83.000        0.500        0.500        0.357   \n",
              "75%       1200.000        1.000        272.860        0.854        0.854        0.802   \n",
              "max       1448.000        3.000   21904700.000        1.000        1.000        1.000   \n",
              "\n",
              "       weekday_sin     week_cos     week_sin  meter_reading_prev  is_equal_prev          day  \\\n",
              "count 18948184.000 18948184.000 18948184.000        18948183.000   18948184.000 18948184.000   \n",
              "mean         0.498        0.488        0.493            2232.996          0.161      185.601   \n",
              "std          0.363        0.352        0.355          158278.582          0.367      105.237   \n",
              "min          0.000        0.000        0.000               0.000          0.000        1.000   \n",
              "25%          0.099        0.140        0.131              20.707          0.000       97.000   \n",
              "50%          0.500        0.455        0.470              83.000          0.000      186.000   \n",
              "75%          0.901        0.837        0.848             272.860          0.000      277.000   \n",
              "max          1.000        1.000        1.000        21904700.000          1.000      366.000   \n",
              "\n",
              "       IS_BAD_PRCNT  building_meter_median  building_meter_mean  building_meter_mean_45  \\\n",
              "count  18948184.000           18948184.000         18948184.000            18293583.000   \n",
              "mean          0.161                  0.001             2232.996                2575.451   \n",
              "std           0.314                  0.022            82117.057               85395.660   \n",
              "min           0.000                  0.000                0.000                   0.000   \n",
              "25%           0.000                  0.000               38.634                  47.025   \n",
              "50%           0.000                  0.000              109.848                 127.470   \n",
              "75%           0.125                  0.001              307.502                 358.264   \n",
              "max           1.000                  1.000          3813882.148             3866686.396   \n",
              "\n",
              "              hour  building_meter_hour_median  building_meter_hour_mean  k_fact_med_hour  \\\n",
              "count 18948184.000                18948184.000              18948184.000     18948184.000   \n",
              "mean        11.502                       0.001                  2232.996        23368.884   \n",
              "std          6.922                       0.024                 82265.539      1023290.661   \n",
              "min          0.000                       0.000                     0.000            1.000   \n",
              "25%          6.000                       0.000                    35.973            1.083   \n",
              "50%         12.000                       0.000                   107.921            1.274   \n",
              "75%         18.000                       0.001                   305.962            1.978   \n",
              "max         23.000                       1.000               4138801.770     57329462.143   \n",
              "\n",
              "           weekday  building_meter_weekday_median   is_holiday      site_id  square_feet  \\\n",
              "count 18948184.000                   18948184.000 18948184.000 18948184.000 18948184.000   \n",
              "mean         3.007                          0.009        0.001        0.541        0.121   \n",
              "std          1.997                          0.039        0.034        0.348        0.127   \n",
              "min          0.000                          0.000        0.000        0.000        0.000   \n",
              "25%          1.000                          0.001        0.000        0.200        0.038   \n",
              "50%          3.000                          0.002        0.000        0.600        0.083   \n",
              "75%          5.000                          0.006        0.000        0.867        0.157   \n",
              "max          6.000                          1.000        1.000        1.000        1.000   \n",
              "\n",
              "       year_built  floor_count  primary_use_ID  air_temperature  cloud_coverage  dew_temperature  \\\n",
              "count 6974756.000  2358476.000    18948184.000     18948184.000    18948184.000     18948184.000   \n",
              "mean     1969.248        4.052           0.220            0.595           0.316            0.685   \n",
              "std        31.279        3.071           0.231            0.144           0.306            0.178   \n",
              "min      1900.000        1.000           0.000            0.000           0.000            0.000   \n",
              "25%      1951.000        1.000           0.000            0.497           0.000            0.548   \n",
              "50%      1970.000        4.000           0.200            0.606           0.222            0.702   \n",
              "75%      1999.000        6.000           0.400            0.700           0.500            0.827   \n",
              "max      2017.000       16.000           1.000            1.000           1.000            1.000   \n",
              "\n",
              "       precip_depth_1_hr  sea_level_pressure  wind_direction   wind_speed  \n",
              "count       18078918.000        18948184.000    18948184.000 18948184.000  \n",
              "mean               0.984               0.620           0.470        0.175  \n",
              "std                7.683               0.091           0.314        0.118  \n",
              "min               -1.000               0.000           0.000        0.000  \n",
              "25%                0.000               0.563           0.194        0.111  \n",
              "50%                0.000               0.620           0.472        0.163  \n",
              "75%                0.000               0.675           0.750        0.242  \n",
              "max              343.000               1.000           1.000        1.000  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ij-PYo9p8t0g",
        "colab_type": "code",
        "outputId": "c0e63b96-44f5-44a8-ee2a-25f5362b27bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        }
      },
      "source": [
        "df_test.describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>row_id</th>\n",
              "      <th>building_id</th>\n",
              "      <th>meter</th>\n",
              "      <th>hour_cos</th>\n",
              "      <th>hour_sin</th>\n",
              "      <th>weekday_cos</th>\n",
              "      <th>weekday_sin</th>\n",
              "      <th>week_cos</th>\n",
              "      <th>week_sin</th>\n",
              "      <th>building_meter_median</th>\n",
              "      <th>hour</th>\n",
              "      <th>building_meter_hour_median</th>\n",
              "      <th>weekday</th>\n",
              "      <th>building_meter_weekday_median</th>\n",
              "      <th>is_holiday</th>\n",
              "      <th>primary_use_ID</th>\n",
              "      <th>site_id</th>\n",
              "      <th>square_feet</th>\n",
              "      <th>air_temperature</th>\n",
              "      <th>cloud_coverage</th>\n",
              "      <th>dew_temperature</th>\n",
              "      <th>sea_level_pressure</th>\n",
              "      <th>wind_direction</th>\n",
              "      <th>wind_speed</th>\n",
              "      <th>NN_PRED</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>41697600.0000</td>\n",
              "      <td>41697600.0000</td>\n",
              "      <td>41697600.0000</td>\n",
              "      <td>41697600.0000</td>\n",
              "      <td>41697600.0000</td>\n",
              "      <td>41697600.0000</td>\n",
              "      <td>41697600.0000</td>\n",
              "      <td>41697600.0000</td>\n",
              "      <td>41697600.0000</td>\n",
              "      <td>41697600.0000</td>\n",
              "      <td>41697600.0000</td>\n",
              "      <td>41697600.0000</td>\n",
              "      <td>41697600.0000</td>\n",
              "      <td>41697600.0000</td>\n",
              "      <td>41697600.0000</td>\n",
              "      <td>41697600.0000</td>\n",
              "      <td>41697600.0000</td>\n",
              "      <td>41697600.0000</td>\n",
              "      <td>41697600.0000</td>\n",
              "      <td>41697600.0000</td>\n",
              "      <td>41697600.0000</td>\n",
              "      <td>41697600.0000</td>\n",
              "      <td>41697600.0000</td>\n",
              "      <td>41697600.0000</td>\n",
              "      <td>41697600.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>20848799.5000</td>\n",
              "      <td>807.5824</td>\n",
              "      <td>0.6643</td>\n",
              "      <td>0.5000</td>\n",
              "      <td>0.5000</td>\n",
              "      <td>0.4751</td>\n",
              "      <td>0.4995</td>\n",
              "      <td>0.4913</td>\n",
              "      <td>0.5000</td>\n",
              "      <td>0.0013</td>\n",
              "      <td>11.5000</td>\n",
              "      <td>0.0014</td>\n",
              "      <td>3.0000</td>\n",
              "      <td>0.0088</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.2105</td>\n",
              "      <td>0.5391</td>\n",
              "      <td>0.1219</td>\n",
              "      <td>-0.0003</td>\n",
              "      <td>0.1318</td>\n",
              "      <td>12.2029</td>\n",
              "      <td>13.7401</td>\n",
              "      <td>19.5723</td>\n",
              "      <td>0.6340</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>12037060.4366</td>\n",
              "      <td>429.7680</td>\n",
              "      <td>0.9278</td>\n",
              "      <td>0.3536</td>\n",
              "      <td>0.3536</td>\n",
              "      <td>0.3722</td>\n",
              "      <td>0.3625</td>\n",
              "      <td>0.3508</td>\n",
              "      <td>0.3566</td>\n",
              "      <td>0.0215</td>\n",
              "      <td>6.9222</td>\n",
              "      <td>0.0236</td>\n",
              "      <td>2.0034</td>\n",
              "      <td>0.0375</td>\n",
              "      <td>0.0023</td>\n",
              "      <td>0.2301</td>\n",
              "      <td>0.3423</td>\n",
              "      <td>0.1327</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.1338</td>\n",
              "      <td>6.3944</td>\n",
              "      <td>0.0915</td>\n",
              "      <td>9.9943</td>\n",
              "      <td>0.0308</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>-0.0003</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>-10.6000</td>\n",
              "      <td>13.1524</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.5728</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>10424399.7500</td>\n",
              "      <td>404.7500</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.1464</td>\n",
              "      <td>0.1464</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0990</td>\n",
              "      <td>0.1405</td>\n",
              "      <td>0.1516</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>5.7500</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.0005</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2000</td>\n",
              "      <td>0.0365</td>\n",
              "      <td>-0.0003</td>\n",
              "      <td>0.0178</td>\n",
              "      <td>7.6000</td>\n",
              "      <td>13.6999</td>\n",
              "      <td>11.2593</td>\n",
              "      <td>0.6131</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>20848799.5000</td>\n",
              "      <td>900.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.5000</td>\n",
              "      <td>0.5000</td>\n",
              "      <td>0.3569</td>\n",
              "      <td>0.5000</td>\n",
              "      <td>0.5144</td>\n",
              "      <td>0.5000</td>\n",
              "      <td>0.0002</td>\n",
              "      <td>11.5000</td>\n",
              "      <td>0.0002</td>\n",
              "      <td>3.0000</td>\n",
              "      <td>0.0020</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0667</td>\n",
              "      <td>0.6000</td>\n",
              "      <td>0.0823</td>\n",
              "      <td>-0.0003</td>\n",
              "      <td>0.0978</td>\n",
              "      <td>12.4000</td>\n",
              "      <td>13.7472</td>\n",
              "      <td>20.2222</td>\n",
              "      <td>0.6307</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>31273199.2500</td>\n",
              "      <td>1194.2500</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.8536</td>\n",
              "      <td>0.8536</td>\n",
              "      <td>0.8019</td>\n",
              "      <td>0.9010</td>\n",
              "      <td>0.8373</td>\n",
              "      <td>0.8484</td>\n",
              "      <td>0.0006</td>\n",
              "      <td>17.2500</td>\n",
              "      <td>0.0006</td>\n",
              "      <td>5.0000</td>\n",
              "      <td>0.0061</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.8667</td>\n",
              "      <td>0.1579</td>\n",
              "      <td>-0.0003</td>\n",
              "      <td>0.2133</td>\n",
              "      <td>17.0667</td>\n",
              "      <td>13.7922</td>\n",
              "      <td>27.4074</td>\n",
              "      <td>0.6514</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>41697599.0000</td>\n",
              "      <td>1448.0000</td>\n",
              "      <td>3.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.9965</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>23.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>6.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.0667</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>-0.0003</td>\n",
              "      <td>0.6000</td>\n",
              "      <td>26.7000</td>\n",
              "      <td>14.0407</td>\n",
              "      <td>40.0000</td>\n",
              "      <td>0.9689</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             row_id   building_id         meter      hour_cos      hour_sin   weekday_cos  \\\n",
              "count 41697600.0000 41697600.0000 41697600.0000 41697600.0000 41697600.0000 41697600.0000   \n",
              "mean  20848799.5000      807.5824        0.6643        0.5000        0.5000        0.4751   \n",
              "std   12037060.4366      429.7680        0.9278        0.3536        0.3536        0.3722   \n",
              "min          0.0000        0.0000        0.0000        0.0000        0.0000        0.0000   \n",
              "25%   10424399.7500      404.7500        0.0000        0.1464        0.1464        0.0000   \n",
              "50%   20848799.5000      900.0000        0.0000        0.5000        0.5000        0.3569   \n",
              "75%   31273199.2500     1194.2500        1.0000        0.8536        0.8536        0.8019   \n",
              "max   41697599.0000     1448.0000        3.0000        1.0000        1.0000        1.0000   \n",
              "\n",
              "        weekday_sin      week_cos      week_sin  building_meter_median          hour  \\\n",
              "count 41697600.0000 41697600.0000 41697600.0000          41697600.0000 41697600.0000   \n",
              "mean         0.4995        0.4913        0.5000                 0.0013       11.5000   \n",
              "std          0.3625        0.3508        0.3566                 0.0215        6.9222   \n",
              "min          0.0000        0.0000        0.0000                 0.0000        0.0000   \n",
              "25%          0.0990        0.1405        0.1516                 0.0001        5.7500   \n",
              "50%          0.5000        0.5144        0.5000                 0.0002       11.5000   \n",
              "75%          0.9010        0.8373        0.8484                 0.0006       17.2500   \n",
              "max          1.0000        0.9965        1.0000                 1.0000       23.0000   \n",
              "\n",
              "       building_meter_hour_median       weekday  building_meter_weekday_median    is_holiday  \\\n",
              "count               41697600.0000 41697600.0000                  41697600.0000 41697600.0000   \n",
              "mean                       0.0014        3.0000                         0.0088        0.0001   \n",
              "std                        0.0236        2.0034                         0.0375        0.0023   \n",
              "min                        0.0000        0.0000                         0.0000        0.0000   \n",
              "25%                        0.0001        1.0000                         0.0005        0.0000   \n",
              "50%                        0.0002        3.0000                         0.0020        0.0000   \n",
              "75%                        0.0006        5.0000                         0.0061        0.0000   \n",
              "max                        1.0000        6.0000                         1.0000        0.0667   \n",
              "\n",
              "       primary_use_ID       site_id   square_feet  air_temperature  cloud_coverage  \\\n",
              "count   41697600.0000 41697600.0000 41697600.0000    41697600.0000   41697600.0000   \n",
              "mean           0.2105        0.5391        0.1219          -0.0003          0.1318   \n",
              "std            0.2301        0.3423        0.1327           0.0000          0.1338   \n",
              "min            0.0000        0.0000        0.0000          -0.0003          0.0000   \n",
              "25%            0.0000        0.2000        0.0365          -0.0003          0.0178   \n",
              "50%            0.0667        0.6000        0.0823          -0.0003          0.0978   \n",
              "75%            0.4000        0.8667        0.1579          -0.0003          0.2133   \n",
              "max            1.0000        1.0000        1.0000          -0.0003          0.6000   \n",
              "\n",
              "       dew_temperature  sea_level_pressure  wind_direction    wind_speed       NN_PRED  \n",
              "count    41697600.0000       41697600.0000   41697600.0000 41697600.0000 41697600.0000  \n",
              "mean           12.2029             13.7401         19.5723        0.6340        0.0000  \n",
              "std             6.3944              0.0915          9.9943        0.0308        0.0000  \n",
              "min           -10.6000             13.1524          0.0000        0.5728        0.0000  \n",
              "25%             7.6000             13.6999         11.2593        0.6131        0.0000  \n",
              "50%            12.4000             13.7472         20.2222        0.6307        0.0000  \n",
              "75%            17.0667             13.7922         27.4074        0.6514        0.0000  \n",
              "max            26.7000             14.0407         40.0000        0.9689        0.0000  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HcOED4IDv0k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "show_plot(hist) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3y8HyLW1fPvb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvoCZeopmulB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nn = load_model(DIR, 'model_nn')\n",
        "opt = Adam(lr = 0.05)\n",
        "nn.compile(optimizer = opt, loss = mse)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}