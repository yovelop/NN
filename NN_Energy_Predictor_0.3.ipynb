{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of NN Energy Predictor.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yovelop/NN/blob/master/NN_Energy_Predictor_0.3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zO1azhvf_t9_",
        "colab_type": "code",
        "outputId": "6cb7494c-a43c-4201-83a8-f2d15417f258",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "DIR = '/content/drive/My Drive/Colab Notebooks/ENSaver/'\n",
        "#drive.flush_and_unmount()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRgT9oDx_vpi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Импорты\n",
        "  import numpy as np # linear algebra\n",
        "  import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "  import gc\n",
        "\n",
        "  import matplotlib.pyplot as plt\n",
        "  import matplotlib.style\n",
        "  matplotlib.style.use('ggplot')\n",
        "\n",
        "  from sys import getsizeof\n",
        "\n",
        "  import os\n",
        "  for dirname, _, filenames in os.walk(DIR):\n",
        "      for filename in filenames:\n",
        "          print(os.path.join(dirname, filename))\n",
        "\n",
        "  pd.options.mode.chained_assignment = None  # default='warn'\n",
        "  import warnings\n",
        "  pd.set_option('display.max_rows', 500)\n",
        "  pd.set_option('display.max_columns', 500)\n",
        "  pd.set_option('display.width', 100)\n",
        "  warnings.filterwarnings('ignore')\n",
        "  np.set_printoptions(precision = 4, suppress  = True)\n",
        "\n",
        "  def reduce_mem_usage(df):\n",
        "      start_mem_usg = df.memory_usage().sum() / 1024**2 \n",
        "      print(\"Memory usage of properties dataframe is :\",start_mem_usg,\" MB\")\n",
        "      NAlist = [] # Keeps track of columns that have missing values filled in. \n",
        "      for col in df.columns:\n",
        "          if (df[col].dtype != object) &  (df[col].dtype != 'datetime64[ns]'):  # Exclude strings            \n",
        "              # Print current column type\n",
        "              print(\"******************************\")\n",
        "              print(\"Column: \",col)\n",
        "              print(\"dtype before: \",df[col].dtype)            \n",
        "              # make variables for Int, max and min\n",
        "              IsInt = False\n",
        "              mx = df[col].max()\n",
        "              mn = df[col].min()\n",
        "              print(\"min for this col: \",mn)\n",
        "              print(\"max for this col: \",mx)\n",
        "              # Integer does not support NA, therefore, NA needs to be filled\n",
        "              if not np.isfinite(df[col]).all(): \n",
        "                  NAlist.append(col)\n",
        "                  df[col].fillna(mn-1,inplace=True)  \n",
        "                    \n",
        "              # test if column can be converted to an integer\n",
        "              asint = df[col].fillna(0).astype(np.int64)\n",
        "              result = abs(df[col] - asint)\n",
        "              result = result.sum()\n",
        "              if result > -0.01 and result < 0.01:\n",
        "                  IsInt = True            \n",
        "              # Make Integer/unsigned Integer datatypes\n",
        "              if IsInt:\n",
        "                  if mn >= 0:\n",
        "                      if mx < 255:\n",
        "                          df[col] = df[col].astype(np.uint8)\n",
        "                      elif mx < 65535:\n",
        "                          df[col] = df[col].astype(np.uint16)\n",
        "                      elif mx < 4294967295:\n",
        "                          df[col] = df[col].astype(np.uint32)\n",
        "                      else:\n",
        "                          df[col] = df[col].astype(np.uint64)\n",
        "                  else:\n",
        "                      if mn > np.iinfo(np.int8).min and mx < np.iinfo(np.int8).max:\n",
        "                          df[col] = df[col].astype(np.int8)\n",
        "                      elif mn > np.iinfo(np.int16).min and mx < np.iinfo(np.int16).max:\n",
        "                          df[col] = df[col].astype(np.int16)\n",
        "                      elif mn > np.iinfo(np.int32).min and mx < np.iinfo(np.int32).max:\n",
        "                          df[col] = df[col].astype(np.int32)\n",
        "                      elif mn > np.iinfo(np.int64).min and mx < np.iinfo(np.int64).max:\n",
        "                          df[col] = df[col].astype(np.int64)    \n",
        "              # Make float datatypes 32 bit\n",
        "              else:\n",
        "                  df[col] = df[col].astype(np.float32)\n",
        "              \n",
        "              # Print new column type\n",
        "              print(\"dtype after: \",df[col].dtype)\n",
        "              print(\"******************************\")\n",
        "      # Print final result\n",
        "      print(\"___MEMORY USAGE AFTER COMPLETION:___\")\n",
        "      mem_usg = df.memory_usage().sum() / 1024**2 \n",
        "      print(\"Memory usage is: \",mem_usg,\" MB\")\n",
        "      print(\"This is \",100*mem_usg/start_mem_usg,\"% of the initial size\")\n",
        "      return df, NAlist\n",
        "\n",
        "  def show_plot(hist):\n",
        "    plt.plot(hist.history['loss'])\n",
        "    plt.plot(hist.history['val_loss'])\n",
        "    plt.title('Model NN')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend(['Train','Val'])\n",
        "    plt.show()\n",
        "    \n",
        "    plt.plot(hist.history['loss'])\n",
        "    plt.plot(hist.history['val_loss'])\n",
        "    plt.title('Model NN')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.ylim([1,2])\n",
        "    plt.legend(['Train','Val'])\n",
        "    plt.show()\n",
        "\n",
        "    plt.plot(hist.history['loss'])\n",
        "    plt.plot(hist.history['val_loss'])\n",
        "    plt.title('Model NN')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.ylim([0,1])\n",
        "    plt.legend(['Train','Val'])\n",
        "    plt.show()\n",
        "\n",
        "  #Импорты Керас:\n",
        "  from keras.models import Sequential, load_model\n",
        "\n",
        "  from keras.layers import Dense\n",
        "  from keras.initializers import TruncatedNormal, Constant\n",
        "  from keras.regularizers import l1,l2,l1_l2\n",
        "  from keras.optimizers import Adam\n",
        "  import keras.backend as K\n",
        "\n",
        "  from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "  #from keras.utils import plot_model\n",
        "  from keras.losses import mean_squared_error as mse #, mean_absolute_percentage_error as mape\n",
        "\n",
        "  def RMSLE(y_true, y_pred):\n",
        "    return K.pow( K.mean( K.pow(K.log(y_true+1) - K.log(y_pred+1),2.00000)),0.5000)\n",
        "\n",
        "  def tweedieloss(y_true, y_pred):\n",
        "      return K.mean(  K.pow(    K.pow(backend.maximum(0.000,K.maximum(0.013000,y_true)),0.5)  -   K.pow(K.maximum(0.013000,y_pred),0.5)   , 2 ) / K.pow(K.maximum(0.013000,y_pred),0.5)\n",
        "                  )\n",
        "\n",
        "  def tweedieloss_bkp(y_true, y_pred):\n",
        "      p=1.5\n",
        "      dev = 2 * (K.pow(K.maximum(0.000,y_true), 2-p)/((1-p) * (2-p)) -\n",
        "                    y_true * K.pow(y_pred, 1-p)/(1-p) +\n",
        "                    K.pow(y_pred, 2-p)/(2-p))\n",
        "      return K.mean(dev)\n",
        "\n",
        "  def VAL_ (y_true, y_pred):\n",
        "      return  K.maximum(0.0330000, K.sum(y_pred))/ K.maximum(0.033000, K.sum(y_true)) \n",
        "      \n",
        "  def VAL_2 (y_true, y_pred):\n",
        "      return  K.minimum( 5.000000, K.exp ( K.abs( K.log( VAL_ (y_true, y_pred))))-1)\n",
        "  \n",
        "  def VAL_3 (y_true, y_pred):\n",
        "      return  K.exp ( K.abs( K.log( VAL_ (y_true, y_pred))))-1\n",
        "\n",
        "  def MAPE_ (y_true, y_pred):\n",
        "      return K.mean( K.minimum( 5.000000,  K.abs(y_true - y_pred)/ K.maximum(0.033000, y_true)) )\n",
        "      \n",
        "  def MAE_(y_true, y_pred):\n",
        "      return K.sum( K.abs(y_true - y_pred))/ K.maximum(0.033000, K.sum(y_true))\n",
        "\n",
        "  def MSE_(y_true, y_pred):\n",
        "      return K.sum( K.pow(y_true - y_pred,2.00000))/ K.maximum(0.033000,  K.sum(K.pow(y_true,2.00000)))\n",
        "\n",
        "  def MAE_MAPE(y_true, y_pred):\n",
        "      return (\n",
        "                        MAE_(y_true, y_pred)\n",
        "          +  0.250000 * MAPE_ (y_true, y_pred)\n",
        "      )\n",
        "              \n",
        "  def MAE_VAL_MAPE(y_true, y_pred):\n",
        "      return (\n",
        "                        MAE_(y_true, y_pred)\n",
        "          + 1.800000 *   VAL_2 (y_true, y_pred)          \n",
        "          + 0.950000 *   MAPE_ (y_true, y_pred)\n",
        "          )\n",
        "\n",
        "  def MAE_VAL(y_true, y_pred):\n",
        "      return (\n",
        "                        MAE_(y_true, y_pred)\n",
        "          + 0.800000 *   VAL_2 (y_true, y_pred)                     \n",
        "              )\n",
        "\n",
        "  def MAPE_VAL(y_true, y_pred):\n",
        "      return (\n",
        "                      MAPE_ (y_true, y_pred)\n",
        "          + 0.4000 *  VAL_2 (y_true, y_pred)             \n",
        "              )\n",
        "\n",
        "  def MSE_VAL_MAPE(y_true, y_pred):\n",
        "      return (\n",
        "            5.000000 *   MSE_(y_true, y_pred)\n",
        "          + 2.200000 *   VAL_2 (y_true, y_pred)          \n",
        "          + 0.750000 *   MAPE_ (y_true, y_pred)\n",
        "          )\n",
        "\n",
        "  def MASPE_VAL(y_true, y_pred):\n",
        "      return (\n",
        "                        MAE_(y_true, y_pred)               \n",
        "          + 0.500000 *   MSE_(y_true, y_pred)\n",
        "          + 1.200000 *   VAL_2 (y_true, y_pred)          \n",
        "          + 0.250000 *   MAPE_ (y_true, y_pred)\n",
        "          )\n",
        "  \n",
        "  def MAE_RMSLE(y_true, y_pred):\n",
        "      return (\n",
        "            1.000000 *   MAE_   (y_true, y_pred)\n",
        "          + 2.000000 *   RMSLE  (y_true, y_pred)          \n",
        "          )  \n",
        "\n",
        "  def MAPE_RMSLE(y_true, y_pred):\n",
        "      return (\n",
        "            1.000000 *   MAPE_   (y_true, y_pred)\n",
        "          + 0.100000 *   RMSLE  (y_true, y_pred)          \n",
        "          )  \n",
        "  \n",
        "  def MAPE_VAL_RMSLE(y_true, y_pred):\n",
        "      return (\n",
        "            1.000000 *   MAPE_   (y_true, y_pred)\n",
        "          + 1.000000 *   RMSLE   (y_true, y_pred)    \n",
        "          + 1.000000 *   VAL_2   (y_true, y_pred)      \n",
        "          )  \n",
        " \n",
        "  import keras.metrics\n",
        "  keras.metrics.MAE_ = MAE_\n",
        "  keras.metrics.VAL_ = VAL_\n",
        "  keras.metrics.VAL_2 = VAL_2\n",
        "  keras.metrics.MAPE_ = MAPE_\n",
        "  keras.metrics.MSE_ = MSE_\n",
        "  keras.metrics.tweedieloss = tweedieloss\n",
        "  keras.metrics.MAE_RMSLE = MAE_RMSLE\n",
        "  keras.metrics.MAPE_RMSLE = MAPE_RMSLE\n",
        "  keras.metrics.MAPE_VAL_RMSLE = MAPE_VAL_RMSLE\n",
        "  keras.metrics.RMSLE = RMSLE\n",
        "\n",
        "  import keras.losses\n",
        "  keras.losses.MAE_VAL_MAPE = MAE_VAL_MAPE\n",
        "  keras.losses.MSE_VAL_MAPE = MSE_VAL_MAPE\n",
        "  keras.losses.MAE_ = MAE_\n",
        "  keras.losses.MASPE_VAL = MASPE_VAL\n",
        "  keras.losses.tweedieloss = tweedieloss\n",
        "  keras.losses.MAE_RMSLE = MAE_RMSLE\n",
        "  keras.losses.MAPE_RMSLE = MAPE_RMSLE\n",
        "  keras.losses.MAPE_VAL_RMSLE = MAPE_VAL_RMSLE\n",
        "  keras.losses.RMSLE = RMSLE\n",
        "\n",
        "  class MyCustomCallback(keras.callbacks.Callback):\n",
        "    \n",
        "    def __init__(self, epochs, stats_print_step): \n",
        "        \n",
        "        self.__epochs = epochs\n",
        "        self.__stats_print_step = stats_print_step\n",
        "    \n",
        "    def on_train_begin(self, logs={}):\n",
        "        pass\n",
        "        #print('on_train_begin', logs)\n",
        " \n",
        "    def on_train_end(self, logs={}):\n",
        "        pass\n",
        "        #print('on_train_end', logs)\n",
        " \n",
        "    def on_epoch_begin(self, epoch, logs={}):\n",
        "        pass\n",
        " \n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if ((epoch < 5) or (epoch % self.__stats_print_step == 0)) :\n",
        "            print('# ' + str('{:04d}'.format(epoch + 1)) + ' | ' + self.get_stats_by_epoch(logs))\n",
        "        if epoch == 2:\n",
        "            print('.......')\n",
        "        if epoch == self.__epochs - 1:\n",
        "            print('# ' + str('{:04d}'.format(epoch + 1)) + ' | ' + self.get_stats_by_epoch(logs))\n",
        "        else:\n",
        "            print('# ' + str('{:04d}'.format(epoch + 1)) + ' | ' + self.get_stats_by_epoch(logs), end=\"\\r\")\n",
        " \n",
        "    def on_batch_begin(self, batch, logs={}):\n",
        "        pass\n",
        "        #print('on_batch_begin', batch, logs)\n",
        " \n",
        "    def on_batch_end(self, batch, logs={}):\n",
        "        pass\n",
        "        #print('on_batch_end', batch, logs)\n",
        "\n",
        "    def get_stats_by_epoch(self, logs):\n",
        "        \n",
        "        is_test = True\n",
        "        s = ''\n",
        "        \n",
        "        for key, value in logs.items(): \n",
        "            if is_test:\n",
        "                if 'val_' not in str(key):\n",
        "                    s += ' /// '\n",
        "                    is_test = False\n",
        "            if is_test:\n",
        "                s += ' ' + str(key).replace('val_', 'TST_') + ': ' + \"{0:.4f}\".format(value)\n",
        "            else:\n",
        "                s += ' ' + 'TRN_' + str(key) + ': ' + \"{0:.4f}\".format(value)\n",
        "\n",
        "        return s #'val_loss: ' + \"{0:.4f}\".format(logs['val_loss']) + ' | loss: ' + \"{0:.4f}\".format(logs['loss'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQppkzTWUjLm",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Fv4ErMY_vsQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#0: electricity, 1: chilledwater, 2: steam, 3: hotwater\n",
        "#  Подготовка данных\n",
        "  df = pd.read_csv(DIR + \"train.csv\", engine = 'python')\n",
        "  #df_test = pd.read_csv(DIR + \"test.csv\", engine = 'python')\n",
        "\n",
        "  df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
        "  #df_test['timestamp'] = pd.to_datetime(df_test['timestamp'])\n",
        "\n",
        "  #Очистка от корявых данных\n",
        "  #df = df.query('not (building_id <= 104 & meter == 0 & timestamp <= \"2016-05-20\")')\n",
        "\n",
        "  #df['meter_reading'] = np.log1p(df['meter_reading'])\n",
        "\n",
        "  #df = pd.concat([df_train, df_test], sort=False)\n",
        "\n",
        "  df['hour_cos'] = np.cos(df['timestamp'].dt.hour * 2 * np.pi / 24)\n",
        "  df['hour_sin'] = np.sin(df['timestamp'].dt.hour * 2 * np.pi / 24)\n",
        "\n",
        "  df['weekday_cos'] = np.cos(df['timestamp'].dt.weekday * 2 * np.pi / 7)\n",
        "  df['weekday_sin'] = np.sin(df['timestamp'].dt.weekday * 2 * np.pi / 7)\n",
        "\n",
        "  df['week_cos'] = np.cos(df['timestamp'].dt.week * 2 * np.pi / 53)\n",
        "  df['week_sin'] = np.sin(df['timestamp'].dt.week * 2 * np.pi / 53)\n",
        "\n",
        "  #df_train['weekends'] = (df_train['weekday'] >= 6) * 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3xRu7Y_2MP5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Очистка от подозрительных нулей\n",
        "  #print(df[df['building_id']==2][['timestamp','meter_reading','meter','ds_zero','de_zero','is_bad_zero']].head(20))\n",
        "  df = df.sort_values(by = ['meter','building_id','timestamp'])\n",
        "  df['meter_reading_prev'] = 0\n",
        "\n",
        "  #for bid in df['building_id'].unique():\n",
        "  #  for met in df['meter'].unique():\n",
        "  df['meter_reading_prev'] = df['meter_reading'].shift()\n",
        "  df['is_equal_prev']= (df['meter_reading_prev'] == df['meter_reading'] )*1\n",
        "\n",
        "  df['day'] = df['timestamp'].dt.dayofyear\n",
        "  df_bad_rows = df.groupby(by=['building_id','day','meter'], as_index = False)['is_equal_prev'].mean()\n",
        "  df_bad_rows.rename({\"is_equal_prev\": \"IS_BAD_PRCNT\"}, axis='columns', inplace=True)\n",
        "\n",
        "  df = pd.merge(df, df_bad_rows, how = 'inner', on = ['building_id','day','meter'])\n",
        "  #print(df_bad_rows[df_bad_rows['building_id']==109].head(365))\n",
        "  del df_bad_rows \n",
        "\n",
        "  #print(df[df['building_id']==2][['timestamp','meter_reading','is_equal_prev','IS_BAD_PRCNT','day']].head(30))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g52hlFMS2cpu",
        "colab_type": "code",
        "outputId": "c0ec2e81-a17e-4c67-e564-47a239dfcac1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Добавление медианы по метрике постройки\n",
        "  df_median = df.groupby(by=['building_id','meter'])['meter_reading'].median()\n",
        "  df_median.name = 'building_meter_median'\n",
        "  df = pd.merge(df, df_median, how = 'inner', on = ['building_id','meter'])\n",
        "  del df_median \n",
        "# Добавление медианы по часу, по неделе, метрике постройки\n",
        "  df['hour'] = df['timestamp'].dt.hour\n",
        "  df_median = df.groupby(by=['building_id','hour','meter'])['meter_reading'].median()\n",
        "  df_median.name = 'building_meter_hour_median'\n",
        "  df = pd.merge(df, df_median, how = 'inner', on = ['building_id','hour','meter'])\n",
        "  del df_median \n",
        "\n",
        "  df['weekday'] = df['timestamp'].dt.weekday\n",
        "  df_median = df.groupby(by=['building_id','weekday','meter'])['meter_reading'].median()\n",
        "  df_median.name = 'building_meter_weekday_median'\n",
        "  df = pd.merge(df, df_median, how = 'inner', on = ['building_id','weekday','meter'])\n",
        "  del df_median \n",
        "\n",
        "  holidays = [\"2016-01-01\", \"2016-01-18\", \"2016-02-15\", \"2016-05-30\", \"2016-07-04\",\n",
        "                    \"2016-09-05\", \"2016-10-10\", \"2016-11-11\", \"2016-11-24\", \"2016-12-26\",\n",
        "                    \"2017-01-02\", \"2017-01-16\", \"2017-02-20\", \"2017-05-29\", \"2017-07-04\",\n",
        "                    \"2017-09-04\", \"2017-10-09\", \"2017-11-10\", \"2017-11-23\", \"2017-12-25\",\n",
        "                    \"2018-01-01\", \"2018-01-15\", \"2018-02-19\", \"2018-05-28\", \"2018-07-04\",\n",
        "                    \"2018-09-03\", \"2018-10-08\", \"2018-11-12\", \"2018-11-22\", \"2018-12-25\",\n",
        "                    \"2019-01-01\"]\n",
        "  df[\"is_holiday\"] = (df.timestamp.isin(holidays)).astype(int)\n",
        "  del holidays\n",
        "#Подстановка параметров сооружения\n",
        "  building_df = pd.read_csv(DIR + \"building_metadata.csv\", engine = 'python')\n",
        "  from sklearn.preprocessing import LabelEncoder\n",
        "  le = LabelEncoder()\n",
        "  building_df[\"primary_use_ID\"] = le.fit_transform(building_df[\"primary_use\"])\n",
        "\n",
        "  #building_df['primary_use'] = building_df['primary_use'].astype('category')\n",
        "  #building_df = pd.get_dummies(building_df)\n",
        "\n",
        "  df = df.merge(building_df, left_on = \"building_id\", right_on = \"building_id\", how = \"left\")\n",
        "  df.head(5)\n",
        "  del building_df\n",
        "  gc.collect()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIDKj_YCb_bD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Вставка данных погоды\n",
        "#Восстановление пустых данных погоды через соседей по линейной инетрполяции\n",
        "  df_weather = pd.read_csv(DIR + \"weather_train.csv\", engine = 'python')\n",
        "  df_weather['timestamp'] = pd.to_datetime(df_weather['timestamp'])\n",
        "\n",
        "  #weather_train.groupby('site_id').apply(lambda group: group.isna().sum())\n",
        "  df_times = df.drop_duplicates(['site_id','timestamp'])[['site_id','timestamp']]\n",
        "  df_times = pd.merge(df_times, df_weather, how = 'left', on = ['site_id','timestamp'])\n",
        "  df_times = df_times.sort_values(by = ['site_id','timestamp'])\n",
        "  \n",
        "  df_times = df_times.groupby('site_id').apply(lambda group: group.interpolate(limit_direction='both'))\n",
        "  df = pd.merge(df, df_times, how = 'left', on = ['site_id','timestamp'])\n",
        "  #del df_weather"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vojXrtAOc0t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Инфо о корявости данных:\n",
        "  print('0 Всего:',df[df['meter']==0].shape, 'Откинуть:', df[(df['meter']==0) & (df['IS_BAD_PRCNT']>0.45)].shape)\n",
        "  print('1 Всего:',df[df['meter']==1].shape, 'Откинуть:', df[(df['meter']==1) & (df['IS_BAD_PRCNT']>0.75)].shape)\n",
        "  print('2 Всего:',df[df['meter']==2].shape, 'Откинуть:', df[(df['meter']==2) & (df['IS_BAD_PRCNT']>0.75)].shape)\n",
        "  print('3 Всего:',df[df['meter']==3].shape, 'Откинуть:', df[(df['meter']==3) & (df['IS_BAD_PRCNT']>0.75)].shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmQtkGKQCueL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# #Вывести кол-во пустот по полям. Затем заполнить из средним значением по полю\n",
        "  #   for col in df.columns:\n",
        "  #     print(col)\n",
        "  #     for met in df['meter'].unique():\n",
        "  #       if np.sum(df[col].isnull()) > 0:\n",
        "  #         print(met)\n",
        "  #         print(np.sum(df[col].isnull()))\n",
        "\n",
        "  #         df_col = df.groupby(by=['building_id','meter'], as_index = False)[col].mean()\n",
        "  #         df_col.rename({col: \"tmp\"}, axis='columns', inplace=True)\n",
        "  #         df = df.merge(df_col, left_on = ['building_id','meter'], right_on = ['building_id','meter'], how = \"left\")\n",
        "  #         df[col].fillna( df_col['tmp'], inplace = True)\n",
        "  #         df.drop(columns = ['tmp'],inplace = True)\n",
        "  #         del df_col\n",
        "\n",
        "  #         df_col = df.groupby(by=['meter'], as_index = False)[col].mean()\n",
        "  #         df_col.rename({col: \"tmp\"}, axis='columns', inplace=True)\n",
        "  #         df = df.merge(df_col, left_on = ['meter'], right_on = ['meter'], how = \"left\")\n",
        "  #         df[col].fillna( df_col['tmp'], inplace = True)\n",
        "  #         df.drop(columns = ['tmp'],inplace = True)\n",
        "  #         del df_col\n",
        "\n",
        "  #         df[col].fillna( df[col].mean(), inplace = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxPaU99v4PI-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#df.to_feather(DIR + 'DF_TRAIN_EXTENDED2.FTHR')\n",
        "#df = pd.read_feather(DIR + 'DF_TRAIN_EXTENDED2.FTHR')\n",
        "reduce_mem_usage(df)\n",
        "df.to_feather(DIR + 'DF_TRAIN_REDUCED3.FTHR')\n",
        "gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6XbWpxAUnQb",
        "colab_type": "text"
      },
      "source": [
        "  Скорость"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asr3-4DHF_sx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_feather(DIR + 'DF_TRAIN_REDUCED3.FTHR')\n",
        "gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXdw-5dNTYz8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRnpeXMU_vu5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.head(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfToQh4ArZ3R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_Em3Xm6rdeV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Out_Columns = 'meter_reading'\n",
        "In_Columns = [ 'hour_cos','hour_sin', 'weekday_cos', 'weekday_sin', 'week_cos', 'week_sin',\n",
        "       'site_id', 'square_feet',\n",
        "       'primary_use_ID', 'is_holiday',\n",
        "       'air_temperature', 'cloud_coverage',\n",
        "       'dew_temperature', 'sea_level_pressure',\n",
        "       'wind_direction', 'wind_speed',\n",
        "       'building_meter_median','building_meter_hour_median','building_meter_weekday_median',\n",
        "       #КАНДИДАТЫ нА ИСКЛЮЧЕНИЕ:\n",
        "          'year_built', 'floor_count', 'precip_depth_1_hr',\n",
        "          #  'primary_use_Education', 'primary_use_Entertainment/public assembly', 'primary_use_Food sales and service', 'primary_use_Healthcare',\n",
        "          #  'primary_use_Lodging/residential','primary_use_Manufacturing/industrial', 'primary_use_Office',\n",
        "          #  'primary_use_Other', 'primary_use_Parking', 'primary_use_Public services', 'primary_use_Religious worship',\n",
        "          #  'primary_use_Retail', 'primary_use_Services', 'primary_use_Technology/science', 'primary_use_Utility','primary_use_Warehouse/storage',\n",
        "       ]\n",
        "# Нормализация\n",
        "if 1==1:\n",
        "  df.dropna(subset = In_Columns + [Out_Columns], inplace=True)\n",
        "\n",
        "  from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, OneHotEncoder\n",
        "  scaler =  MinMaxScaler (copy=True, feature_range=(0, 1))                                  #quantile_range  = (15.0,85.0)) #Normalizer #(copy=True, feature_range=(-1, 1)) # MinMaxScaler(copy=True, feature_range=(-1, 1)) #StandardScaler() #MinMaxScaler(copy=True, feature_range=(-1, 1)) # RobustScaler()\n",
        "  scaler.fit( df[In_Columns] )\n",
        "  df[In_Columns]     = pd.DataFrame(data = scaler.transform( df[In_Columns])    , columns = df[In_Columns].columns   , index=df.index) \n",
        "  gc.collect()\n",
        "\n",
        "  import pickle\n",
        "  with open(DIR+'scaler3.pickle', 'wb') as handle:\n",
        "    pickle.dump(scaler, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "    pickle.dump(In_Columns, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "    pickle.dump(Out_Columns, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "  \n",
        "  #with open('filename.pickle', 'rb') as handle:\n",
        "  #  b = pickle.load(handle)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WwbRnvu0Vfb",
        "colab_type": "text"
      },
      "source": [
        "**-- -- -- -- -- -- -- -- --РАСЧЁТ НЕЙРОНОК -- -- -- -- -- -- -- -- --**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aup6pDdkDoZZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#0: electricity, 1: chilledwater, 2: steam, 3: hotwater\n",
        "# РАСЧЁТ НЕЙРОНОК:\n",
        "\n",
        "  reg = 0.00001\n",
        "  batch_size = 2048\n",
        "  epochs = 50\n",
        "  meter = 0\n",
        "\n",
        "  earlyStopping = EarlyStopping(monitor='loss', patience=100, verbose=1, mode='min')\n",
        "  reduce_lr_loss = ReduceLROnPlateau(monitor='loss', factor=0.3, patience=5, verbose=1, min_delta=1e-3, mode='min')\n",
        "  model_checkpoint = ModelCheckpoint(monitor='loss', save_best_only=True, filepath = DIR + 'best_nn_' + str(meter) + '.model', save_weights_only = False, verbose=0, mode='min')\n",
        "\n",
        "  init = TruncatedNormal(mean=0.0, stddev=0.05, seed=159)\n",
        "  bias = Constant(value = 1e-3)\n",
        "  \n",
        "  if 0==0:\n",
        "    meter = 0\n",
        "    opt = Adam(lr = 0.009)\n",
        "\n",
        "    nn_0 = Sequential()\n",
        "    nn_0.add(Dense(60, input_shape = df[In_Columns].shape[1:], activation = 'tanh', kernel_regularizer=l1(reg), kernel_initializer = 'normal'))\n",
        "    nn_0.add(Dense(60, activation = 'tanh',  kernel_initializer = 'normal'))\n",
        "    nn_0.add(Dense(1, activation = 'relu', kernel_initializer = 'normal'))\n",
        "\n",
        "    nn_0.compile(optimizer = opt, loss = RMSLE, metrics=[ MAE_, RMSLE, VAL_, 'mse', MAPE_ ])\n",
        "    \n",
        "    val = df[(df['meter']==meter) & (df['day']%6==0)]\n",
        "    hist = nn_0.fit( df[(df['meter']==meter) & (df['IS_BAD_PRCNT']<0.45)][In_Columns], df[(df['meter']==meter) & (df['IS_BAD_PRCNT']<0.45)][Out_Columns], batch_size = batch_size, verbose = 0\n",
        "                    , epochs = epochs, shuffle = True, callbacks=[MyCustomCallback(epochs, 1), earlyStopping, reduce_lr_loss,model_checkpoint]\n",
        "                    , validation_data=(val[In_Columns], val[Out_Columns])\n",
        "                    ) \n",
        "    nn_0.save(DIR + str(meter) + 'HANDLY_SAVED3.MODEL')\n",
        "    gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3l71K063-sz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for lr in [0.007,0.003]:\n",
        "  opt = Adam(lr = lr)\n",
        "  epochs = 15\n",
        "  batch_size = 2048\n",
        "  meter = 0\n",
        "  val = df[(df['meter']==meter) & (df['day']%6==0)]\n",
        "  print('*'*9, lr, '*'*33)\n",
        "  nn_0.compile(optimizer = opt, loss = RMSLE, metrics=[ MAE_, RMSLE, VAL_, 'mse', MAPE_ ])\n",
        "  hist = nn_0.fit( df[(df['meter']==meter) & (df['IS_BAD_PRCNT']<0.25)][In_Columns], df[(df['meter']==meter) & (df['IS_BAD_PRCNT']<0.25)][Out_Columns], batch_size = batch_size, verbose = 0\n",
        "                  , epochs = epochs, shuffle = True, callbacks=[ MyCustomCallback(epochs, 1), earlyStopping, reduce_lr_loss]\n",
        "                  , validation_data=(val[In_Columns], val[Out_Columns])\n",
        "                  ) \n",
        "  nn_0.save(DIR + str(meter) + 'HANDLY_SAVED3.MODEL')\n",
        "  gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mf8-ceMw8N1q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if 1==1:\n",
        "  reg = 0.00001\n",
        "  meter = 1\n",
        "  epochs = 75\n",
        "  batch_size = 512\n",
        "  opt = Adam(lr = 0.007)\n",
        "\n",
        "  earlyStopping = EarlyStopping(monitor='loss', patience=100, verbose=1, mode='min')\n",
        "  reduce_lr_loss = ReduceLROnPlateau(monitor='loss', factor=0.3, patience=5, verbose=1, min_delta=1e-3, mode='min')\n",
        "  model_checkpoint = ModelCheckpoint(monitor='loss', save_best_only=True, filepath = DIR + 'best_nn_' + str(meter) + '.model', save_weights_only = False, verbose=0, mode='min')\n",
        "\n",
        "  nn_1 = Sequential()\n",
        "  nn_1.add(Dense(90, input_shape = df[In_Columns].shape[1:], activation = 'tanh', kernel_regularizer=l1(reg), kernel_initializer = 'normal'))\n",
        "  nn_1.add(Dense(90, activation = 'tanh',  kernel_initializer = 'normal'))\n",
        "  nn_1.add(Dense(90, activation = 'relu',  kernel_initializer = 'normal'))\n",
        "  nn_1.add(Dense(90, activation = 'relu',  kernel_initializer = 'normal'))\n",
        "  nn_1.add(Dense(1, activation = 'relu', kernel_initializer = 'normal'))\n",
        "\n",
        "  nn_1.compile(optimizer = opt, loss = RMSLE, metrics=[ MAE_, RMSLE, VAL_, 'mse', MAPE_ ])\n",
        "  \n",
        "  val = df[(df['meter']==meter) & (df['day']%6==0)]\n",
        "  hist = nn_1.fit( df[(df['meter']==meter) & (df['IS_BAD_PRCNT']<0.45)][In_Columns], df[(df['meter']==meter) & (df['IS_BAD_PRCNT']<0.45)][Out_Columns], batch_size = batch_size, verbose = 0\n",
        "                  , epochs = epochs, shuffle = True, callbacks=[MyCustomCallback(epochs, 1), earlyStopping, reduce_lr_loss,model_checkpoint]\n",
        "                  , validation_data=(val[In_Columns], val[Out_Columns])\n",
        "                  ) \n",
        "  nn_1.save(DIR + str(meter) + 'HANDLY_SAVED3.MODEL')\n",
        "  gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2H75zE193qOf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for lr in [0.007,0.003]:\n",
        "  opt = Adam(lr = lr)\n",
        "  epochs = 25\n",
        "  meter = 1\n",
        "  batch_size = 720\n",
        "  val = df[(df['meter']==meter) & (df['day']%6==0)]\n",
        "  print('*'*9, lr, '*'*33)\n",
        "  nn_1.compile(optimizer = opt, loss = RMSLE, metrics=[ MAE_, RMSLE, VAL_, 'mse', MAPE_ ])\n",
        "  hist = nn_1.fit( df[(df['meter']==meter) & (df['IS_BAD_PRCNT']<0.45)][In_Columns], df[(df['meter']==meter) & (df['IS_BAD_PRCNT']<0.45)][Out_Columns], batch_size = batch_size, verbose = 0\n",
        "                  , epochs = epochs, shuffle = True, callbacks=[ MyCustomCallback(epochs, 1), earlyStopping, reduce_lr_loss]\n",
        "                  , validation_data=(val[In_Columns], val[Out_Columns])\n",
        "                  ) \n",
        "  nn_1.save(DIR + str(meter) + 'HANDLY_SAVED3.MODEL')\n",
        "  gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHKu4TMG8ROI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if 2==2:\n",
        "  reg = 0.000001\n",
        "  meter = 2\n",
        "  epochs = 50\n",
        "  batch_size = 200\n",
        "  opt = Adam(lr = 0.003)\n",
        "\n",
        "  earlyStopping = EarlyStopping(monitor='loss', patience=30, verbose=1, mode='min')\n",
        "  reduce_lr_loss = ReduceLROnPlateau(monitor='loss', factor=0.2, patience=55, verbose=1, min_delta=1e-3, mode='min')\n",
        "  model_checkpoint = ModelCheckpoint(monitor='loss', save_best_only=True, filepath = DIR + 'best_nn_' + str(meter) + '.model', save_weights_only = False, verbose=0, mode='min')\n",
        "\n",
        "  nn_2 = Sequential()\n",
        "  nn_2.add(Dense(90, input_shape = df[In_Columns].shape[1:], activation = 'tanh', kernel_regularizer=l1(reg), kernel_initializer = keras.initializers.RandomUniform(minval=-0.25, maxval=0.25, seed=None), bias_initializer=keras.initializers.Constant(0.1)))\n",
        "  nn_2.add(Dense(90, activation = 'tanh',  kernel_initializer = keras.initializers.RandomUniform(minval=-0.25, maxval=0.25, seed=None), bias_initializer=keras.initializers.Constant(0.1)))\n",
        "  nn_2.add(Dense( 1, activation = 'relu', kernel_initializer = 'normal'))\n",
        "\n",
        "  nn_2.compile(optimizer = opt, loss = RMSLE, metrics=[ MAE_, RMSLE, VAL_, 'mse', MAPE_ ])\n",
        "  \n",
        "  val = df[(df['meter']==meter) & (df['day']%6==0)]\n",
        "  hist = nn_2.fit( df[(df['meter']==meter) & (df['IS_BAD_PRCNT']<0.75)][In_Columns], df[(df['meter']==meter) & (df['IS_BAD_PRCNT']<0.75)][Out_Columns], batch_size = batch_size, verbose = 0\n",
        "                  , epochs = epochs, shuffle = True, callbacks=[MyCustomCallback(epochs, 1), earlyStopping, reduce_lr_loss,model_checkpoint]\n",
        "                  , validation_data=(val[In_Columns], val[Out_Columns])\n",
        "                  ) \n",
        "  nn_2.save(DIR + str(meter) + 'HANDLY_SAVED3.MODEL')\n",
        "  gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PlNOAoppy96",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for lr in [0.007,0.005,0.002,0.001]:\n",
        "  opt = Adam(lr = lr)\n",
        "  epochs = 5\n",
        "  meter = 2\n",
        "  print('*'*9, lr, '*'*33)\n",
        "  val = df[(df['meter']==meter) & (df['day']%6==0)]\n",
        "  nn_2.compile(optimizer = opt, loss = RMSLE, metrics=[ MAE_, RMSLE, VAL_, 'mse', MAPE_ ])\n",
        "  hist = nn_2.fit( df[(df['meter']==meter) & (df['IS_BAD_PRCNT']<0.25)][In_Columns], df[(df['meter']==meter) & (df['IS_BAD_PRCNT']<0.25)][Out_Columns], batch_size = batch_size, verbose = 0\n",
        "                  , epochs = epochs, shuffle = True, callbacks=[ MyCustomCallback(epochs, 1), earlyStopping, reduce_lr_loss]\n",
        "                  , validation_data=(val[In_Columns], val[Out_Columns])\n",
        "                  ) \n",
        "  nn_2.save(DIR + str(meter) + 'HANDLY_SAVED3.MODEL')\n",
        "  gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdad7yTx8Uri",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if 3==3:\n",
        "  meter = 3\n",
        "  epochs = 50\n",
        "  batch_size = 200\n",
        "  opt = Adam(lr = 0.0007)\n",
        "\n",
        "  earlyStopping = EarlyStopping(monitor='loss', patience=50, verbose=1, mode='min')\n",
        "  reduce_lr_loss = ReduceLROnPlateau(monitor='loss', factor=0.2, patience=10, verbose=1, min_delta=1e-3, mode='min')\n",
        "  model_checkpoint = ModelCheckpoint(monitor='loss', save_best_only=True, filepath = DIR + 'best_nn_' + str(meter) + '.model', save_weights_only = False, verbose=0, mode='min')\n",
        "\n",
        "  nn_3 = Sequential()\n",
        "  nn_3.add(Dense(45, input_shape = df[In_Columns].shape[1:], activation = 'relu', kernel_regularizer=l1(reg), kernel_initializer = 'normal', bias_initializer=keras.initializers.Constant(0.1)))\n",
        "  nn_3.add(Dense(45, activation = 'relu',  kernel_initializer = 'normal', bias_initializer=keras.initializers.Constant(0.1)))\n",
        "  nn_3.add(Dense(70, activation = 'relu',  kernel_initializer = 'normal', bias_initializer=keras.initializers.Constant(0.1)))\n",
        "  nn_3.add(Dense(1, activation = 'relu', kernel_initializer = 'normal'))\n",
        "\n",
        "  nn_3.compile(optimizer = opt, loss = RMSLE, metrics=[ MAE_, RMSLE, VAL_, 'mse', MAPE_ ])\n",
        "  \n",
        "  val = df[(df['meter']==meter) & (df['day']%6==0)]\n",
        "  hist = nn_3.fit( df[(df['meter']==meter) & (df['IS_BAD_PRCNT']<0.25)][In_Columns], df[(df['meter']==meter) & (df['IS_BAD_PRCNT']<0.25)][Out_Columns], batch_size = batch_size, verbose = 0\n",
        "                  , epochs = epochs, shuffle = True, callbacks=[MyCustomCallback(epochs, 1), earlyStopping, reduce_lr_loss]\n",
        "                  , validation_data=(val[In_Columns], val[Out_Columns])\n",
        "                  ) \n",
        "  nn_3.save(DIR + str(meter) + 'HANDLY_SAVED03.MODEL')\n",
        "  gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38XziDvm_mhH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for lr in [0.0004,0.0002,0.0007]:\n",
        "  opt = Adam(lr = lr)\n",
        "  epochs = 33\n",
        "  meter = 3\n",
        "  print('*'*9, lr, '*'*33)\n",
        "  val = df[(df['meter']==meter) & (df['day']%6==0)]\n",
        "  nn_3.compile(optimizer = opt, loss = RMSLE, metrics=[ MAE_, RMSLE, VAL_, 'mse', MAPE_ ])\n",
        "  hist = nn_3.fit( df[(df['meter']==meter) & (df['IS_BAD_PRCNT']<0.25)][In_Columns], df[(df['meter']==meter) & (df['IS_BAD_PRCNT']<0.25)][Out_Columns], batch_size = batch_size, verbose = 0\n",
        "                  , epochs = epochs, shuffle = True, callbacks=[ MyCustomCallback(epochs, 1), earlyStopping, reduce_lr_loss]\n",
        "                  , validation_data=(val[In_Columns], val[Out_Columns])\n",
        "                  ) \n",
        "  nn_3.save(DIR + str(meter) + 'HANDLY_SAVED03.MODEL')\n",
        "  gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H75KbUGtAdOG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#nn_3.save(DIR + str(meter) + 'HANDLY_SAVED.MODEL')\n",
        "# keras.initializers.RandomUniform(minval=-0.05, maxval=0.05, seed=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYdF9Mh00i4a",
        "colab_type": "text"
      },
      "source": [
        "-- -- -- -- -- -- -- -- -- Предсказание -- -- -- -- -- -- -- -- --"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQ7txJwCTi6Z",
        "colab_type": "code",
        "outputId": "86d67559-28b1-41cb-925a-ef594ebecb96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "#Предсказание из 4х значений:\n",
        "  nn_0 = keras.models.load_model (DIR + '0HANDLY_SAVED3.MODEL')\n",
        "  nn_1 = keras.models.load_model (DIR + '1HANDLY_SAVED3.MODEL')\n",
        "  nn_2 = keras.models.load_model (DIR + '2HANDLY_SAVED3.MODEL')\n",
        "  nn_3 = keras.models.load_model (DIR + '3HANDLY_SAVED03.MODEL')\n",
        "\n",
        "  # score = model.evaluate(X, Y, verbose=0)\n",
        "  # print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))\n",
        "  gc.collect()\n",
        "\n",
        "  df['NN_PRED'] = 0\n",
        "  df['NN_PRED_0'] = nn_0.predict(df[In_Columns], batch_size = 10000) \n",
        "  df['NN_PRED_1'] = nn_1.predict(df[In_Columns], batch_size = 10000) \n",
        "  df['NN_PRED_2'] = nn_2.predict(df[In_Columns], batch_size = 10000) \n",
        "  df['NN_PRED_3'] = nn_3.predict(df[In_Columns], batch_size = 10000) \n",
        "  df['NN_PRED'] = np.where(df['meter'] == 0, df['NN_PRED_0'], df['NN_PRED'])\n",
        "  df['NN_PRED'] = np.where(df['meter'] == 1, df['NN_PRED_1'], df['NN_PRED'])\n",
        "  df['NN_PRED'] = np.where(df['meter'] == 2, df['NN_PRED_2'], df['NN_PRED'])\n",
        "  df['NN_PRED'] = np.where(df['meter'] == 3, df['NN_PRED_3'], df['NN_PRED'])\n",
        "  df.drop(columns = ['NN_PRED_0', 'NN_PRED_1', 'NN_PRED_2', 'NN_PRED_3'], inplace = True)\n",
        "  #df.drop(columns = ['Value_x', 'Value_y'])\n",
        "  gc.collect()\n",
        "\n",
        "  df['NN_ERR'] = np.abs(df['NN_PRED']-df['meter_reading'])\n",
        "  df['k_NN_ERR'] = (df['NN_PRED']+0.33)/(df['meter_reading']+0.33)\n",
        "\n",
        "  print( 'Ошибка общая: ', np.sqrt( np.mean( np.power(np.log(df['meter_reading']+1) - np.log(df['NN_PRED']+1),2.00000)))\n",
        "      , 'Ошибка (VAL): ', np.sqrt( np.mean( np.power(np.log(df[(df['day']%6 == 0)]['meter_reading']+1) - np.log(df[(df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка (VAL_чист): ' , np.sqrt( np.mean( np.power(np.log(df[  (df['IS_BAD_PRCNT'] < 0.25) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[(df['IS_BAD_PRCNT'] < 0.25) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка (VAL_чист2): ', np.sqrt( np.mean( np.power(np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "  )\n",
        "  print('Ошибка 0: ', np.sqrt( np.mean( np.power(np.log(df[df['meter']==0]['meter_reading']+1) - np.log(df[df['meter']==0]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка 0 (VAL): ', np.sqrt( np.mean( np.power(np.log(df[(df['meter']==0) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[(df['meter']==0) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка 0 (VAL_чист): ' , np.sqrt( np.mean( np.power(np.log(df[  (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==0) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[ (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==0) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка 0 (VAL_чист2): ', np.sqrt( np.mean( np.power(np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==0) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==0) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "  )\n",
        "  print('Ошибка 1: ', np.sqrt( np.mean( np.power(np.log(df[df['meter']==1]['meter_reading']+1) - np.log(df[df['meter']==1]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка 1 (VAL): ', np.sqrt( np.mean( np.power(np.log(df[(df['meter']==1) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[(df['meter']==1) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка 1 (VAL_чист): ' , np.sqrt( np.mean( np.power(np.log(df[  (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==1) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[ (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==1) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка 1 (VAL_чист2): ', np.sqrt( np.mean( np.power(np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==1) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==1) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "  )\n",
        "  print('Ошибка 2: ', np.sqrt( np.mean( np.power(np.log(df[df['meter']==2]['meter_reading']+1) - np.log(df[df['meter']==2]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка 2 (VAL): ', np.sqrt( np.mean( np.power(np.log(df[(df['meter']==2) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[(df['meter']==2) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка 2 (VAL_чист): ' , np.sqrt( np.mean( np.power(np.log(df[  (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==2) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[ (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==2) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка 2 (VAL_чист2): ', np.sqrt( np.mean( np.power(np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==2) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==2) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "  )\n",
        "  print('Ошибка 3: ', np.sqrt( np.mean( np.power(np.log(df[df['meter']==3]['meter_reading']+1) - np.log(df[df['meter']==3]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка 3 (VAL): ', np.sqrt( np.mean( np.power(np.log(df[(df['meter']==3) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[(df['meter']==3) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка 3 (VAL_чист): ' , np.sqrt( np.mean( np.power(np.log(df[  (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==3) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[ (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==3) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка 3 (VAL_чист2): ', np.sqrt( np.mean( np.power(np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==3) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==3) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "  )\n",
        "  # print('Ошибка 1: ', np.sqrt( np.mean( np.power(np.log(df[df['meter']==1]['meter_reading']+1) - np.log(df[df['meter']==1]['NN_PRED']+1),2.00000)))        )\n",
        "  # print('Ошибка 2: ', np.sqrt( np.mean( np.power(np.log(df[df['meter']==2]['meter_reading']+1) - np.log(df[df['meter']==2]['NN_PRED']+1),2.00000)))        )\n",
        "  # print('Ошибка 3: ', np.sqrt( np.mean( np.power(np.log(df[df['meter']==3]['meter_reading']+1) - np.log(df[df['meter']==3]['NN_PRED']+1),2.00000)))        )\n",
        "\n",
        "  gc.collect()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ошибка общая:  1.3473873510158345 Ошибка (VAL):  1.3483414756663568 Ошибка (VAL_чист):  0.5756767186919248 Ошибка (VAL_чист2):  0.462361504102313\n",
            "Ошибка 0:  1.0971504229404558 Ошибка 0 (VAL):  1.0891509074774033 Ошибка 0 (VAL_чист):  0.3389179667173395 Ошибка 0 (VAL_чист2):  0.3149224768996143\n",
            "Ошибка 1:  1.5319581160458586 Ошибка 1 (VAL):  1.5591904792676097 Ошибка 1 (VAL_чист):  0.7038461338617784 Ошибка 1 (VAL_чист2):  0.5850605758832433\n",
            "Ошибка 2:  1.6638634087676607 Ошибка 2 (VAL):  1.6575566177087862 Ошибка 2 (VAL_чист):  0.918408148629441 Ошибка 2 (VAL_чист2):  0.6847326774214916\n",
            "Ошибка 3:  1.9625404709477796 Ошибка 3 (VAL):  1.9555454713909437 Ошибка 3 (VAL_чист):  1.117054007408267 Ошибка 3 (VAL_чист2):  0.7521327942946583\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uDkGvOTYNcy",
        "colab_type": "code",
        "outputId": "bfebb4b0-f373-479c-cd70-18b2f3b83475",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ошибка общая:  1.3473874674637107 Ошибка (VAL):  1.3483415928656848 Ошибка (VAL_чист):  0.5756767405084868 Ошибка (VAL_чист2):  0.4623615327006715\n",
            "Ошибка 0:  1.097150680567493 Ошибка 0 (VAL):  1.0891511641164369 Ошибка 0 (VAL_чист):  0.33891800740903766 Ошибка 0 (VAL_чист2):  0.3149225188104313\n",
            "Ошибка 1:  1.5319581086991891 Ошибка 1 (VAL):  1.5591904765901698 Ошибка 1 (VAL_чист):  0.7038461305727779 Ошибка 1 (VAL_чист2):  0.5850605730802025\n",
            "Ошибка 2:  1.6638633608261502 Ошибка 2 (VAL):  1.6575565750506658 Ошибка 2 (VAL_чист):  0.9184081840472923 Ошибка 2 (VAL_чист2):  0.6847327356541326\n",
            "Ошибка 3:  1.9625404814033556 Ошибка 3 (VAL):  1.955545484766667 Ошибка 3 (VAL_чист):  1.1170540079900018 Ошибка 3 (VAL_чист2):  0.7521327934769413\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxFd8mjwt7KQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#тмп\n",
        "  pd.set_option('display.max_rows', 500)\n",
        "  pd.set_option('display.max_columns', 500)\n",
        "  pd.set_option('display.width', 100)\n",
        "  warnings.filterwarnings('ignore')\n",
        "  np.set_printoptions (precision = 4, suppress  = True)\n",
        "\n",
        "  df['k_NN_ERR'] = (df['NN_PRED']+0.33)/(df['meter_reading']+0.33)\n",
        "  print(len(df), len(df[(df['k_NN_ERR']<50) & (df['k_NN_ERR']>1/50) & (df['IS_BAD_PRCNT']<0.25)]))\n",
        "  print(df[(df['hour']==14) & (df['meter']==0) & (df['building_id']==1) & (df['IS_BAD_PRCNT']<0.25)][['timestamp','hour','weekday','meter_reading','NN_PRED','NN_ERR','k_NN_ERR']].sort_values('timestamp').head(400))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ti8V0jrzZ1C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df[(df['k_NN_ERR']<50) & (df['k_NN_ERR']>1/50)  & (df['IS_BAD_PRCNT']<0.25)].describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Uz_DyKXziWJ",
        "colab_type": "code",
        "outputId": "ef5493d2-c496-4f5e-e570-a09bb29f9aa2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print( np.sqrt( np.mean( np.power(np.log(df['meter_reading']+1) - np.log(df['NN_PRED']+1),2.00000)))     )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.3473874674637107\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpFQ9A4v0qd9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBMy61yg06BW",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "**-- -- -- -- -- -- -- -- --РАСЧЁТ НЕЙРОНОК после очистки -- -- -- -- -- -- -- -- --**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Q9aG2Cg_01Ci",
        "colab": {}
      },
      "source": [
        "#0: electricity, 1: chilledwater, 2: steam, 3: hotwater\n",
        "# РАСЧЁТ НЕЙРОНОК:\n",
        "  reg = 0.00001\n",
        "  batch_size = 2048\n",
        "  epochs = 30\n",
        "  meter = 0\n",
        "\n",
        "  earlyStopping = EarlyStopping(monitor='loss', patience=100, verbose=1, mode='min')\n",
        "  reduce_lr_loss = ReduceLROnPlateau(monitor='loss', factor=0.3, patience=5, verbose=1, min_delta=1e-3, mode='min')\n",
        "  model_checkpoint = ModelCheckpoint(monitor='loss', save_best_only=True, filepath = DIR + 'best_nn_' + str(meter) + '.model', save_weights_only = False, verbose=0, mode='min')\n",
        "\n",
        "  init = TruncatedNormal(mean=0.0, stddev=0.05, seed=159)\n",
        "  bias = Constant(value = 0.1)\n",
        "  \n",
        "  if 0==0:\n",
        "    meter = 0\n",
        "    opt = Adam(lr = 0.001)\n",
        "\n",
        "    nn_0 = Sequential()\n",
        "    nn_0.add(Dense(100, input_shape = df[In_Columns].shape[1:], activation = 'tanh', kernel_initializer = 'normal', kernel_regularizer=l2(reg), bias_initializer=bias))\n",
        "    nn_0.add(Dense(100, activation = 'tanh',  kernel_initializer = 'normal', bias_initializer=bias))\n",
        "    nn_0.add(Dense(100, activation = 'tanh',  kernel_initializer = 'normal', bias_initializer=bias, kernel_regularizer=l1(reg)))\n",
        "    nn_0.add(Dense(100, activation = 'tanh',  kernel_initializer = 'normal', bias_initializer=bias))\n",
        "    nn_0.add(Dense(1, activation = 'relu', kernel_initializer = 'normal'))\n",
        "\n",
        "    nn_0.compile(optimizer = opt, loss = RMSLE, metrics=[ MAE_, RMSLE, VAL_, 'mse', MAPE_ ])\n",
        "    \n",
        "    val = df[(df['meter'] == meter) & (df['day']%6 == 0) ]# & (df['k_NN_ERR'] < 100) & (df['k_NN_ERR'] > 1/100 & (df['IS_BAD_PRCNT'] < 0.25)]\n",
        "    #val_2 = df[(df['meter'] == meter) & (df['day']%6 == 0) & (df['k_NN_ERR'] < 100) & (df['k_NN_ERR'] > 1/100) & (df['IS_BAD_PRCNT'] < 0.25)]\n",
        "    df_cleared = df[(df['day']%6 != 0) & (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['meter'] == meter) & (df['IS_BAD_PRCNT'] < 0.25)][In_Columns + [Out_Columns]]\n",
        "\n",
        "    hist = nn_0.fit( df_cleared[In_Columns], df_cleared[Out_Columns], batch_size = batch_size, verbose = 0\n",
        "                    , epochs = epochs, shuffle = True, callbacks=[MyCustomCallback(epochs, 1), earlyStopping, reduce_lr_loss,model_checkpoint]\n",
        "                    , validation_data=(val[In_Columns], val[Out_Columns])\n",
        "                    ) \n",
        "    nn_0.save(DIR + str(meter) + 'HANDLY_SAVED_3.MODEL')\n",
        "    gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "f9h2QsKV01Cn",
        "outputId": "f71a533a-2c93-4b25-8f24-48929886c7b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        }
      },
      "source": [
        "for lr in [0.002]:\n",
        "  nn_0 = keras.models.load_model (DIR + '0HANDLY_SAVED_3.MODEL')\n",
        "  opt = Adam(lr = lr)\n",
        "  epochs = 30\n",
        "  batch_size = 2048\n",
        "  meter = 0\n",
        "  val = df[(df['meter'] == meter) & (df['day']%6 == 0) & (df['k_NN_ERR'] < 100) & (df['k_NN_ERR'] > 1/100) & (df['IS_BAD_PRCNT'] < 0.25)]\n",
        "  df_cleared = df[(df['k_NN_ERR']<50) & (df['k_NN_ERR']>1/50) & (df['meter']==meter) & (df['IS_BAD_PRCNT']<0.25)][In_Columns + [Out_Columns]]\n",
        "  print('*'*9, lr, '*'*33)\n",
        "  nn_0.compile(optimizer = opt, loss = RMSLE, metrics=[ MAE_, RMSLE, VAL_, 'mse', MAPE_ ])\n",
        "  hist = nn_0.fit( df_cleared[In_Columns], df_cleared[Out_Columns], batch_size = batch_size, verbose = 0\n",
        "                  , epochs = epochs, shuffle = True, callbacks=[ MyCustomCallback(epochs, 1), earlyStopping, reduce_lr_loss]\n",
        "                  , validation_data=(val[In_Columns], val[Out_Columns])\n",
        "                  ) \n",
        "  nn_0.save(DIR + str(meter) + 'HANDLY_SAVED_3.MODEL')\n",
        "  gc.collect()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "********* 0.002 *********************************\n",
            "# 0001 |  TST_loss: 0.2610 TST_MAE_: 0.1713 TST_RMSLE: 0.2462 TST_VAL_: 0.9609 TST_mean_squared_error: 36450.8059 TST_MAPE_: 0.2066 ///  TRN_loss: 0.2921 TRN_MAE_: 0.2046 TRN_RMSLE: 0.2772 TRN_VAL_: 0.8834 TRN_mean_squared_error: 36407.3369 TRN_MAPE_: 0.2031\n",
            "# 0002 |  TST_loss: 0.2674 TST_MAE_: 0.1739 TST_RMSLE: 0.2524 TST_VAL_: 0.9862 TST_mean_squared_error: 36267.7065 TST_MAPE_: 0.2208 ///  TRN_loss: 0.2912 TRN_MAE_: 0.2039 TRN_RMSLE: 0.2763 TRN_VAL_: 0.8841 TRN_mean_squared_error: 36254.7990 TRN_MAPE_: 0.2023\n",
            "# 0003 |  TST_loss: 0.2664 TST_MAE_: 0.1732 TST_RMSLE: 0.2515 TST_VAL_: 0.9207 TST_mean_squared_error: 36260.8113 TST_MAPE_: 0.1926 ///  TRN_loss: 0.2909 TRN_MAE_: 0.2033 TRN_RMSLE: 0.2760 TRN_VAL_: 0.8847 TRN_mean_squared_error: 36106.1856 TRN_MAPE_: 0.2022\n",
            ".......\n",
            "# 0004 |  TST_loss: 0.2584 TST_MAE_: 0.1697 TST_RMSLE: 0.2435 TST_VAL_: 0.9663 TST_mean_squared_error: 35953.5736 TST_MAPE_: 0.1995 ///  TRN_loss: 0.2904 TRN_MAE_: 0.2027 TRN_RMSLE: 0.2755 TRN_VAL_: 0.8854 TRN_mean_squared_error: 35960.2419 TRN_MAPE_: 0.2018\n",
            "# 0005 |  TST_loss: 0.2595 TST_MAE_: 0.1698 TST_RMSLE: 0.2446 TST_VAL_: 0.9565 TST_mean_squared_error: 35834.7952 TST_MAPE_: 0.1994 ///  TRN_loss: 0.2902 TRN_MAE_: 0.2021 TRN_RMSLE: 0.2752 TRN_VAL_: 0.8860 TRN_mean_squared_error: 35818.0788 TRN_MAPE_: 0.2017\n",
            "# 0006 |  TST_loss: 0.2597 TST_MAE_: 0.1699 TST_RMSLE: 0.2447 TST_VAL_: 0.9312 TST_mean_squared_error: 35799.3252 TST_MAPE_: 0.1931 ///  TRN_loss: 0.2900 TRN_MAE_: 0.2016 TRN_RMSLE: 0.2750 TRN_VAL_: 0.8866 TRN_mean_squared_error: 35682.6630 TRN_MAPE_: 0.2016\n",
            "# 0007 |  TST_loss: 0.2586 TST_MAE_: 0.1697 TST_RMSLE: 0.2435 TST_VAL_: 0.9573 TST_mean_squared_error: 35562.6565 TST_MAPE_: 0.2008 ///  TRN_loss: 0.2895 TRN_MAE_: 0.2010 TRN_RMSLE: 0.2745 TRN_VAL_: 0.8871 TRN_mean_squared_error: 35546.6735 TRN_MAPE_: 0.2013\n",
            "# 0008 |  TST_loss: 0.2747 TST_MAE_: 0.1818 TST_RMSLE: 0.2597 TST_VAL_: 0.9433 TST_mean_squared_error: 35521.5764 TST_MAPE_: 0.2158 ///  TRN_loss: 0.2893 TRN_MAE_: 0.2005 TRN_RMSLE: 0.2743 TRN_VAL_: 0.8877 TRN_mean_squared_error: 35412.8586 TRN_MAPE_: 0.2011\n",
            "# 0009 |  TST_loss: 0.2616 TST_MAE_: 0.1704 TST_RMSLE: 0.2466 TST_VAL_: 0.9934 TST_mean_squared_error: 35283.6075 TST_MAPE_: 0.2115 ///  TRN_loss: 0.2889 TRN_MAE_: 0.2000 TRN_RMSLE: 0.2739 TRN_VAL_: 0.8882 TRN_mean_squared_error: 35282.2051 TRN_MAPE_: 0.2008\n",
            "# 0010 |  TST_loss: 0.2594 TST_MAE_: 0.1687 TST_RMSLE: 0.2444 TST_VAL_: 0.9358 TST_mean_squared_error: 35263.7000 TST_MAPE_: 0.1929 ///  TRN_loss: 0.2884 TRN_MAE_: 0.1995 TRN_RMSLE: 0.2733 TRN_VAL_: 0.8887 TRN_mean_squared_error: 35152.3963 TRN_MAPE_: 0.2004\n",
            "# 0011 |  TST_loss: 0.2571 TST_MAE_: 0.1669 TST_RMSLE: 0.2421 TST_VAL_: 0.9689 TST_mean_squared_error: 35057.7441 TST_MAPE_: 0.2004 ///  TRN_loss: 0.2879 TRN_MAE_: 0.1990 TRN_RMSLE: 0.2728 TRN_VAL_: 0.8892 TRN_mean_squared_error: 35023.5374 TRN_MAPE_: 0.2000\n",
            "# 0012 |  TST_loss: 0.2575 TST_MAE_: 0.1677 TST_RMSLE: 0.2425 TST_VAL_: 0.9519 TST_mean_squared_error: 34907.7178 TST_MAPE_: 0.1928 ///  TRN_loss: 0.2878 TRN_MAE_: 0.1985 TRN_RMSLE: 0.2727 TRN_VAL_: 0.8898 TRN_mean_squared_error: 34897.7167 TRN_MAPE_: 0.1999\n",
            "# 0013 |  TST_loss: 0.2662 TST_MAE_: 0.1709 TST_RMSLE: 0.2511 TST_VAL_: 0.9268 TST_mean_squared_error: 34815.6974 TST_MAPE_: 0.1913 ///  TRN_loss: 0.2875 TRN_MAE_: 0.1980 TRN_RMSLE: 0.2724 TRN_VAL_: 0.8903 TRN_mean_squared_error: 34772.6041 TRN_MAPE_: 0.1998\n",
            "# 0014 |  TST_loss: 0.2584 TST_MAE_: 0.1675 TST_RMSLE: 0.2431 TST_VAL_: 0.9443 TST_mean_squared_error: 34676.1850 TST_MAPE_: 0.1913 ///  TRN_loss: 0.2872 TRN_MAE_: 0.1976 TRN_RMSLE: 0.2721 TRN_VAL_: 0.8909 TRN_mean_squared_error: 34649.6813 TRN_MAPE_: 0.1997\n",
            "# 0015 |  TST_loss: 0.2552 TST_MAE_: 0.1660 TST_RMSLE: 0.2401 TST_VAL_: 0.9702 TST_mean_squared_error: 34550.0560 TST_MAPE_: 0.1974 ///  TRN_loss: 0.2867 TRN_MAE_: 0.1971 TRN_RMSLE: 0.2716 TRN_VAL_: 0.8913 TRN_mean_squared_error: 34530.6804 TRN_MAPE_: 0.1992\n",
            "# 0016 |  TST_loss: 0.2584 TST_MAE_: 0.1687 TST_RMSLE: 0.2433 TST_VAL_: 0.9509 TST_mean_squared_error: 34518.3677 TST_MAPE_: 0.1983 ///  TRN_loss: 0.2866 TRN_MAE_: 0.1966 TRN_RMSLE: 0.2715 TRN_VAL_: 0.8918 TRN_mean_squared_error: 34409.6951 TRN_MAPE_: 0.1992\n",
            "# 0017 |  TST_loss: 0.3316 TST_MAE_: 0.2031 TST_RMSLE: 0.3164 TST_VAL_: 0.8599 TST_mean_squared_error: 34633.9748 TST_MAPE_: 0.2279 ///  TRN_loss: 0.2862 TRN_MAE_: 0.1962 TRN_RMSLE: 0.2711 TRN_VAL_: 0.8924 TRN_mean_squared_error: 34294.0879 TRN_MAPE_: 0.1989\n",
            "# 0018 |  TST_loss: 0.2536 TST_MAE_: 0.1652 TST_RMSLE: 0.2385 TST_VAL_: 0.9530 TST_mean_squared_error: 34295.1393 TST_MAPE_: 0.1943 ///  TRN_loss: 0.2858 TRN_MAE_: 0.1957 TRN_RMSLE: 0.2707 TRN_VAL_: 0.8928 TRN_mean_squared_error: 34175.8843 TRN_MAPE_: 0.1986\n",
            "# 0019 |  TST_loss: 0.2556 TST_MAE_: 0.1654 TST_RMSLE: 0.2406 TST_VAL_: 0.9518 TST_mean_squared_error: 34123.1618 TST_MAPE_: 0.1914 ///  TRN_loss: 0.2852 TRN_MAE_: 0.1953 TRN_RMSLE: 0.2701 TRN_VAL_: 0.8934 TRN_mean_squared_error: 34060.7482 TRN_MAPE_: 0.1981\n",
            "# 0020 |  TST_loss: 0.2582 TST_MAE_: 0.1681 TST_RMSLE: 0.2431 TST_VAL_: 0.9580 TST_mean_squared_error: 33999.7582 TST_MAPE_: 0.1953 ///  TRN_loss: 0.2853 TRN_MAE_: 0.1949 TRN_RMSLE: 0.2703 TRN_VAL_: 0.8938 TRN_mean_squared_error: 33947.4253 TRN_MAPE_: 0.1985\n",
            "# 0021 |  TST_loss: 0.2547 TST_MAE_: 0.1651 TST_RMSLE: 0.2397 TST_VAL_: 0.9521 TST_mean_squared_error: 33894.8138 TST_MAPE_: 0.1910 ///  TRN_loss: 0.2850 TRN_MAE_: 0.1945 TRN_RMSLE: 0.2699 TRN_VAL_: 0.8943 TRN_mean_squared_error: 33838.7124 TRN_MAPE_: 0.1982\n",
            "# 0022 |  TST_loss: 0.2528 TST_MAE_: 0.1641 TST_RMSLE: 0.2377 TST_VAL_: 0.9515 TST_mean_squared_error: 33810.0276 TST_MAPE_: 0.1906 ///  TRN_loss: 0.2846 TRN_MAE_: 0.1940 TRN_RMSLE: 0.2695 TRN_VAL_: 0.8947 TRN_mean_squared_error: 33731.2898 TRN_MAPE_: 0.1979\n",
            "# 0023 |  TST_loss: 0.2628 TST_MAE_: 0.1723 TST_RMSLE: 0.2477 TST_VAL_: 0.9994 TST_mean_squared_error: 33653.8621 TST_MAPE_: 0.2204 ///  TRN_loss: 0.2845 TRN_MAE_: 0.1937 TRN_RMSLE: 0.2694 TRN_VAL_: 0.8952 TRN_mean_squared_error: 33626.5965 TRN_MAPE_: 0.1978\n",
            "# 0024 |  TST_loss: 0.2625 TST_MAE_: 0.1708 TST_RMSLE: 0.2474 TST_VAL_: 0.9212 TST_mean_squared_error: 33679.3089 TST_MAPE_: 0.1905 ///  TRN_loss: 0.2841 TRN_MAE_: 0.1932 TRN_RMSLE: 0.2690 TRN_VAL_: 0.8957 TRN_mean_squared_error: 33521.3658 TRN_MAPE_: 0.1976\n",
            "# 0025 |  TST_loss: 0.2631 TST_MAE_: 0.1698 TST_RMSLE: 0.2480 TST_VAL_: 0.9860 TST_mean_squared_error: 33518.9062 TST_MAPE_: 0.2149 ///  TRN_loss: 0.2840 TRN_MAE_: 0.1929 TRN_RMSLE: 0.2688 TRN_VAL_: 0.8962 TRN_mean_squared_error: 33418.2593 TRN_MAPE_: 0.1976\n",
            "# 0026 |  TST_loss: 0.2566 TST_MAE_: 0.1670 TST_RMSLE: 0.2415 TST_VAL_: 0.9913 TST_mean_squared_error: 33359.7039 TST_MAPE_: 0.2079 ///  TRN_loss: 0.2837 TRN_MAE_: 0.1926 TRN_RMSLE: 0.2685 TRN_VAL_: 0.8966 TRN_mean_squared_error: 33318.8950 TRN_MAPE_: 0.1972\n",
            "# 0027 |  TST_loss: 0.2510 TST_MAE_: 0.1620 TST_RMSLE: 0.2360 TST_VAL_: 0.9556 TST_mean_squared_error: 33254.0052 TST_MAPE_: 0.1875 ///  TRN_loss: 0.2831 TRN_MAE_: 0.1921 TRN_RMSLE: 0.2680 TRN_VAL_: 0.8970 TRN_mean_squared_error: 33216.6869 TRN_MAPE_: 0.1968\n",
            "# 0028 |  TST_loss: 0.2551 TST_MAE_: 0.1665 TST_RMSLE: 0.2400 TST_VAL_: 0.9317 TST_mean_squared_error: 33270.3735 TST_MAPE_: 0.1887 ///  TRN_loss: 0.2828 TRN_MAE_: 0.1917 TRN_RMSLE: 0.2677 TRN_VAL_: 0.8975 TRN_mean_squared_error: 33113.5935 TRN_MAPE_: 0.1967\n",
            "# 0029 |  TST_loss: 0.2592 TST_MAE_: 0.1664 TST_RMSLE: 0.2441 TST_VAL_: 0.9355 TST_mean_squared_error: 33102.6577 TST_MAPE_: 0.1905 ///  TRN_loss: 0.2825 TRN_MAE_: 0.1914 TRN_RMSLE: 0.2674 TRN_VAL_: 0.8979 TRN_mean_squared_error: 33016.9040 TRN_MAPE_: 0.1965\n",
            "# 0030 |  TST_loss: 0.2538 TST_MAE_: 0.1651 TST_RMSLE: 0.2388 TST_VAL_: 0.9784 TST_mean_squared_error: 32969.6232 TST_MAPE_: 0.2023 ///  TRN_loss: 0.2828 TRN_MAE_: 0.1912 TRN_RMSLE: 0.2676 TRN_VAL_: 0.8983 TRN_mean_squared_error: 32923.1633 TRN_MAPE_: 0.1969\n",
            "# 0030 |  TST_loss: 0.2538 TST_MAE_: 0.1651 TST_RMSLE: 0.2388 TST_VAL_: 0.9784 TST_mean_squared_error: 32969.6232 TST_MAPE_: 0.2023 ///  TRN_loss: 0.2828 TRN_MAE_: 0.1912 TRN_RMSLE: 0.2676 TRN_VAL_: 0.8983 TRN_mean_squared_error: 32923.1633 TRN_MAPE_: 0.1969\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SssjG5U44j38",
        "colab_type": "code",
        "outputId": "c763aea3-7b78-4f86-e0ab-6729a3d6c575",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "#Предсказание из 4х значений = 0:\n",
        "  nn_0 = keras.models.load_model (DIR + '0HANDLY_SAVED_3.MODEL')\n",
        "  #nn_1 = keras.models.load_model (DIR + '1HANDLY_SAVED_3.MODEL')\n",
        "  #nn_2 = keras.models.load_model (DIR + '2HANDLY_SAVED_3.MODEL')\n",
        "  #nn_3 = keras.models.load_model (DIR + '3HANDLY_SAVED_3.MODEL')\n",
        "\n",
        "  # score = model.evaluate(X, Y, verbose=0)\n",
        "  # print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))\n",
        "  gc.collect()\n",
        "\n",
        "  df['NN_PRED'] = 0\n",
        "  df['NN_PRED_0'] = nn_0.predict(df[In_Columns], batch_size = 10000) \n",
        "  #df['NN_PRED_1'] = nn_1.predict(df[In_Columns], batch_size = 10000) \n",
        "  #df['NN_PRED_2'] = nn_2.predict(df[In_Columns], batch_size = 10000) \n",
        "  #df['NN_PRED_3'] = nn_3.predict(df[In_Columns], batch_size = 10000) \n",
        "  df['NN_PRED'] = np.where(df['meter'] == 0, df['NN_PRED_0'], df['NN_PRED'])\n",
        "  #df['NN_PRED'] = np.where(df['meter'] == 1, df['NN_PRED_1'], df['NN_PRED'])\n",
        "  #df['NN_PRED'] = np.where(df['meter'] == 2, df['NN_PRED_2'], df['NN_PRED'])\n",
        "  #df['NN_PRED'] = np.where(df['meter'] == 3, df['NN_PRED_3'], df['NN_PRED'])\n",
        "  df.drop(columns = ['NN_PRED_0'], inplace = True) #, 'NN_PRED_1', 'NN_PRED_2', 'NN_PRED_3'\n",
        "  #df.drop(columns = ['Value_x', 'Value_y'])\n",
        "  gc.collect()\n",
        "\n",
        "  df['NN_ERR'] = np.abs(df['NN_PRED']-df['meter_reading'])\n",
        "  print( np.sqrt( np.mean( np.power(np.log(df['meter_reading']+1) - np.log(df['NN_PRED']+1),2.00000)))     )\n",
        "  print('Ошибка 0: ', np.sqrt( np.mean( np.power(np.log(df[df['meter']==0]['meter_reading']+1) - np.log(df[df['meter']==0]['NN_PRED']+1),2.00000)))        \n",
        "  , 'Ошибка 0 (VAL): ', np.sqrt( np.mean( np.power(np.log(df[(df['meter']==0) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[(df['meter']==0) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "  , 'Ошибка 0 (VAL_чист): ', np.sqrt( np.mean( np.power(np.log(df[ (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==0) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[ (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==0) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "  , 'Ошибка 0 (VAL_чист): ', np.sqrt( np.mean( np.power(np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==0) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==0) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        )\n",
        "  #print('Ошибка 1: ', np.sqrt( np.mean( np.power(np.log(df[df['meter']==1]['meter_reading']+1) - np.log(df[df['meter']==1]['NN_PRED']+1),2.00000)))        )\n",
        "  #print('Ошибка 2: ', np.sqrt( np.mean( np.power(np.log(df[df['meter']==2]['meter_reading']+1) - np.log(df[df['meter']==2]['NN_PRED']+1),2.00000)))        )\n",
        "  #print('Ошибка 3: ', np.sqrt( np.mean( np.power(np.log(df[df['meter']==3]['meter_reading']+1) - np.log(df[df['meter']==3]['NN_PRED']+1),2.00000)))        )\n",
        "  #df['k_NN_ERR'] = (df['NN_PRED']+0.33)/(df['meter_reading']+0.33)\n",
        "  gc.collect()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3.368696721360348\n",
            "Ошибка 0:  1.1049203738272573 Ошибка 0 (VAL):  1.0965952553822587 Ошибка 0 (VAL_чист):  0.2917643053771373 Ошибка 0 (VAL_чист):  0.26447247330596413\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAcxnR-6GGQp",
        "colab_type": "code",
        "outputId": "83011776-8fc2-42dd-c216-c1ad5112eda8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "Ошибка 0:  1.1024091953998731 Ошибка 0 (VAL):  1.0939318102859754 Ошибка 0 (VAL_чист):  0.2971202786841661 Ошибка 0 (VAL_чист):  0.27036618063814444\n",
        "0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3.368345386414799\n",
            "Ошибка 0:  1.1031235719254835 Ошибка 0 (VAL):  1.0950360556837644 Ошибка 0 (VAL_чист):  0.31399483273137624 Ошибка 0 (VAL_чист):  0.28882754272712563\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NyBVLwrQvDf",
        "colab_type": "code",
        "outputId": "c6e86fbe-dbce-45ee-8578-8e8e7bb980e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Ошибка 0: ', np.sqrt( np.mean( np.power(np.log(df[df['meter']==0]['meter_reading']+1) - np.log(df[df['meter']==0]['NN_PRED']+1),2.00000)))        \n",
        "  , 'Ошибка 0 (VAL): ', np.sqrt( np.mean( np.power(np.log(df[(df['meter']==0) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[(df['meter']==0) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "  , 'Ошибка 0 (VAL_чист): ', np.sqrt( np.mean( np.power(np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==0) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==0) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        )\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ошибка 0:  1.0967505629134169 Ошибка 0 (VAL):  1.0889958705909204 Ошибка 0 (VAL_чист):  0.29653998158216416\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnyFhUOxHnW8",
        "colab_type": "code",
        "outputId": "6558bcb5-0bbe-4a7c-c104-16b128b8306c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ошибка 0:  2.251761485803078 Ошибка 0 (VAL):  2.2413384395492075 Ошибка 0 (VAL_чист):  2.0921576372906086\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2V4xV9ON01Co",
        "outputId": "ef3f7177-242c-4df4-c3e6-b6bb1be96146",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "if 1==1:\n",
        "  reg = 0.00001\n",
        "  meter = 1\n",
        "  epochs = 190\n",
        "  batch_size = 1024\n",
        "  opt = Adam(lr = 0.001)\n",
        "  bias = Constant(value = 0.1)\n",
        "\n",
        "  earlyStopping = EarlyStopping(monitor='loss', patience=100, verbose=1, mode='min')\n",
        "  reduce_lr_loss = ReduceLROnPlateau(monitor='loss', factor=0.3, patience=15, verbose=1, min_delta=1e-3, mode='min')\n",
        "  model_checkpoint = ModelCheckpoint(monitor='loss', save_best_only=True, filepath = DIR + 'best_nn_' + str(meter) + '.model', save_weights_only = False, verbose=0, mode='min')\n",
        "\n",
        "  nn_1 = Sequential()\n",
        "  nn_1.add(Dense(100, input_shape = df[In_Columns].shape[1:], activation = 'tanh', kernel_initializer = 'normal', kernel_regularizer=l2(reg), bias_initializer=bias))\n",
        "  nn_1.add(Dense(100, activation = 'tanh',  kernel_initializer = 'normal', bias_initializer=bias))\n",
        "  nn_1.add(Dense(100, activation = 'tanh',  kernel_initializer = 'normal', bias_initializer=bias, kernel_regularizer=l1(reg)))\n",
        "  nn_1.add(Dense(100, activation = 'tanh',  kernel_initializer = 'normal', bias_initializer=bias))\n",
        "  nn_1.add(Dense(1, activation = 'relu', kernel_initializer = 'normal'))\n",
        "\n",
        "  nn_1.compile(optimizer = opt, loss = RMSLE, metrics=[ MAE_, RMSLE, VAL_, 'mse', MAPE_ ])\n",
        "  \n",
        "  \n",
        "  val = df[(df['meter'] == meter) & (df['day']%6 == 0) & (df['k_NN_ERR'] < 100) & (df['k_NN_ERR'] > 1/100) & (df['IS_BAD_PRCNT'] < 0.25)]\n",
        "  df_cleared = df[(df['k_NN_ERR']<50) & (df['k_NN_ERR']>1/50) & (df['day']%6 != 0) & (df['meter']==meter) & (df['IS_BAD_PRCNT']<0.25)][In_Columns + [Out_Columns]]\n",
        "\n",
        "  hist = nn_1.fit( df_cleared[In_Columns], df_cleared[Out_Columns], batch_size = batch_size, verbose = 0\n",
        "                  , epochs = epochs, shuffle = True, callbacks=[MyCustomCallback(epochs, 1), earlyStopping, reduce_lr_loss,model_checkpoint]\n",
        "                  , validation_data=(val[In_Columns], val[Out_Columns])\n",
        "                  ) \n",
        "  nn_1.save(DIR + str(meter) + 'HANDLY_SAVED_3.MODEL')\n",
        "  gc.collect()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# 0001 |  TST_loss: 1.7362 TST_MAE_: 1.7639 TST_RMSLE: 1.7355 TST_VAL_: 1.7431 TST_mean_squared_error: 64375561.5457 TST_MAPE_: 1.6023 ///  TRN_loss: 2.0505 TRN_MAE_: 0.9240 TRN_RMSLE: 2.0494 TRN_VAL_: 0.1497 TRN_mean_squared_error: 71984808.4860 TRN_MAPE_: 1.4047\n",
            "# 0002 |  TST_loss: 1.0397 TST_MAE_: 0.5930 TST_RMSLE: 1.0323 TST_VAL_: 0.6498 TST_mean_squared_error: 64231873.3554 TST_MAPE_: 0.7885 ///  TRN_loss: 1.4206 TRN_MAE_: 0.8224 TRN_RMSLE: 1.4165 TRN_VAL_: 0.2470 TRN_mean_squared_error: 71850379.2986 TRN_MAPE_: 1.0585\n",
            "# 0003 |  TST_loss: 0.9576 TST_MAE_: 0.5655 TST_RMSLE: 0.9467 TST_VAL_: 0.7695 TST_mean_squared_error: 64153656.4229 TST_MAPE_: 0.7862 ///  TRN_loss: 1.1119 TRN_MAE_: 0.7438 TRN_RMSLE: 1.1026 TRN_VAL_: 0.3072 TRN_mean_squared_error: 71736440.5440 TRN_MAPE_: 0.7799\n",
            ".......\n",
            "# 0004 |  TST_loss: 0.9069 TST_MAE_: 0.5096 TST_RMSLE: 0.8942 TST_VAL_: 0.7110 TST_mean_squared_error: 64081131.4554 TST_MAPE_: 0.6964 ///  TRN_loss: 1.0361 TRN_MAE_: 0.7142 TRN_RMSLE: 1.0243 TRN_VAL_: 0.3410 TRN_mean_squared_error: 71659432.8812 TRN_MAPE_: 0.7359\n",
            "# 0005 |  TST_loss: 0.8532 TST_MAE_: 0.4964 TST_RMSLE: 0.8382 TST_VAL_: 0.8307 TST_mean_squared_error: 64019132.8787 TST_MAPE_: 0.7261 ///  TRN_loss: 0.9745 TRN_MAE_: 0.6904 TRN_RMSLE: 0.9606 TRN_VAL_: 0.3662 TRN_mean_squared_error: 71590137.0495 TRN_MAPE_: 0.6934\n",
            "# 0006 |  TST_loss: 0.8193 TST_MAE_: 0.4463 TST_RMSLE: 0.8029 TST_VAL_: 0.7050 TST_mean_squared_error: 63966520.4577 TST_MAPE_: 0.6101 ///  TRN_loss: 0.9199 TRN_MAE_: 0.6709 TRN_RMSLE: 0.9042 TRN_VAL_: 0.3874 TRN_mean_squared_error: 71530121.6608 TRN_MAPE_: 0.6518\n",
            "# 0007 |  TST_loss: 0.7656 TST_MAE_: 0.4243 TST_RMSLE: 0.7482 TST_VAL_: 0.7904 TST_mean_squared_error: 63926105.6109 TST_MAPE_: 0.6146 ///  TRN_loss: 0.8781 TRN_MAE_: 0.6547 TRN_RMSLE: 0.8613 TRN_VAL_: 0.4047 TRN_mean_squared_error: 71480482.9853 TRN_MAPE_: 0.6207\n",
            "# 0008 |  TST_loss: 0.7365 TST_MAE_: 0.4112 TST_RMSLE: 0.7182 TST_VAL_: 0.7963 TST_mean_squared_error: 63882006.2598 TST_MAPE_: 0.6009 ///  TRN_loss: 0.8431 TRN_MAE_: 0.6403 TRN_RMSLE: 0.8252 TRN_VAL_: 0.4200 TRN_mean_squared_error: 71437022.8466 TRN_MAPE_: 0.5966\n",
            "# 0009 |  TST_loss: 0.7133 TST_MAE_: 0.3961 TST_RMSLE: 0.6941 TST_VAL_: 0.7689 TST_mean_squared_error: 63854091.3856 TST_MAPE_: 0.5689 ///  TRN_loss: 0.8120 TRN_MAE_: 0.6279 TRN_RMSLE: 0.7933 TRN_VAL_: 0.4334 TRN_mean_squared_error: 71401883.9280 TRN_MAPE_: 0.5768\n",
            "# 0010 |  TST_loss: 0.6909 TST_MAE_: 0.3822 TST_RMSLE: 0.6708 TST_VAL_: 0.8175 TST_mean_squared_error: 63817236.5004 TST_MAPE_: 0.5635 ///  TRN_loss: 0.7872 TRN_MAE_: 0.6170 TRN_RMSLE: 0.7675 TRN_VAL_: 0.4453 TRN_mean_squared_error: 71367829.2459 TRN_MAPE_: 0.5603\n",
            "# 0011 |  TST_loss: 0.6769 TST_MAE_: 0.3771 TST_RMSLE: 0.6562 TST_VAL_: 0.7711 TST_mean_squared_error: 63787815.2879 TST_MAPE_: 0.5325 ///  TRN_loss: 0.7664 TRN_MAE_: 0.6069 TRN_RMSLE: 0.7460 TRN_VAL_: 0.4565 TRN_mean_squared_error: 71332285.0608 TRN_MAPE_: 0.5447\n",
            "# 0012 |  TST_loss: 0.6669 TST_MAE_: 0.3689 TST_RMSLE: 0.6456 TST_VAL_: 0.7794 TST_mean_squared_error: 63754912.5730 TST_MAPE_: 0.5120 ///  TRN_loss: 0.7506 TRN_MAE_: 0.5982 TRN_RMSLE: 0.7296 TRN_VAL_: 0.4661 TRN_mean_squared_error: 71301555.4570 TRN_MAPE_: 0.5328\n",
            "# 0013 |  TST_loss: 0.6723 TST_MAE_: 0.3766 TST_RMSLE: 0.6505 TST_VAL_: 0.8418 TST_mean_squared_error: 63728156.6974 TST_MAPE_: 0.5509 ///  TRN_loss: 0.7369 TRN_MAE_: 0.5906 TRN_RMSLE: 0.7153 TRN_VAL_: 0.4747 TRN_mean_squared_error: 71272983.0093 TRN_MAPE_: 0.5228\n",
            "# 0014 |  TST_loss: 0.6482 TST_MAE_: 0.3630 TST_RMSLE: 0.6261 TST_VAL_: 0.8466 TST_mean_squared_error: 63700613.2492 TST_MAPE_: 0.5326 ///  TRN_loss: 0.7248 TRN_MAE_: 0.5833 TRN_RMSLE: 0.7029 TRN_VAL_: 0.4828 TRN_mean_squared_error: 71247091.9422 TRN_MAPE_: 0.5141\n",
            "# 0015 |  TST_loss: 0.6297 TST_MAE_: 0.3480 TST_RMSLE: 0.6070 TST_VAL_: 0.8120 TST_mean_squared_error: 63687355.1732 TST_MAPE_: 0.5008 ///  TRN_loss: 0.7145 TRN_MAE_: 0.5776 TRN_RMSLE: 0.6922 TRN_VAL_: 0.4893 TRN_mean_squared_error: 71223775.3363 TRN_MAPE_: 0.5072\n",
            "# 0016 |  TST_loss: 0.6505 TST_MAE_: 0.3552 TST_RMSLE: 0.6276 TST_VAL_: 0.8011 TST_mean_squared_error: 63663705.8514 TST_MAPE_: 0.5087 ///  TRN_loss: 0.7053 TRN_MAE_: 0.5717 TRN_RMSLE: 0.6825 TRN_VAL_: 0.4960 TRN_mean_squared_error: 71202834.1322 TRN_MAPE_: 0.5006\n",
            "# 0017 |  TST_loss: 0.6174 TST_MAE_: 0.3404 TST_RMSLE: 0.5941 TST_VAL_: 0.8495 TST_mean_squared_error: 63643132.4878 TST_MAPE_: 0.5022 ///  TRN_loss: 0.6968 TRN_MAE_: 0.5659 TRN_RMSLE: 0.6737 TRN_VAL_: 0.5028 TRN_mean_squared_error: 71182444.9283 TRN_MAPE_: 0.4949\n",
            "# 0018 |  TST_loss: 0.6135 TST_MAE_: 0.3376 TST_RMSLE: 0.5899 TST_VAL_: 0.8525 TST_mean_squared_error: 63626840.1272 TST_MAPE_: 0.4866 ///  TRN_loss: 0.6903 TRN_MAE_: 0.5610 TRN_RMSLE: 0.6668 TRN_VAL_: 0.5083 TRN_mean_squared_error: 71164552.5511 TRN_MAPE_: 0.4903\n",
            "# 0019 |  TST_loss: 0.6012 TST_MAE_: 0.3303 TST_RMSLE: 0.5772 TST_VAL_: 0.8413 TST_mean_squared_error: 63610067.2170 TST_MAPE_: 0.4855 ///  TRN_loss: 0.6841 TRN_MAE_: 0.5563 TRN_RMSLE: 0.6603 TRN_VAL_: 0.5139 TRN_mean_squared_error: 71146755.4702 TRN_MAPE_: 0.4863\n",
            "# 0020 |  TST_loss: 0.6180 TST_MAE_: 0.3396 TST_RMSLE: 0.5937 TST_VAL_: 0.8455 TST_mean_squared_error: 63599077.9708 TST_MAPE_: 0.5040 ///  TRN_loss: 0.6786 TRN_MAE_: 0.5526 TRN_RMSLE: 0.6544 TRN_VAL_: 0.5180 TRN_mean_squared_error: 71131023.4691 TRN_MAPE_: 0.4821\n",
            "# 0021 |  TST_loss: 0.5965 TST_MAE_: 0.3283 TST_RMSLE: 0.5720 TST_VAL_: 0.8256 TST_mean_squared_error: 63582427.8329 TST_MAPE_: 0.4690 ///  TRN_loss: 0.6724 TRN_MAE_: 0.5482 TRN_RMSLE: 0.6480 TRN_VAL_: 0.5233 TRN_mean_squared_error: 71115262.5905 TRN_MAPE_: 0.4777\n",
            "# 0022 |  TST_loss: 0.5929 TST_MAE_: 0.3256 TST_RMSLE: 0.5682 TST_VAL_: 0.8339 TST_mean_squared_error: 63567720.6926 TST_MAPE_: 0.4687 ///  TRN_loss: 0.6673 TRN_MAE_: 0.5447 TRN_RMSLE: 0.6427 TRN_VAL_: 0.5274 TRN_mean_squared_error: 71101464.0077 TRN_MAPE_: 0.4742\n",
            "# 0023 |  TST_loss: 0.5893 TST_MAE_: 0.3222 TST_RMSLE: 0.5645 TST_VAL_: 0.8164 TST_mean_squared_error: 63554889.6731 TST_MAPE_: 0.4554 ///  TRN_loss: 0.6614 TRN_MAE_: 0.5409 TRN_RMSLE: 0.6366 TRN_VAL_: 0.5316 TRN_mean_squared_error: 71087213.8308 TRN_MAPE_: 0.4697\n",
            "# 0024 |  TST_loss: 0.5869 TST_MAE_: 0.3220 TST_RMSLE: 0.5618 TST_VAL_: 0.8709 TST_mean_squared_error: 63541784.2774 TST_MAPE_: 0.4734 ///  TRN_loss: 0.6577 TRN_MAE_: 0.5375 TRN_RMSLE: 0.6328 TRN_VAL_: 0.5357 TRN_mean_squared_error: 71074363.0660 TRN_MAPE_: 0.4672\n",
            "# 0025 |  TST_loss: 0.5839 TST_MAE_: 0.3188 TST_RMSLE: 0.5586 TST_VAL_: 0.8478 TST_mean_squared_error: 63531360.4042 TST_MAPE_: 0.4602 ///  TRN_loss: 0.6532 TRN_MAE_: 0.5341 TRN_RMSLE: 0.6280 TRN_VAL_: 0.5395 TRN_mean_squared_error: 71060574.4038 TRN_MAPE_: 0.4639\n",
            "# 0026 |  TST_loss: 0.6000 TST_MAE_: 0.3296 TST_RMSLE: 0.5746 TST_VAL_: 0.7809 TST_mean_squared_error: 63520927.8613 TST_MAPE_: 0.4460 ///  TRN_loss: 0.6493 TRN_MAE_: 0.5316 TRN_RMSLE: 0.6240 TRN_VAL_: 0.5425 TRN_mean_squared_error: 71048885.4200 TRN_MAPE_: 0.4614\n",
            "# 0027 |  TST_loss: 0.5778 TST_MAE_: 0.3161 TST_RMSLE: 0.5521 TST_VAL_: 0.8630 TST_mean_squared_error: 63506118.7598 TST_MAPE_: 0.4592 ///  TRN_loss: 0.6469 TRN_MAE_: 0.5284 TRN_RMSLE: 0.6214 TRN_VAL_: 0.5464 TRN_mean_squared_error: 71036736.1179 TRN_MAPE_: 0.4607\n",
            "# 0028 |  TST_loss: 0.5799 TST_MAE_: 0.3159 TST_RMSLE: 0.5542 TST_VAL_: 0.8547 TST_mean_squared_error: 63500605.2288 TST_MAPE_: 0.4620 ///  TRN_loss: 0.6429 TRN_MAE_: 0.5259 TRN_RMSLE: 0.6172 TRN_VAL_: 0.5495 TRN_mean_squared_error: 71026287.5597 TRN_MAPE_: 0.4576\n",
            "# 0029 |  TST_loss: 0.5713 TST_MAE_: 0.3123 TST_RMSLE: 0.5455 TST_VAL_: 0.8481 TST_mean_squared_error: 63487321.2827 TST_MAPE_: 0.4535 ///  TRN_loss: 0.6399 TRN_MAE_: 0.5228 TRN_RMSLE: 0.6140 TRN_VAL_: 0.5529 TRN_mean_squared_error: 71015806.1070 TRN_MAPE_: 0.4559\n",
            "# 0030 |  TST_loss: 0.5808 TST_MAE_: 0.3128 TST_RMSLE: 0.5548 TST_VAL_: 0.8642 TST_mean_squared_error: 63478584.3242 TST_MAPE_: 0.4599 ///  TRN_loss: 0.6367 TRN_MAE_: 0.5199 TRN_RMSLE: 0.6107 TRN_VAL_: 0.5563 TRN_mean_squared_error: 71005782.1164 TRN_MAPE_: 0.4537\n",
            "# 0031 |  TST_loss: 0.5750 TST_MAE_: 0.3109 TST_RMSLE: 0.5488 TST_VAL_: 0.8361 TST_mean_squared_error: 63472009.6142 TST_MAPE_: 0.4502 ///  TRN_loss: 0.6327 TRN_MAE_: 0.5179 TRN_RMSLE: 0.6067 TRN_VAL_: 0.5584 TRN_mean_squared_error: 70995857.4491 TRN_MAPE_: 0.4508\n",
            "# 0032 |  TST_loss: 0.5725 TST_MAE_: 0.3107 TST_RMSLE: 0.5463 TST_VAL_: 0.9053 TST_mean_squared_error: 63455707.2685 TST_MAPE_: 0.4780 ///  TRN_loss: 0.6300 TRN_MAE_: 0.5151 TRN_RMSLE: 0.6038 TRN_VAL_: 0.5615 TRN_mean_squared_error: 70985638.5617 TRN_MAPE_: 0.4493\n",
            "# 0033 |  TST_loss: 0.5722 TST_MAE_: 0.3120 TST_RMSLE: 0.5459 TST_VAL_: 0.8532 TST_mean_squared_error: 63451325.6693 TST_MAPE_: 0.4604 ///  TRN_loss: 0.6269 TRN_MAE_: 0.5131 TRN_RMSLE: 0.6006 TRN_VAL_: 0.5639 TRN_mean_squared_error: 70976330.0166 TRN_MAPE_: 0.4471\n",
            "# 0034 |  TST_loss: 0.5666 TST_MAE_: 0.3058 TST_RMSLE: 0.5402 TST_VAL_: 0.8741 TST_mean_squared_error: 63437539.1067 TST_MAPE_: 0.4553 ///  TRN_loss: 0.6247 TRN_MAE_: 0.5108 TRN_RMSLE: 0.5983 TRN_VAL_: 0.5665 TRN_mean_squared_error: 70967006.7387 TRN_MAPE_: 0.4460\n",
            "# 0035 |  TST_loss: 0.5690 TST_MAE_: 0.3075 TST_RMSLE: 0.5425 TST_VAL_: 0.9071 TST_mean_squared_error: 63431426.7518 TST_MAPE_: 0.4755 ///  TRN_loss: 0.6219 TRN_MAE_: 0.5086 TRN_RMSLE: 0.5954 TRN_VAL_: 0.5688 TRN_mean_squared_error: 70958203.2658 TRN_MAPE_: 0.4439\n",
            "# 0036 |  TST_loss: 0.5581 TST_MAE_: 0.3016 TST_RMSLE: 0.5315 TST_VAL_: 0.8886 TST_mean_squared_error: 63423433.8812 TST_MAPE_: 0.4524 ///  TRN_loss: 0.6213 TRN_MAE_: 0.5067 TRN_RMSLE: 0.5947 TRN_VAL_: 0.5713 TRN_mean_squared_error: 70950103.9886 TRN_MAPE_: 0.4440\n",
            "# 0037 |  TST_loss: 0.5728 TST_MAE_: 0.3071 TST_RMSLE: 0.5460 TST_VAL_: 0.8501 TST_mean_squared_error: 63418094.1007 TST_MAPE_: 0.4500 ///  TRN_loss: 0.6199 TRN_MAE_: 0.5051 TRN_RMSLE: 0.5932 TRN_VAL_: 0.5734 TRN_mean_squared_error: 70941706.7240 TRN_MAPE_: 0.4433\n",
            "# 0038 |  TST_loss: 0.5573 TST_MAE_: 0.3008 TST_RMSLE: 0.5305 TST_VAL_: 0.9086 TST_mean_squared_error: 63407915.4812 TST_MAPE_: 0.4614 ///  TRN_loss: 0.6159 TRN_MAE_: 0.5031 TRN_RMSLE: 0.5891 TRN_VAL_: 0.5752 TRN_mean_squared_error: 70933529.9806 TRN_MAPE_: 0.4398\n",
            "# 0039 |  TST_loss: 0.5563 TST_MAE_: 0.3016 TST_RMSLE: 0.5294 TST_VAL_: 0.8283 TST_mean_squared_error: 63401568.4198 TST_MAPE_: 0.4213 ///  TRN_loss: 0.6143 TRN_MAE_: 0.5008 TRN_RMSLE: 0.5875 TRN_VAL_: 0.5780 TRN_mean_squared_error: 70925717.7266 TRN_MAPE_: 0.4395\n",
            "# 0040 |  TST_loss: 0.5499 TST_MAE_: 0.2963 TST_RMSLE: 0.5229 TST_VAL_: 0.8656 TST_mean_squared_error: 63395265.7317 TST_MAPE_: 0.4404 ///  TRN_loss: 0.6132 TRN_MAE_: 0.4992 TRN_RMSLE: 0.5863 TRN_VAL_: 0.5797 TRN_mean_squared_error: 70918508.8498 TRN_MAPE_: 0.4379\n",
            "# 0041 |  TST_loss: 0.5591 TST_MAE_: 0.3006 TST_RMSLE: 0.5320 TST_VAL_: 0.8844 TST_mean_squared_error: 63386385.1268 TST_MAPE_: 0.4555 ///  TRN_loss: 0.6089 TRN_MAE_: 0.4970 TRN_RMSLE: 0.5820 TRN_VAL_: 0.5819 TRN_mean_squared_error: 70909902.4910 TRN_MAPE_: 0.4351\n",
            "# 0042 |  TST_loss: 0.5725 TST_MAE_: 0.3053 TST_RMSLE: 0.5455 TST_VAL_: 0.8799 TST_mean_squared_error: 63375891.6567 TST_MAPE_: 0.4589 ///  TRN_loss: 0.6088 TRN_MAE_: 0.4955 TRN_RMSLE: 0.5817 TRN_VAL_: 0.5838 TRN_mean_squared_error: 70902724.5496 TRN_MAPE_: 0.4348\n",
            "# 0043 |  TST_loss: 0.5515 TST_MAE_: 0.2936 TST_RMSLE: 0.5244 TST_VAL_: 0.8995 TST_mean_squared_error: 63372524.2764 TST_MAPE_: 0.4561 ///  TRN_loss: 0.6054 TRN_MAE_: 0.4939 TRN_RMSLE: 0.5783 TRN_VAL_: 0.5854 TRN_mean_squared_error: 70895261.2204 TRN_MAPE_: 0.4327\n",
            "# 0044 |  TST_loss: 0.5425 TST_MAE_: 0.2895 TST_RMSLE: 0.5154 TST_VAL_: 0.8626 TST_mean_squared_error: 63365460.5177 TST_MAPE_: 0.4197 ///  TRN_loss: 0.6048 TRN_MAE_: 0.4922 TRN_RMSLE: 0.5776 TRN_VAL_: 0.5875 TRN_mean_squared_error: 70888496.1764 TRN_MAPE_: 0.4330\n",
            "# 0045 |  TST_loss: 0.5390 TST_MAE_: 0.2906 TST_RMSLE: 0.5117 TST_VAL_: 0.9005 TST_mean_squared_error: 63359994.8110 TST_MAPE_: 0.4364 ///  TRN_loss: 0.6036 TRN_MAE_: 0.4914 TRN_RMSLE: 0.5763 TRN_VAL_: 0.5886 TRN_mean_squared_error: 70881694.1332 TRN_MAPE_: 0.4317\n",
            "# 0046 |  TST_loss: 0.5465 TST_MAE_: 0.2918 TST_RMSLE: 0.5192 TST_VAL_: 0.8813 TST_mean_squared_error: 63351900.7329 TST_MAPE_: 0.4362 ///  TRN_loss: 0.6014 TRN_MAE_: 0.4895 TRN_RMSLE: 0.5741 TRN_VAL_: 0.5904 TRN_mean_squared_error: 70874853.2016 TRN_MAPE_: 0.4295\n",
            "# 0047 |  TST_loss: 0.5415 TST_MAE_: 0.2884 TST_RMSLE: 0.5140 TST_VAL_: 0.8832 TST_mean_squared_error: 63349185.5251 TST_MAPE_: 0.4282 ///  TRN_loss: 0.6011 TRN_MAE_: 0.4875 TRN_RMSLE: 0.5737 TRN_VAL_: 0.5929 TRN_mean_squared_error: 70867937.6252 TRN_MAPE_: 0.4304\n",
            "# 0048 |  TST_loss: 0.5424 TST_MAE_: 0.2909 TST_RMSLE: 0.5149 TST_VAL_: 0.8826 TST_mean_squared_error: 63337294.8912 TST_MAPE_: 0.4357 ///  TRN_loss: 0.5988 TRN_MAE_: 0.4863 TRN_RMSLE: 0.5713 TRN_VAL_: 0.5940 TRN_mean_squared_error: 70862811.4770 TRN_MAPE_: 0.4280\n",
            "# 0049 |  TST_loss: 0.5365 TST_MAE_: 0.2853 TST_RMSLE: 0.5089 TST_VAL_: 0.8672 TST_mean_squared_error: 63336675.7365 TST_MAPE_: 0.4199 ///  TRN_loss: 0.5967 TRN_MAE_: 0.4849 TRN_RMSLE: 0.5692 TRN_VAL_: 0.5956 TRN_mean_squared_error: 70854867.8479 TRN_MAPE_: 0.4270\n",
            "# 0050 |  TST_loss: 0.5539 TST_MAE_: 0.2943 TST_RMSLE: 0.5264 TST_VAL_: 0.8598 TST_mean_squared_error: 63329701.7185 TST_MAPE_: 0.4284 ///  TRN_loss: 0.5956 TRN_MAE_: 0.4832 TRN_RMSLE: 0.5680 TRN_VAL_: 0.5975 TRN_mean_squared_error: 70849119.4287 TRN_MAPE_: 0.4262\n",
            "# 0051 |  TST_loss: 0.5377 TST_MAE_: 0.2868 TST_RMSLE: 0.5100 TST_VAL_: 0.9055 TST_mean_squared_error: 63320071.9023 TST_MAPE_: 0.4411 ///  TRN_loss: 0.5941 TRN_MAE_: 0.4826 TRN_RMSLE: 0.5664 TRN_VAL_: 0.5981 TRN_mean_squared_error: 70842666.5356 TRN_MAPE_: 0.4252\n",
            "# 0052 |  TST_loss: 0.5600 TST_MAE_: 0.2966 TST_RMSLE: 0.5323 TST_VAL_: 0.9029 TST_mean_squared_error: 63320602.4763 TST_MAPE_: 0.4524 ///  TRN_loss: 0.5945 TRN_MAE_: 0.4810 TRN_RMSLE: 0.5667 TRN_VAL_: 0.6001 TRN_mean_squared_error: 70836577.5265 TRN_MAPE_: 0.4261\n",
            "# 0053 |  TST_loss: 0.5393 TST_MAE_: 0.2877 TST_RMSLE: 0.5115 TST_VAL_: 0.8935 TST_mean_squared_error: 63308892.4718 TST_MAPE_: 0.4362 ///  TRN_loss: 0.5911 TRN_MAE_: 0.4789 TRN_RMSLE: 0.5633 TRN_VAL_: 0.6023 TRN_mean_squared_error: 70830399.1410 TRN_MAPE_: 0.4230\n",
            "# 0054 |  TST_loss: 0.5514 TST_MAE_: 0.3017 TST_RMSLE: 0.5235 TST_VAL_: 0.9079 TST_mean_squared_error: 63306154.6907 TST_MAPE_: 0.4548 ///  TRN_loss: 0.5909 TRN_MAE_: 0.4785 TRN_RMSLE: 0.5631 TRN_VAL_: 0.6029 TRN_mean_squared_error: 70824217.7873 TRN_MAPE_: 0.4235\n",
            "# 0055 |  TST_loss: 0.5392 TST_MAE_: 0.2856 TST_RMSLE: 0.5113 TST_VAL_: 0.9109 TST_mean_squared_error: 63297867.0661 TST_MAPE_: 0.4423 ///  TRN_loss: 0.5895 TRN_MAE_: 0.4766 TRN_RMSLE: 0.5616 TRN_VAL_: 0.6051 TRN_mean_squared_error: 70818664.8287 TRN_MAPE_: 0.4218\n",
            "# 0056 |  TST_loss: 0.5446 TST_MAE_: 0.2886 TST_RMSLE: 0.5166 TST_VAL_: 0.9074 TST_mean_squared_error: 63292017.6337 TST_MAPE_: 0.4310 ///  TRN_loss: 0.5898 TRN_MAE_: 0.4755 TRN_RMSLE: 0.5618 TRN_VAL_: 0.6062 TRN_mean_squared_error: 70814698.4616 TRN_MAPE_: 0.4225\n",
            "# 0057 |  TST_loss: 0.5298 TST_MAE_: 0.2823 TST_RMSLE: 0.5018 TST_VAL_: 0.8760 TST_mean_squared_error: 63286747.2443 TST_MAPE_: 0.4155 ///  TRN_loss: 0.5869 TRN_MAE_: 0.4744 TRN_RMSLE: 0.5589 TRN_VAL_: 0.6073 TRN_mean_squared_error: 70807569.3302 TRN_MAPE_: 0.4209\n",
            "# 0058 |  TST_loss: 0.5280 TST_MAE_: 0.2798 TST_RMSLE: 0.4999 TST_VAL_: 0.8769 TST_mean_squared_error: 63281673.9346 TST_MAPE_: 0.4209 ///  TRN_loss: 0.5869 TRN_MAE_: 0.4735 TRN_RMSLE: 0.5588 TRN_VAL_: 0.6086 TRN_mean_squared_error: 70802281.0371 TRN_MAPE_: 0.4208\n",
            "# 0059 |  TST_loss: 0.5412 TST_MAE_: 0.2873 TST_RMSLE: 0.5130 TST_VAL_: 0.9337 TST_mean_squared_error: 63276391.1407 TST_MAPE_: 0.4555 ///  TRN_loss: 0.5862 TRN_MAE_: 0.4725 TRN_RMSLE: 0.5580 TRN_VAL_: 0.6097 TRN_mean_squared_error: 70796457.5072 TRN_MAPE_: 0.4200\n",
            "# 0060 |  TST_loss: 0.5443 TST_MAE_: 0.2877 TST_RMSLE: 0.5160 TST_VAL_: 0.8680 TST_mean_squared_error: 63273213.3540 TST_MAPE_: 0.4195 ///  TRN_loss: 0.5858 TRN_MAE_: 0.4712 TRN_RMSLE: 0.5576 TRN_VAL_: 0.6112 TRN_mean_squared_error: 70791254.7177 TRN_MAPE_: 0.4199\n",
            "# 0061 |  TST_loss: 0.5314 TST_MAE_: 0.2801 TST_RMSLE: 0.5031 TST_VAL_: 0.8907 TST_mean_squared_error: 63269851.4098 TST_MAPE_: 0.4283 ///  TRN_loss: 0.5831 TRN_MAE_: 0.4699 TRN_RMSLE: 0.5548 TRN_VAL_: 0.6126 TRN_mean_squared_error: 70785901.5074 TRN_MAPE_: 0.4178\n",
            "# 0062 |  TST_loss: 0.5213 TST_MAE_: 0.2761 TST_RMSLE: 0.4931 TST_VAL_: 0.8872 TST_mean_squared_error: 63261506.0197 TST_MAPE_: 0.4110 ///  TRN_loss: 0.5819 TRN_MAE_: 0.4690 TRN_RMSLE: 0.5536 TRN_VAL_: 0.6136 TRN_mean_squared_error: 70780333.9413 TRN_MAPE_: 0.4177\n",
            "# 0063 |  TST_loss: 0.5350 TST_MAE_: 0.2843 TST_RMSLE: 0.5065 TST_VAL_: 0.8625 TST_mean_squared_error: 63261994.4682 TST_MAPE_: 0.4159 ///  TRN_loss: 0.5833 TRN_MAE_: 0.4683 TRN_RMSLE: 0.5549 TRN_VAL_: 0.6149 TRN_mean_squared_error: 70776217.8990 TRN_MAPE_: 0.4184\n",
            "# 0064 |  TST_loss: 0.5239 TST_MAE_: 0.2771 TST_RMSLE: 0.4955 TST_VAL_: 0.8730 TST_mean_squared_error: 63252434.1804 TST_MAPE_: 0.4070 ///  TRN_loss: 0.5817 TRN_MAE_: 0.4674 TRN_RMSLE: 0.5533 TRN_VAL_: 0.6160 TRN_mean_squared_error: 70770980.3337 TRN_MAPE_: 0.4175\n",
            "# 0065 |  TST_loss: 0.5326 TST_MAE_: 0.2825 TST_RMSLE: 0.5040 TST_VAL_: 0.9086 TST_mean_squared_error: 63246885.2719 TST_MAPE_: 0.4354 ///  TRN_loss: 0.5801 TRN_MAE_: 0.4660 TRN_RMSLE: 0.5516 TRN_VAL_: 0.6168 TRN_mean_squared_error: 70766365.4672 TRN_MAPE_: 0.4163\n",
            "# 0066 |  TST_loss: 0.5238 TST_MAE_: 0.2766 TST_RMSLE: 0.4952 TST_VAL_: 0.8661 TST_mean_squared_error: 63243625.4260 TST_MAPE_: 0.4019 ///  TRN_loss: 0.5791 TRN_MAE_: 0.4654 TRN_RMSLE: 0.5506 TRN_VAL_: 0.6182 TRN_mean_squared_error: 70760880.3655 TRN_MAPE_: 0.4157\n",
            "# 0067 |  TST_loss: 0.5297 TST_MAE_: 0.2802 TST_RMSLE: 0.5010 TST_VAL_: 0.9148 TST_mean_squared_error: 63239686.6571 TST_MAPE_: 0.4359 ///  TRN_loss: 0.5781 TRN_MAE_: 0.4635 TRN_RMSLE: 0.5495 TRN_VAL_: 0.6198 TRN_mean_squared_error: 70756821.0987 TRN_MAPE_: 0.4157\n",
            "# 0068 |  TST_loss: 0.5240 TST_MAE_: 0.2763 TST_RMSLE: 0.4954 TST_VAL_: 0.9054 TST_mean_squared_error: 63236078.7608 TST_MAPE_: 0.4214 ///  TRN_loss: 0.5767 TRN_MAE_: 0.4627 TRN_RMSLE: 0.5480 TRN_VAL_: 0.6210 TRN_mean_squared_error: 70752809.3361 TRN_MAPE_: 0.4140\n",
            "# 0069 |  TST_loss: 0.5252 TST_MAE_: 0.2767 TST_RMSLE: 0.4964 TST_VAL_: 0.8752 TST_mean_squared_error: 63230218.9427 TST_MAPE_: 0.4050 ///  TRN_loss: 0.5785 TRN_MAE_: 0.4629 TRN_RMSLE: 0.5497 TRN_VAL_: 0.6217 TRN_mean_squared_error: 70748144.9152 TRN_MAPE_: 0.4157\n",
            "# 0070 |  TST_loss: 0.5287 TST_MAE_: 0.2791 TST_RMSLE: 0.5000 TST_VAL_: 0.8914 TST_mean_squared_error: 63225933.4390 TST_MAPE_: 0.4165 ///  TRN_loss: 0.5760 TRN_MAE_: 0.4614 TRN_RMSLE: 0.5472 TRN_VAL_: 0.6224 TRN_mean_squared_error: 70742662.3046 TRN_MAPE_: 0.4137\n",
            "# 0071 |  TST_loss: 0.5213 TST_MAE_: 0.2764 TST_RMSLE: 0.4925 TST_VAL_: 0.8726 TST_mean_squared_error: 63223274.8942 TST_MAPE_: 0.4119 ///  TRN_loss: 0.5745 TRN_MAE_: 0.4608 TRN_RMSLE: 0.5457 TRN_VAL_: 0.6229 TRN_mean_squared_error: 70738313.7600 TRN_MAPE_: 0.4117\n",
            "# 0072 |  TST_loss: 0.5236 TST_MAE_: 0.2785 TST_RMSLE: 0.4947 TST_VAL_: 0.9014 TST_mean_squared_error: 63219890.8715 TST_MAPE_: 0.4234 ///  TRN_loss: 0.5737 TRN_MAE_: 0.4595 TRN_RMSLE: 0.5449 TRN_VAL_: 0.6245 TRN_mean_squared_error: 70734794.4613 TRN_MAPE_: 0.4115\n",
            "# 0073 |  TST_loss: 0.5443 TST_MAE_: 0.2909 TST_RMSLE: 0.5154 TST_VAL_: 0.9623 TST_mean_squared_error: 63216112.4358 TST_MAPE_: 0.4718 ///  TRN_loss: 0.5745 TRN_MAE_: 0.4588 TRN_RMSLE: 0.5456 TRN_VAL_: 0.6254 TRN_mean_squared_error: 70731021.3554 TRN_MAPE_: 0.4128\n",
            "# 0074 |  TST_loss: 0.5173 TST_MAE_: 0.2731 TST_RMSLE: 0.4884 TST_VAL_: 0.8892 TST_mean_squared_error: 63213420.3208 TST_MAPE_: 0.4096 ///  TRN_loss: 0.5731 TRN_MAE_: 0.4580 TRN_RMSLE: 0.5442 TRN_VAL_: 0.6264 TRN_mean_squared_error: 70727295.7975 TRN_MAPE_: 0.4114\n",
            "# 0075 |  TST_loss: 0.5464 TST_MAE_: 0.2834 TST_RMSLE: 0.5175 TST_VAL_: 0.9130 TST_mean_squared_error: 63204786.5420 TST_MAPE_: 0.4536 ///  TRN_loss: 0.5717 TRN_MAE_: 0.4570 TRN_RMSLE: 0.5428 TRN_VAL_: 0.6275 TRN_mean_squared_error: 70723196.3260 TRN_MAPE_: 0.4108\n",
            "# 0075 |  TST_loss: 0.5464 TST_MAE_: 0.2834 TST_RMSLE: 0.5175 TST_VAL_: 0.9130 TST_mean_squared_error: 63204786.5420 TST_MAPE_: 0.4536 ///  TRN_loss: 0.5717 TRN_MAE_: 0.4570 TRN_RMSLE: 0.5428 TRN_VAL_: 0.6275 TRN_mean_squared_error: 70723196.3260 TRN_MAPE_: 0.4108\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qy1YnwWo01Cq",
        "outputId": "d80513b7-a3a9-42de-fed8-fa5af2526787",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for lr in [0.007]:\n",
        "  opt = Adam(lr = lr)\n",
        "  epochs = 70\n",
        "  meter = 1\n",
        "  batch_size = 720\n",
        "\n",
        "  val = df[(df['meter'] == meter) & (df['day']%6 == 0) & (df['k_NN_ERR'] < 100) & (df['k_NN_ERR'] > 1/100) & (df['IS_BAD_PRCNT'] < 0.45)]\n",
        "  df_cleared = df[(df['k_NN_ERR']<50) & (df['k_NN_ERR']>1/50) & (df['day']%6 != 0) & (df['meter']==meter) & (df['IS_BAD_PRCNT']<0.45)][In_Columns + [Out_Columns]]\n",
        "\n",
        "  print('*'*9, lr, '*'*33)\n",
        "  nn_1.compile(optimizer = opt, loss = RMSLE, metrics=[ MAE_, RMSLE, VAL_, 'mse', MAPE_ ])\n",
        "  hist = nn_1.fit( df_cleared[In_Columns], df_cleared[Out_Columns], batch_size = batch_size, verbose = 0\n",
        "                  , epochs = epochs, shuffle = True, callbacks=[ MyCustomCallback(epochs, 1), earlyStopping, reduce_lr_loss]\n",
        "                  , validation_data=(val[In_Columns], val[Out_Columns])\n",
        "                  ) \n",
        "  nn_1.save(DIR + str(meter) + 'HANDLY_SAVED_3.MODEL')\n",
        "  gc.collect()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "********* 0.007 *********************************\n",
            "# 0001 |  TST_loss: 0.7098 TST_MAE_: 0.3477 TST_RMSLE: 0.6628 TST_VAL_: 0.9297 TST_mean_squared_error: 72204742.1120 TST_MAPE_: 0.6525 ///  TRN_loss: 0.6867 TRN_MAE_: 0.4424 TRN_RMSLE: 0.6432 TRN_VAL_: 0.6701 TRN_mean_squared_error: 68614348.7748 TRN_MAPE_: 0.5628\n",
            "# 0002 |  TST_loss: 0.6679 TST_MAE_: 0.3217 TST_RMSLE: 0.6161 TST_VAL_: 0.9048 TST_mean_squared_error: 72206036.0513 TST_MAPE_: 0.5964 ///  TRN_loss: 0.6954 TRN_MAE_: 0.4445 TRN_RMSLE: 0.6457 TRN_VAL_: 0.6698 TRN_mean_squared_error: 68617318.2252 TRN_MAPE_: 0.5663\n",
            "# 0003 |  TST_loss: 0.6755 TST_MAE_: 0.3328 TST_RMSLE: 0.6204 TST_VAL_: 0.8534 TST_mean_squared_error: 72200849.8137 TST_MAPE_: 0.5563 ///  TRN_loss: 0.7034 TRN_MAE_: 0.4461 TRN_RMSLE: 0.6495 TRN_VAL_: 0.6682 TRN_mean_squared_error: 68614370.5538 TRN_MAPE_: 0.5704\n",
            ".......\n",
            "# 0004 |  TST_loss: 0.6777 TST_MAE_: 0.3253 TST_RMSLE: 0.6202 TST_VAL_: 0.8805 TST_mean_squared_error: 72206518.2538 TST_MAPE_: 0.5817 ///  TRN_loss: 0.7047 TRN_MAE_: 0.4454 TRN_RMSLE: 0.6483 TRN_VAL_: 0.6686 TRN_mean_squared_error: 68612474.9302 TRN_MAPE_: 0.5697\n",
            "# 0005 |  TST_loss: 0.7233 TST_MAE_: 0.3361 TST_RMSLE: 0.6636 TST_VAL_: 0.8518 TST_mean_squared_error: 72181697.5206 TST_MAPE_: 0.5713 ///  TRN_loss: 0.7075 TRN_MAE_: 0.4449 TRN_RMSLE: 0.6490 TRN_VAL_: 0.6700 TRN_mean_squared_error: 68608400.0982 TRN_MAPE_: 0.5710\n",
            "# 0006 |  TST_loss: 0.7105 TST_MAE_: 0.3292 TST_RMSLE: 0.6494 TST_VAL_: 0.8554 TST_mean_squared_error: 72181291.0727 TST_MAPE_: 0.5702 ///  TRN_loss: 0.7108 TRN_MAE_: 0.4459 TRN_RMSLE: 0.6505 TRN_VAL_: 0.6694 TRN_mean_squared_error: 68603223.2299 TRN_MAPE_: 0.5719\n",
            "\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.002100000064820051.\n",
            "# 0007 |  TST_loss: 0.6206 TST_MAE_: 0.2903 TST_RMSLE: 0.5636 TST_VAL_: 0.8885 TST_mean_squared_error: 72167239.9156 TST_MAPE_: 0.5129 ///  TRN_loss: 0.6329 TRN_MAE_: 0.4298 TRN_RMSLE: 0.5740 TRN_VAL_: 0.6720 TRN_mean_squared_error: 68580562.7877 TRN_MAPE_: 0.5024\n",
            "# 0008 |  TST_loss: 0.6014 TST_MAE_: 0.2861 TST_RMSLE: 0.5470 TST_VAL_: 0.9034 TST_mean_squared_error: 72161979.6155 TST_MAPE_: 0.5143 ///  TRN_loss: 0.6159 TRN_MAE_: 0.4255 TRN_RMSLE: 0.5602 TRN_VAL_: 0.6736 TRN_mean_squared_error: 68575353.5118 TRN_MAPE_: 0.4879\n",
            "# 0009 |  TST_loss: 0.5881 TST_MAE_: 0.2789 TST_RMSLE: 0.5356 TST_VAL_: 0.9144 TST_mean_squared_error: 72159758.2714 TST_MAPE_: 0.5005 ///  TRN_loss: 0.6087 TRN_MAE_: 0.4244 TRN_RMSLE: 0.5553 TRN_VAL_: 0.6728 TRN_mean_squared_error: 68573499.1907 TRN_MAPE_: 0.4823\n",
            "# 0010 |  TST_loss: 0.5940 TST_MAE_: 0.2828 TST_RMSLE: 0.5430 TST_VAL_: 0.9134 TST_mean_squared_error: 72157984.0552 TST_MAPE_: 0.4966 ///  TRN_loss: 0.6029 TRN_MAE_: 0.4238 TRN_RMSLE: 0.5511 TRN_VAL_: 0.6728 TRN_mean_squared_error: 68571191.3257 TRN_MAPE_: 0.4781\n",
            "# 0011 |  TST_loss: 0.5862 TST_MAE_: 0.2781 TST_RMSLE: 0.5364 TST_VAL_: 0.9210 TST_mean_squared_error: 72159747.6344 TST_MAPE_: 0.5039 ///  TRN_loss: 0.6001 TRN_MAE_: 0.4230 TRN_RMSLE: 0.5497 TRN_VAL_: 0.6730 TRN_mean_squared_error: 68570246.8864 TRN_MAPE_: 0.4762\n",
            "# 0012 |  TST_loss: 0.5818 TST_MAE_: 0.2773 TST_RMSLE: 0.5331 TST_VAL_: 0.8982 TST_mean_squared_error: 72155117.9265 TST_MAPE_: 0.5012 ///  TRN_loss: 0.5946 TRN_MAE_: 0.4214 TRN_RMSLE: 0.5453 TRN_VAL_: 0.6740 TRN_mean_squared_error: 68568111.8247 TRN_MAPE_: 0.4717\n",
            "# 0013 |  TST_loss: 0.5877 TST_MAE_: 0.2809 TST_RMSLE: 0.5398 TST_VAL_: 0.8768 TST_mean_squared_error: 72155642.5119 TST_MAPE_: 0.5045 ///  TRN_loss: 0.5929 TRN_MAE_: 0.4224 TRN_RMSLE: 0.5446 TRN_VAL_: 0.6729 TRN_mean_squared_error: 68566577.9024 TRN_MAPE_: 0.4710\n",
            "# 0014 |  TST_loss: 0.5836 TST_MAE_: 0.2801 TST_RMSLE: 0.5364 TST_VAL_: 0.8560 TST_mean_squared_error: 72158373.6986 TST_MAPE_: 0.4792 ///  TRN_loss: 0.5909 TRN_MAE_: 0.4209 TRN_RMSLE: 0.5434 TRN_VAL_: 0.6741 TRN_mean_squared_error: 68565229.7997 TRN_MAPE_: 0.4694\n",
            "# 0015 |  TST_loss: 0.5792 TST_MAE_: 0.2771 TST_RMSLE: 0.5327 TST_VAL_: 0.9272 TST_mean_squared_error: 72149368.1829 TST_MAPE_: 0.5053 ///  TRN_loss: 0.5886 TRN_MAE_: 0.4207 TRN_RMSLE: 0.5418 TRN_VAL_: 0.6743 TRN_mean_squared_error: 68563351.1931 TRN_MAPE_: 0.4678\n",
            "# 0016 |  TST_loss: 0.5745 TST_MAE_: 0.2739 TST_RMSLE: 0.5286 TST_VAL_: 0.9276 TST_mean_squared_error: 72147891.4313 TST_MAPE_: 0.5065 ///  TRN_loss: 0.5873 TRN_MAE_: 0.4190 TRN_RMSLE: 0.5411 TRN_VAL_: 0.6759 TRN_mean_squared_error: 68562276.1730 TRN_MAPE_: 0.4671\n",
            "# 0017 |  TST_loss: 0.5821 TST_MAE_: 0.2817 TST_RMSLE: 0.5366 TST_VAL_: 0.8487 TST_mean_squared_error: 72152023.5337 TST_MAPE_: 0.4853 ///  TRN_loss: 0.5870 TRN_MAE_: 0.4195 TRN_RMSLE: 0.5413 TRN_VAL_: 0.6755 TRN_mean_squared_error: 68560866.0335 TRN_MAPE_: 0.4670\n",
            "# 0018 |  TST_loss: 0.5715 TST_MAE_: 0.2733 TST_RMSLE: 0.5265 TST_VAL_: 0.9257 TST_mean_squared_error: 72144568.2269 TST_MAPE_: 0.4870 ///  TRN_loss: 0.5846 TRN_MAE_: 0.4192 TRN_RMSLE: 0.5393 TRN_VAL_: 0.6754 TRN_mean_squared_error: 68559212.3426 TRN_MAPE_: 0.4650\n",
            "# 0019 |  TST_loss: 0.5763 TST_MAE_: 0.2774 TST_RMSLE: 0.5316 TST_VAL_: 0.9366 TST_mean_squared_error: 72144702.9100 TST_MAPE_: 0.4902 ///  TRN_loss: 0.5836 TRN_MAE_: 0.4186 TRN_RMSLE: 0.5388 TRN_VAL_: 0.6761 TRN_mean_squared_error: 68557622.3054 TRN_MAPE_: 0.4640\n",
            "# 0020 |  TST_loss: 0.5724 TST_MAE_: 0.2720 TST_RMSLE: 0.5281 TST_VAL_: 0.8812 TST_mean_squared_error: 72145338.1952 TST_MAPE_: 0.4764 ///  TRN_loss: 0.5825 TRN_MAE_: 0.4182 TRN_RMSLE: 0.5380 TRN_VAL_: 0.6768 TRN_mean_squared_error: 68557552.7051 TRN_MAPE_: 0.4639\n",
            "# 0021 |  TST_loss: 0.5700 TST_MAE_: 0.2724 TST_RMSLE: 0.5259 TST_VAL_: 0.8841 TST_mean_squared_error: 72144154.0915 TST_MAPE_: 0.4565 ///  TRN_loss: 0.5819 TRN_MAE_: 0.4177 TRN_RMSLE: 0.5377 TRN_VAL_: 0.6771 TRN_mean_squared_error: 68554792.5843 TRN_MAPE_: 0.4628\n",
            "# 0022 |  TST_loss: 0.5704 TST_MAE_: 0.2727 TST_RMSLE: 0.5267 TST_VAL_: 0.8897 TST_mean_squared_error: 72140522.5672 TST_MAPE_: 0.4823 ///  TRN_loss: 0.5808 TRN_MAE_: 0.4169 TRN_RMSLE: 0.5370 TRN_VAL_: 0.6777 TRN_mean_squared_error: 68553222.8784 TRN_MAPE_: 0.4626\n",
            "# 0023 |  TST_loss: 0.5682 TST_MAE_: 0.2713 TST_RMSLE: 0.5247 TST_VAL_: 0.9112 TST_mean_squared_error: 72138472.9813 TST_MAPE_: 0.4875 ///  TRN_loss: 0.5807 TRN_MAE_: 0.4175 TRN_RMSLE: 0.5370 TRN_VAL_: 0.6771 TRN_mean_squared_error: 68552746.5321 TRN_MAPE_: 0.4625\n",
            "# 0024 |  TST_loss: 0.5667 TST_MAE_: 0.2699 TST_RMSLE: 0.5234 TST_VAL_: 0.9119 TST_mean_squared_error: 72136828.4308 TST_MAPE_: 0.4874 ///  TRN_loss: 0.5792 TRN_MAE_: 0.4170 TRN_RMSLE: 0.5359 TRN_VAL_: 0.6777 TRN_mean_squared_error: 68551434.0820 TRN_MAPE_: 0.4612\n",
            "# 0025 |  TST_loss: 0.5722 TST_MAE_: 0.2718 TST_RMSLE: 0.5292 TST_VAL_: 0.8962 TST_mean_squared_error: 72138853.5818 TST_MAPE_: 0.5017 ///  TRN_loss: 0.5784 TRN_MAE_: 0.4165 TRN_RMSLE: 0.5352 TRN_VAL_: 0.6780 TRN_mean_squared_error: 68549011.9705 TRN_MAPE_: 0.4607\n",
            "# 0026 |  TST_loss: 0.5703 TST_MAE_: 0.2712 TST_RMSLE: 0.5274 TST_VAL_: 0.9221 TST_mean_squared_error: 72136953.0851 TST_MAPE_: 0.5116 ///  TRN_loss: 0.5775 TRN_MAE_: 0.4165 TRN_RMSLE: 0.5346 TRN_VAL_: 0.6781 TRN_mean_squared_error: 68548204.5946 TRN_MAPE_: 0.4606\n",
            "# 0027 |  TST_loss: 0.5730 TST_MAE_: 0.2729 TST_RMSLE: 0.5303 TST_VAL_: 0.9128 TST_mean_squared_error: 72136807.1792 TST_MAPE_: 0.4993 ///  TRN_loss: 0.5772 TRN_MAE_: 0.4162 TRN_RMSLE: 0.5344 TRN_VAL_: 0.6785 TRN_mean_squared_error: 68546719.2682 TRN_MAPE_: 0.4599\n",
            "# 0028 |  TST_loss: 0.5654 TST_MAE_: 0.2708 TST_RMSLE: 0.5228 TST_VAL_: 0.9077 TST_mean_squared_error: 72133061.2507 TST_MAPE_: 0.4877 ///  TRN_loss: 0.5786 TRN_MAE_: 0.4172 TRN_RMSLE: 0.5359 TRN_VAL_: 0.6779 TRN_mean_squared_error: 68545815.3495 TRN_MAPE_: 0.4613\n",
            "# 0029 |  TST_loss: 0.5700 TST_MAE_: 0.2737 TST_RMSLE: 0.5276 TST_VAL_: 0.8859 TST_mean_squared_error: 72133127.2335 TST_MAPE_: 0.4632 ///  TRN_loss: 0.5770 TRN_MAE_: 0.4160 TRN_RMSLE: 0.5345 TRN_VAL_: 0.6789 TRN_mean_squared_error: 68544273.8820 TRN_MAPE_: 0.4601\n",
            "# 0030 |  TST_loss: 0.5667 TST_MAE_: 0.2715 TST_RMSLE: 0.5244 TST_VAL_: 0.8967 TST_mean_squared_error: 72131968.8611 TST_MAPE_: 0.4878 ///  TRN_loss: 0.5757 TRN_MAE_: 0.4151 TRN_RMSLE: 0.5334 TRN_VAL_: 0.6797 TRN_mean_squared_error: 68542873.4241 TRN_MAPE_: 0.4588\n",
            "# 0031 |  TST_loss: 0.5765 TST_MAE_: 0.2764 TST_RMSLE: 0.5343 TST_VAL_: 0.9030 TST_mean_squared_error: 72132438.1647 TST_MAPE_: 0.4740 ///  TRN_loss: 0.5767 TRN_MAE_: 0.4153 TRN_RMSLE: 0.5345 TRN_VAL_: 0.6793 TRN_mean_squared_error: 68542007.2122 TRN_MAPE_: 0.4597\n",
            "# 0032 |  TST_loss: 0.5647 TST_MAE_: 0.2697 TST_RMSLE: 0.5226 TST_VAL_: 0.9275 TST_mean_squared_error: 72135237.4891 TST_MAPE_: 0.4960 ///  TRN_loss: 0.5758 TRN_MAE_: 0.4158 TRN_RMSLE: 0.5336 TRN_VAL_: 0.6791 TRN_mean_squared_error: 68540013.9370 TRN_MAPE_: 0.4588\n",
            "# 0033 |  TST_loss: 0.5672 TST_MAE_: 0.2747 TST_RMSLE: 0.5252 TST_VAL_: 0.8651 TST_mean_squared_error: 72129113.7119 TST_MAPE_: 0.4687 ///  TRN_loss: 0.5742 TRN_MAE_: 0.4151 TRN_RMSLE: 0.5321 TRN_VAL_: 0.6793 TRN_mean_squared_error: 68538921.3169 TRN_MAPE_: 0.4577\n",
            "# 0034 |  TST_loss: 0.5814 TST_MAE_: 0.2807 TST_RMSLE: 0.5395 TST_VAL_: 0.9417 TST_mean_squared_error: 72127736.5353 TST_MAPE_: 0.5132 ///  TRN_loss: 0.5748 TRN_MAE_: 0.4142 TRN_RMSLE: 0.5329 TRN_VAL_: 0.6809 TRN_mean_squared_error: 68538148.3596 TRN_MAPE_: 0.4585\n",
            "# 0035 |  TST_loss: 0.5669 TST_MAE_: 0.2709 TST_RMSLE: 0.5250 TST_VAL_: 0.8949 TST_mean_squared_error: 72133813.6936 TST_MAPE_: 0.4861 ///  TRN_loss: 0.5749 TRN_MAE_: 0.4145 TRN_RMSLE: 0.5330 TRN_VAL_: 0.6807 TRN_mean_squared_error: 68536430.3821 TRN_MAPE_: 0.4587\n",
            "# 0036 |  TST_loss: 0.5608 TST_MAE_: 0.2680 TST_RMSLE: 0.5191 TST_VAL_: 0.9183 TST_mean_squared_error: 72119890.7096 TST_MAPE_: 0.4947 ///  TRN_loss: 0.5735 TRN_MAE_: 0.4140 TRN_RMSLE: 0.5317 TRN_VAL_: 0.6807 TRN_mean_squared_error: 68535125.6014 TRN_MAPE_: 0.4576\n",
            "# 0037 |  TST_loss: 0.5686 TST_MAE_: 0.2725 TST_RMSLE: 0.5270 TST_VAL_: 0.9044 TST_mean_squared_error: 72120618.0556 TST_MAPE_: 0.4834 ///  TRN_loss: 0.5740 TRN_MAE_: 0.4141 TRN_RMSLE: 0.5323 TRN_VAL_: 0.6809 TRN_mean_squared_error: 68533589.3110 TRN_MAPE_: 0.4575\n",
            "# 0038 |  TST_loss: 0.5621 TST_MAE_: 0.2675 TST_RMSLE: 0.5206 TST_VAL_: 0.8996 TST_mean_squared_error: 72119512.4362 TST_MAPE_: 0.4738 ///  TRN_loss: 0.5736 TRN_MAE_: 0.4139 TRN_RMSLE: 0.5319 TRN_VAL_: 0.6812 TRN_mean_squared_error: 68532420.1558 TRN_MAPE_: 0.4575\n",
            "# 0038 |  TST_loss: 0.5621 TST_MAE_: 0.2675 TST_RMSLE: 0.5206 TST_VAL_: 0.8996 TST_mean_squared_error: 72119512.4362 TST_MAPE_: 0.4738 ///  TRN_loss: 0.5736 TRN_MAE_: 0.4139 TRN_RMSLE: 0.5319 TRN_VAL_: 0.6812 TRN_mean_squared_error: 68532420.1558 TRN_MAPE_: 0.4575\n",
            "Epoch 00038: ReduceLROnPlateau reducing learning rate to 0.0006300000473856926.\n",
            "# 0039 |  TST_loss: 0.5504 TST_MAE_: 0.2636 TST_RMSLE: 0.5093 TST_VAL_: 0.8803 TST_mean_squared_error: 72117733.1065 TST_MAPE_: 0.4506 ///  TRN_loss: 0.5473 TRN_MAE_: 0.4098 TRN_RMSLE: 0.5060 TRN_VAL_: 0.6806 TRN_mean_squared_error: 68528046.2899 TRN_MAPE_: 0.4322\n",
            "# 0040 |  TST_loss: 0.5434 TST_MAE_: 0.2587 TST_RMSLE: 0.5026 TST_VAL_: 0.9156 TST_mean_squared_error: 72115753.7833 TST_MAPE_: 0.4529 ///  TRN_loss: 0.5443 TRN_MAE_: 0.4080 TRN_RMSLE: 0.5034 TRN_VAL_: 0.6818 TRN_mean_squared_error: 68527369.0588 TRN_MAPE_: 0.4289\n",
            "# 0041 |  TST_loss: 0.5433 TST_MAE_: 0.2584 TST_RMSLE: 0.5028 TST_VAL_: 0.9257 TST_mean_squared_error: 72115130.5207 TST_MAPE_: 0.4738 ///  TRN_loss: 0.5431 TRN_MAE_: 0.4073 TRN_RMSLE: 0.5025 TRN_VAL_: 0.6826 TRN_mean_squared_error: 68526747.2203 TRN_MAPE_: 0.4283\n",
            "# 0042 |  TST_loss: 0.5409 TST_MAE_: 0.2592 TST_RMSLE: 0.5006 TST_VAL_: 0.9153 TST_mean_squared_error: 72114679.8295 TST_MAPE_: 0.4590 ///  TRN_loss: 0.5425 TRN_MAE_: 0.4082 TRN_RMSLE: 0.5022 TRN_VAL_: 0.6815 TRN_mean_squared_error: 68526609.1576 TRN_MAPE_: 0.4277\n",
            "# 0043 |  TST_loss: 0.5394 TST_MAE_: 0.2573 TST_RMSLE: 0.4994 TST_VAL_: 0.9001 TST_mean_squared_error: 72114310.4750 TST_MAPE_: 0.4468 ///  TRN_loss: 0.5414 TRN_MAE_: 0.4070 TRN_RMSLE: 0.5013 TRN_VAL_: 0.6824 TRN_mean_squared_error: 68525889.9752 TRN_MAPE_: 0.4266\n",
            "# 0044 |  TST_loss: 0.5423 TST_MAE_: 0.2586 TST_RMSLE: 0.5026 TST_VAL_: 0.9209 TST_mean_squared_error: 72114088.9056 TST_MAPE_: 0.4577 ///  TRN_loss: 0.5409 TRN_MAE_: 0.4076 TRN_RMSLE: 0.5010 TRN_VAL_: 0.6816 TRN_mean_squared_error: 68525263.8208 TRN_MAPE_: 0.4263\n",
            "# 0045 |  TST_loss: 0.5393 TST_MAE_: 0.2578 TST_RMSLE: 0.4998 TST_VAL_: 0.8984 TST_mean_squared_error: 72113475.9518 TST_MAPE_: 0.4517 ///  TRN_loss: 0.5404 TRN_MAE_: 0.4073 TRN_RMSLE: 0.5007 TRN_VAL_: 0.6820 TRN_mean_squared_error: 68524766.0636 TRN_MAPE_: 0.4262\n",
            "# 0046 |  TST_loss: 0.5419 TST_MAE_: 0.2576 TST_RMSLE: 0.5026 TST_VAL_: 0.9232 TST_mean_squared_error: 72113496.1407 TST_MAPE_: 0.4690 ///  TRN_loss: 0.5396 TRN_MAE_: 0.4077 TRN_RMSLE: 0.5002 TRN_VAL_: 0.6815 TRN_mean_squared_error: 68524140.9568 TRN_MAPE_: 0.4257\n",
            "# 0047 |  TST_loss: 0.5470 TST_MAE_: 0.2620 TST_RMSLE: 0.5079 TST_VAL_: 0.9484 TST_mean_squared_error: 72110990.3149 TST_MAPE_: 0.4877 ///  TRN_loss: 0.5391 TRN_MAE_: 0.4076 TRN_RMSLE: 0.4998 TRN_VAL_: 0.6815 TRN_mean_squared_error: 68523584.5695 TRN_MAPE_: 0.4254\n",
            "# 0048 |  TST_loss: 0.5381 TST_MAE_: 0.2564 TST_RMSLE: 0.4992 TST_VAL_: 0.9175 TST_mean_squared_error: 72111834.3898 TST_MAPE_: 0.4379 ///  TRN_loss: 0.5386 TRN_MAE_: 0.4074 TRN_RMSLE: 0.4995 TRN_VAL_: 0.6819 TRN_mean_squared_error: 68523044.0509 TRN_MAPE_: 0.4253\n",
            "# 0049 |  TST_loss: 0.5401 TST_MAE_: 0.2589 TST_RMSLE: 0.5013 TST_VAL_: 0.8967 TST_mean_squared_error: 72111797.8933 TST_MAPE_: 0.4545 ///  TRN_loss: 0.5389 TRN_MAE_: 0.4074 TRN_RMSLE: 0.5000 TRN_VAL_: 0.6818 TRN_mean_squared_error: 68522431.1450 TRN_MAPE_: 0.4256\n",
            "# 0050 |  TST_loss: 0.5356 TST_MAE_: 0.2560 TST_RMSLE: 0.4970 TST_VAL_: 0.9112 TST_mean_squared_error: 72110389.2419 TST_MAPE_: 0.4577 ///  TRN_loss: 0.5389 TRN_MAE_: 0.4063 TRN_RMSLE: 0.5002 TRN_VAL_: 0.6832 TRN_mean_squared_error: 68521996.3509 TRN_MAPE_: 0.4257\n",
            "# 0051 |  TST_loss: 0.5369 TST_MAE_: 0.2581 TST_RMSLE: 0.4984 TST_VAL_: 0.9072 TST_mean_squared_error: 72109997.7557 TST_MAPE_: 0.4564 ///  TRN_loss: 0.5372 TRN_MAE_: 0.4068 TRN_RMSLE: 0.4986 TRN_VAL_: 0.6823 TRN_mean_squared_error: 68521450.0405 TRN_MAPE_: 0.4241\n",
            "# 0052 |  TST_loss: 0.5360 TST_MAE_: 0.2563 TST_RMSLE: 0.4977 TST_VAL_: 0.9006 TST_mean_squared_error: 72110228.9163 TST_MAPE_: 0.4351 ///  TRN_loss: 0.5371 TRN_MAE_: 0.4062 TRN_RMSLE: 0.4986 TRN_VAL_: 0.6831 TRN_mean_squared_error: 68521166.4883 TRN_MAPE_: 0.4242\n",
            "# 0053 |  TST_loss: 0.5447 TST_MAE_: 0.2598 TST_RMSLE: 0.5065 TST_VAL_: 0.9232 TST_mean_squared_error: 72110256.2644 TST_MAPE_: 0.4717 ///  TRN_loss: 0.5368 TRN_MAE_: 0.4065 TRN_RMSLE: 0.4985 TRN_VAL_: 0.6825 TRN_mean_squared_error: 68520159.4364 TRN_MAPE_: 0.4239\n",
            "# 0054 |  TST_loss: 0.5347 TST_MAE_: 0.2556 TST_RMSLE: 0.4966 TST_VAL_: 0.8993 TST_mean_squared_error: 72108723.7760 TST_MAPE_: 0.4515 ///  TRN_loss: 0.5364 TRN_MAE_: 0.4069 TRN_RMSLE: 0.4983 TRN_VAL_: 0.6821 TRN_mean_squared_error: 68519731.2095 TRN_MAPE_: 0.4237\n",
            "# 0055 |  TST_loss: 0.5398 TST_MAE_: 0.2584 TST_RMSLE: 0.5019 TST_VAL_: 0.8840 TST_mean_squared_error: 72108759.0727 TST_MAPE_: 0.4482 ///  TRN_loss: 0.5362 TRN_MAE_: 0.4068 TRN_RMSLE: 0.4981 TRN_VAL_: 0.6821 TRN_mean_squared_error: 68519261.2734 TRN_MAPE_: 0.4238\n",
            "# 0056 |  TST_loss: 0.5372 TST_MAE_: 0.2578 TST_RMSLE: 0.4993 TST_VAL_: 0.9104 TST_mean_squared_error: 72107148.3591 TST_MAPE_: 0.4546 ///  TRN_loss: 0.5363 TRN_MAE_: 0.4060 TRN_RMSLE: 0.4984 TRN_VAL_: 0.6833 TRN_mean_squared_error: 68518764.1532 TRN_MAPE_: 0.4240\n",
            "# 0057 |  TST_loss: 0.5346 TST_MAE_: 0.2567 TST_RMSLE: 0.4969 TST_VAL_: 0.8987 TST_mean_squared_error: 72107583.2957 TST_MAPE_: 0.4413 ///  TRN_loss: 0.5357 TRN_MAE_: 0.4053 TRN_RMSLE: 0.4979 TRN_VAL_: 0.6837 TRN_mean_squared_error: 68518280.5241 TRN_MAPE_: 0.4236\n",
            "# 0058 |  TST_loss: 0.5395 TST_MAE_: 0.2590 TST_RMSLE: 0.5018 TST_VAL_: 0.8920 TST_mean_squared_error: 72106461.0539 TST_MAPE_: 0.4560 ///  TRN_loss: 0.5353 TRN_MAE_: 0.4060 TRN_RMSLE: 0.4976 TRN_VAL_: 0.6832 TRN_mean_squared_error: 68517756.3022 TRN_MAPE_: 0.4235\n",
            "# 0059 |  TST_loss: 0.5328 TST_MAE_: 0.2542 TST_RMSLE: 0.4953 TST_VAL_: 0.9054 TST_mean_squared_error: 72105580.9908 TST_MAPE_: 0.4493 ///  TRN_loss: 0.5352 TRN_MAE_: 0.4053 TRN_RMSLE: 0.4977 TRN_VAL_: 0.6840 TRN_mean_squared_error: 68516995.8372 TRN_MAPE_: 0.4232\n",
            "# 0060 |  TST_loss: 0.5377 TST_MAE_: 0.2592 TST_RMSLE: 0.5003 TST_VAL_: 0.8820 TST_mean_squared_error: 72106859.4231 TST_MAPE_: 0.4427 ///  TRN_loss: 0.5344 TRN_MAE_: 0.4056 TRN_RMSLE: 0.4969 TRN_VAL_: 0.6834 TRN_mean_squared_error: 68516449.7311 TRN_MAPE_: 0.4222\n",
            "# 0061 |  TST_loss: 0.5373 TST_MAE_: 0.2571 TST_RMSLE: 0.5000 TST_VAL_: 0.9232 TST_mean_squared_error: 72104380.1694 TST_MAPE_: 0.4608 ///  TRN_loss: 0.5346 TRN_MAE_: 0.4057 TRN_RMSLE: 0.4973 TRN_VAL_: 0.6835 TRN_mean_squared_error: 68516176.3854 TRN_MAPE_: 0.4230\n",
            "# 0062 |  TST_loss: 0.5335 TST_MAE_: 0.2552 TST_RMSLE: 0.4962 TST_VAL_: 0.9220 TST_mean_squared_error: 72102814.3268 TST_MAPE_: 0.4604 ///  TRN_loss: 0.5343 TRN_MAE_: 0.4053 TRN_RMSLE: 0.4970 TRN_VAL_: 0.6841 TRN_mean_squared_error: 68515463.1041 TRN_MAPE_: 0.4225\n",
            "# 0063 |  TST_loss: 0.5355 TST_MAE_: 0.2551 TST_RMSLE: 0.4984 TST_VAL_: 0.9269 TST_mean_squared_error: 72102800.1374 TST_MAPE_: 0.4604 ///  TRN_loss: 0.5340 TRN_MAE_: 0.4055 TRN_RMSLE: 0.4968 TRN_VAL_: 0.6837 TRN_mean_squared_error: 68514966.4556 TRN_MAPE_: 0.4224\n",
            "# 0064 |  TST_loss: 0.5370 TST_MAE_: 0.2584 TST_RMSLE: 0.5000 TST_VAL_: 0.8802 TST_mean_squared_error: 72105336.1490 TST_MAPE_: 0.4539 ///  TRN_loss: 0.5338 TRN_MAE_: 0.4061 TRN_RMSLE: 0.4967 TRN_VAL_: 0.6830 TRN_mean_squared_error: 68514422.7741 TRN_MAPE_: 0.4222\n",
            "# 0065 |  TST_loss: 0.5340 TST_MAE_: 0.2554 TST_RMSLE: 0.4971 TST_VAL_: 0.9061 TST_mean_squared_error: 72102214.6924 TST_MAPE_: 0.4439 ///  TRN_loss: 0.5336 TRN_MAE_: 0.4051 TRN_RMSLE: 0.4966 TRN_VAL_: 0.6841 TRN_mean_squared_error: 68513933.0298 TRN_MAPE_: 0.4222\n",
            "# 0065 |  TST_loss: 0.5340 TST_MAE_: 0.2554 TST_RMSLE: 0.4971 TST_VAL_: 0.9061 TST_mean_squared_error: 72102214.6924 TST_MAPE_: 0.4439 ///  TRN_loss: 0.5336 TRN_MAE_: 0.4051 TRN_RMSLE: 0.4966 TRN_VAL_: 0.6841 TRN_mean_squared_error: 68513933.0298 TRN_MAPE_: 0.4222\n",
            "Epoch 00065: ReduceLROnPlateau reducing learning rate to 0.00018900000723078846.\n",
            "# 0066 |  TST_loss: 0.5283 TST_MAE_: 0.2525 TST_RMSLE: 0.4915 TST_VAL_: 0.9117 TST_mean_squared_error: 72101579.9502 TST_MAPE_: 0.4406 ///  TRN_loss: 0.5244 TRN_MAE_: 0.4039 TRN_RMSLE: 0.4875 TRN_VAL_: 0.6840 TRN_mean_squared_error: 68512726.2679 TRN_MAPE_: 0.4129\n",
            "# 0067 |  TST_loss: 0.5271 TST_MAE_: 0.2524 TST_RMSLE: 0.4903 TST_VAL_: 0.8993 TST_mean_squared_error: 72101972.2353 TST_MAPE_: 0.4382 ///  TRN_loss: 0.5236 TRN_MAE_: 0.4041 TRN_RMSLE: 0.4868 TRN_VAL_: 0.6833 TRN_mean_squared_error: 68512585.5661 TRN_MAPE_: 0.4118\n",
            "# 0068 |  TST_loss: 0.5262 TST_MAE_: 0.2518 TST_RMSLE: 0.4895 TST_VAL_: 0.9058 TST_mean_squared_error: 72101575.3846 TST_MAPE_: 0.4451 ///  TRN_loss: 0.5233 TRN_MAE_: 0.4034 TRN_RMSLE: 0.4866 TRN_VAL_: 0.6841 TRN_mean_squared_error: 68512397.4296 TRN_MAPE_: 0.4114\n",
            "# 0069 |  TST_loss: 0.5276 TST_MAE_: 0.2522 TST_RMSLE: 0.4909 TST_VAL_: 0.9026 TST_mean_squared_error: 72101434.8555 TST_MAPE_: 0.4439 ///  TRN_loss: 0.5231 TRN_MAE_: 0.4033 TRN_RMSLE: 0.4865 TRN_VAL_: 0.6842 TRN_mean_squared_error: 68512147.9321 TRN_MAPE_: 0.4113\n",
            "# 0070 |  TST_loss: 0.5267 TST_MAE_: 0.2523 TST_RMSLE: 0.4901 TST_VAL_: 0.9036 TST_mean_squared_error: 72101231.8824 TST_MAPE_: 0.4342 ///  TRN_loss: 0.5229 TRN_MAE_: 0.4028 TRN_RMSLE: 0.4863 TRN_VAL_: 0.6846 TRN_mean_squared_error: 68512143.2564 TRN_MAPE_: 0.4112\n",
            "# 0070 |  TST_loss: 0.5267 TST_MAE_: 0.2523 TST_RMSLE: 0.4901 TST_VAL_: 0.9036 TST_mean_squared_error: 72101231.8824 TST_MAPE_: 0.4342 ///  TRN_loss: 0.5229 TRN_MAE_: 0.4028 TRN_RMSLE: 0.4863 TRN_VAL_: 0.6846 TRN_mean_squared_error: 68512143.2564 TRN_MAPE_: 0.4112\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfcTV2-g1JNG",
        "colab_type": "code",
        "outputId": "70c085c9-40ed-4d71-d7b8-530fc0dcad8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "#Предсказание из 4х значений = 0:\n",
        "  #nn_0 = keras.models.load_model (DIR + '0HANDLY_SAVED_3.MODEL')\n",
        "  nn_1 = keras.models.load_model (DIR + '1HANDLY_SAVED_3.MODEL')\n",
        "  #nn_2 = keras.models.load_model (DIR + '2HANDLY_SAVED_3.MODEL')\n",
        "  #nn_3 = keras.models.load_model (DIR + '3HANDLY_SAVED_3.MODEL')\n",
        "\n",
        "  # score = model.evaluate(X, Y, verbose=0)\n",
        "  # print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))\n",
        "  gc.collect()\n",
        "\n",
        "  df['NN_PRED'] = 0\n",
        "  #df['NN_PRED_0'] = nn_0.predict(df[In_Columns], batch_size = 10000) \n",
        "  df['NN_PRED_1'] = nn_1.predict(df[In_Columns], batch_size = 10000) \n",
        "  #df['NN_PRED_2'] = nn_2.predict(df[In_Columns], batch_size = 10000) \n",
        "  #df['NN_PRED_3'] = nn_3.predict(df[In_Columns], batch_size = 10000) \n",
        "  #df['NN_PRED'] = np.where(df['meter'] == 0, df['NN_PRED_0'], df['NN_PRED'])\n",
        "  df['NN_PRED'] = np.where(df['meter'] == 1, df['NN_PRED_1'], df['NN_PRED'])\n",
        "  #df['NN_PRED'] = np.where(df['meter'] == 2, df['NN_PRED_2'], df['NN_PRED'])\n",
        "  #df['NN_PRED'] = np.where(df['meter'] == 3, df['NN_PRED_3'], df['NN_PRED'])\n",
        "  #df.drop(columns = ['NN_PRED_0'], inplace = True) #, 'NN_PRED_1', 'NN_PRED_2', 'NN_PRED_3'\n",
        "  #df.drop(columns = ['Value_x', 'Value_y'])\n",
        "  gc.collect()\n",
        "\n",
        "  df['NN_ERR'] = np.abs(df['NN_PRED']-df['meter_reading'])\n",
        "  print( np.sqrt( np.mean( np.power(np.log(df['meter_reading']+1) - np.log(df['NN_PRED']+1),2.00000)))     )\n",
        "  # print('Ошибка 0: ', np.sqrt( np.mean( np.power(np.log(df[df['meter']==0]['meter_reading']+1) - np.log(df[df['meter']==0]['NN_PRED']+1),2.00000)))        \n",
        "  # , 'Ошибка 0 (VAL): ', np.sqrt( np.mean( np.power(np.log(df[(df['meter']==0) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[(df['meter']==0) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "  # , 'Ошибка 0 (VAL_чист): ', np.sqrt( np.mean( np.power(np.log(df[ (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==0) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[ (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==0) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "  # , 'Ошибка 0 (VAL_чист): ', np.sqrt( np.mean( np.power(np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==0) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==0) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        )\n",
        "  \n",
        "  print('Ошибка 0: ', np.sqrt( np.mean( np.power(np.log(df[df['meter']==1]['meter_reading']+1) - np.log(df[df['meter']==1]['NN_PRED']+1),2.00000)))        \n",
        "  , 'Ошибка 0 (VAL): ', np.sqrt( np.mean( np.power(np.log(df[(df['meter']==1) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[(df['meter']==1) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "  , 'Ошибка 0 (VAL_чист): ', np.sqrt( np.mean( np.power(np.log(df[ (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==1) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[ (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==1) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "  , 'Ошибка 0 (VAL_чист): ', np.sqrt( np.mean( np.power(np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==1) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==1) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        )\n",
        "  \n",
        "  #print('Ошибка 1: ', np.sqrt( np.mean( np.power(np.log(df[df['meter']==1]['meter_reading']+1) - np.log(df[df['meter']==1]['NN_PRED']+1),2.00000)))        )\n",
        "  #print('Ошибка 2: ', np.sqrt( np.mean( np.power(np.log(df[df['meter']==2]['meter_reading']+1) - np.log(df[df['meter']==2]['NN_PRED']+1),2.00000)))        )\n",
        "  #print('Ошибка 3: ', np.sqrt( np.mean( np.power(np.log(df[df['meter']==3]['meter_reading']+1) - np.log(df[df['meter']==3]['NN_PRED']+1),2.00000)))        )\n",
        "  #df['k_NN_ERR'] = (df['NN_PRED']+0.33)/(df['meter_reading']+0.33)\n",
        "  gc.collect()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4.143660029954269\n",
            "Ошибка 0:  1.4462519064009887 Ошибка 0 (VAL):  1.4819992377016542 Ошибка 0 (VAL_чист):  0.628029160200588 Ошибка 0 (VAL_чист):  0.4921451933316616\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RW6m54J1Ixjn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Ошибка 0:  1.4622222874555681 Ошибка 0 (VAL):  1.4974377063554198 Ошибка 0 (VAL_чист):  0.6416758062352609 Ошибка 0 (VAL_чист):  0.5087780382284447\n",
        "Ошибка 0:  1.4513305175601738 Ошибка 0 (VAL):  1.4857607748364132 Ошибка 0 (VAL_чист):  0.6544772099268412 Ошибка 0 (VAL_чист):  0.5241878970208895\n",
        "Ошибка 0:  1.559959814457174 Ошибка 0 (VAL):  1.5880652782130562 Ошибка 0 (VAL_чист):  0.6931055197830647 Ошибка 0 (VAL_чист):  0.5696662087687516\n",
        "Ошибка 1:  1.5319581160458586 Ошибка 1 (VAL):  1.5591904792676097 Ошибка 1 (VAL_чист):  0.7038461338617784 Ошибка 1 (VAL_чист2):  0.5850605758832433"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ur0NQSVo01Cs",
        "outputId": "100dbc4c-3501-4898-ce45-d557535bd7c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "if 2==2:\n",
        "  reg = 0.000001\n",
        "  meter = 2\n",
        "  epochs = 80\n",
        "  batch_size = 700\n",
        "  opt = Adam(lr = 0.000510)\n",
        "\n",
        "  earlyStopping = EarlyStopping(monitor='loss', patience=30, verbose=1, mode='min')\n",
        "  reduce_lr_loss = ReduceLROnPlateau(monitor='loss', factor=0.2, patience=55, verbose=1, min_delta=1e-3, mode='min')\n",
        "  model_checkpoint = ModelCheckpoint(monitor='loss', save_best_only=True, filepath = DIR + 'best_nn_' + str(meter) + '.model', save_weights_only = False, verbose=0, mode='min')\n",
        "\n",
        "  nn_2 = Sequential()\n",
        "  nn_2.add(Dense(100, input_shape = df[In_Columns].shape[1:], activation = 'tanh', kernel_initializer = 'normal', kernel_regularizer=l2(reg), bias_initializer=bias))\n",
        "  nn_2.add(Dense(100, activation = 'tanh',  kernel_initializer = 'normal', bias_initializer=bias))\n",
        "  nn_2.add(Dense(100, activation = 'tanh',  kernel_initializer = 'normal', bias_initializer=bias, kernel_regularizer=l1(reg)))\n",
        "  nn_2.add(Dense(100, activation = 'tanh',  kernel_initializer = 'normal', bias_initializer=bias))\n",
        "  nn_2.add(Dense( 1, activation = 'relu', kernel_initializer = 'normal'))\n",
        "\n",
        "  nn_2.compile(optimizer = opt, loss = RMSLE, metrics=[ MAE_, RMSLE, VAL_, 'mse', MAPE_ ])\n",
        "  \n",
        "  val = df[(df['meter'] == meter) & (df['day']%6 == 0) & (df['k_NN_ERR'] < 100) & (df['k_NN_ERR'] > 1/100) & (df['IS_BAD_PRCNT'] < 0.45)]\n",
        "  df_cleared = df[(df['k_NN_ERR']<50) & (df['k_NN_ERR']>1/50) & (df['meter']==meter) & (df['IS_BAD_PRCNT']<0.45)][In_Columns + [Out_Columns]]\n",
        "\n",
        "  hist = nn_2.fit( df_cleared[In_Columns], df_cleared[Out_Columns], batch_size = batch_size, verbose = 0\n",
        "                  , epochs = epochs, shuffle = True, callbacks=[MyCustomCallback(epochs, 1), earlyStopping, reduce_lr_loss,model_checkpoint]\n",
        "                  , validation_data=(val[In_Columns], val[Out_Columns])\n",
        "                  ) \n",
        "  nn_2.save(DIR + str(meter) + 'HANDLY_SAVED_3.MODEL')\n",
        "  gc.collect()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# 0001 |  TST_loss: 2.2015 TST_MAE_: 1.4143 TST_RMSLE: 2.2011 TST_VAL_: 0.9200 TST_mean_squared_error: 41170967.6353 TST_MAPE_: 1.0952 ///  TRN_loss: 2.9053 TRN_MAE_: 0.9781 TRN_RMSLE: 2.9048 TRN_VAL_: 0.0269 TRN_mean_squared_error: 38408743.0351 TRN_MAPE_: 1.0154\n",
            "# 0002 |  TST_loss: 1.9356 TST_MAE_: 2.0386 TST_RMSLE: 1.9354 TST_VAL_: 1.7778 TST_mean_squared_error: 40914474.9369 TST_MAPE_: 1.3133 ///  TRN_loss: 2.2264 TRN_MAE_: 0.9541 TRN_RMSLE: 2.2262 TRN_VAL_: 0.0696 TRN_mean_squared_error: 38159611.7076 TRN_MAPE_: 1.1683\n",
            "# 0003 |  TST_loss: 1.8484 TST_MAE_: 2.8025 TST_RMSLE: 1.8483 TST_VAL_: 2.7097 TST_mean_squared_error: 40649422.0739 TST_MAPE_: 1.5211 ///  TRN_loss: 2.0381 TRN_MAE_: 0.9387 TRN_RMSLE: 2.0380 TRN_VAL_: 0.1167 TRN_mean_squared_error: 37897013.9858 TRN_MAPE_: 1.3921\n",
            ".......\n",
            "# 0004 |  TST_loss: 1.3349 TST_MAE_: 0.7758 TST_RMSLE: 1.3343 TST_VAL_: 0.6523 TST_mean_squared_error: 40261915.7753 TST_MAPE_: 0.8599 ///  TRN_loss: 1.6253 TRN_MAE_: 0.8970 TRN_RMSLE: 1.6249 TRN_VAL_: 0.1277 TRN_mean_squared_error: 37547335.0774 TRN_MAPE_: 0.9044\n",
            "# 0005 |  TST_loss: 1.2681 TST_MAE_: 0.6481 TST_RMSLE: 1.2671 TST_VAL_: 0.5801 TST_mean_squared_error: 40057481.0980 TST_MAPE_: 0.8417 ///  TRN_loss: 1.4659 TRN_MAE_: 0.8732 TRN_RMSLE: 1.4651 TRN_VAL_: 0.1510 TRN_mean_squared_error: 37275470.0255 TRN_MAPE_: 0.8145\n",
            "# 0006 |  TST_loss: 1.2426 TST_MAE_: 0.7390 TST_RMSLE: 1.2413 TST_VAL_: 0.6675 TST_mean_squared_error: 39885327.7405 TST_MAPE_: 0.8275 ///  TRN_loss: 1.4059 TRN_MAE_: 0.8604 TRN_RMSLE: 1.4048 TRN_VAL_: 0.1666 TRN_mean_squared_error: 37092299.9499 TRN_MAPE_: 0.8029\n",
            "# 0007 |  TST_loss: 1.1917 TST_MAE_: 0.7024 TST_RMSLE: 1.1902 TST_VAL_: 0.7166 TST_mean_squared_error: 39737219.4889 TST_MAPE_: 0.8263 ///  TRN_loss: 1.3617 TRN_MAE_: 0.8498 TRN_RMSLE: 1.3602 TRN_VAL_: 0.1791 TRN_mean_squared_error: 36933553.8594 TRN_MAPE_: 0.7931\n",
            "# 0008 |  TST_loss: 1.1535 TST_MAE_: 0.5879 TST_RMSLE: 1.1516 TST_VAL_: 0.5939 TST_mean_squared_error: 39616326.7025 TST_MAPE_: 0.7981 ///  TRN_loss: 1.3187 TRN_MAE_: 0.8409 TRN_RMSLE: 1.3170 TRN_VAL_: 0.1896 TRN_mean_squared_error: 36800537.8639 TRN_MAPE_: 0.7788\n",
            "# 0009 |  TST_loss: 1.1234 TST_MAE_: 0.6122 TST_RMSLE: 1.1212 TST_VAL_: 0.6555 TST_mean_squared_error: 39510038.5274 TST_MAPE_: 0.7873 ///  TRN_loss: 1.2955 TRN_MAE_: 0.8332 TRN_RMSLE: 1.2935 TRN_VAL_: 0.1982 TRN_mean_squared_error: 36687985.8692 TRN_MAPE_: 0.7770\n",
            "# 0010 |  TST_loss: 1.0914 TST_MAE_: 0.5694 TST_RMSLE: 1.0889 TST_VAL_: 0.6315 TST_mean_squared_error: 39419706.0814 TST_MAPE_: 0.7628 ///  TRN_loss: 1.2431 TRN_MAE_: 0.8258 TRN_RMSLE: 1.2407 TRN_VAL_: 0.2050 TRN_mean_squared_error: 36590334.8557 TRN_MAPE_: 0.7419\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "04uJSEPL01Cu",
        "colab": {}
      },
      "source": [
        "for lr in [0.007,0.005,0.002,0.001]:\n",
        "  opt = Adam(lr = lr)\n",
        "  epochs = 5\n",
        "  meter = 2\n",
        "  print('*'*9, lr, '*'*33)\n",
        "\n",
        "  val = df[(df['meter']==meter) & (df['day']%6==0)]\n",
        "  df_cleared = df[(df['k_NN_ERR']<50) & (df['k_NN_ERR']>1/50) & (df['meter']==meter) & (df['IS_BAD_PRCNT']<0.25)][In_Columns + [Out_Columns]]\n",
        "\n",
        "  nn_2.compile(optimizer = opt, loss = RMSLE, metrics=[ MAE_, RMSLE, VAL_, 'mse', MAPE_ ])\n",
        "  hist = nn_2.fit( df_cleared[In_Columns], df_cleared[Out_Columns], batch_size = batch_size, verbose = 0\n",
        "                  , epochs = epochs, shuffle = True, callbacks=[ MyCustomCallback(epochs, 1), earlyStopping, reduce_lr_loss]\n",
        "                  , validation_data=(val[In_Columns], val[Out_Columns])\n",
        "                  ) \n",
        "  nn_2.save(DIR + str(meter) + 'HANDLY_SAVED_3.MODEL')\n",
        "  gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DQZRFeEH01Cw",
        "outputId": "58b41b4c-fec8-429a-e30d-d64fb7926f01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "if 3==3:\n",
        "  meter = 3\n",
        "  epochs = 300\n",
        "  batch_size = 700\n",
        "  opt = Adam(lr = 0.007)\n",
        "\n",
        "  earlyStopping = EarlyStopping(monitor='loss', patience=50, verbose=1, mode='min')\n",
        "  reduce_lr_loss = ReduceLROnPlateau(monitor='loss', factor=0.2, patience=10, verbose=1, min_delta=1e-3, mode='min')\n",
        "  model_checkpoint = ModelCheckpoint(monitor='loss', save_best_only=True, filepath = DIR + 'best_nn_' + str(meter) + '.model', save_weights_only = False, verbose=0, mode='min')\n",
        "\n",
        "  nn_3 = Sequential()\n",
        "  nn_3.add(Dense(100, input_shape = df[In_Columns].shape[1:], activation = 'tanh', kernel_initializer = 'normal', kernel_regularizer=l2(reg), bias_initializer=bias))\n",
        "  nn_3.add(Dense(100, activation = 'tanh',  kernel_initializer = 'normal', bias_initializer=bias))\n",
        "  nn_3.add(Dense(100, activation = 'tanh',  kernel_initializer = 'normal', bias_initializer=bias, kernel_regularizer=l1(reg)))\n",
        "  nn_3.add(Dense(100, activation = 'tanh',  kernel_initializer = 'normal', bias_initializer=bias))\n",
        "  nn_3.add(Dense(1, activation = 'relu', kernel_initializer = 'normal'))\n",
        "\n",
        "  nn_3.compile(optimizer = opt, loss = RMSLE, metrics=[ MAE_, RMSLE, VAL_, 'mse', MAPE_ ])\n",
        "  \n",
        "  val = df[(df['meter'] == meter) & (df['day']%6 == 0) & (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.45)]\n",
        "  df_cleared = df[(df['k_NN_ERR']<50) & (df['k_NN_ERR']>1/50)  & (df['day']%6!=0) & (df['meter']==meter) & (df['IS_BAD_PRCNT']<0.45)][In_Columns + [Out_Columns]]\n",
        "\n",
        "  hist = nn_3.fit( df_cleared[In_Columns], df_cleared[Out_Columns], batch_size = batch_size, verbose = 0\n",
        "                  , epochs = epochs, shuffle = True, callbacks=[MyCustomCallback(epochs, 1), earlyStopping, reduce_lr_loss]\n",
        "                  , validation_data=(val[In_Columns], val[Out_Columns])\n",
        "                  ) \n",
        "  nn_3.save(DIR + str(meter) + 'HANDLY_SAVED0_3.MODEL')\n",
        "  gc.collect()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# 0001 |  TST_loss: 1.8114 TST_MAE_: 1.1592 TST_RMSLE: 1.8110 TST_VAL_: 1.0320 TST_mean_squared_error: 9743834.9856 TST_MAPE_: 1.5158 ///  TRN_loss: 2.1120 TRN_MAE_: 0.9323 TRN_RMSLE: 2.1115 TRN_VAL_: 0.1284 TRN_mean_squared_error: 9429363.3379 TRN_MAPE_: 1.4112\n",
            "# 0002 |  TST_loss: 1.8026 TST_MAE_: 1.2332 TST_RMSLE: 1.8024 TST_VAL_: 1.1600 TST_mean_squared_error: 9730397.6223 TST_MAPE_: 1.5703 ///  TRN_loss: 1.9842 TRN_MAE_: 0.9141 TRN_RMSLE: 1.9840 TRN_VAL_: 0.1977 TRN_mean_squared_error: 9386636.8622 TRN_MAPE_: 1.5625\n",
            "# 0003 |  TST_loss: 1.8028 TST_MAE_: 1.2420 TST_RMSLE: 1.8015 TST_VAL_: 1.1752 TST_mean_squared_error: 9728719.6182 TST_MAPE_: 1.5765 ///  TRN_loss: 1.9873 TRN_MAE_: 0.9129 TRN_RMSLE: 1.9866 TRN_VAL_: 0.2066 TRN_mean_squared_error: 9381488.6871 TRN_MAPE_: 1.5827\n",
            ".......\n",
            "# 0004 |  TST_loss: 1.8035 TST_MAE_: 1.2392 TST_RMSLE: 1.8020 TST_VAL_: 1.1701 TST_mean_squared_error: 9729357.9398 TST_MAPE_: 1.5745 ///  TRN_loss: 1.9850 TRN_MAE_: 0.9134 TRN_RMSLE: 1.9834 TRN_VAL_: 0.2023 TRN_mean_squared_error: 9383749.1009 TRN_MAPE_: 1.5733\n",
            "# 0005 |  TST_loss: 1.2717 TST_MAE_: 0.7044 TST_RMSLE: 1.2678 TST_VAL_: 0.7736 TST_mean_squared_error: 9594639.3563 TST_MAPE_: 1.1612 ///  TRN_loss: 1.6849 TRN_MAE_: 0.8658 TRN_RMSLE: 1.6825 TRN_VAL_: 0.2129 TRN_mean_squared_error: 9326885.4238 TRN_MAPE_: 1.3107\n",
            "# 0006 |  TST_loss: 1.1454 TST_MAE_: 0.6392 TST_RMSLE: 1.1409 TST_VAL_: 0.7105 TST_mean_squared_error: 9542111.0395 TST_MAPE_: 1.0348 ///  TRN_loss: 1.3011 TRN_MAE_: 0.7888 TRN_RMSLE: 1.2968 TRN_VAL_: 0.2797 TRN_mean_squared_error: 9218554.9841 TRN_MAPE_: 1.0318\n",
            "# 0007 |  TST_loss: 1.1741 TST_MAE_: 0.7656 TST_RMSLE: 1.1692 TST_VAL_: 0.9928 TST_mean_squared_error: 9506602.9221 TST_MAPE_: 1.2105 ///  TRN_loss: 1.2407 TRN_MAE_: 0.7681 TRN_RMSLE: 1.2361 TRN_VAL_: 0.3048 TRN_mean_squared_error: 9176510.6876 TRN_MAPE_: 0.9923\n",
            "# 0008 |  TST_loss: 1.0973 TST_MAE_: 0.6388 TST_RMSLE: 1.0917 TST_VAL_: 0.8815 TST_mean_squared_error: 9479031.7888 TST_MAPE_: 1.0599 ///  TRN_loss: 1.2034 TRN_MAE_: 0.7542 TRN_RMSLE: 1.1981 TRN_VAL_: 0.3203 TRN_mean_squared_error: 9146611.1744 TRN_MAPE_: 0.9690\n",
            "# 0009 |  TST_loss: 1.0571 TST_MAE_: 0.6025 TST_RMSLE: 1.0508 TST_VAL_: 0.8423 TST_mean_squared_error: 9456522.2474 TST_MAPE_: 1.0173 ///  TRN_loss: 1.1722 TRN_MAE_: 0.7437 TRN_RMSLE: 1.1662 TRN_VAL_: 0.3324 TRN_mean_squared_error: 9122979.3254 TRN_MAPE_: 0.9475\n",
            "# 0010 |  TST_loss: 1.3139 TST_MAE_: 0.8989 TST_RMSLE: 1.3069 TST_VAL_: 1.3202 TST_mean_squared_error: 9440507.9843 TST_MAPE_: 1.4536 ///  TRN_loss: 1.1523 TRN_MAE_: 0.7366 TRN_RMSLE: 1.1456 TRN_VAL_: 0.3438 TRN_mean_squared_error: 9103497.6128 TRN_MAPE_: 0.9400\n",
            "# 0011 |  TST_loss: 1.1335 TST_MAE_: 0.5868 TST_RMSLE: 1.1257 TST_VAL_: 0.5991 TST_mean_squared_error: 9435825.6777 TST_MAPE_: 0.8511 ///  TRN_loss: 1.1694 TRN_MAE_: 0.7331 TRN_RMSLE: 1.1617 TRN_VAL_: 0.3554 TRN_mean_squared_error: 9091634.6426 TRN_MAPE_: 0.9633\n",
            "# 0012 |  TST_loss: 1.0213 TST_MAE_: 0.5883 TST_RMSLE: 1.0128 TST_VAL_: 0.8618 TST_mean_squared_error: 9417333.2719 TST_MAPE_: 0.9989 ///  TRN_loss: 1.1279 TRN_MAE_: 0.7256 TRN_RMSLE: 1.1197 TRN_VAL_: 0.3637 TRN_mean_squared_error: 9078433.6012 TRN_MAPE_: 0.9290\n",
            "# 0013 |  TST_loss: 1.2623 TST_MAE_: 0.9838 TST_RMSLE: 1.2531 TST_VAL_: 1.4597 TST_mean_squared_error: 9401570.9245 TST_MAPE_: 1.4479 ///  TRN_loss: 1.1064 TRN_MAE_: 0.7199 TRN_RMSLE: 1.0976 TRN_VAL_: 0.3693 TRN_mean_squared_error: 9066950.6184 TRN_MAPE_: 0.9164\n",
            "# 0014 |  TST_loss: 1.1719 TST_MAE_: 0.5760 TST_RMSLE: 1.1618 TST_VAL_: 0.6592 TST_mean_squared_error: 9412451.0007 TST_MAPE_: 0.8456 ///  TRN_loss: 1.1069 TRN_MAE_: 0.7196 TRN_RMSLE: 1.0971 TRN_VAL_: 0.3688 TRN_mean_squared_error: 9069916.0670 TRN_MAPE_: 0.9136\n",
            "# 0015 |  TST_loss: 0.9822 TST_MAE_: 0.5991 TST_RMSLE: 0.9716 TST_VAL_: 0.9002 TST_mean_squared_error: 9399806.0246 TST_MAPE_: 0.9231 ///  TRN_loss: 1.0788 TRN_MAE_: 0.7141 TRN_RMSLE: 1.0684 TRN_VAL_: 0.3725 TRN_mean_squared_error: 9059220.0606 TRN_MAPE_: 0.8817\n",
            "# 0016 |  TST_loss: 1.2484 TST_MAE_: 0.5958 TST_RMSLE: 1.2374 TST_VAL_: 0.4977 TST_mean_squared_error: 9406100.9897 TST_MAPE_: 0.8092 ///  TRN_loss: 1.0674 TRN_MAE_: 0.7098 TRN_RMSLE: 1.0566 TRN_VAL_: 0.3775 TRN_mean_squared_error: 9048052.0218 TRN_MAPE_: 0.8702\n",
            "# 0017 |  TST_loss: 1.0216 TST_MAE_: 0.6497 TST_RMSLE: 1.0100 TST_VAL_: 1.0428 TST_mean_squared_error: 9377160.7838 TST_MAPE_: 1.0779 ///  TRN_loss: 1.0637 TRN_MAE_: 0.7078 TRN_RMSLE: 1.0523 TRN_VAL_: 0.3824 TRN_mean_squared_error: 9038233.6279 TRN_MAPE_: 0.8723\n",
            "# 0018 |  TST_loss: 1.0628 TST_MAE_: 0.6496 TST_RMSLE: 1.0508 TST_VAL_: 0.9865 TST_mean_squared_error: 9369510.2682 TST_MAPE_: 1.1051 ///  TRN_loss: 1.0522 TRN_MAE_: 0.7034 TRN_RMSLE: 1.0405 TRN_VAL_: 0.3875 TRN_mean_squared_error: 9028843.9360 TRN_MAPE_: 0.8621\n",
            "# 0019 |  TST_loss: 1.3647 TST_MAE_: 1.1439 TST_RMSLE: 1.3523 TST_VAL_: 1.6650 TST_mean_squared_error: 9363967.8691 TST_MAPE_: 1.6333 ///  TRN_loss: 1.0481 TRN_MAE_: 0.7009 TRN_RMSLE: 1.0360 TRN_VAL_: 0.3922 TRN_mean_squared_error: 9019887.7680 TRN_MAPE_: 0.8616\n",
            "# 0020 |  TST_loss: 0.9945 TST_MAE_: 0.5872 TST_RMSLE: 0.9818 TST_VAL_: 0.9707 TST_mean_squared_error: 9350896.4778 TST_MAPE_: 1.0392 ///  TRN_loss: 1.0474 TRN_MAE_: 0.7004 TRN_RMSLE: 1.0348 TRN_VAL_: 0.3960 TRN_mean_squared_error: 9013656.3331 TRN_MAPE_: 0.8640\n",
            "# 0021 |  TST_loss: 0.9455 TST_MAE_: 0.5405 TST_RMSLE: 0.9324 TST_VAL_: 0.6909 TST_mean_squared_error: 9360367.7343 TST_MAPE_: 0.8479 ///  TRN_loss: 1.0393 TRN_MAE_: 0.6950 TRN_RMSLE: 1.0263 TRN_VAL_: 0.4008 TRN_mean_squared_error: 9004240.7881 TRN_MAPE_: 0.8574\n",
            "# 0022 |  TST_loss: 1.4246 TST_MAE_: 0.6146 TST_RMSLE: 1.4112 TST_VAL_: 0.4695 TST_mean_squared_error: 9354724.0537 TST_MAPE_: 0.8317 ///  TRN_loss: 1.0328 TRN_MAE_: 0.6925 TRN_RMSLE: 1.0196 TRN_VAL_: 0.4025 TRN_mean_squared_error: 8997719.2045 TRN_MAPE_: 0.8531\n",
            "# 0023 |  TST_loss: 0.9923 TST_MAE_: 0.5926 TST_RMSLE: 0.9787 TST_VAL_: 0.9046 TST_mean_squared_error: 9339049.8230 TST_MAPE_: 1.0231 ///  TRN_loss: 1.0653 TRN_MAE_: 0.6936 TRN_RMSLE: 1.0517 TRN_VAL_: 0.4032 TRN_mean_squared_error: 8996606.0370 TRN_MAPE_: 0.9096\n",
            "# 0024 |  TST_loss: 0.9215 TST_MAE_: 0.5514 TST_RMSLE: 0.9077 TST_VAL_: 0.8978 TST_mean_squared_error: 9331529.9739 TST_MAPE_: 0.8854 ///  TRN_loss: 1.0270 TRN_MAE_: 0.6897 TRN_RMSLE: 1.0132 TRN_VAL_: 0.4059 TRN_mean_squared_error: 8989951.2364 TRN_MAPE_: 0.8608\n",
            "# 0025 |  TST_loss: 0.9430 TST_MAE_: 0.5542 TST_RMSLE: 0.9289 TST_VAL_: 0.8816 TST_mean_squared_error: 9324771.4158 TST_MAPE_: 0.8816 ///  TRN_loss: 1.0185 TRN_MAE_: 0.6871 TRN_RMSLE: 1.0045 TRN_VAL_: 0.4104 TRN_mean_squared_error: 8983391.0179 TRN_MAPE_: 0.8484\n",
            "# 0026 |  TST_loss: 1.1082 TST_MAE_: 0.7183 TST_RMSLE: 1.0938 TST_VAL_: 1.1220 TST_mean_squared_error: 9316631.9498 TST_MAPE_: 1.2236 ///  TRN_loss: 1.0166 TRN_MAE_: 0.6853 TRN_RMSLE: 1.0023 TRN_VAL_: 0.4137 TRN_mean_squared_error: 8977077.6599 TRN_MAPE_: 0.8513\n",
            "# 0027 |  TST_loss: 0.9178 TST_MAE_: 0.5228 TST_RMSLE: 0.9032 TST_VAL_: 0.7336 TST_mean_squared_error: 9336188.3601 TST_MAPE_: 0.8031 ///  TRN_loss: 1.0059 TRN_MAE_: 0.6822 TRN_RMSLE: 0.9914 TRN_VAL_: 0.4187 TRN_mean_squared_error: 8970983.1387 TRN_MAPE_: 0.8423\n",
            "# 0028 |  TST_loss: 1.0276 TST_MAE_: 0.5590 TST_RMSLE: 1.0128 TST_VAL_: 0.5375 TST_mean_squared_error: 9324524.2611 TST_MAPE_: 0.7293 ///  TRN_loss: 1.0025 TRN_MAE_: 0.6807 TRN_RMSLE: 0.9878 TRN_VAL_: 0.4206 TRN_mean_squared_error: 8965379.4600 TRN_MAPE_: 0.8402\n",
            "# 0029 |  TST_loss: 0.9395 TST_MAE_: 0.5279 TST_RMSLE: 0.9244 TST_VAL_: 0.6649 TST_mean_squared_error: 9316882.9967 TST_MAPE_: 0.8794 ///  TRN_loss: 0.9974 TRN_MAE_: 0.6783 TRN_RMSLE: 0.9825 TRN_VAL_: 0.4231 TRN_mean_squared_error: 8959406.8038 TRN_MAPE_: 0.8377\n",
            "# 0030 |  TST_loss: 0.9524 TST_MAE_: 0.5106 TST_RMSLE: 0.9371 TST_VAL_: 0.6521 TST_mean_squared_error: 9304561.4616 TST_MAPE_: 0.7482 ///  TRN_loss: 0.9950 TRN_MAE_: 0.6778 TRN_RMSLE: 0.9797 TRN_VAL_: 0.4259 TRN_mean_squared_error: 8953988.3150 TRN_MAPE_: 0.8404\n",
            "# 0031 |  TST_loss: 0.9511 TST_MAE_: 0.5530 TST_RMSLE: 0.9357 TST_VAL_: 0.9598 TST_mean_squared_error: 9290616.9405 TST_MAPE_: 0.9838 ///  TRN_loss: 0.9864 TRN_MAE_: 0.6753 TRN_RMSLE: 0.9711 TRN_VAL_: 0.4302 TRN_mean_squared_error: 8948497.6410 TRN_MAPE_: 0.8334\n",
            "# 0032 |  TST_loss: 0.9126 TST_MAE_: 0.5196 TST_RMSLE: 0.8969 TST_VAL_: 0.7235 TST_mean_squared_error: 9312812.3554 TST_MAPE_: 0.8382 ///  TRN_loss: 0.9847 TRN_MAE_: 0.6740 TRN_RMSLE: 0.9691 TRN_VAL_: 0.4334 TRN_mean_squared_error: 8943661.5215 TRN_MAPE_: 0.8317\n",
            "# 0033 |  TST_loss: 0.8748 TST_MAE_: 0.5116 TST_RMSLE: 0.8588 TST_VAL_: 0.9056 TST_mean_squared_error: 9279351.2535 TST_MAPE_: 0.8225 ///  TRN_loss: 0.9861 TRN_MAE_: 0.6734 TRN_RMSLE: 0.9701 TRN_VAL_: 0.4346 TRN_mean_squared_error: 8939152.9574 TRN_MAPE_: 0.8352\n",
            "# 0034 |  TST_loss: 0.9028 TST_MAE_: 0.5112 TST_RMSLE: 0.8867 TST_VAL_: 0.7422 TST_mean_squared_error: 9277403.3934 TST_MAPE_: 0.8071 ///  TRN_loss: 0.9819 TRN_MAE_: 0.6707 TRN_RMSLE: 0.9659 TRN_VAL_: 0.4382 TRN_mean_squared_error: 8933998.2999 TRN_MAPE_: 0.8330\n",
            "# 0035 |  TST_loss: 0.8673 TST_MAE_: 0.4960 TST_RMSLE: 0.8510 TST_VAL_: 0.8378 TST_mean_squared_error: 9271037.5256 TST_MAPE_: 0.8192 ///  TRN_loss: 0.9776 TRN_MAE_: 0.6695 TRN_RMSLE: 0.9614 TRN_VAL_: 0.4398 TRN_mean_squared_error: 8930147.3087 TRN_MAPE_: 0.8299\n",
            "# 0036 |  TST_loss: 0.8639 TST_MAE_: 0.4910 TST_RMSLE: 0.8474 TST_VAL_: 0.8370 TST_mean_squared_error: 9266771.3565 TST_MAPE_: 0.8104 ///  TRN_loss: 0.9764 TRN_MAE_: 0.6680 TRN_RMSLE: 0.9600 TRN_VAL_: 0.4426 TRN_mean_squared_error: 8925699.6582 TRN_MAPE_: 0.8271\n",
            "# 0037 |  TST_loss: 0.9730 TST_MAE_: 0.6273 TST_RMSLE: 0.9564 TST_VAL_: 1.1169 TST_mean_squared_error: 9262667.5477 TST_MAPE_: 1.0665 ///  TRN_loss: 0.9712 TRN_MAE_: 0.6676 TRN_RMSLE: 0.9546 TRN_VAL_: 0.4421 TRN_mean_squared_error: 8921856.0088 TRN_MAPE_: 0.8210\n",
            "# 0038 |  TST_loss: 0.9226 TST_MAE_: 0.5941 TST_RMSLE: 0.9058 TST_VAL_: 1.0655 TST_mean_squared_error: 9258158.2700 TST_MAPE_: 1.0042 ///  TRN_loss: 0.9677 TRN_MAE_: 0.6653 TRN_RMSLE: 0.9510 TRN_VAL_: 0.4441 TRN_mean_squared_error: 8917771.2747 TRN_MAPE_: 0.8183\n",
            "# 0039 |  TST_loss: 1.1945 TST_MAE_: 0.5482 TST_RMSLE: 1.1776 TST_VAL_: 0.6161 TST_mean_squared_error: 9279579.7662 TST_MAPE_: 0.7426 ///  TRN_loss: 0.9669 TRN_MAE_: 0.6637 TRN_RMSLE: 0.9500 TRN_VAL_: 0.4465 TRN_mean_squared_error: 8913100.9221 TRN_MAPE_: 0.8193\n",
            "# 0040 |  TST_loss: 0.8654 TST_MAE_: 0.4753 TST_RMSLE: 0.8483 TST_VAL_: 0.8179 TST_mean_squared_error: 9252891.7974 TST_MAPE_: 0.7885 ///  TRN_loss: 0.9659 TRN_MAE_: 0.6627 TRN_RMSLE: 0.9489 TRN_VAL_: 0.4484 TRN_mean_squared_error: 8909644.1948 TRN_MAPE_: 0.8177\n",
            "# 0041 |  TST_loss: 1.2374 TST_MAE_: 1.0001 TST_RMSLE: 1.2202 TST_VAL_: 1.5900 TST_mean_squared_error: 9250298.6500 TST_MAPE_: 1.4784 ///  TRN_loss: 0.9614 TRN_MAE_: 0.6610 TRN_RMSLE: 0.9442 TRN_VAL_: 0.4488 TRN_mean_squared_error: 8905567.8265 TRN_MAPE_: 0.8126\n",
            "# 0042 |  TST_loss: 0.9032 TST_MAE_: 0.5719 TST_RMSLE: 0.8858 TST_VAL_: 0.9892 TST_mean_squared_error: 9261081.0412 TST_MAPE_: 0.9233 ///  TRN_loss: 0.9842 TRN_MAE_: 0.6710 TRN_RMSLE: 0.9667 TRN_VAL_: 0.4369 TRN_mean_squared_error: 8937276.0270 TRN_MAPE_: 0.8332\n",
            "# 0043 |  TST_loss: 0.8674 TST_MAE_: 0.4997 TST_RMSLE: 0.8498 TST_VAL_: 0.9228 TST_mean_squared_error: 9240446.5189 TST_MAPE_: 0.8410 ///  TRN_loss: 0.9639 TRN_MAE_: 0.6626 TRN_RMSLE: 0.9464 TRN_VAL_: 0.4460 TRN_mean_squared_error: 8915694.2122 TRN_MAPE_: 0.8153\n",
            "# 0044 |  TST_loss: 0.8563 TST_MAE_: 0.4721 TST_RMSLE: 0.8386 TST_VAL_: 0.7691 TST_mean_squared_error: 9241473.2252 TST_MAPE_: 0.7706 ///  TRN_loss: 0.9576 TRN_MAE_: 0.6580 TRN_RMSLE: 0.9399 TRN_VAL_: 0.4548 TRN_mean_squared_error: 8894518.3937 TRN_MAPE_: 0.8109\n",
            "# 0045 |  TST_loss: 0.9786 TST_MAE_: 0.6161 TST_RMSLE: 0.9607 TST_VAL_: 1.0904 TST_mean_squared_error: 9233601.5972 TST_MAPE_: 1.0715 ///  TRN_loss: 0.9563 TRN_MAE_: 0.6571 TRN_RMSLE: 0.9385 TRN_VAL_: 0.4560 TRN_mean_squared_error: 8891225.8578 TRN_MAPE_: 0.8109\n",
            "# 0046 |  TST_loss: 0.9725 TST_MAE_: 0.6072 TST_RMSLE: 0.9545 TST_VAL_: 1.0689 TST_mean_squared_error: 9229216.9550 TST_MAPE_: 1.0267 ///  TRN_loss: 0.9550 TRN_MAE_: 0.6560 TRN_RMSLE: 0.9370 TRN_VAL_: 0.4579 TRN_mean_squared_error: 8888026.8609 TRN_MAPE_: 0.8105\n",
            "# 0047 |  TST_loss: 0.8762 TST_MAE_: 0.4997 TST_RMSLE: 0.8582 TST_VAL_: 0.9490 TST_mean_squared_error: 9226819.3081 TST_MAPE_: 0.8711 ///  TRN_loss: 0.9539 TRN_MAE_: 0.6554 TRN_RMSLE: 0.9359 TRN_VAL_: 0.4588 TRN_mean_squared_error: 8885135.4542 TRN_MAPE_: 0.8114\n",
            "# 0048 |  TST_loss: 0.9253 TST_MAE_: 0.4978 TST_RMSLE: 0.9071 TST_VAL_: 0.6277 TST_mean_squared_error: 9235731.9737 TST_MAPE_: 0.7346 ///  TRN_loss: 0.9540 TRN_MAE_: 0.6544 TRN_RMSLE: 0.9359 TRN_VAL_: 0.4601 TRN_mean_squared_error: 8881542.0691 TRN_MAPE_: 0.8108\n",
            "# 0049 |  TST_loss: 0.8630 TST_MAE_: 0.4829 TST_RMSLE: 0.8448 TST_VAL_: 0.7165 TST_mean_squared_error: 9233409.4041 TST_MAPE_: 0.7512 ///  TRN_loss: 0.9466 TRN_MAE_: 0.6529 TRN_RMSLE: 0.9283 TRN_VAL_: 0.4607 TRN_mean_squared_error: 8878523.1998 TRN_MAPE_: 0.8017\n",
            "# 0050 |  TST_loss: 0.9158 TST_MAE_: 0.5487 TST_RMSLE: 0.8975 TST_VAL_: 0.8653 TST_mean_squared_error: 9303672.3400 TST_MAPE_: 0.8991 ///  TRN_loss: 0.9503 TRN_MAE_: 0.6523 TRN_RMSLE: 0.9320 TRN_VAL_: 0.4630 TRN_mean_squared_error: 8875494.8922 TRN_MAPE_: 0.8076\n",
            "# 0051 |  TST_loss: 0.9818 TST_MAE_: 0.5243 TST_RMSLE: 0.9635 TST_VAL_: 0.5749 TST_mean_squared_error: 9233081.5799 TST_MAPE_: 0.7136 ///  TRN_loss: 0.9457 TRN_MAE_: 0.6507 TRN_RMSLE: 0.9273 TRN_VAL_: 0.4647 TRN_mean_squared_error: 8872344.2756 TRN_MAPE_: 0.8050\n",
            "# 0052 |  TST_loss: 0.8620 TST_MAE_: 0.4671 TST_RMSLE: 0.8435 TST_VAL_: 0.7295 TST_mean_squared_error: 9214643.8983 TST_MAPE_: 0.7762 ///  TRN_loss: 0.9476 TRN_MAE_: 0.6495 TRN_RMSLE: 0.9292 TRN_VAL_: 0.4660 TRN_mean_squared_error: 8869430.3243 TRN_MAPE_: 0.8067\n",
            "# 0053 |  TST_loss: 0.8695 TST_MAE_: 0.4734 TST_RMSLE: 0.8510 TST_VAL_: 0.7030 TST_mean_squared_error: 9217837.6281 TST_MAPE_: 0.7117 ///  TRN_loss: 0.9427 TRN_MAE_: 0.6498 TRN_RMSLE: 0.9241 TRN_VAL_: 0.4656 TRN_mean_squared_error: 8866484.7476 TRN_MAPE_: 0.7989\n",
            "# 0054 |  TST_loss: 0.9127 TST_MAE_: 0.5216 TST_RMSLE: 0.8941 TST_VAL_: 0.6473 TST_mean_squared_error: 9232646.8749 TST_MAPE_: 0.8033 ///  TRN_loss: 0.9426 TRN_MAE_: 0.6482 TRN_RMSLE: 0.9240 TRN_VAL_: 0.4672 TRN_mean_squared_error: 8863792.8542 TRN_MAPE_: 0.8009\n",
            "# 0055 |  TST_loss: 0.9286 TST_MAE_: 0.5701 TST_RMSLE: 0.9100 TST_VAL_: 1.0638 TST_mean_squared_error: 9202945.7148 TST_MAPE_: 1.0308 ///  TRN_loss: 0.9428 TRN_MAE_: 0.6475 TRN_RMSLE: 0.9241 TRN_VAL_: 0.4685 TRN_mean_squared_error: 8861403.1694 TRN_MAPE_: 0.8020\n",
            "# 0056 |  TST_loss: 0.9260 TST_MAE_: 0.4964 TST_RMSLE: 0.9073 TST_VAL_: 0.9056 TST_mean_squared_error: 9203038.0490 TST_MAPE_: 0.8299 ///  TRN_loss: 0.9386 TRN_MAE_: 0.6460 TRN_RMSLE: 0.9199 TRN_VAL_: 0.4696 TRN_mean_squared_error: 8857912.7545 TRN_MAPE_: 0.7982\n",
            "# 0057 |  TST_loss: 0.8483 TST_MAE_: 0.4665 TST_RMSLE: 0.8294 TST_VAL_: 0.8608 TST_mean_squared_error: 9198834.1729 TST_MAPE_: 0.8220 ///  TRN_loss: 0.9470 TRN_MAE_: 0.6458 TRN_RMSLE: 0.9281 TRN_VAL_: 0.4741 TRN_mean_squared_error: 8855932.0698 TRN_MAPE_: 0.8109\n",
            "# 0058 |  TST_loss: 0.8477 TST_MAE_: 0.4658 TST_RMSLE: 0.8288 TST_VAL_: 0.8161 TST_mean_squared_error: 9196865.7447 TST_MAPE_: 0.7197 ///  TRN_loss: 0.9342 TRN_MAE_: 0.6444 TRN_RMSLE: 0.9152 TRN_VAL_: 0.4719 TRN_mean_squared_error: 8853053.0884 TRN_MAPE_: 0.7926\n",
            "# 0059 |  TST_loss: 0.8726 TST_MAE_: 0.4726 TST_RMSLE: 0.8537 TST_VAL_: 0.8089 TST_mean_squared_error: 9198655.9427 TST_MAPE_: 0.8659 ///  TRN_loss: 0.9341 TRN_MAE_: 0.6435 TRN_RMSLE: 0.9152 TRN_VAL_: 0.4736 TRN_mean_squared_error: 8850008.9912 TRN_MAPE_: 0.7947\n",
            "# 0060 |  TST_loss: 0.8446 TST_MAE_: 0.4665 TST_RMSLE: 0.8256 TST_VAL_: 0.8230 TST_mean_squared_error: 9190394.0227 TST_MAPE_: 0.7866 ///  TRN_loss: 0.9363 TRN_MAE_: 0.6428 TRN_RMSLE: 0.9174 TRN_VAL_: 0.4737 TRN_mean_squared_error: 8847829.8847 TRN_MAPE_: 0.7958\n",
            "# 0061 |  TST_loss: 0.8207 TST_MAE_: 0.4604 TST_RMSLE: 0.8018 TST_VAL_: 0.8401 TST_mean_squared_error: 9188325.7357 TST_MAPE_: 0.7663 ///  TRN_loss: 0.9314 TRN_MAE_: 0.6415 TRN_RMSLE: 0.9124 TRN_VAL_: 0.4745 TRN_mean_squared_error: 8845080.8974 TRN_MAPE_: 0.7900\n",
            "# 0062 |  TST_loss: 0.9659 TST_MAE_: 0.6438 TST_RMSLE: 0.9468 TST_VAL_: 1.1875 TST_mean_squared_error: 9184887.5364 TST_MAPE_: 1.1062 ///  TRN_loss: 0.9366 TRN_MAE_: 0.6427 TRN_RMSLE: 0.9176 TRN_VAL_: 0.4758 TRN_mean_squared_error: 8842590.7515 TRN_MAPE_: 0.7987\n",
            "# 0063 |  TST_loss: 0.8318 TST_MAE_: 0.4701 TST_RMSLE: 0.8127 TST_VAL_: 0.8880 TST_mean_squared_error: 9182218.8009 TST_MAPE_: 0.7728 ///  TRN_loss: 0.9294 TRN_MAE_: 0.6416 TRN_RMSLE: 0.9103 TRN_VAL_: 0.4762 TRN_mean_squared_error: 8840120.1605 TRN_MAPE_: 0.7887\n",
            "# 0064 |  TST_loss: 1.1145 TST_MAE_: 0.4929 TST_RMSLE: 1.0954 TST_VAL_: 0.6743 TST_mean_squared_error: 9187224.1877 TST_MAPE_: 0.6962 ///  TRN_loss: 0.9293 TRN_MAE_: 0.6398 TRN_RMSLE: 0.9102 TRN_VAL_: 0.4766 TRN_mean_squared_error: 8837669.8401 TRN_MAPE_: 0.7869\n",
            "# 0065 |  TST_loss: 0.8394 TST_MAE_: 0.4579 TST_RMSLE: 0.8201 TST_VAL_: 0.8864 TST_mean_squared_error: 9178384.9049 TST_MAPE_: 0.8394 ///  TRN_loss: 0.9373 TRN_MAE_: 0.6393 TRN_RMSLE: 0.9181 TRN_VAL_: 0.4798 TRN_mean_squared_error: 8835192.0597 TRN_MAPE_: 0.7995\n",
            "# 0066 |  TST_loss: 0.9961 TST_MAE_: 0.6482 TST_RMSLE: 0.9767 TST_VAL_: 1.1763 TST_mean_squared_error: 9175098.9379 TST_MAPE_: 1.0893 ///  TRN_loss: 0.9309 TRN_MAE_: 0.6393 TRN_RMSLE: 0.9115 TRN_VAL_: 0.4787 TRN_mean_squared_error: 8833470.1489 TRN_MAPE_: 0.7899\n",
            "# 0067 |  TST_loss: 0.8682 TST_MAE_: 0.4942 TST_RMSLE: 0.8487 TST_VAL_: 0.9285 TST_mean_squared_error: 9173601.8947 TST_MAPE_: 0.8975 ///  TRN_loss: 0.9336 TRN_MAE_: 0.6393 TRN_RMSLE: 0.9141 TRN_VAL_: 0.4800 TRN_mean_squared_error: 8831021.7752 TRN_MAPE_: 0.7963\n",
            "# 0068 |  TST_loss: 1.1626 TST_MAE_: 0.5224 TST_RMSLE: 1.1431 TST_VAL_: 0.6153 TST_mean_squared_error: 9198170.6948 TST_MAPE_: 0.7372 ///  TRN_loss: 0.9283 TRN_MAE_: 0.6382 TRN_RMSLE: 0.9087 TRN_VAL_: 0.4806 TRN_mean_squared_error: 8829179.1827 TRN_MAPE_: 0.7899\n",
            "# 0069 |  TST_loss: 1.0069 TST_MAE_: 0.6533 TST_RMSLE: 0.9874 TST_VAL_: 1.2315 TST_mean_squared_error: 9171453.7035 TST_MAPE_: 1.1485 ///  TRN_loss: 0.9322 TRN_MAE_: 0.6367 TRN_RMSLE: 0.9126 TRN_VAL_: 0.4825 TRN_mean_squared_error: 8827026.2066 TRN_MAPE_: 0.7957\n",
            "# 0070 |  TST_loss: 0.8481 TST_MAE_: 0.4607 TST_RMSLE: 0.8285 TST_VAL_: 0.7966 TST_mean_squared_error: 9168477.3475 TST_MAPE_: 0.7683 ///  TRN_loss: 0.9265 TRN_MAE_: 0.6368 TRN_RMSLE: 0.9069 TRN_VAL_: 0.4832 TRN_mean_squared_error: 8824496.1038 TRN_MAPE_: 0.7877\n",
            "# 0071 |  TST_loss: 0.8996 TST_MAE_: 0.5087 TST_RMSLE: 0.8799 TST_VAL_: 1.0169 TST_mean_squared_error: 9164439.8562 TST_MAPE_: 0.9551 ///  TRN_loss: 0.9362 TRN_MAE_: 0.6370 TRN_RMSLE: 0.9165 TRN_VAL_: 0.4841 TRN_mean_squared_error: 8823065.9810 TRN_MAPE_: 0.8132\n",
            "# 0072 |  TST_loss: 0.8364 TST_MAE_: 0.4570 TST_RMSLE: 0.8166 TST_VAL_: 0.8458 TST_mean_squared_error: 9164771.1220 TST_MAPE_: 0.8269 ///  TRN_loss: 0.9356 TRN_MAE_: 0.6359 TRN_RMSLE: 0.9157 TRN_VAL_: 0.4848 TRN_mean_squared_error: 8821665.0206 TRN_MAPE_: 0.8102\n",
            "# 0073 |  TST_loss: 0.8405 TST_MAE_: 0.4690 TST_RMSLE: 0.8207 TST_VAL_: 0.7536 TST_mean_squared_error: 9165120.8864 TST_MAPE_: 0.7374 ///  TRN_loss: 0.9257 TRN_MAE_: 0.6341 TRN_RMSLE: 0.9059 TRN_VAL_: 0.4856 TRN_mean_squared_error: 8819470.8905 TRN_MAPE_: 0.7955\n",
            "# 0074 |  TST_loss: 0.8651 TST_MAE_: 0.5134 TST_RMSLE: 0.8453 TST_VAL_: 1.0066 TST_mean_squared_error: 9160079.8499 TST_MAPE_: 0.9200 ///  TRN_loss: 0.9260 TRN_MAE_: 0.6348 TRN_RMSLE: 0.9062 TRN_VAL_: 0.4865 TRN_mean_squared_error: 8817302.9368 TRN_MAPE_: 0.7977\n",
            "# 0075 |  TST_loss: 0.8216 TST_MAE_: 0.4574 TST_RMSLE: 0.8019 TST_VAL_: 0.7991 TST_mean_squared_error: 9161348.3264 TST_MAPE_: 0.7692 ///  TRN_loss: 0.9291 TRN_MAE_: 0.6338 TRN_RMSLE: 0.9094 TRN_VAL_: 0.4874 TRN_mean_squared_error: 8816186.7333 TRN_MAPE_: 0.8014\n",
            "# 0076 |  TST_loss: 0.9069 TST_MAE_: 0.5250 TST_RMSLE: 0.8870 TST_VAL_: 0.7419 TST_mean_squared_error: 9166621.8495 TST_MAPE_: 0.8477 ///  TRN_loss: 0.9296 TRN_MAE_: 0.6325 TRN_RMSLE: 0.9098 TRN_VAL_: 0.4873 TRN_mean_squared_error: 8813996.7950 TRN_MAPE_: 0.8014\n",
            "# 0077 |  TST_loss: 1.0005 TST_MAE_: 0.6331 TST_RMSLE: 0.9805 TST_VAL_: 1.1725 TST_mean_squared_error: 9156335.7114 TST_MAPE_: 1.0989 ///  TRN_loss: 0.9307 TRN_MAE_: 0.6341 TRN_RMSLE: 0.9108 TRN_VAL_: 0.4884 TRN_mean_squared_error: 8812954.1552 TRN_MAPE_: 0.8051\n",
            "# 0078 |  TST_loss: 0.8997 TST_MAE_: 0.4937 TST_RMSLE: 0.8790 TST_VAL_: 0.8590 TST_mean_squared_error: 9293254.8387 TST_MAPE_: 0.8552 ///  TRN_loss: 1.0853 TRN_MAE_: 0.6774 TRN_RMSLE: 1.0646 TRN_VAL_: 0.4507 TRN_mean_squared_error: 8916567.7370 TRN_MAPE_: 0.9263\n",
            "# 0079 |  TST_loss: 0.8891 TST_MAE_: 0.4845 TST_RMSLE: 0.8682 TST_VAL_: 0.7281 TST_mean_squared_error: 9289997.6729 TST_MAPE_: 0.8401 ///  TRN_loss: 0.9882 TRN_MAE_: 0.6703 TRN_RMSLE: 0.9675 TRN_VAL_: 0.4308 TRN_mean_squared_error: 8944456.8464 TRN_MAPE_: 0.8110\n",
            "# 0080 |  TST_loss: 0.8964 TST_MAE_: 0.5336 TST_RMSLE: 0.8750 TST_VAL_: 0.9688 TST_mean_squared_error: 9217112.2255 TST_MAPE_: 0.9140 ///  TRN_loss: 1.0242 TRN_MAE_: 0.6712 TRN_RMSLE: 1.0031 TRN_VAL_: 0.4434 TRN_mean_squared_error: 8925252.4568 TRN_MAPE_: 0.8956\n",
            "\n",
            "Epoch 00080: ReduceLROnPlateau reducing learning rate to 0.0014000000432133675.\n",
            "# 0081 |  TST_loss: 0.8234 TST_MAE_: 0.4570 TST_RMSLE: 0.8022 TST_VAL_: 0.8512 TST_mean_squared_error: 9218239.5541 TST_MAPE_: 0.7930 ///  TRN_loss: 0.9185 TRN_MAE_: 0.6446 TRN_RMSLE: 0.8971 TRN_VAL_: 0.4618 TRN_mean_squared_error: 8870735.8515 TRN_MAPE_: 0.7654\n",
            "# 0082 |  TST_loss: 0.8224 TST_MAE_: 0.4478 TST_RMSLE: 0.8014 TST_VAL_: 0.7693 TST_mean_squared_error: 9216879.0183 TST_MAPE_: 0.7734 ///  TRN_loss: 0.9103 TRN_MAE_: 0.6420 TRN_RMSLE: 0.8892 TRN_VAL_: 0.4613 TRN_mean_squared_error: 8869276.1812 TRN_MAPE_: 0.7564\n",
            "# 0083 |  TST_loss: 0.8196 TST_MAE_: 0.4453 TST_RMSLE: 0.7988 TST_VAL_: 0.7715 TST_mean_squared_error: 9215281.1607 TST_MAPE_: 0.7499 ///  TRN_loss: 0.9059 TRN_MAE_: 0.6412 TRN_RMSLE: 0.8851 TRN_VAL_: 0.4596 TRN_mean_squared_error: 8868191.5975 TRN_MAPE_: 0.7481\n",
            "# 0084 |  TST_loss: 0.8121 TST_MAE_: 0.4425 TST_RMSLE: 0.7916 TST_VAL_: 0.7903 TST_mean_squared_error: 9212042.9976 TST_MAPE_: 0.6997 ///  TRN_loss: 0.9018 TRN_MAE_: 0.6407 TRN_RMSLE: 0.8811 TRN_VAL_: 0.4584 TRN_mean_squared_error: 8867193.2374 TRN_MAPE_: 0.7392\n",
            "# 0085 |  TST_loss: 0.8705 TST_MAE_: 0.4761 TST_RMSLE: 0.8501 TST_VAL_: 0.6520 TST_mean_squared_error: 9216878.7715 TST_MAPE_: 0.6697 ///  TRN_loss: 0.9000 TRN_MAE_: 0.6402 TRN_RMSLE: 0.8795 TRN_VAL_: 0.4580 TRN_mean_squared_error: 8866189.9680 TRN_MAPE_: 0.7343\n",
            "# 0086 |  TST_loss: 0.8124 TST_MAE_: 0.4455 TST_RMSLE: 0.7921 TST_VAL_: 0.8563 TST_mean_squared_error: 9210553.9913 TST_MAPE_: 0.7628 ///  TRN_loss: 0.9061 TRN_MAE_: 0.6404 TRN_RMSLE: 0.8858 TRN_VAL_: 0.4583 TRN_mean_squared_error: 8865279.8034 TRN_MAPE_: 0.7353\n",
            "# 0087 |  TST_loss: 0.8013 TST_MAE_: 0.4379 TST_RMSLE: 0.7813 TST_VAL_: 0.7982 TST_mean_squared_error: 9210008.1082 TST_MAPE_: 0.7340 ///  TRN_loss: 0.8941 TRN_MAE_: 0.6393 TRN_RMSLE: 0.8740 TRN_VAL_: 0.4572 TRN_mean_squared_error: 8864173.4590 TRN_MAPE_: 0.7276\n",
            "# 0088 |  TST_loss: 0.8046 TST_MAE_: 0.4397 TST_RMSLE: 0.7848 TST_VAL_: 0.8578 TST_mean_squared_error: 9207811.8939 TST_MAPE_: 0.7406 ///  TRN_loss: 0.8906 TRN_MAE_: 0.6372 TRN_RMSLE: 0.8706 TRN_VAL_: 0.4594 TRN_mean_squared_error: 8863020.8409 TRN_MAPE_: 0.7230\n",
            "# 0089 |  TST_loss: 0.8019 TST_MAE_: 0.4358 TST_RMSLE: 0.7822 TST_VAL_: 0.7659 TST_mean_squared_error: 9208723.1386 TST_MAPE_: 0.7028 ///  TRN_loss: 0.8890 TRN_MAE_: 0.6375 TRN_RMSLE: 0.8692 TRN_VAL_: 0.4587 TRN_mean_squared_error: 8862297.3616 TRN_MAPE_: 0.7220\n",
            "# 0090 |  TST_loss: 0.8819 TST_MAE_: 0.4611 TST_RMSLE: 0.8624 TST_VAL_: 0.7381 TST_mean_squared_error: 9206779.6500 TST_MAPE_: 0.7151 ///  TRN_loss: 0.8879 TRN_MAE_: 0.6370 TRN_RMSLE: 0.8683 TRN_VAL_: 0.4592 TRN_mean_squared_error: 8861279.6988 TRN_MAPE_: 0.7202\n",
            "# 0091 |  TST_loss: 0.8035 TST_MAE_: 0.4421 TST_RMSLE: 0.7841 TST_VAL_: 0.8033 TST_mean_squared_error: 9208712.5116 TST_MAPE_: 0.7052 ///  TRN_loss: 0.8876 TRN_MAE_: 0.6377 TRN_RMSLE: 0.8681 TRN_VAL_: 0.4583 TRN_mean_squared_error: 8860213.5106 TRN_MAPE_: 0.7201\n",
            "# 0092 |  TST_loss: 0.8114 TST_MAE_: 0.4529 TST_RMSLE: 0.7921 TST_VAL_: 0.9238 TST_mean_squared_error: 9203607.3498 TST_MAPE_: 0.7803 ///  TRN_loss: 0.8838 TRN_MAE_: 0.6350 TRN_RMSLE: 0.8644 TRN_VAL_: 0.4606 TRN_mean_squared_error: 8859255.1341 TRN_MAPE_: 0.7153\n",
            "# 0093 |  TST_loss: 0.7935 TST_MAE_: 0.4340 TST_RMSLE: 0.7743 TST_VAL_: 0.8134 TST_mean_squared_error: 9203838.9087 TST_MAPE_: 0.7100 ///  TRN_loss: 0.8837 TRN_MAE_: 0.6360 TRN_RMSLE: 0.8645 TRN_VAL_: 0.4589 TRN_mean_squared_error: 8858190.4722 TRN_MAPE_: 0.7148\n",
            "# 0094 |  TST_loss: 0.7963 TST_MAE_: 0.4355 TST_RMSLE: 0.7773 TST_VAL_: 0.7574 TST_mean_squared_error: 9205373.6664 TST_MAPE_: 0.7207 ///  TRN_loss: 0.8808 TRN_MAE_: 0.6356 TRN_RMSLE: 0.8617 TRN_VAL_: 0.4596 TRN_mean_squared_error: 8857144.4560 TRN_MAPE_: 0.7119\n",
            "# 0095 |  TST_loss: 0.8535 TST_MAE_: 0.4957 TST_RMSLE: 0.8345 TST_VAL_: 0.9994 TST_mean_squared_error: 9179316.7588 TST_MAPE_: 0.8968 ///  TRN_loss: 0.8776 TRN_MAE_: 0.6298 TRN_RMSLE: 0.8586 TRN_VAL_: 0.4684 TRN_mean_squared_error: 8839348.0635 TRN_MAPE_: 0.7117\n",
            "# 0096 |  TST_loss: 0.7969 TST_MAE_: 0.4414 TST_RMSLE: 0.7781 TST_VAL_: 0.8856 TST_mean_squared_error: 9178085.8277 TST_MAPE_: 0.7341 ///  TRN_loss: 0.8747 TRN_MAE_: 0.6281 TRN_RMSLE: 0.8558 TRN_VAL_: 0.4696 TRN_mean_squared_error: 8834481.4587 TRN_MAPE_: 0.7095\n",
            "# 0097 |  TST_loss: 0.7918 TST_MAE_: 0.4356 TST_RMSLE: 0.7731 TST_VAL_: 0.8264 TST_mean_squared_error: 9179711.3103 TST_MAPE_: 0.7248 ///  TRN_loss: 0.8725 TRN_MAE_: 0.6280 TRN_RMSLE: 0.8537 TRN_VAL_: 0.4705 TRN_mean_squared_error: 8833622.9511 TRN_MAPE_: 0.7051\n",
            "# 0098 |  TST_loss: 0.7899 TST_MAE_: 0.4356 TST_RMSLE: 0.7713 TST_VAL_: 0.8886 TST_mean_squared_error: 9176109.5958 TST_MAPE_: 0.7370 ///  TRN_loss: 0.8715 TRN_MAE_: 0.6281 TRN_RMSLE: 0.8529 TRN_VAL_: 0.4696 TRN_mean_squared_error: 8832560.1799 TRN_MAPE_: 0.7030\n",
            "# 0099 |  TST_loss: 0.8091 TST_MAE_: 0.4554 TST_RMSLE: 0.7905 TST_VAL_: 0.9190 TST_mean_squared_error: 9176133.0345 TST_MAPE_: 0.7739 ///  TRN_loss: 0.8704 TRN_MAE_: 0.6271 TRN_RMSLE: 0.8518 TRN_VAL_: 0.4711 TRN_mean_squared_error: 8831518.2744 TRN_MAPE_: 0.7025\n",
            "# 0100 |  TST_loss: 0.7868 TST_MAE_: 0.4252 TST_RMSLE: 0.7684 TST_VAL_: 0.7859 TST_mean_squared_error: 9176863.4435 TST_MAPE_: 0.6964 ///  TRN_loss: 0.8693 TRN_MAE_: 0.6261 TRN_RMSLE: 0.8508 TRN_VAL_: 0.4725 TRN_mean_squared_error: 8830714.6650 TRN_MAPE_: 0.7001\n",
            "# 0101 |  TST_loss: 0.7886 TST_MAE_: 0.4301 TST_RMSLE: 0.7703 TST_VAL_: 0.8792 TST_mean_squared_error: 9174220.6917 TST_MAPE_: 0.7297 ///  TRN_loss: 0.8663 TRN_MAE_: 0.6258 TRN_RMSLE: 0.8479 TRN_VAL_: 0.4720 TRN_mean_squared_error: 8829871.3605 TRN_MAPE_: 0.6962\n",
            "# 0102 |  TST_loss: 0.7819 TST_MAE_: 0.4252 TST_RMSLE: 0.7637 TST_VAL_: 0.7851 TST_mean_squared_error: 9175258.7186 TST_MAPE_: 0.6891 ///  TRN_loss: 0.8660 TRN_MAE_: 0.6253 TRN_RMSLE: 0.8477 TRN_VAL_: 0.4724 TRN_mean_squared_error: 8828792.6564 TRN_MAPE_: 0.6973\n",
            "# 0103 |  TST_loss: 0.8088 TST_MAE_: 0.4370 TST_RMSLE: 0.7907 TST_VAL_: 0.7602 TST_mean_squared_error: 9173490.6216 TST_MAPE_: 0.6672 ///  TRN_loss: 0.8645 TRN_MAE_: 0.6251 TRN_RMSLE: 0.8464 TRN_VAL_: 0.4730 TRN_mean_squared_error: 8827948.0403 TRN_MAPE_: 0.6954\n",
            "# 0104 |  TST_loss: 0.7831 TST_MAE_: 0.4232 TST_RMSLE: 0.7650 TST_VAL_: 0.8486 TST_mean_squared_error: 9171318.6414 TST_MAPE_: 0.6895 ///  TRN_loss: 0.8654 TRN_MAE_: 0.6247 TRN_RMSLE: 0.8473 TRN_VAL_: 0.4727 TRN_mean_squared_error: 8827016.6163 TRN_MAPE_: 0.6952\n",
            "# 0105 |  TST_loss: 0.7919 TST_MAE_: 0.4222 TST_RMSLE: 0.7739 TST_VAL_: 0.7896 TST_mean_squared_error: 9172447.2356 TST_MAPE_: 0.6521 ///  TRN_loss: 0.8623 TRN_MAE_: 0.6230 TRN_RMSLE: 0.8443 TRN_VAL_: 0.4745 TRN_mean_squared_error: 8826129.4165 TRN_MAPE_: 0.6934\n",
            "# 0106 |  TST_loss: 0.7768 TST_MAE_: 0.4195 TST_RMSLE: 0.7589 TST_VAL_: 0.8053 TST_mean_squared_error: 9170876.0348 TST_MAPE_: 0.6707 ///  TRN_loss: 0.8613 TRN_MAE_: 0.6235 TRN_RMSLE: 0.8434 TRN_VAL_: 0.4739 TRN_mean_squared_error: 8825283.2119 TRN_MAPE_: 0.6924\n",
            "# 0107 |  TST_loss: 0.8085 TST_MAE_: 0.4596 TST_RMSLE: 0.7907 TST_VAL_: 0.9624 TST_mean_squared_error: 9168827.8315 TST_MAPE_: 0.8268 ///  TRN_loss: 0.8599 TRN_MAE_: 0.6233 TRN_RMSLE: 0.8420 TRN_VAL_: 0.4742 TRN_mean_squared_error: 8824444.8967 TRN_MAPE_: 0.6893\n",
            "# 0108 |  TST_loss: 0.7719 TST_MAE_: 0.4161 TST_RMSLE: 0.7542 TST_VAL_: 0.8028 TST_mean_squared_error: 9169879.2952 TST_MAPE_: 0.6809 ///  TRN_loss: 0.8598 TRN_MAE_: 0.6235 TRN_RMSLE: 0.8421 TRN_VAL_: 0.4742 TRN_mean_squared_error: 8823545.6938 TRN_MAPE_: 0.6911\n",
            "# 0109 |  TST_loss: 0.7960 TST_MAE_: 0.4273 TST_RMSLE: 0.7784 TST_VAL_: 0.7508 TST_mean_squared_error: 9169489.8500 TST_MAPE_: 0.6855 ///  TRN_loss: 0.8576 TRN_MAE_: 0.6221 TRN_RMSLE: 0.8400 TRN_VAL_: 0.4757 TRN_mean_squared_error: 8822703.3844 TRN_MAPE_: 0.6880\n",
            "# 0110 |  TST_loss: 0.8194 TST_MAE_: 0.4692 TST_RMSLE: 0.8018 TST_VAL_: 0.9425 TST_mean_squared_error: 9167169.2619 TST_MAPE_: 0.8366 ///  TRN_loss: 0.8588 TRN_MAE_: 0.6228 TRN_RMSLE: 0.8412 TRN_VAL_: 0.4748 TRN_mean_squared_error: 8821976.3481 TRN_MAPE_: 0.6903\n",
            "# 0111 |  TST_loss: 0.7756 TST_MAE_: 0.4191 TST_RMSLE: 0.7581 TST_VAL_: 0.7867 TST_mean_squared_error: 9168452.9799 TST_MAPE_: 0.6793 ///  TRN_loss: 0.8566 TRN_MAE_: 0.6225 TRN_RMSLE: 0.8390 TRN_VAL_: 0.4744 TRN_mean_squared_error: 8821090.3679 TRN_MAPE_: 0.6869\n",
            "# 0112 |  TST_loss: 0.7758 TST_MAE_: 0.4202 TST_RMSLE: 0.7584 TST_VAL_: 0.8472 TST_mean_squared_error: 9165440.9112 TST_MAPE_: 0.7544 ///  TRN_loss: 0.8550 TRN_MAE_: 0.6220 TRN_RMSLE: 0.8375 TRN_VAL_: 0.4751 TRN_mean_squared_error: 8820393.0852 TRN_MAPE_: 0.6834\n",
            "# 0113 |  TST_loss: 0.7736 TST_MAE_: 0.4188 TST_RMSLE: 0.7563 TST_VAL_: 0.8570 TST_mean_squared_error: 9164051.2384 TST_MAPE_: 0.7064 ///  TRN_loss: 0.8545 TRN_MAE_: 0.6217 TRN_RMSLE: 0.8371 TRN_VAL_: 0.4754 TRN_mean_squared_error: 8819474.9638 TRN_MAPE_: 0.6848\n",
            "# 0114 |  TST_loss: 0.7835 TST_MAE_: 0.4260 TST_RMSLE: 0.7663 TST_VAL_: 0.7340 TST_mean_squared_error: 9168350.5995 TST_MAPE_: 0.6567 ///  TRN_loss: 0.8540 TRN_MAE_: 0.6209 TRN_RMSLE: 0.8367 TRN_VAL_: 0.4764 TRN_mean_squared_error: 8818562.8381 TRN_MAPE_: 0.6836\n",
            "# 0115 |  TST_loss: 0.7769 TST_MAE_: 0.4252 TST_RMSLE: 0.7597 TST_VAL_: 0.7548 TST_mean_squared_error: 9166296.5677 TST_MAPE_: 0.6679 ///  TRN_loss: 0.8527 TRN_MAE_: 0.6207 TRN_RMSLE: 0.8354 TRN_VAL_: 0.4769 TRN_mean_squared_error: 8817750.6967 TRN_MAPE_: 0.6831\n",
            "# 0116 |  TST_loss: 0.7767 TST_MAE_: 0.4227 TST_RMSLE: 0.7595 TST_VAL_: 0.8832 TST_mean_squared_error: 9162592.3809 TST_MAPE_: 0.7056 ///  TRN_loss: 0.8543 TRN_MAE_: 0.6204 TRN_RMSLE: 0.8371 TRN_VAL_: 0.4766 TRN_mean_squared_error: 8817038.3364 TRN_MAPE_: 0.6852\n",
            "# 0117 |  TST_loss: 0.7739 TST_MAE_: 0.4193 TST_RMSLE: 0.7568 TST_VAL_: 0.7599 TST_mean_squared_error: 9144409.7948 TST_MAPE_: 0.6590 ///  TRN_loss: 0.8492 TRN_MAE_: 0.6191 TRN_RMSLE: 0.8320 TRN_VAL_: 0.4783 TRN_mean_squared_error: 8812200.0608 TRN_MAPE_: 0.6774\n",
            "# 0118 |  TST_loss: 0.7990 TST_MAE_: 0.4476 TST_RMSLE: 0.7819 TST_VAL_: 0.6790 TST_mean_squared_error: 9150903.1417 TST_MAPE_: 0.7058 ///  TRN_loss: 0.8470 TRN_MAE_: 0.6156 TRN_RMSLE: 0.8299 TRN_VAL_: 0.4843 TRN_mean_squared_error: 8794993.9288 TRN_MAPE_: 0.6788\n",
            "# 0119 |  TST_loss: 0.7717 TST_MAE_: 0.4131 TST_RMSLE: 0.7547 TST_VAL_: 0.8070 TST_mean_squared_error: 9140230.2861 TST_MAPE_: 0.6626 ///  TRN_loss: 0.8470 TRN_MAE_: 0.6143 TRN_RMSLE: 0.8300 TRN_VAL_: 0.4857 TRN_mean_squared_error: 8794366.4120 TRN_MAPE_: 0.6798\n",
            "# 0120 |  TST_loss: 0.7761 TST_MAE_: 0.4133 TST_RMSLE: 0.7591 TST_VAL_: 0.8242 TST_mean_squared_error: 9140109.6414 TST_MAPE_: 0.6759 ///  TRN_loss: 0.8450 TRN_MAE_: 0.6138 TRN_RMSLE: 0.8280 TRN_VAL_: 0.4861 TRN_mean_squared_error: 8793478.0957 TRN_MAPE_: 0.6776\n",
            "# 0121 |  TST_loss: 0.7602 TST_MAE_: 0.4074 TST_RMSLE: 0.7433 TST_VAL_: 0.8304 TST_mean_squared_error: 9138530.8969 TST_MAPE_: 0.6725 ///  TRN_loss: 0.8438 TRN_MAE_: 0.6137 TRN_RMSLE: 0.8269 TRN_VAL_: 0.4866 TRN_mean_squared_error: 8792632.9035 TRN_MAPE_: 0.6755\n",
            "# 0122 |  TST_loss: 0.7596 TST_MAE_: 0.4087 TST_RMSLE: 0.7428 TST_VAL_: 0.8375 TST_mean_squared_error: 9137414.1648 TST_MAPE_: 0.6657 ///  TRN_loss: 0.8423 TRN_MAE_: 0.6145 TRN_RMSLE: 0.8255 TRN_VAL_: 0.4848 TRN_mean_squared_error: 8791923.1633 TRN_MAPE_: 0.6749\n",
            "# 0123 |  TST_loss: 0.7735 TST_MAE_: 0.4195 TST_RMSLE: 0.7568 TST_VAL_: 0.8996 TST_mean_squared_error: 9135866.9117 TST_MAPE_: 0.7007 ///  TRN_loss: 0.8428 TRN_MAE_: 0.6131 TRN_RMSLE: 0.8260 TRN_VAL_: 0.4865 TRN_mean_squared_error: 8791159.4331 TRN_MAPE_: 0.6747\n",
            "# 0124 |  TST_loss: 0.7608 TST_MAE_: 0.4142 TST_RMSLE: 0.7441 TST_VAL_: 0.8691 TST_mean_squared_error: 9136108.4640 TST_MAPE_: 0.7000 ///  TRN_loss: 0.8423 TRN_MAE_: 0.6135 TRN_RMSLE: 0.8256 TRN_VAL_: 0.4862 TRN_mean_squared_error: 8790423.9623 TRN_MAPE_: 0.6745\n",
            "# 0125 |  TST_loss: 0.7739 TST_MAE_: 0.4161 TST_RMSLE: 0.7572 TST_VAL_: 0.7642 TST_mean_squared_error: 9137515.0147 TST_MAPE_: 0.6441 ///  TRN_loss: 0.8416 TRN_MAE_: 0.6128 TRN_RMSLE: 0.8249 TRN_VAL_: 0.4865 TRN_mean_squared_error: 8789738.3810 TRN_MAPE_: 0.6748\n",
            "# 0126 |  TST_loss: 0.7660 TST_MAE_: 0.4103 TST_RMSLE: 0.7494 TST_VAL_: 0.8394 TST_mean_squared_error: 9134136.8618 TST_MAPE_: 0.6619 ///  TRN_loss: 0.8423 TRN_MAE_: 0.6131 TRN_RMSLE: 0.8256 TRN_VAL_: 0.4868 TRN_mean_squared_error: 8789142.8648 TRN_MAPE_: 0.6742\n",
            "# 0127 |  TST_loss: 0.7565 TST_MAE_: 0.4069 TST_RMSLE: 0.7399 TST_VAL_: 0.8182 TST_mean_squared_error: 9134376.8249 TST_MAPE_: 0.6622 ///  TRN_loss: 0.8404 TRN_MAE_: 0.6122 TRN_RMSLE: 0.8238 TRN_VAL_: 0.4876 TRN_mean_squared_error: 8788285.3481 TRN_MAPE_: 0.6729\n",
            "# 0128 |  TST_loss: 0.7707 TST_MAE_: 0.4166 TST_RMSLE: 0.7541 TST_VAL_: 0.7640 TST_mean_squared_error: 9134783.0895 TST_MAPE_: 0.6460 ///  TRN_loss: 0.8417 TRN_MAE_: 0.6126 TRN_RMSLE: 0.8251 TRN_VAL_: 0.4871 TRN_mean_squared_error: 8787460.5634 TRN_MAPE_: 0.6749\n",
            "# 0129 |  TST_loss: 0.7657 TST_MAE_: 0.4140 TST_RMSLE: 0.7492 TST_VAL_: 0.8708 TST_mean_squared_error: 9131739.3356 TST_MAPE_: 0.6780 ///  TRN_loss: 0.8394 TRN_MAE_: 0.6112 TRN_RMSLE: 0.8229 TRN_VAL_: 0.4885 TRN_mean_squared_error: 8786925.7096 TRN_MAPE_: 0.6724\n",
            "# 0130 |  TST_loss: 0.7735 TST_MAE_: 0.4211 TST_RMSLE: 0.7570 TST_VAL_: 0.7394 TST_mean_squared_error: 9135078.5773 TST_MAPE_: 0.6486 ///  TRN_loss: 0.8374 TRN_MAE_: 0.6121 TRN_RMSLE: 0.8209 TRN_VAL_: 0.4877 TRN_mean_squared_error: 8786007.7104 TRN_MAPE_: 0.6690\n",
            "# 0131 |  TST_loss: 0.7626 TST_MAE_: 0.4155 TST_RMSLE: 0.7461 TST_VAL_: 0.8121 TST_mean_squared_error: 9133874.8654 TST_MAPE_: 0.6807 ///  TRN_loss: 0.8397 TRN_MAE_: 0.6117 TRN_RMSLE: 0.8233 TRN_VAL_: 0.4883 TRN_mean_squared_error: 8785403.8845 TRN_MAPE_: 0.6724\n",
            "# 0132 |  TST_loss: 0.7616 TST_MAE_: 0.4078 TST_RMSLE: 0.7453 TST_VAL_: 0.8096 TST_mean_squared_error: 9131525.3819 TST_MAPE_: 0.6453 ///  TRN_loss: 0.8376 TRN_MAE_: 0.6121 TRN_RMSLE: 0.8212 TRN_VAL_: 0.4874 TRN_mean_squared_error: 8784654.0696 TRN_MAPE_: 0.6686\n",
            "# 0133 |  TST_loss: 0.7557 TST_MAE_: 0.4093 TST_RMSLE: 0.7394 TST_VAL_: 0.8770 TST_mean_squared_error: 9128554.9178 TST_MAPE_: 0.7094 ///  TRN_loss: 0.8370 TRN_MAE_: 0.6111 TRN_RMSLE: 0.8206 TRN_VAL_: 0.4873 TRN_mean_squared_error: 8783944.7333 TRN_MAPE_: 0.6689\n",
            "# 0134 |  TST_loss: 0.7757 TST_MAE_: 0.4296 TST_RMSLE: 0.7594 TST_VAL_: 0.9336 TST_mean_squared_error: 9127590.2737 TST_MAPE_: 0.7450 ///  TRN_loss: 0.8366 TRN_MAE_: 0.6107 TRN_RMSLE: 0.8203 TRN_VAL_: 0.4881 TRN_mean_squared_error: 8783268.6959 TRN_MAPE_: 0.6683\n",
            "# 0135 |  TST_loss: 0.7611 TST_MAE_: 0.4161 TST_RMSLE: 0.7449 TST_VAL_: 0.9059 TST_mean_squared_error: 9126573.8573 TST_MAPE_: 0.7103 ///  TRN_loss: 0.8362 TRN_MAE_: 0.6109 TRN_RMSLE: 0.8199 TRN_VAL_: 0.4885 TRN_mean_squared_error: 8782429.2912 TRN_MAPE_: 0.6692\n",
            "# 0136 |  TST_loss: 0.7554 TST_MAE_: 0.4076 TST_RMSLE: 0.7392 TST_VAL_: 0.7926 TST_mean_squared_error: 9129219.9629 TST_MAPE_: 0.6547 ///  TRN_loss: 0.8351 TRN_MAE_: 0.6104 TRN_RMSLE: 0.8189 TRN_VAL_: 0.4885 TRN_mean_squared_error: 8781710.8662 TRN_MAPE_: 0.6683\n",
            "# 0137 |  TST_loss: 0.7505 TST_MAE_: 0.4052 TST_RMSLE: 0.7343 TST_VAL_: 0.8355 TST_mean_squared_error: 9126707.3392 TST_MAPE_: 0.6669 ///  TRN_loss: 0.8360 TRN_MAE_: 0.6096 TRN_RMSLE: 0.8198 TRN_VAL_: 0.4898 TRN_mean_squared_error: 8781032.9027 TRN_MAPE_: 0.6694\n",
            "# 0138 |  TST_loss: 0.7679 TST_MAE_: 0.4142 TST_RMSLE: 0.7518 TST_VAL_: 0.7588 TST_mean_squared_error: 9127061.4124 TST_MAPE_: 0.6416 ///  TRN_loss: 0.8343 TRN_MAE_: 0.6096 TRN_RMSLE: 0.8182 TRN_VAL_: 0.4895 TRN_mean_squared_error: 8780249.4805 TRN_MAPE_: 0.6677\n",
            "# 0139 |  TST_loss: 0.7513 TST_MAE_: 0.4052 TST_RMSLE: 0.7352 TST_VAL_: 0.8520 TST_mean_squared_error: 9124494.2749 TST_MAPE_: 0.6828 ///  TRN_loss: 0.8336 TRN_MAE_: 0.6101 TRN_RMSLE: 0.8175 TRN_VAL_: 0.4894 TRN_mean_squared_error: 8779516.3078 TRN_MAPE_: 0.6682\n",
            "# 0140 |  TST_loss: 0.7607 TST_MAE_: 0.4098 TST_RMSLE: 0.7447 TST_VAL_: 0.8134 TST_mean_squared_error: 9124818.4271 TST_MAPE_: 0.6682 ///  TRN_loss: 0.8347 TRN_MAE_: 0.6092 TRN_RMSLE: 0.8187 TRN_VAL_: 0.4902 TRN_mean_squared_error: 8778894.4344 TRN_MAPE_: 0.6695\n",
            "# 0141 |  TST_loss: 0.7600 TST_MAE_: 0.4123 TST_RMSLE: 0.7440 TST_VAL_: 0.9063 TST_mean_squared_error: 9122286.9563 TST_MAPE_: 0.7098 ///  TRN_loss: 0.8347 TRN_MAE_: 0.6101 TRN_RMSLE: 0.8187 TRN_VAL_: 0.4891 TRN_mean_squared_error: 8778256.6193 TRN_MAPE_: 0.6700\n",
            "# 0142 |  TST_loss: 0.7604 TST_MAE_: 0.4122 TST_RMSLE: 0.7445 TST_VAL_: 0.8255 TST_mean_squared_error: 9124543.8089 TST_MAPE_: 0.6925 ///  TRN_loss: 0.8336 TRN_MAE_: 0.6088 TRN_RMSLE: 0.8176 TRN_VAL_: 0.4908 TRN_mean_squared_error: 8777543.5810 TRN_MAPE_: 0.6674\n",
            "# 0143 |  TST_loss: 0.7541 TST_MAE_: 0.4070 TST_RMSLE: 0.7382 TST_VAL_: 0.8449 TST_mean_squared_error: 9123062.8328 TST_MAPE_: 0.6778 ///  TRN_loss: 0.8321 TRN_MAE_: 0.6082 TRN_RMSLE: 0.8161 TRN_VAL_: 0.4915 TRN_mean_squared_error: 8776733.2106 TRN_MAPE_: 0.6656\n",
            "# 0144 |  TST_loss: 0.7585 TST_MAE_: 0.4074 TST_RMSLE: 0.7426 TST_VAL_: 0.8336 TST_mean_squared_error: 9121677.2539 TST_MAPE_: 0.6567 ///  TRN_loss: 0.8323 TRN_MAE_: 0.6089 TRN_RMSLE: 0.8163 TRN_VAL_: 0.4902 TRN_mean_squared_error: 8776112.4501 TRN_MAPE_: 0.6659\n",
            "# 0145 |  TST_loss: 0.7676 TST_MAE_: 0.4078 TST_RMSLE: 0.7517 TST_VAL_: 0.7855 TST_mean_squared_error: 9124155.6490 TST_MAPE_: 0.6483 ///  TRN_loss: 0.8310 TRN_MAE_: 0.6086 TRN_RMSLE: 0.8151 TRN_VAL_: 0.4913 TRN_mean_squared_error: 8775270.2317 TRN_MAPE_: 0.6663\n",
            "# 0146 |  TST_loss: 0.7592 TST_MAE_: 0.4112 TST_RMSLE: 0.7434 TST_VAL_: 0.7795 TST_mean_squared_error: 9122140.0471 TST_MAPE_: 0.6620 ///  TRN_loss: 0.8338 TRN_MAE_: 0.6094 TRN_RMSLE: 0.8180 TRN_VAL_: 0.4904 TRN_mean_squared_error: 8774871.9288 TRN_MAPE_: 0.6701\n",
            "# 0147 |  TST_loss: 0.7597 TST_MAE_: 0.4080 TST_RMSLE: 0.7439 TST_VAL_: 0.8801 TST_mean_squared_error: 9119259.6231 TST_MAPE_: 0.7285 ///  TRN_loss: 0.8313 TRN_MAE_: 0.6092 TRN_RMSLE: 0.8155 TRN_VAL_: 0.4906 TRN_mean_squared_error: 8774082.4567 TRN_MAPE_: 0.6659\n",
            "# 0148 |  TST_loss: 0.7731 TST_MAE_: 0.4139 TST_RMSLE: 0.7574 TST_VAL_: 0.7674 TST_mean_squared_error: 9121125.9691 TST_MAPE_: 0.6351 ///  TRN_loss: 0.8303 TRN_MAE_: 0.6080 TRN_RMSLE: 0.8146 TRN_VAL_: 0.4916 TRN_mean_squared_error: 8773328.2160 TRN_MAPE_: 0.6652\n",
            "# 0149 |  TST_loss: 0.7665 TST_MAE_: 0.4111 TST_RMSLE: 0.7508 TST_VAL_: 0.7736 TST_mean_squared_error: 9120815.4653 TST_MAPE_: 0.6458 ///  TRN_loss: 0.8310 TRN_MAE_: 0.6079 TRN_RMSLE: 0.8152 TRN_VAL_: 0.4923 TRN_mean_squared_error: 8772719.3336 TRN_MAPE_: 0.6673\n",
            "# 0150 |  TST_loss: 0.7443 TST_MAE_: 0.4010 TST_RMSLE: 0.7286 TST_VAL_: 0.8316 TST_mean_squared_error: 9117894.4665 TST_MAPE_: 0.6544 ///  TRN_loss: 0.8303 TRN_MAE_: 0.6072 TRN_RMSLE: 0.8146 TRN_VAL_: 0.4930 TRN_mean_squared_error: 8772010.2281 TRN_MAPE_: 0.6663\n",
            "# 0151 |  TST_loss: 0.7789 TST_MAE_: 0.4184 TST_RMSLE: 0.7632 TST_VAL_: 0.9161 TST_mean_squared_error: 9115787.1970 TST_MAPE_: 0.7668 ///  TRN_loss: 0.8295 TRN_MAE_: 0.6073 TRN_RMSLE: 0.8138 TRN_VAL_: 0.4927 TRN_mean_squared_error: 8771250.9643 TRN_MAPE_: 0.6652\n",
            "# 0152 |  TST_loss: 0.7565 TST_MAE_: 0.4069 TST_RMSLE: 0.7409 TST_VAL_: 0.8312 TST_mean_squared_error: 9117609.8027 TST_MAPE_: 0.6872 ///  TRN_loss: 0.8284 TRN_MAE_: 0.6063 TRN_RMSLE: 0.8127 TRN_VAL_: 0.4939 TRN_mean_squared_error: 8770609.6003 TRN_MAPE_: 0.6644\n",
            "# 0153 |  TST_loss: 0.7597 TST_MAE_: 0.4083 TST_RMSLE: 0.7440 TST_VAL_: 0.8372 TST_mean_squared_error: 9117414.2010 TST_MAPE_: 0.6869 ///  TRN_loss: 0.8282 TRN_MAE_: 0.6070 TRN_RMSLE: 0.8126 TRN_VAL_: 0.4934 TRN_mean_squared_error: 8769948.2548 TRN_MAPE_: 0.6637\n",
            "# 0154 |  TST_loss: 0.7570 TST_MAE_: 0.4102 TST_RMSLE: 0.7415 TST_VAL_: 0.9011 TST_mean_squared_error: 9113930.6174 TST_MAPE_: 0.7055 ///  TRN_loss: 0.8289 TRN_MAE_: 0.6065 TRN_RMSLE: 0.8133 TRN_VAL_: 0.4939 TRN_mean_squared_error: 8769261.3015 TRN_MAPE_: 0.6652\n",
            "# 0155 |  TST_loss: 0.7521 TST_MAE_: 0.4082 TST_RMSLE: 0.7366 TST_VAL_: 0.8069 TST_mean_squared_error: 9117166.8583 TST_MAPE_: 0.6706 ///  TRN_loss: 0.8297 TRN_MAE_: 0.6067 TRN_RMSLE: 0.8141 TRN_VAL_: 0.4940 TRN_mean_squared_error: 8768708.3009 TRN_MAPE_: 0.6661\n",
            "# 0156 |  TST_loss: 0.7488 TST_MAE_: 0.4043 TST_RMSLE: 0.7333 TST_VAL_: 0.8027 TST_mean_squared_error: 9114111.8056 TST_MAPE_: 0.6544 ///  TRN_loss: 0.8272 TRN_MAE_: 0.6072 TRN_RMSLE: 0.8117 TRN_VAL_: 0.4930 TRN_mean_squared_error: 8768018.9687 TRN_MAPE_: 0.6635\n",
            "# 0157 |  TST_loss: 0.7467 TST_MAE_: 0.4011 TST_RMSLE: 0.7312 TST_VAL_: 0.8237 TST_mean_squared_error: 9113047.4698 TST_MAPE_: 0.6554 ///  TRN_loss: 0.8270 TRN_MAE_: 0.6058 TRN_RMSLE: 0.8115 TRN_VAL_: 0.4949 TRN_mean_squared_error: 8767251.4343 TRN_MAPE_: 0.6626\n",
            "# 0158 |  TST_loss: 0.7529 TST_MAE_: 0.4036 TST_RMSLE: 0.7374 TST_VAL_: 0.8561 TST_mean_squared_error: 9112588.6809 TST_MAPE_: 0.6930 ///  TRN_loss: 0.8274 TRN_MAE_: 0.6070 TRN_RMSLE: 0.8119 TRN_VAL_: 0.4928 TRN_mean_squared_error: 8766539.0616 TRN_MAPE_: 0.6638\n",
            "# 0159 |  TST_loss: 0.7573 TST_MAE_: 0.4138 TST_RMSLE: 0.7418 TST_VAL_: 0.8984 TST_mean_squared_error: 9111294.5613 TST_MAPE_: 0.6954 ///  TRN_loss: 0.8267 TRN_MAE_: 0.6061 TRN_RMSLE: 0.8112 TRN_VAL_: 0.4944 TRN_mean_squared_error: 8765912.8722 TRN_MAPE_: 0.6632\n",
            "# 0160 |  TST_loss: 0.7517 TST_MAE_: 0.4117 TST_RMSLE: 0.7364 TST_VAL_: 0.7683 TST_mean_squared_error: 9113420.4142 TST_MAPE_: 0.6622 ///  TRN_loss: 0.8267 TRN_MAE_: 0.6051 TRN_RMSLE: 0.8112 TRN_VAL_: 0.4959 TRN_mean_squared_error: 8765380.4400 TRN_MAPE_: 0.6638\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_Ihng3E901Cy",
        "colab": {}
      },
      "source": [
        "for lr in [0.0005]:\n",
        "  nn_3 = keras.models.load_model (DIR + '3HANDLY_SAVED0_3.MODEL')\n",
        "  opt = Adam(lr = lr)\n",
        "  epochs = 300\n",
        "  batch_size = 1024\n",
        "  meter = 3\n",
        "  val = df[(df['meter'] == meter) & (df['day']%6 == 0) & (df['k_NN_ERR'] < 100) & (df['k_NN_ERR'] > 1/100) & (df['IS_BAD_PRCNT'] < 0.45)]\n",
        "  df_cleared = df[(df['k_NN_ERR']<50) & (df['day']%6 != 0) & (df['k_NN_ERR']>1/50) & (df['meter']==meter) & (df['IS_BAD_PRCNT']<0.45)][In_Columns + [Out_Columns]]\n",
        "  print('*'*9, lr, '*'*33)\n",
        "  nn_3.compile(optimizer = opt, loss = RMSLE, metrics=[ MAE_, RMSLE, VAL_, 'mse', MAPE_ ])\n",
        "  hist = nn_3.fit( df_cleared[In_Columns], df_cleared[Out_Columns], batch_size = batch_size, verbose = 0\n",
        "                  , epochs = epochs, shuffle = True, callbacks=[ MyCustomCallback(epochs, 1), earlyStopping, reduce_lr_loss]\n",
        "                  , validation_data=(val[In_Columns], val[Out_Columns])\n",
        "                  ) \n",
        "  nn_3.save(DIR + str(meter) + 'HANDLY_SAVED_3.MODEL')\n",
        "  gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_knQD6Zw0yFy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "76896cde-56f3-40aa-84cb-ffc48839df69"
      },
      "source": [
        "#Предсказание из 4х значений:\n",
        "  #nn_0 = keras.models.load_model (DIR + '0HANDLY_SAVED_3.MODEL')\n",
        "  #nn_1 = keras.models.load_model (DIR + '1HANDLY_SAVED_3.MODEL')\n",
        "  #nn_2 = keras.models.load_model (DIR + '2HANDLY_SAVED_3.MODEL')\n",
        "  #nn_3 = keras.models.load_model (DIR + '3HANDLY_SAVED_3.MODEL')\n",
        "\n",
        "  # score = model.evaluate(X, Y, verbose=0)\n",
        "  # print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))\n",
        "  gc.collect()\n",
        "\n",
        "  df['NN_PRED'] = 0\n",
        "  df['NN_PRED_0'] = nn_0.predict(df[In_Columns], batch_size = 10000) \n",
        "  df['NN_PRED_1'] = nn_1.predict(df[In_Columns], batch_size = 10000) \n",
        "  df['NN_PRED_2'] = nn_2.predict(df[In_Columns], batch_size = 10000) \n",
        "  df['NN_PRED_3'] = nn_3.predict(df[In_Columns], batch_size = 10000) \n",
        "  df['NN_PRED'] = np.where(df['meter'] == 0, df['NN_PRED_0'], df['NN_PRED'])\n",
        "  df['NN_PRED'] = np.where(df['meter'] == 1, df['NN_PRED_1'], df['NN_PRED'])\n",
        "  df['NN_PRED'] = np.where(df['meter'] == 2, df['NN_PRED_2'], df['NN_PRED'])\n",
        "  df['NN_PRED'] = np.where(df['meter'] == 3, df['NN_PRED_3'], df['NN_PRED'])\n",
        "  df.drop(columns = ['NN_PRED_0', 'NN_PRED_1', 'NN_PRED_2', 'NN_PRED_3'], inplace = True)\n",
        "  #df.drop(columns = ['Value_x', 'Value_y'])\n",
        "  gc.collect()\n",
        "\n",
        "  df['NN_ERR'] = np.abs(df['NN_PRED']-df['meter_reading'])\n",
        "  # \"df['k_NN_ERR'] = (df['NN_PRED']+0.33)/(df['meter_reading']+0.33)\n",
        "\n",
        "  print( 'Ошибка общая: ', np.sqrt( np.mean( np.power(np.log(df['meter_reading']+1) - np.log(df['NN_PRED']+1),2.00000)))\n",
        "      , 'Ошибка (VAL): ', np.sqrt( np.mean( np.power(np.log(df[(df['day']%6 == 0)]['meter_reading']+1) - np.log(df[(df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка (VAL_чист): ' , np.sqrt( np.mean( np.power(np.log(df[  (df['IS_BAD_PRCNT'] < 0.25) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[(df['IS_BAD_PRCNT'] < 0.25) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка (VAL_чист2): ', np.sqrt( np.mean( np.power(np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "  )\n",
        "  print('Ошибка 0: ', np.sqrt( np.mean( np.power(np.log(df[df['meter']==0]['meter_reading']+1) - np.log(df[df['meter']==0]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка 0 (VAL): ', np.sqrt( np.mean( np.power(np.log(df[(df['meter']==0) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[(df['meter']==0) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка 0 (VAL_чист): ' , np.sqrt( np.mean( np.power(np.log(df[  (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==0) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[ (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==0) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка 0 (VAL_чист2): ', np.sqrt( np.mean( np.power(np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==0) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==0) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "  )\n",
        "  print('Ошибка 1: ', np.sqrt( np.mean( np.power(np.log(df[df['meter']==1]['meter_reading']+1) - np.log(df[df['meter']==1]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка 1 (VAL): ', np.sqrt( np.mean( np.power(np.log(df[(df['meter']==1) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[(df['meter']==1) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка 1 (VAL_чист): ' , np.sqrt( np.mean( np.power(np.log(df[  (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==1) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[ (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==1) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка 1 (VAL_чист2): ', np.sqrt( np.mean( np.power(np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==1) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==1) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "  )\n",
        "  print('Ошибка 2: ', np.sqrt( np.mean( np.power(np.log(df[df['meter']==2]['meter_reading']+1) - np.log(df[df['meter']==2]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка 2 (VAL): ', np.sqrt( np.mean( np.power(np.log(df[(df['meter']==2) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[(df['meter']==2) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка 2 (VAL_чист): ' , np.sqrt( np.mean( np.power(np.log(df[  (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==2) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[ (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==2) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка 2 (VAL_чист2): ', np.sqrt( np.mean( np.power(np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==2) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==2) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "  )\n",
        "  print('Ошибка 3: ', np.sqrt( np.mean( np.power(np.log(df[df['meter']==3]['meter_reading']+1) - np.log(df[df['meter']==3]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка 3 (VAL): ', np.sqrt( np.mean( np.power(np.log(df[(df['meter']==3) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[(df['meter']==3) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка 3 (VAL_чист): ' , np.sqrt( np.mean( np.power(np.log(df[  (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==3) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[ (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==3) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "      , 'Ошибка 3 (VAL_чист2): ', np.sqrt( np.mean( np.power(np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==3) & (df['day']%6 == 0)]['meter_reading']+1) - np.log(df[ (df['k_NN_ERR'] < 50) & (df['k_NN_ERR'] > 1/50) & (df['IS_BAD_PRCNT'] < 0.25) & (df['meter']==3) & (df['day']%6 == 0)]['NN_PRED']+1),2.00000)))        \n",
        "  )\n",
        "  # print('Ошибка 1: ', np.sqrt( np.mean( np.power(np.log(df[df['meter']==1]['meter_reading']+1) - np.log(df[df['meter']==1]['NN_PRED']+1),2.00000)))        )\n",
        "  # print('Ошибка 2: ', np.sqrt( np.mean( np.power(np.log(df[df['meter']==2]['meter_reading']+1) - np.log(df[df['meter']==2]['NN_PRED']+1),2.00000)))        )\n",
        "  # print('Ошибка 3: ', np.sqrt( np.mean( np.power(np.log(df[df['meter']==3]['meter_reading']+1) - np.log(df[df['meter']==3]['NN_PRED']+1),2.00000)))        )\n",
        "\n",
        "  gc.collect()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ошибка общая:  2.421829886388046 Ошибка (VAL):  2.427636557087622 Ошибка (VAL_чист):  2.312688190140441 Ошибка (VAL_чист2):  2.2910642577645044\n",
            "Ошибка 0:  1.1049203738272573 Ошибка 0 (VAL):  1.0965952553822587 Ошибка 0 (VAL_чист):  0.2917643053771373 Ошибка 0 (VAL_чист2):  0.26447247330596413\n",
            "Ошибка 1:  1.4462519064009887 Ошибка 1 (VAL):  1.4819992377016542 Ошибка 1 (VAL_чист):  0.628029160200588 Ошибка 1 (VAL_чист2):  0.4921451933316616\n",
            "Ошибка 2:  5.761433733138059 Ошибка 2 (VAL):  5.77141354252708 Ошибка 2 (VAL_чист):  6.2374618631673 Ошибка 2 (VAL_чист2):  6.255482358649611\n",
            "Ошибка 3:  2.0256390320779274 Ошибка 3 (VAL):  2.0173923049615716 Ошибка 3 (VAL_чист):  1.1389625084579613 Ошибка 3 (VAL_чист2):  0.7322620127346706\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSg8qh29X2xl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Evaluate:\n",
        "  score = nn_0.evaluate(df[df['meter']==0][In_Columns], df[df['meter']==0][Out_Columns], verbose=1, batch_size = 30000)\n",
        "  print(0)\n",
        "  for i in range(len(nn_0.metrics_names)):\n",
        "    print(\"%s: %.2f%%\" % (nn_0.metrics_names[i], score[i]*100))\n",
        "\n",
        "  score = nn_1.evaluate(df[df['meter']==1][In_Columns], df[df['meter']==1][Out_Columns], verbose=1, batch_size = 30000)\n",
        "  print(1)\n",
        "  for i in range(len(nn_1.metrics_names)):\n",
        "    print(\"%s: %.2f%%\" % (nn_1.metrics_names[i], score[i]*100))\n",
        "\n",
        "  score = nn_2.evaluate(df[df['meter']==2][In_Columns], df[df['meter']==2][Out_Columns], verbose=1, batch_size = 30000)\n",
        "  print(2)\n",
        "  for i in range(len(nn_2.metrics_names)):\n",
        "    print(\"%s: %.2f%%\" % (nn_2.metrics_names[i], score[i]*100))\n",
        "\n",
        "  score = nn_3.evaluate(df[df['meter']==3][In_Columns], df[df['meter']==3][Out_Columns], verbose=1, batch_size = 30000)\n",
        "  print(3)\n",
        "  for i in range(len(nn_3.metrics_names)):\n",
        "    print(\"%s: %.2f%%\" % (nn_3.metrics_names[i], score[i]*100))\n",
        "  \n",
        "  gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8qHP3Icaw2D",
        "colab_type": "code",
        "outputId": "e3a8a1b3-f78d-4dbb-bebf-7437f3783de7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        }
      },
      "source": [
        "#Важность показателей 0\n",
        "  from sklearn.utils import shuffle\n",
        "  nn = keras.models.load_model (DIR + '0HANDLY_SAVED3.MODEL')\n",
        "  meter = 0\n",
        "  val = df[(df['meter']==meter) & (df['day']%6==0)  & (df['IS_BAD_PRCNT']<0.25)]\n",
        "  #Подставить нужную нейронку в зависимости от meter\n",
        "  #print(nn.metrics_names)\n",
        "  k = pd.DataFrame( [nn.evaluate(val[In_Columns], val[Out_Columns], batch_size = 800000, verbose = 0)],columns=nn.metrics_names)\n",
        "  k['name'] = '---INITIAL---'\n",
        "  tmp_out=k.copy()\n",
        "  for i in range(len(In_Columns)):\n",
        "      X_val_2 = val[In_Columns].copy()\n",
        "      s = shuffle(X_val_2.iloc[:,i])\n",
        "      s.index = X_val_2.index\n",
        "      X_val_2.iloc[:, i] = s\n",
        "      tmp = pd.DataFrame([nn.evaluate(X_val_2, val[Out_Columns], batch_size = 800000, verbose = 0)], columns = nn.metrics_names)-k[nn.metrics_names] \n",
        "      tmp['name'] = In_Columns[i]\n",
        "      tmp_out = pd.concat([tmp_out, tmp])\n",
        "      X_val_2 = None\n",
        "      gc.collect()\n",
        "  tmp_out.set_index('name', inplace = True)\n",
        "  pd.option_context('display.float_format', '{:0.4f}'.format)\n",
        "  pd.set_option(\"display.precision\", 3)\n",
        "  print (tmp_out[nn.metrics_names].sort_values('RMSLE', ascending=False))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                    loss       MAE_      RMSLE       VAL_  mean_squared_error  \\\n",
            "name                                                                                            \n",
            "building_meter_hour_median     1.064e+00  6.843e-01  1.064e+00  4.756e-03           60254.056   \n",
            "building_meter_weekday_median  5.194e-01  2.463e-01  5.193e-01  3.660e-03           15909.947   \n",
            "---INITIAL---                  3.479e-01  1.875e-01  3.379e-01  9.186e-01           26271.034   \n",
            "square_feet                    3.263e-01  5.057e-02  3.263e-01  8.871e-03            2742.090   \n",
            "site_id                        7.959e-02  3.408e-02  7.959e-02 -1.697e-02            1520.522   \n",
            "week_cos                       5.175e-02  1.491e-02  5.175e-02 -1.527e-02             709.881   \n",
            "primary_use_ID                 4.548e-02  1.170e-02  4.548e-02  2.004e-03             804.085   \n",
            "week_sin                       4.197e-02  9.893e-03  4.196e-02 -9.141e-03             412.243   \n",
            "year_built                     3.071e-02  1.451e-02  3.071e-02 -2.024e-02            1008.902   \n",
            "weekday_sin                    2.722e-02  1.188e-02  2.722e-02 -2.377e-03             288.923   \n",
            "hour_cos                       2.090e-02  8.760e-03  2.090e-02  1.478e-04             177.350   \n",
            "air_temperature                1.313e-02  6.603e-03  1.313e-02 -8.382e-03             312.215   \n",
            "sea_level_pressure             9.510e-03  2.218e-03  9.511e-03 -7.435e-04              46.763   \n",
            "floor_count                    7.779e-03  3.254e-03  7.778e-03 -1.845e-03             123.975   \n",
            "weekday_cos                    7.317e-03  3.398e-03  7.316e-03 -2.213e-03              78.564   \n",
            "dew_temperature                3.562e-03  1.568e-03  3.561e-03 -5.556e-03              66.144   \n",
            "hour_sin                       1.752e-03  1.654e-03  1.752e-03 -3.805e-04              33.932   \n",
            "cloud_coverage                 5.257e-04  1.237e-04  5.255e-04  2.366e-05               2.040   \n",
            "wind_direction                 1.076e-04  1.793e-05  1.057e-04 -1.031e-04               1.504   \n",
            "wind_speed                     7.809e-05  2.015e-05  7.650e-05 -7.548e-05              -0.355   \n",
            "precip_depth_1_hr              3.219e-05  7.819e-06  3.209e-05 -6.845e-05               0.584   \n",
            "is_holiday                     5.201e-06  3.541e-06  2.699e-06 -8.568e-06               0.051   \n",
            "building_meter_median          0.000e+00 -1.624e-07  1.215e-08  4.468e-06              -0.032   \n",
            "\n",
            "                                   MAPE_  \n",
            "name                                      \n",
            "building_meter_hour_median     1.312e+00  \n",
            "building_meter_weekday_median  6.447e-01  \n",
            "---INITIAL---                  2.350e-01  \n",
            "square_feet                    1.958e-01  \n",
            "site_id                        5.955e-02  \n",
            "week_cos                       2.166e-02  \n",
            "primary_use_ID                 2.972e-02  \n",
            "week_sin                       1.623e-02  \n",
            "year_built                     1.341e-02  \n",
            "weekday_sin                    2.539e-02  \n",
            "hour_cos                       2.436e-02  \n",
            "air_temperature                8.541e-03  \n",
            "sea_level_pressure             1.175e-02  \n",
            "floor_count                    5.352e-03  \n",
            "weekday_cos                    6.269e-03  \n",
            "dew_temperature               -3.361e-04  \n",
            "hour_sin                       2.650e-03  \n",
            "cloud_coverage                 5.020e-04  \n",
            "wind_direction                 3.283e-05  \n",
            "wind_speed                    -5.926e-06  \n",
            "precip_depth_1_hr              1.986e-05  \n",
            "is_holiday                     2.573e-06  \n",
            "building_meter_median          1.172e-06  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCDCxcqhKHO1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Важность показателей 1\n",
        "  from sklearn.utils import shuffle\n",
        "  nn = keras.models.load_model (DIR + '1HANDLY_SAVED3.MODEL')\n",
        "  meter = 1\n",
        "  val = df[(df['meter']==meter) & (df['day']%6==0)  & (df['IS_BAD_PRCNT']<0.25)]\n",
        "  #Подставить нужную нейронку в зависимости от meter\n",
        "  #print(nn.metrics_names)\n",
        "  k = pd.DataFrame( [nn.evaluate(val[In_Columns], val[Out_Columns], batch_size = 800000, verbose = 0)],columns=nn.metrics_names)\n",
        "  k['name'] = '---INITIAL---'\n",
        "  tmp_out=k.copy()\n",
        "  for i in range(len(In_Columns)):\n",
        "      X_val_2 = val[In_Columns].copy()\n",
        "      s = shuffle(X_val_2.iloc[:,i])\n",
        "      s.index = X_val_2.index\n",
        "      X_val_2.iloc[:, i] = s\n",
        "      tmp = pd.DataFrame([nn.evaluate(X_val_2, val[Out_Columns], batch_size = 800000, verbose = 0)], columns = nn.metrics_names)-k[nn.metrics_names] \n",
        "      tmp['name'] = In_Columns[i]\n",
        "      tmp_out = pd.concat([tmp_out, tmp])\n",
        "      X_val_2 = None\n",
        "      gc.collect()\n",
        "  tmp_out.set_index('name', inplace = True)\n",
        "  pd.option_context('display.float_format', '{:0.4f}'.format)\n",
        "  pd.set_option(\"display.precision\", 3)\n",
        "  print (tmp_out[nn.metrics_names].sort_values('RMSLE', ascending=False))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIfQd2t9KN04",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Важность показателей 2\n",
        "  from sklearn.utils import shuffle\n",
        "  nn = keras.models.load_model (DIR + '2HANDLY_SAVED3.MODEL')\n",
        "  meter = 2\n",
        "  val = df[(df['meter']==meter) & (df['day']%6==0)  & (df['IS_BAD_PRCNT']<0.25)]\n",
        "  #Подставить нужную нейронку в зависимости от meter\n",
        "  #print(nn.metrics_names)\n",
        "  k = pd.DataFrame( [nn.evaluate(val[In_Columns], val[Out_Columns], batch_size = 800000, verbose = 0)],columns=nn.metrics_names)\n",
        "  k['name'] = '---INITIAL---'\n",
        "  tmp_out=k.copy()\n",
        "  for i in range(len(In_Columns)):\n",
        "      X_val_2 = val[In_Columns].copy()\n",
        "      s = shuffle(X_val_2.iloc[:,i])\n",
        "      s.index = X_val_2.index\n",
        "      X_val_2.iloc[:, i] = s\n",
        "      tmp = pd.DataFrame([nn.evaluate(X_val_2, val[Out_Columns], batch_size = 800000, verbose = 0)], columns = nn.metrics_names)-k[nn.metrics_names] \n",
        "      tmp['name'] = In_Columns[i]\n",
        "      tmp_out = pd.concat([tmp_out, tmp])\n",
        "      X_val_2 = None\n",
        "      gc.collect()\n",
        "  tmp_out.set_index('name', inplace = True)\n",
        "  pd.option_context('display.float_format', '{:0.4f}'.format)\n",
        "  pd.set_option(\"display.precision\", 3)\n",
        "  print (tmp_out[nn.metrics_names].sort_values('RMSLE', ascending=False))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wxn_T9DhKRzX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Важность показателей 3\n",
        "  from sklearn.utils import shuffle\n",
        "  nn = keras.models.load_model (DIR + '3HANDLY_SAVED03.MODEL')\n",
        "  meter = 3\n",
        "  val = df[(df['meter']==meter) & (df['day']%6==0)  & (df['IS_BAD_PRCNT']<0.25)]\n",
        "  #Подставить нужную нейронку в зависимости от meter\n",
        "  #print(nn.metrics_names)\n",
        "  k = pd.DataFrame( [nn.evaluate(val[In_Columns], val[Out_Columns], batch_size = 800000, verbose = 0)],columns=nn.metrics_names)\n",
        "  k['name'] = '---INITIAL---'\n",
        "  tmp_out=k.copy()\n",
        "  for i in range(len(In_Columns)):\n",
        "      X_val_2 = val[In_Columns].copy()\n",
        "      s = shuffle(X_val_2.iloc[:,i])\n",
        "      s.index = X_val_2.index\n",
        "      X_val_2.iloc[:, i] = s\n",
        "      tmp = pd.DataFrame([nn.evaluate(X_val_2, val[Out_Columns], batch_size = 800000, verbose = 0)], columns = nn.metrics_names)-k[nn.metrics_names] \n",
        "      tmp['name'] = In_Columns[i]\n",
        "      tmp_out = pd.concat([tmp_out, tmp])\n",
        "      X_val_2 = None\n",
        "      gc.collect()\n",
        "  tmp_out.set_index('name', inplace = True)\n",
        "  pd.option_context('display.float_format', '{:0.4f}'.format)\n",
        "  pd.set_option(\"display.precision\", 3)\n",
        "  print (tmp_out[nn.metrics_names].sort_values('RMSLE', ascending=False))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsiTWGypOAHb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ИДЕИ:\n",
        "  1) Сделать не показатель, а его отклонение от медианы по строению/дню/часу\n",
        "  2) \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLLVe_MMYIz-",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6AezgKyEBi6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reduce_mem_usage(df_test)\n",
        "gc.collect()\n",
        "df_test.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWDYNM3xOBZx",
        "colab_type": "code",
        "outputId": "9d6a801b-6d5e-460d-cfc5-4a3fa25042e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Подготовка данных тест:\n",
        "  df_test = pd.read_csv(DIR + \"test.csv\", engine = 'python')\n",
        "  print('Забрали с диска')\n",
        "  df_test['timestamp'] = pd.to_datetime(df_test['timestamp'])\n",
        "\n",
        "  df_test['hour_cos'] = np.cos(df_test['timestamp'].dt.hour * 2. * np.pi / 24.)\n",
        "  df_test['hour_sin'] = np.sin(df_test['timestamp'].dt.hour * 2. * np.pi / 24.)\n",
        "\n",
        "  df_test['weekday_cos'] = np.cos(df_test['timestamp'].dt.weekday * 2. * np.pi / 7.)\n",
        "  df_test['weekday_sin'] = np.sin(df_test['timestamp'].dt.weekday * 2. * np.pi / 7.)\n",
        "\n",
        "  df_test['week_cos'] = np.cos(df_test['timestamp'].dt.week * 2. * np.pi / 53.)\n",
        "  df_test['week_sin'] = np.sin(df_test['timestamp'].dt.week * 2. * np.pi / 53.)\n",
        "\n",
        "  reduce_mem_usage(df_test)\n",
        "  gc.collect()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Забрали с диска\n",
            "Memory usage of properties dataframe is : 3181.2745361328125  MB\n",
            "******************************\n",
            "Column:  row_id\n",
            "dtype before:  int64\n",
            "min for this col:  0\n",
            "max for this col:  41697599\n",
            "dtype after:  uint32\n",
            "******************************\n",
            "******************************\n",
            "Column:  building_id\n",
            "dtype before:  int64\n",
            "min for this col:  0\n",
            "max for this col:  1448\n",
            "dtype after:  uint16\n",
            "******************************\n",
            "******************************\n",
            "Column:  meter\n",
            "dtype before:  int64\n",
            "min for this col:  0\n",
            "max for this col:  3\n",
            "dtype after:  uint8\n",
            "******************************\n",
            "******************************\n",
            "Column:  hour_cos\n",
            "dtype before:  float64\n",
            "min for this col:  -1.0\n",
            "max for this col:  1.0\n",
            "dtype after:  float32\n",
            "******************************\n",
            "******************************\n",
            "Column:  hour_sin\n",
            "dtype before:  float64\n",
            "min for this col:  -1.0\n",
            "max for this col:  1.0\n",
            "dtype after:  float32\n",
            "******************************\n",
            "******************************\n",
            "Column:  weekday_cos\n",
            "dtype before:  float64\n",
            "min for this col:  -0.9009688679024191\n",
            "max for this col:  1.0\n",
            "dtype after:  float32\n",
            "******************************\n",
            "******************************\n",
            "Column:  weekday_sin\n",
            "dtype before:  float64\n",
            "min for this col:  -0.9749279121818236\n",
            "max for this col:  0.9749279121818236\n",
            "dtype after:  float32\n",
            "******************************\n",
            "******************************\n",
            "Column:  week_cos\n",
            "dtype before:  float64\n",
            "min for this col:  -0.9982437317643215\n",
            "max for this col:  0.992981096013517\n",
            "dtype after:  float32\n",
            "******************************\n",
            "******************************\n",
            "Column:  week_sin\n",
            "dtype before:  float64\n",
            "min for this col:  -0.9995608365087943\n",
            "max for this col:  0.9995608365087943\n",
            "dtype after:  float32\n",
            "******************************\n",
            "___MEMORY USAGE AFTER COMPLETION:___\n",
            "Memory usage is:  1550.8713989257812  MB\n",
            "This is  48.75000196653996 % of the initial size\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "90"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRkbaJjBUGZP",
        "colab_type": "code",
        "outputId": "abf56744-0a78-4719-d8c6-53e19df3f366",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# Добавление медианы по метрике постройки\n",
        "  df_median = df.groupby(by=['building_id','meter'])['meter_reading'].median()\n",
        "  df_median.name = 'building_meter_median'\n",
        "  df_test = pd.merge(df_test, df_median, how = 'inner', on = ['building_id','meter'])\n",
        "  del df_median \n",
        "  gc.collect()\n",
        "  print('Построены медианы по сооружению')\n",
        "# Добавление медианы по часу, по неделе, метрике постройки\n",
        "  df_test['hour'] = df_test['timestamp'].dt.hour\n",
        "  df_median = df.groupby(by=['building_id','hour','meter'])['meter_reading'].median()\n",
        "  df_median.name = 'building_meter_hour_median'\n",
        "  df_test = pd.merge(df_test, df_median, how = 'inner', on = ['building_id','hour','meter'])\n",
        "  del df_median \n",
        "  gc.collect()\n",
        "  df_test['weekday'] = df_test['timestamp'].dt.weekday\n",
        "  df_median = df.groupby(by=['building_id','weekday','meter'])['meter_reading'].median()\n",
        "  df_median.name = 'building_meter_weekday_median'\n",
        "  df_test = pd.merge(df_test, df_median, how = 'inner', on = ['building_id','weekday','meter'])\n",
        "  del df_median \n",
        "  print('Построены медианы по сооружению/часу')\n",
        "  holidays = [\"2016-01-01\", \"2016-01-18\", \"2016-02-15\", \"2016-05-30\", \"2016-07-04\",\n",
        "                    \"2016-09-05\", \"2016-10-10\", \"2016-11-11\", \"2016-11-24\", \"2016-12-26\",\n",
        "                    \"2017-01-02\", \"2017-01-16\", \"2017-02-20\", \"2017-05-29\", \"2017-07-04\",\n",
        "                    \"2017-09-04\", \"2017-10-09\", \"2017-11-10\", \"2017-11-23\", \"2017-12-25\",\n",
        "                    \"2018-01-01\", \"2018-01-15\", \"2018-02-19\", \"2018-05-28\", \"2018-07-04\",\n",
        "                    \"2018-09-03\", \"2018-10-08\", \"2018-11-12\", \"2018-11-22\", \"2018-12-25\",\n",
        "                    \"2019-01-01\"]\n",
        "  df_test[\"is_holiday\"] = (df_test.timestamp.isin(holidays)).astype(int)\n",
        "  del holidays\n",
        "  gc.collect()\n",
        "# Подстановка параметров сооружения\n",
        "  building_df = pd.read_csv(DIR + \"building_metadata.csv\", engine = 'python')\n",
        "  from sklearn.preprocessing import LabelEncoder\n",
        "  le = LabelEncoder()\n",
        "  building_df[\"primary_use_ID\"] = le.fit_transform(building_df[\"primary_use\"])\n",
        "\n",
        "  #building_df['primary_use'] = building_df['primary_use'].astype('category')\n",
        "  #building_df = pd.get_dummies(building_df)\n",
        "\n",
        "  df_test = df_test.merge(building_df, left_on = \"building_id\", right_on = \"building_id\", how = \"left\")\n",
        "  del building_df\n",
        "  print('Подставлены данные по сооружению')\n",
        "  gc.collect()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Построены медианы по сооружению\n",
            "Построены медианы по сооружению/часу\n",
            "Подставлены данные по сооружению\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i34pNJGAWNLV",
        "colab_type": "code",
        "outputId": "0c99097f-03fc-4a67-c08b-37e111d4a046",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#del df\n",
        "#del tmp\n",
        "gc.collect()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gZDPAWaD0M5n",
        "colab": {}
      },
      "source": [
        "#Вставка данных погоды\n",
        "#Восстановление пустых данных погоды через соседей по линейной инетрполяции\n",
        "  df_weather = pd.read_csv(DIR + \"weather_test.csv\", engine = 'python')\n",
        "  df_weather['timestamp'] = pd.to_datetime(df_weather['timestamp'])\n",
        "  gc.collect()\n",
        "  #weather_train.groupby('site_id').apply(lambda group: group.isna().sum())\n",
        "  df_times = df_test.drop_duplicates(['site_id','timestamp'])[['site_id','timestamp']]\n",
        "  df_times = pd.merge(df_times, df_weather, how = 'left', on = ['site_id','timestamp'])\n",
        "  df_times = df_times.sort_values(by = ['site_id','timestamp'])\n",
        "  gc.collect()\n",
        "  df_times = df_times.groupby('site_id').apply(lambda group: group.interpolate(limit_direction='both'))\n",
        "  df_test = pd.merge(df_test, df_times, how = 'left', on = ['site_id','timestamp'])\n",
        "  del df_weather, df_times"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jblybbA1X8IM",
        "colab_type": "code",
        "outputId": "133c03c0-d3b3-451b-fa78-a4cb88c40c54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "reduce_mem_usage(df_test)\n",
        "df_test.to_feather(DIR + 'DF_TEST_REDUCED3.FTHR')\n",
        "gc.collect()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Memory usage of properties dataframe is : 7436.228942871094  MB\n",
            "******************************\n",
            "Column:  row_id\n",
            "dtype before:  uint32\n",
            "min for this col:  0\n",
            "max for this col:  41697599\n",
            "dtype after:  uint32\n",
            "******************************\n",
            "******************************\n",
            "Column:  building_id\n",
            "dtype before:  uint16\n",
            "min for this col:  0\n",
            "max for this col:  1448\n",
            "dtype after:  uint16\n",
            "******************************\n",
            "******************************\n",
            "Column:  meter\n",
            "dtype before:  uint8\n",
            "min for this col:  0\n",
            "max for this col:  3\n",
            "dtype after:  uint8\n",
            "******************************\n",
            "******************************\n",
            "Column:  hour_cos\n",
            "dtype before:  float32\n",
            "min for this col:  -1.0\n",
            "max for this col:  1.0\n",
            "dtype after:  float32\n",
            "******************************\n",
            "******************************\n",
            "Column:  hour_sin\n",
            "dtype before:  float32\n",
            "min for this col:  -1.0\n",
            "max for this col:  1.0\n",
            "dtype after:  float32\n",
            "******************************\n",
            "******************************\n",
            "Column:  weekday_cos\n",
            "dtype before:  float32\n",
            "min for this col:  -0.9009688496589661\n",
            "max for this col:  1.0\n",
            "dtype after:  float32\n",
            "******************************\n",
            "******************************\n",
            "Column:  weekday_sin\n",
            "dtype before:  float32\n",
            "min for this col:  -0.9749279022216797\n",
            "max for this col:  0.9749279022216797\n",
            "dtype after:  float32\n",
            "******************************\n",
            "******************************\n",
            "Column:  week_cos\n",
            "dtype before:  float32\n",
            "min for this col:  -0.9982437491416931\n",
            "max for this col:  0.9929810762405396\n",
            "dtype after:  float32\n",
            "******************************\n",
            "******************************\n",
            "Column:  week_sin\n",
            "dtype before:  float32\n",
            "min for this col:  -0.9995608329772949\n",
            "max for this col:  0.9995608329772949\n",
            "dtype after:  float32\n",
            "******************************\n",
            "******************************\n",
            "Column:  building_meter_median\n",
            "dtype before:  float32\n",
            "min for this col:  0.0\n",
            "max for this col:  40031.19921875\n",
            "dtype after:  float32\n",
            "******************************\n",
            "******************************\n",
            "Column:  hour\n",
            "dtype before:  int64\n",
            "min for this col:  0\n",
            "max for this col:  23\n",
            "dtype after:  uint8\n",
            "******************************\n",
            "******************************\n",
            "Column:  building_meter_hour_median\n",
            "dtype before:  float32\n",
            "min for this col:  0.0\n",
            "max for this col:  44921.8515625\n",
            "dtype after:  float32\n",
            "******************************\n",
            "******************************\n",
            "Column:  weekday\n",
            "dtype before:  int64\n",
            "min for this col:  0\n",
            "max for this col:  6\n",
            "dtype after:  uint8\n",
            "******************************\n",
            "******************************\n",
            "Column:  building_meter_weekday_median\n",
            "dtype before:  float32\n",
            "min for this col:  0.0\n",
            "max for this col:  41437.5\n",
            "dtype after:  float32\n",
            "******************************\n",
            "******************************\n",
            "Column:  is_holiday\n",
            "dtype before:  int64\n",
            "min for this col:  0\n",
            "max for this col:  1\n",
            "dtype after:  uint8\n",
            "******************************\n",
            "******************************\n",
            "Column:  site_id\n",
            "dtype before:  int64\n",
            "min for this col:  0\n",
            "max for this col:  15\n",
            "dtype after:  uint8\n",
            "******************************\n",
            "******************************\n",
            "Column:  square_feet\n",
            "dtype before:  int64\n",
            "min for this col:  283\n",
            "max for this col:  875000\n",
            "dtype after:  uint32\n",
            "******************************\n",
            "******************************\n",
            "Column:  year_built\n",
            "dtype before:  float64\n",
            "min for this col:  1900.0\n",
            "max for this col:  2017.0\n",
            "dtype after:  uint16\n",
            "******************************\n",
            "******************************\n",
            "Column:  floor_count\n",
            "dtype before:  float64\n",
            "min for this col:  1.0\n",
            "max for this col:  26.0\n",
            "dtype after:  uint8\n",
            "******************************\n",
            "******************************\n",
            "Column:  primary_use_ID\n",
            "dtype before:  int64\n",
            "min for this col:  0\n",
            "max for this col:  15\n",
            "dtype after:  uint8\n",
            "******************************\n",
            "******************************\n",
            "Column:  air_temperature\n",
            "dtype before:  float64\n",
            "min for this col:  -28.1\n",
            "max for this col:  48.3\n",
            "dtype after:  float32\n",
            "******************************\n",
            "******************************\n",
            "Column:  cloud_coverage\n",
            "dtype before:  float64\n",
            "min for this col:  0.0\n",
            "max for this col:  9.0\n",
            "dtype after:  float32\n",
            "******************************\n",
            "******************************\n",
            "Column:  dew_temperature\n",
            "dtype before:  float64\n",
            "min for this col:  -31.6\n",
            "max for this col:  26.7\n",
            "dtype after:  float32\n",
            "******************************\n",
            "******************************\n",
            "Column:  precip_depth_1_hr\n",
            "dtype before:  float64\n",
            "min for this col:  -1.0\n",
            "max for this col:  597.0\n",
            "dtype after:  float32\n",
            "******************************\n",
            "******************************\n",
            "Column:  sea_level_pressure\n",
            "dtype before:  float64\n",
            "min for this col:  972.0\n",
            "max for this col:  1050.1\n",
            "dtype after:  float32\n",
            "******************************\n",
            "******************************\n",
            "Column:  wind_direction\n",
            "dtype before:  float64\n",
            "min for this col:  0.0\n",
            "max for this col:  360.0\n",
            "dtype after:  float32\n",
            "******************************\n",
            "******************************\n",
            "Column:  wind_speed\n",
            "dtype before:  float64\n",
            "min for this col:  0.0\n",
            "max for this col:  24.2\n",
            "dtype after:  float32\n",
            "******************************\n",
            "___MEMORY USAGE AFTER COMPLETION:___\n",
            "Memory usage is:  4254.954528808594  MB\n",
            "This is  57.219251336898395 % of the initial size\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjgCdq3PZh81",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_test = pd.read_feather(DIR + 'DF_TEST_REDUCED3.FTHR')\n",
        "gc.collect()\n",
        "\n",
        "import pickle\n",
        "with open(DIR+'scaler3.pickle', 'rb') as handle:\n",
        "    scaler = pickle.load(handle)\n",
        "    In_Columns = pickle.load(handle)\n",
        "    Out_Columns = pickle.load(handle)\n",
        "  \n",
        "  #with open('filename.pickle', 'rb') as handle:\n",
        "  #  b = pickle.load(handle)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTDcNmss8mK5",
        "colab_type": "code",
        "outputId": "647e2a1b-5e06-41ec-80b0-60465ee23d0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "# Нормализация\n",
        "i=0\n",
        "#df_test.dropna(subset = In_Columns + [Out_Columns], inplace=True)\n",
        "for c in In_Columns:\n",
        "  print(i, c, scaler.scale_[i],scaler.min_[i])\n",
        "  df_test[c] = df_test[c] * scaler.scale_[i] + scaler.min_[i]\n",
        "  i+=1\n",
        "  gc.collect()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 hour_cos 0.5 0.5\n",
            "1 hour_sin 0.5 0.5\n",
            "2 weekday_cos 0.5260475468492817 0.4739524531507184\n",
            "3 weekday_sin 0.5128584368757862 0.5\n",
            "4 week_cos 0.5004394486055721 0.49956055139442795\n",
            "5 week_sin 0.5002196799875587 0.5\n",
            "6 site_id 0.06666666666666667 0.0\n",
            "7 square_feet 1.1432268950986433e-06 -0.00032353321131291604\n",
            "8 primary_use_ID 0.06666666666666667 0.0\n",
            "9 is_holiday 1.0 0.0\n",
            "10 air_temperature 0.01314060440193505 0.3797634622031802\n",
            "11 cloud_coverage 0.1 0.1\n",
            "12 dew_temperature 0.016366612009110198 0.5728314203188569\n",
            "13 sea_level_pressure 0.012771394072807236 -12.352492503119965\n",
            "14 wind_direction 0.002777777777777778 0.0\n",
            "15 wind_speed 0.05263157894736842 0.0\n",
            "16 building_meter_median 2.4980515685665876e-05 0.0\n",
            "17 building_meter_hour_median 2.2260881179590182e-05 0.0\n",
            "18 building_meter_weekday_median 2.4132730015082955e-05 0.0\n",
            "19 year_built 0.00847457627118644 -16.093220338983052\n",
            "20 floor_count 0.038461538461538464 0.0\n",
            "21 precip_depth_1_hr 0.002898550724637681 0.005797101449275362\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cG1CZk1i-CHl",
        "colab_type": "code",
        "outputId": "0d735b9b-c8e4-40b2-e7f1-7da94d326407",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Выбор нейронок:\n",
        "  nn_0 = keras.models.load_model (DIR + '0HANDLY_SAVED3.MODEL')\n",
        "  nn_1 = keras.models.load_model (DIR + '1HANDLY_SAVED3.MODEL')\n",
        "  nn_2 = keras.models.load_model (DIR + '2HANDLY_SAVED3.MODEL')\n",
        "  nn_3 = keras.models.load_model (DIR + '3HANDLY_SAVED03.MODEL')\n",
        "  # score = model.evaluate(X, Y, verbose=0)\n",
        "  # print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))\n",
        "  gc.collect()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "342"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqmLUHDySwg-",
        "colab_type": "code",
        "outputId": "99aca60e-e7e4-4a4d-fea5-ec38f5d23662",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Предсказание из 4х значений:\n",
        "  df_test['NN_PRED'] = 0 \n",
        "  df_test['NN_PRED']  = df_test['NN_PRED'].astype('float32')\n",
        "  l = len(df_test)\n",
        "  print( len(df_test) )\n",
        "  step = 200000\n",
        "  for i in range(int(l/step)+1):\n",
        "    print(i*step, (i+1)*step)\n",
        "    tmp = df_test[i*step: (i+1)*step][In_Columns + ['row_id','meter']]\n",
        "    gc.collect() \n",
        "    tmp['NN_PRED'] = 0 \n",
        "    tmp['NN_PRED_0'] = nn_0.predict(tmp[In_Columns], batch_size = 20000) \n",
        "    tmp['NN_PRED_1'] = nn_1.predict(tmp[In_Columns], batch_size = 20000) \n",
        "    tmp['NN_PRED_2'] = nn_2.predict(tmp[In_Columns], batch_size = 20000) \n",
        "    tmp['NN_PRED_3'] = nn_3.predict(tmp[In_Columns], batch_size = 20000) \n",
        "    gc.collect()\n",
        "    tmp['NN_PRED'] = np.where(tmp['meter'] == 0, tmp['NN_PRED_0'], tmp['NN_PRED'])\n",
        "    tmp['NN_PRED'] = np.where(tmp['meter'] == 1, tmp['NN_PRED_1'], tmp['NN_PRED'])\n",
        "    tmp['NN_PRED'] = np.where(tmp['meter'] == 2, tmp['NN_PRED_2'], tmp['NN_PRED'])\n",
        "    tmp['NN_PRED'] = np.where(tmp['meter'] == 3, tmp['NN_PRED_3'], tmp['NN_PRED'])\n",
        "    gc.collect()\n",
        "    #print('спрогнозили')\n",
        "    #df_test[i*step: (i+1)*step]['NN_PRED'] = pd.merge(df_test, tmp[['row_id','NN_PRED']], how = 'left', on = ['row_id'])\n",
        "    #df_test.loc[i*step: (i+1)*step, 'NN_PRED'] = tmp['NN_PRED']\n",
        "    \n",
        "    if i==0:\n",
        "      a = tmp[['row_id','NN_PRED']].copy()\n",
        "    else:\n",
        "      a = pd.concat([a, tmp[['row_id','NN_PRED']].copy()], sort=False)\n",
        "    #del tmp\n",
        "    #gc.collect() "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "41697600\n",
            "0 200000\n",
            "200000 400000\n",
            "400000 600000\n",
            "600000 800000\n",
            "800000 1000000\n",
            "1000000 1200000\n",
            "1200000 1400000\n",
            "1400000 1600000\n",
            "1600000 1800000\n",
            "1800000 2000000\n",
            "2000000 2200000\n",
            "2200000 2400000\n",
            "2400000 2600000\n",
            "2600000 2800000\n",
            "2800000 3000000\n",
            "3000000 3200000\n",
            "3200000 3400000\n",
            "3400000 3600000\n",
            "3600000 3800000\n",
            "3800000 4000000\n",
            "4000000 4200000\n",
            "4200000 4400000\n",
            "4400000 4600000\n",
            "4600000 4800000\n",
            "4800000 5000000\n",
            "5000000 5200000\n",
            "5200000 5400000\n",
            "5400000 5600000\n",
            "5600000 5800000\n",
            "5800000 6000000\n",
            "6000000 6200000\n",
            "6200000 6400000\n",
            "6400000 6600000\n",
            "6600000 6800000\n",
            "6800000 7000000\n",
            "7000000 7200000\n",
            "7200000 7400000\n",
            "7400000 7600000\n",
            "7600000 7800000\n",
            "7800000 8000000\n",
            "8000000 8200000\n",
            "8200000 8400000\n",
            "8400000 8600000\n",
            "8600000 8800000\n",
            "8800000 9000000\n",
            "9000000 9200000\n",
            "9200000 9400000\n",
            "9400000 9600000\n",
            "9600000 9800000\n",
            "9800000 10000000\n",
            "10000000 10200000\n",
            "10200000 10400000\n",
            "10400000 10600000\n",
            "10600000 10800000\n",
            "10800000 11000000\n",
            "11000000 11200000\n",
            "11200000 11400000\n",
            "11400000 11600000\n",
            "11600000 11800000\n",
            "11800000 12000000\n",
            "12000000 12200000\n",
            "12200000 12400000\n",
            "12400000 12600000\n",
            "12600000 12800000\n",
            "12800000 13000000\n",
            "13000000 13200000\n",
            "13200000 13400000\n",
            "13400000 13600000\n",
            "13600000 13800000\n",
            "13800000 14000000\n",
            "14000000 14200000\n",
            "14200000 14400000\n",
            "14400000 14600000\n",
            "14600000 14800000\n",
            "14800000 15000000\n",
            "15000000 15200000\n",
            "15200000 15400000\n",
            "15400000 15600000\n",
            "15600000 15800000\n",
            "15800000 16000000\n",
            "16000000 16200000\n",
            "16200000 16400000\n",
            "16400000 16600000\n",
            "16600000 16800000\n",
            "16800000 17000000\n",
            "17000000 17200000\n",
            "17200000 17400000\n",
            "17400000 17600000\n",
            "17600000 17800000\n",
            "17800000 18000000\n",
            "18000000 18200000\n",
            "18200000 18400000\n",
            "18400000 18600000\n",
            "18600000 18800000\n",
            "18800000 19000000\n",
            "19000000 19200000\n",
            "19200000 19400000\n",
            "19400000 19600000\n",
            "19600000 19800000\n",
            "19800000 20000000\n",
            "20000000 20200000\n",
            "20200000 20400000\n",
            "20400000 20600000\n",
            "20600000 20800000\n",
            "20800000 21000000\n",
            "21000000 21200000\n",
            "21200000 21400000\n",
            "21400000 21600000\n",
            "21600000 21800000\n",
            "21800000 22000000\n",
            "22000000 22200000\n",
            "22200000 22400000\n",
            "22400000 22600000\n",
            "22600000 22800000\n",
            "22800000 23000000\n",
            "23000000 23200000\n",
            "23200000 23400000\n",
            "23400000 23600000\n",
            "23600000 23800000\n",
            "23800000 24000000\n",
            "24000000 24200000\n",
            "24200000 24400000\n",
            "24400000 24600000\n",
            "24600000 24800000\n",
            "24800000 25000000\n",
            "25000000 25200000\n",
            "25200000 25400000\n",
            "25400000 25600000\n",
            "25600000 25800000\n",
            "25800000 26000000\n",
            "26000000 26200000\n",
            "26200000 26400000\n",
            "26400000 26600000\n",
            "26600000 26800000\n",
            "26800000 27000000\n",
            "27000000 27200000\n",
            "27200000 27400000\n",
            "27400000 27600000\n",
            "27600000 27800000\n",
            "27800000 28000000\n",
            "28000000 28200000\n",
            "28200000 28400000\n",
            "28400000 28600000\n",
            "28600000 28800000\n",
            "28800000 29000000\n",
            "29000000 29200000\n",
            "29200000 29400000\n",
            "29400000 29600000\n",
            "29600000 29800000\n",
            "29800000 30000000\n",
            "30000000 30200000\n",
            "30200000 30400000\n",
            "30400000 30600000\n",
            "30600000 30800000\n",
            "30800000 31000000\n",
            "31000000 31200000\n",
            "31200000 31400000\n",
            "31400000 31600000\n",
            "31600000 31800000\n",
            "31800000 32000000\n",
            "32000000 32200000\n",
            "32200000 32400000\n",
            "32400000 32600000\n",
            "32600000 32800000\n",
            "32800000 33000000\n",
            "33000000 33200000\n",
            "33200000 33400000\n",
            "33400000 33600000\n",
            "33600000 33800000\n",
            "33800000 34000000\n",
            "34000000 34200000\n",
            "34200000 34400000\n",
            "34400000 34600000\n",
            "34600000 34800000\n",
            "34800000 35000000\n",
            "35000000 35200000\n",
            "35200000 35400000\n",
            "35400000 35600000\n",
            "35600000 35800000\n",
            "35800000 36000000\n",
            "36000000 36200000\n",
            "36200000 36400000\n",
            "36400000 36600000\n",
            "36600000 36800000\n",
            "36800000 37000000\n",
            "37000000 37200000\n",
            "37200000 37400000\n",
            "37400000 37600000\n",
            "37600000 37800000\n",
            "37800000 38000000\n",
            "38000000 38200000\n",
            "38200000 38400000\n",
            "38400000 38600000\n",
            "38600000 38800000\n",
            "38800000 39000000\n",
            "39000000 39200000\n",
            "39200000 39400000\n",
            "39400000 39600000\n",
            "39600000 39800000\n",
            "39800000 40000000\n",
            "40000000 40200000\n",
            "40200000 40400000\n",
            "40400000 40600000\n",
            "40600000 40800000\n",
            "40800000 41000000\n",
            "41000000 41200000\n",
            "41200000 41400000\n",
            "41400000 41600000\n",
            "41600000 41800000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtxkAc9E00Yn",
        "colab_type": "code",
        "outputId": "e84930e3-7ccb-4db7-b433-2c8704305791",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(a))\n",
        "#a.drop_duplicates(inplace =True)\n",
        "#print(len(a))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "41697600\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXmjfkrQC61e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a['row_id']         = a['row_id'].astype('Int32')\n",
        "a['meter_reading']  = a['NN_PRED'].astype('float32')\n",
        "a[['row_id', 'meter_reading']].to_csv(DIR+'OUT_Ver0.3 no clean2.csv', index = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pSaG8s-5_yL",
        "colab_type": "code",
        "outputId": "f113d824-f725-4047-88d3-cfb2a59ebaed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "source": [
        "a.head(-5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>row_id</th>\n",
              "      <th>NN_PRED</th>\n",
              "      <th>meter_reading</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>234.510788</td>\n",
              "      <td>234.510788</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>21672</td>\n",
              "      <td>184.514343</td>\n",
              "      <td>184.514343</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>43344</td>\n",
              "      <td>251.292831</td>\n",
              "      <td>251.292831</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>65016</td>\n",
              "      <td>249.557755</td>\n",
              "      <td>249.557755</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>86688</td>\n",
              "      <td>198.508957</td>\n",
              "      <td>198.508957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41697590</th>\n",
              "      <td>41110039</td>\n",
              "      <td>255.980148</td>\n",
              "      <td>255.980148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41697591</th>\n",
              "      <td>41152039</td>\n",
              "      <td>259.096619</td>\n",
              "      <td>259.096619</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41697592</th>\n",
              "      <td>41194037</td>\n",
              "      <td>263.612885</td>\n",
              "      <td>263.612885</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41697593</th>\n",
              "      <td>41230287</td>\n",
              "      <td>278.547913</td>\n",
              "      <td>278.547913</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41697594</th>\n",
              "      <td>41272287</td>\n",
              "      <td>304.864227</td>\n",
              "      <td>304.864227</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>41697595 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            row_id     NN_PRED  meter_reading\n",
              "0                0  234.510788     234.510788\n",
              "1            21672  184.514343     184.514343\n",
              "2            43344  251.292831     251.292831\n",
              "3            65016  249.557755     249.557755\n",
              "4            86688  198.508957     198.508957\n",
              "...            ...         ...            ...\n",
              "41697590  41110039  255.980148     255.980148\n",
              "41697591  41152039  259.096619     259.096619\n",
              "41697592  41194037  263.612885     263.612885\n",
              "41697593  41230287  278.547913     278.547913\n",
              "41697594  41272287  304.864227     304.864227\n",
              "\n",
              "[41697595 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HcOED4IDv0k",
        "colab_type": "code",
        "outputId": "125bad6b-9605-4831-d451-f1428d5e1b45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 863
        }
      },
      "source": [
        "show_plot(hist) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEaCAYAAAD+E0veAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEEKIIAkFIYQQQf8/SUfcsaGe3N8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEaCAYAAAD+E0veAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhBAuEgpCCCFc/j9ULh4wOxXj0AAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEaCAYAAAD+E0veAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEXEoFERExPF/kJ9R/u9OhAEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3y8HyLW1fPvb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsYpyA4omuiY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import model_from_json\n",
        "\n",
        "def load_model(dir = os.getcwd(), name = 'model'):\n",
        "  json_file = open(os.path.join(dir,name+'.json'), 'r')\n",
        "  loaded_model_json = json_file.read()\n",
        "  json_file.close()\n",
        "  model = model_from_json(loaded_model_json)\n",
        "  model.load_weights(os.path.join(dir,name+'.h5'))\n",
        "  print(\"Loading is complete.\")\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvoCZeopmulB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nn = load_model(DIR, 'model_nn')\n",
        "opt = Adam(lr = 0.05)\n",
        "nn.compile(optimizer = opt, loss = mse)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vze6V-2Dv3R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwGQ3nubDv6C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7cW0BjWDog5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rglOCdGlDojs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "p = nn.predict(X_test, batch_size = 100000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHSFbHZiq7Of",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuyutB_Z1pu4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_sample_submission.to_csv(DIR+'out_file_int.csv', index = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gQzWTyi1Vjb",
        "colab_type": "code",
        "outputId": "4a1a4271-a100-49b4-8b17-4effad4507ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df_sample_submission.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>row_id</th>\n",
              "      <th>meter_reading</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8784</th>\n",
              "      <td>0</td>\n",
              "      <td>187.721802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8785</th>\n",
              "      <td>129</td>\n",
              "      <td>170.970444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8786</th>\n",
              "      <td>258</td>\n",
              "      <td>158.120926</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8787</th>\n",
              "      <td>387</td>\n",
              "      <td>150.405380</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8788</th>\n",
              "      <td>516</td>\n",
              "      <td>149.041794</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      row_id  meter_reading\n",
              "8784       0     187.721802\n",
              "8785     129     170.970444\n",
              "8786     258     158.120926\n",
              "8787     387     150.405380\n",
              "8788     516     149.041794"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaKZlONMsta8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_sample_submission['row_id'] = df_sample_submission['row_id'].astype('Int32')\n",
        "df_sample_submission['meter_reading'] = df_sample_submission['meter_reading'].astype('float16')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOIMC9y_steQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}